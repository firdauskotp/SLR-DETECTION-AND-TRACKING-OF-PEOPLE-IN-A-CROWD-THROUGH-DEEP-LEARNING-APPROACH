Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract,FullTextURL,RelatedURL
0,"Rémi Baqué, Luc Vignaud, Valentine Wasik, Nicolas Castet, Reinhold Herschel, Harun Cetinkaya, Thomas Brandes","MIC: Microwave Imaging Curtain for Dynamic and Automatic Detection of Weapons and Explosive Belts",2023,"Sensors (Basel, Switzerland)","","","",1,"2024-04-24 13:54:52","Journal Article","10.3390/s23239531","1424-8220","",23,23,,,0,0.00,0,7,1,"DEXTER (detection of explosives and firearms to counter terrorism) is a project funded by NATO's Science for Peace and Security (SPS) program with the goal of developing an integrated system capable of remotely and accurately detecting explosives and firearms in public places without impeding the flow of pedestrians. While body scanner systems in secure areas of public places are becoming more and more efficient, the attack at Brussels airport on 22 March 2016, upstream of these systems, in the middle of the crowd of passengers, demonstrated the lack of discreet and real-time security against threats of mass terrorism. The NATO-SPS international and multi-year DEXTER project aims to provide new technical and strategic solutions to fill this gap. This project is based on multi-sensor coordination and fusion, from hyperspectral remote laser to smart glasses, artificial algorithms, and suspect identification and tracking. One of these sensors is dedicated to threat detection (large weapon or explosive belt) using the clothing of pedestrians by means of an active microwave component. This project is referred to as MIC (Microwave Imaging Curtain), also supported by the French SGDSN (General Secretariat of Defense and National Security), and utilizes a radar system capable of generating 3D images in real-time to address non-checkpoint detection of explosives and firearms. The project, led by ONERA (France), is based on a radar imaging system developed by the Fraunhofer FHR institute, using a MIMO architecture with an Ultra-Wide Band waveform. Although high-resolution 3D microwave imaging is already being used in expensive body scanners to detect firearms concealed under clothing, MIC's innovative approach lies in utilizing a high-resolution 3D imaging device that can detect larger dangerous objects carried by moving individuals at a longer range, in addition to providing discrete detection in pedestrian flow. Automatic detection and classification of these dangerous objects is carried out on 3D radar images using a deep-learning network. This paper will outline the project's objectives and constraints, as well as the design, architecture, and performance of the final system. Additionally, it will present real-time imaging results obtained during a live demonstration in a relevant environment.","",""
0,"Xingchen Zhang, Yiannis Demiris","Visible and Infrared Image Fusion Using Deep Learning",2023,"IEEE transactions on pattern analysis and machine intelligence","","","",2,"2024-04-24 13:54:52","Systematic Review","10.1109/TPAMI.2023.3261282","1939-3539","",45,8,10535,10554,0,0.00,0,2,1,"Visible and infrared image fusion (VIF) has attracted a lot of interest in recent years due to its application in many tasks, such as object detection, object tracking, scene segmentation, and crowd counting. In addition to conventional VIF methods, an increasing number of deep learning-based VIF methods have been proposed in the last five years. Different types of methods, such as CNN-based, autoencoder-based, GAN-based, and transformer-based methods, have been proposed. Deep learning-based methods have undoubtedly become dominant methods for the VIF task. However, while much progress has been made, the field will benefit from a systematic review of these deep learning-based methods. In this paper we present a comprehensive review of deep learning-based VIF methods. We discuss motivation, taxonomy, recent development characteristics, datasets, and performance evaluation methods in detail. We also discuss future prospects of the VIF field. This paper can serve as a reference for VIF researchers and those interested in entering this fast-developing field.","",""
0,"Masum Shah Junayed, Md Baharul Islam","Automated Physical Distance Estimation and Crowd Monitoring Through Surveillance Video",2023,"SN computer science","","","",3,"2024-04-24 13:54:52","Journal Article","10.1007/s42979-022-01480-8","2661-8907","",4,1,67,,0,0.00,0,2,1,"The contagious Corona Virus (COVID-19) transmission can be reduced by following and maintaining physical distancing (also known as COVID-19 social distance). The World Health Organisation (WHO) recommends preventing COVID-19 from spreading in public areas. On the other hand, people may not be maintaining the required 2-m physical distance as a mandated safety precaution in shopping malls and public places. The spread of the fatal disease may be slowed by an active monitoring system suitable for identifying distances between people and alerting them. This paper introduced a deep learning-based system for automatically detecting physical distance using video from security cameras. The proposed system introduced the TH-YOLOv5 for object detection and classification and Deepsort for tracking the detected people using bounding boxes from the video. TH-YOLOv5 included another prediction head to identify objects of varying sizes. The original prediction heads are then replaced with Transformer Heads (TH) to investigate the prediction capability of the self-attention mechanism. Then, we include the convolutional block attention model (CBAM) to identify attention areas in settings with dense objects. Pairwise L2 vectorized normalization was utilized to generate a three-dimensional feature space for tracking physical distances and the violation index, determining the number of individuals who follow the distance rules. We use the MS COCO and HumanCrowd, CityPersons, and Oxford Town Centre (OTC) data sets for training and testing. Experimental results demonstrate that the proposed system obtained a weighted mAP score of 89.5% and an FPS score of 29; both are computationally comparable.","",""
0,"Sherif Elbishlawi, Mohamed H Abdelpakey, Agwad Eltantawy, Mohamed S Shehata, Mostafa M Mohamed","Deep Learning-Based Crowd Scene Analysis Survey",2020,"Journal of imaging","","","",4,"2024-04-24 13:54:52","Journal Article","10.3390/jimaging6090095","2313-433X","",6,9,,,0,0.00,0,5,4,"Recently, our world witnessed major events that attracted a lot of attention towards the importance of automatic crowd scene analysis. For example, the COVID-19 breakout and public events require an automatic system to manage, count, secure, and track a crowd that shares the same area. However, analyzing crowd scenes is very challenging due to heavy occlusion, complex behaviors, and posture changes. This paper surveys deep learning-based methods for analyzing crowded scenes. The reviewed methods are categorized as (1) crowd counting and (2) crowd actions recognition. Moreover, crowd scene datasets are surveyed. In additional to the above surveys, this paper proposes an evaluation metric for crowd scene analysis methods. This metric estimates the difference between calculated crowed count and actual count in crowd scene videos.","",""
0,"Amin Muhammad Sadiq, Huynsik Ahn, Young Bok Choi","Human Sentiment and Activity Recognition in Disaster Situations Using Social Media Images Based on Deep Learning",2020,"Sensors (Basel, Switzerland)","","","",5,"2024-04-24 13:54:52","Journal Article","10.3390/s20247115","1424-8220","",20,24,,,0,0.00,0,3,4,"A rapidly increasing growth of social networks and the propensity of users to communicate their physical activities, thoughts, expressions, and viewpoints in text, visual, and audio material have opened up new possibilities and opportunities in sentiment and activity analysis. Although sentiment and activity analysis of text streams has been extensively studied in the literature, it is relatively recent yet challenging to evaluate sentiment and physical activities together from visuals such as photographs and videos. This paper emphasizes human sentiment in a socially crucial field, namely social media disaster/catastrophe analysis, with associated physical activity analysis. We suggest multi-tagging sentiment and associated activity analyzer fused with a a deep human count tracker, a pragmatic technique for multiple object tracking, and count in occluded circumstances with a reduced number of identity switches in disaster-related videos and images. A crowd-sourcing study has been conducted to analyze and annotate human activity and sentiments towards natural disasters and related images in social networks. The crowdsourcing study outcome into a large-scale benchmark dataset with three annotations sets each resolves distinct tasks. The presented analysis and dataset will anchor a baseline for future research in the domain. We believe that the proposed system will contribute to more viable communities by benefiting different stakeholders, such as news broadcasters, emergency relief organizations, and the public in general.","",""
