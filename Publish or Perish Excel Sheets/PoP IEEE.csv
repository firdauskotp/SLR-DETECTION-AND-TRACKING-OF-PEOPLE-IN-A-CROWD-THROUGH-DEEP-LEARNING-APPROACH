"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Pedestrian Tracking Algorithm for Dense Crowd based on Deep Learning","G. Yang; Z. Chen","Engineering Lab on Intelligent Perception for Internet of Things(ELIP), Shenzhen Graduate School, Peking University, Shenzhen, China; Key Laboratory of Intelligent Multimedia Technology, Beijing Normal University (Zhuhai Campus), Zhuhai, China","2019 6th International Conference on Systems and Informatics (ICSAI)","27 Feb 2020","2019","","","568","572","The development of Dense Crowd Visual Tracking algorithm based on Deep Learning (DTDL) is introduced. The main research contents of this paper are as follows: (l) Dense crowd Based on Single Shot Multi-Box Detector (D-SSD). The D-SSD detection algorithm was proposed to reconstruct the pedestrian data set, mark the head and shoulder of pedestrians in the crowd, and modify the size of the candidate box close to the proportion of head and shoulder of pedestrians, so as to obtain a new data set for training. (2) visual tracking framework (Kalman Based on Kernel Correlation Filters, K-KCF): KCF tracking framework is more popular in recent years, KCF used in visual tracking under the common scene both in tracking performance and tracking speed performance is good, but there are severe target block KCF will tracking failure, in the dense population under the background of such inevitable condition. The addition of Kalman filter can largely solve the tracking failure caused by the occlusion of pedestrians. In this paper, Kalman filter is proposed as an auxiliary K-KCF visual tracking framework.","","978-1-7281-5256-1","10.1109/ICSAI48974.2019.9010144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010144","c Pedestian detection;Pedestrian tracking;Deep learning;Kalman filter;Dense crowds;KCF","Target tracking;Kalman filters;Visualization;Detection algorithms;Training;Machine learning","","6","","11","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Tracking Hundreds of People in Densely Crowded Scenes With Particle Filtering Supervising Deep Convolutional Neural Networks","G. Franchi; E. Aldea; S. Dubuisson; I. Bloch","Université Paris-Saclay SATIE; Université Paris-Saclay SATIE; CNRS, LIS, Aix Marseille University; LTCI, Télécom Paris, Institut Polytechnique de Paris","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","2071","2075","Tracking an entire high-density crowd composed of more than five hundred individuals is a difficult task that has not yet been accomplished. In this article, we propose to track pedestrians using a model composed of a Particle Filter (PF) and three Deep Convolutional Neural Networks (DCNN). The first network is a detector that learns to localize the persons. The second one is a pretrained network that estimates the optical flow, and the last one corrects the flow. Our contribution resides in the way we train this last network by PF supervision, and in Markov Random Field linking the different tracks.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190953","Computer Vision;Crowd tracking;Self supervised learning;Deep learning","Training;Adaptive optics;Target tracking;Two dimensional displays;Optical imaging;Task analysis","","","","16","IEEE","30 Sep 2020","","","IEEE","IEEE Conferences"
"Deep Crowd Analysis to Spot Social Distancing Violations in Post-COVID 19 Lifestyle","S. S. Narayanan; A. Nesarani; R. S. Raghav; A. Robert Singh; S. Athisayamani","Department of CSE, VelTech Rangarajan Dr.Sahunthala R&D Institute of Science and Technology, Avadi, Chennai, Tamil Nadu, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vadeeswaram, Guntur, Andra Pradesh, India; School of Computing Sastra Deemed to be University, Thanjavur, Tamil Nadu, India; Department of Computational Intelligence School of Computing, SRM Institute of Science and Technology, Chennai, Tamil Nadu, India; School of Computing Sastra Deemed to be University, Thanjavur, Tamil Nadu, India","2022 IEEE 7th International Conference on Recent Advances and Innovations in Engineering (ICRAIE)","2 Mar 2023","2022","7","","31","36","Crowd analysis is a new field of study that involves processing a large group of people to examine one or more of their behaviors. Deep learning is an appropriate technique for crowd analysis using a convolutional neural network. To calculate the distance between crowd members and to identify social distance violations, a deep crowd analysis is proposed in this study. Pre-trained in a single class To discover the region of interest, CNN is utilised to classify people (RoI). The people in the picture are then localized using a density map. The reference point used to calculate the distance between the people is the centroid of the isolated areas in the density map. A social distance violation is reported if the estimated distance is less than the specified threshold distance (3 meters). Between the two ROIs, a distance measured in pixels is determined.","","978-1-6654-8910-2","10.1109/ICRAIE56454.2022.10054338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054338","Crowd analysis;CNN;Social distance;density map","Deep learning;Meters;Technological innovation;Surveillance;Human factors;Social factors;Behavioral sciences","","","","13","IEEE","2 Mar 2023","","","IEEE","IEEE Conferences"
"Deep Learning Based Crowd Monitoring And Person Identification System","M. F. Haque; T. Al Muhaimin Choudhury; D. Sarkar; S. H. Rafi; M. Shajidur Rahim; A. Chakrabarty; M. Fahim-Ul-Islam","Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh","2023 26th International Conference on Computer and Information Technology (ICCIT)","27 Feb 2024","2023","","","1","6","With the recent outbreak of COVID-19 and other pandemics that might occur in the future, we have realized how crucial it is to monitor crowd behavior and social distancing in public places. This paper introduces a deep learning-based system for crowd monitoring and person identification, addressing the challenges posed by similar kinds of pandemics. The approach proposes a combination of person tracking and distance measurement systems which can be implemented in various public places. In this paper, we come up with two approaches, the first one is based on utilizing Faster R-CNN for person identification along with The Simple Online and Real-time Tracking (SORT) algorithm and the other approach is YOLOv8 for person detection, coupled with the DeepSort-based tracking algorithm which also includes a logging system. Moreover, to implement the system, a custom dataset is created for evaluation and to tackle perspective correction and person-only detection issues. After using our custom dataset for evaluation and also evaluating the performance and robustness, we propose our DeepSort-based second approach as the better system. Moreover, our proposed system achieved over 90% accuracy in human detection and distance estimation.","","979-8-3503-5901-5","10.1109/ICCIT60459.2023.10441350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10441350","COVID-19;Faster R-CNN;YOLOv8;Deep sort;IoT;micro-controller","Deep learning;COVID-19;YOLO;Pandemics;Robustness;Real-time systems;Identification of persons","","","","11","IEEE","27 Feb 2024","","","IEEE","IEEE Conferences"
"Context Aware Crowd Tracking and Anomaly Detection via Deep Learning and Social Force Model","F. Abdullah; M. Abdelhaq; R. Alsaqour; M. H. Alatiyyah; K. Alnowaiser; S. S. Alotaibi; J. Park","Department of Computer Science, Air University, Islamabad, Pakistan; Department of Information Technology, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia; Department of Information Technology, College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; Department of Computer and Information, Prince Sultan University, Riyadh, Saudi Arabia; Department of Computer Engineering, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Information Systems Department, Umm Al-Qura University, Makkah, Saudi Arabia; Department of Computer Engineering, Tech University of Korea, Siheung-si, South Korea","IEEE Access","9 Aug 2023","2023","11","","75884","75898","The world’s expanding populace, the variety of human social factors, and the densely populated environment make humans feel uncertain. Individuals need a safety officer who generally deals with security viewpoints for this frailty. Currently, human monitoring techniques are time-consuming, work concentrated, and incapable. Therefore, autonomous surveillance frameworks are necessary for the modern day since they are able to address these problems. Nevertheless, hardships persist. The central concerns incorporate the detachment of the foreground from the scene and the understanding of the contextual structure of the environment for efficiently identifying unusual objects. In our work, we introduced a novel framework to tackle these difficulties by presenting a semantic segmentation technique for separating a foreground object. In our work, Super-pixels are generated using an improved watershed transform and then a conditional random field is implemented to obtain multi-object segmented frames by performing pixel-level labeling. Next, the Social Force model is introduced to extract the contextual structure of the environment via the fusion of a novel chosen particular histogram of an optical stream and inner force model. After using the computed social force, multi-people tracking is performed via three-dimensional template association using percentile rank and non-maximal suppression. Next, multi-object categorization is performed via deep learning Feature Pyramid Network. Finally, by considering the contextual structure of the environment, Jaccard similarity is utilized to make the decision for abnormality detection and identify the unusual objects from the scene. The invented framework is verified through rigorous investigations, and it obtained multi-people tracking efficiency of 92.2% and 89.1% over the UCSD and CUHK Avenue datasets. However, 95.2% and 93.7% abnormality detection efficiency is accomplished over UCSD and CUHK Avenue datasets, respectively.","2169-3536","","10.1109/ACCESS.2023.3293537","Basic Science Research Program through the National Research Foundation (NRF)(grant numbers:2021R1F1A1063634); Ministry of Science and Information & Communications Technology (MSIT), Republic of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177157","Conditional random field;feature pyramid network;improved watershed transform;Jaccard similarity;multi-object association;social force model","Feature extraction;Force;Tracking;Conditional random fields;Computational modeling;Anomaly detection;Behavioral sciences","","3","","82","CCBYNCND","10 Jul 2023","","","IEEE","IEEE Journals"
"Deep Learning for Crowd Image Classification for Images Captured Under Varying Climatic and Lighting Condition","H. T. Ingale; S. S. Suralkar; A. J. Patil","S.S.B.T.C.O.E&T, Jalgaon, India; S.S.B.T.C.O.E&T, Jalgaon, India; SGOI COE&FOM, Pune, India","2022 IEEE Bombay Section Signature Conference (IBSSC)","14 Feb 2023","2022","","","1","6","Most of recent events have attracted a lot of attention towards importance of automatic crowd classification and management. COVID-19 is the most setback for the entire world. During these events proper breakout and public crowd management leads to the requirement of managing, counting, securing as well as tracking the crowd. But automatic analysis of the crowd is very challenging task because of varying climatic and lighting conditions, varying postures etc. During this paper we have developed PYTHON based system for automatic crowd images classification using Deep learning. This paper is the first attempt for automatic classification of crowd images. We have prepared the dataset of crowd classification consisting of three categories. The proposed methodology of crowd classification starts with preprocessing during which we have used median filtering for noise removal. Deep learning models are developed using 70% training images. The performance of the system is evaluated for various deep learning algorithms including one block VGG, two block VGG and three block VGG. We have also evaluated the performance of three block VGG using dropout. VGG16 transfer learning based crowd classification is developed using PYTHON. Using VGG16 transfer learning we achieved the accuracy of 69.44.% which is highest among all deep learning classification models during this study","","978-1-6654-9291-1","10.1109/IBSSC56953.2022.10037341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10037341","deep learning;one block VGG;two block VGG;three blocks VGG;transfer learning","Deep learning;Training;COVID-19;Filtering;IEEE Sections;Transfer learning;Lighting","","1","","18","IEEE","14 Feb 2023","","","IEEE","IEEE Conferences"
"Research of Pedestrian Object Tracking Algorithms","H. Zuo; Y. Yang; L. Cao","New Energy Vehicle College, Xi'an Vocational University of Automobile, Xi'an, China; New Energy Vehicle College, Xi'an Vocational University of Automobile, Xi'an, China; New Energy Vehicle College, Xi'an Vocational University of Automobile, Xi'an, China","2022 Global Conference on Robotics, Artificial Intelligence and Information Technology (GCRAIT)","4 Oct 2022","2022","","","155","159","High-quality pedestrian tracking algorithms are the basis for solving many problems including video surveillance, action recognition, and crowd behaviour analysis. The problem of pedestrian target detection and tracking is to identify and track the trajectories of different targets in video sequences. It can be divided into single target and tracking, multi-target and tracking, pedestrian re-identification, and so on. In recent years, with improvement of benchmarking, pedestrian object tracking methods have also developed from traditional feature learning to neural network modelling. This paper mainly summarizes and analyses the latest proposed deep learning algorithm models for pedestrian detection and tracking and the corresponding improvement for existing problems. In addition, possible future research directions are also discussed at the end.","","978-1-6654-8192-2","10.1109/GCRAIT55928.2022.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898311","computer vision;deep learning;pedestrian object tracking;neural network","Target tracking;Video sequences;Semantics;Object detection;Feature extraction;Video surveillance;Transformers","","","","29","IEEE","4 Oct 2022","","","IEEE","IEEE Conferences"
"Simulation of Evacuating Crowd Based on Deep Learning and Social Force Model","X. Li; Y. Liang; M. Zhao; C. Wang; H. Bai; Y. Jiang","College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China","IEEE Access","31 Oct 2019","2019","7","","155361","155371","It is always difficult to evacuate crowds in public places like subway stations. The traditional crowd behavior simulation models often ignore two important issues in crowd evacuation: pedestrian tracking and individual differences. To solve the problem, this paper combines social force model (SFM) with deep learning into a novel pedestrian detection method. Firstly, several deep learning algorithms for pedestrian detection were compared, and the best ones for sparse and dense crowds were determined. Next, the pedestrian positions in a real video were acquired by the selected algorithms, and converted into actual coordinates in the scene. Then, the evacuation process was simulated with our method and the SFM based on these coordinates. The results show that our model output closer-to-reality results than the SFM. The research findings shed important new light on evacuation in crowded areas.","2169-3536","","10.1109/ACCESS.2019.2949106","National Natural Science Foundation of China(grant numbers:51679105,61872160,51809112,51939003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880672","Deep learning;social force model (SFM);crowd simulation","Deep learning;Feature extraction;Force;Proposals;Neurons;Trajectory;Acceleration","","12","","40","CCBY","23 Oct 2019","","","IEEE","IEEE Journals"
"Behavioural Analysis For Prospects In Crowd Emotion Sensing: A Survey","M. K; L. Sujihelen","Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai; Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","735","743","Crowd behavioural analysis is an interesting and emerging domain in research, with incomplete set of activities, tasks and lack of intermediate cub-processes which are mandated for productive analysis. Since the domain is untapped to a major extent, the research carried out in the domain needs proper stages of operations. A proper taxonomy will direct the futuristic domains in the right track of processes and organization of intermediate tasks. This review paper intends to document the list of stages and processes, data collection, pipelining the sub-tasks, pre-emptive identification of supposed problems during the later stages in detection of crowd emotions and behavioural analysis. Deep learning techniques have been widely deployed to investigate the models of crowd analysis, anomaly detection, and look for meaningful insights and patterns from datasets. The Different models are investigated thoroughly for their respective understanding about the emotional aspects considered in the studies. Emotional characteristics when powered with crowd behavioural analysis and real world entities will deliver a promising solution for crime detections, anomaly detection and ensure a safer environment for nations. Video surveillance tools, datasets from crime datasets and various other factors contributed to the previous research works, models are now being designed to incorporate the best features of these models into one and thus achieve one fruitful model for continuous video analytics.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9544607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544607","Crowd Anomaly Detection;Behavioural Analysis;Emotion Sensing;Deep Learning;Machine Learning;Crime Detection","Deep learning;Training;Analytical models;Visual analytics;Taxonomy;Tools;Video surveillance","","2","","72","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"People Counting in Public Spaces using Deep Learning-based Object Detection and Tracking Techniques","N. Krishnachaithanya; G. Singh; S. Sharma; R. Dinesh; S. R. Sihag; K. Solanki; A. Agarwal; M. Rana; U. Makkar","School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; Department of Computer Science and Engineering, Amity School of Engineering and Technology, Amity University, Greater Noida, Uttar Pradesh, India; School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; Department of Computer Science and Engineering, University Institute of Engineering and Technology, Maharshi Dayanand University Rohtak, Rohtak, Haryana; School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; School of Computer Science and Engineering, Lovely Professional University, Kapurthala, Punjab, India; Department of Mechanical Engineering, Lovely Professional University, Kapurthala, Punjab, India","2023 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)","21 Jul 2023","2023","","","784","788","Recent advancements in deep learning and machine learning have enabled exact people counting in various applications including crowd management, security, and retail analytics. Deep learning algorithms have proven tremendous promise for accurate and efficient people counting in difficult contexts. This paper offers a technique for counting people that utilises deep learning with MobileNet SSD, centroid tracking, and trackable object script. Gathering and preparing a labelled dataset, training a MobileNet SSD model, implementing centroid tracking and the trackable object script, increasing system performance, testing it on real-world scenarios, and deploying it in a production environment are all part of the approach. The recommended approach provides a wide framework for creating and deploying a deep learning-based people-counting system that can be customized and tuned to match a number of applications and purposes. Additionally, we have added alerts on maximum capacity, timely scheduling and input feed from the internet.","","979-8-3503-2391-7","10.1109/CISES58720.2023.10183503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183503","People Counting;Object detection;Deep learning;Tracking;Real-Time","Deep learning;Training;Resistance;Heuristic algorithms;Computational modeling;System performance;Real-time systems","","21","","20","IEEE","21 Jul 2023","","","IEEE","IEEE Conferences"
"Research on Foreground Extraction and Target Detection and Tracking Algorithm of Surveillance Video Based on Deep Learning","P. Ye","Faculty of Megadata and Computing, Guangdong Baiyun University, Guangzhou, Guangdong, China","2023 2nd International Conference on 3D Immersion, Interaction and Multi-sensory Experiences (ICDIIME)","31 Aug 2023","2023","","","477","480","With the popularization of intelligent monitoring system, it is more and more important to detect remnants and crowd anomalies. At present, most of the anomaly detection methods of left-behind objects rely on tracking the object carriers, while the anomaly detection methods of crowds mostly judge the anomaly by detecting and tracking the trajectory of pedestrian targets and then analyzing whether their behaviors conform to the normal state. How to efficiently analyze the video data acquired by the video surveillance network by artificial intelligence is a frontier topic in the field of computer vision recently. Moreover, with the rapid development of computer science and technology and video surveillance hardware, the industry has higher and higher requirements for intelligent surveillance technology. Therefore, the quality standard of video target tracking and detection technology based on deep learning directly affects the quality of video target tracking based on deep learning. This paper mainly introduces three common methods of video target tracking and detection based on deep learning, and makes a comparative study of different methods, analyzing their advantages and disadvantages, hoping to provide some help for the further research of video tracking and detection algorithm.","","979-8-3503-2381-8","10.1109/ICDIIME59043.2023.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10229786","Deep learning;Monitoring video foreground extraction;Target Detection and Tracking Algorithm","Deep learning;Training;Target tracking;Video tracking;Three-dimensional displays;Object detection;Video surveillance","","","","10","IEEE","31 Aug 2023","","","IEEE","IEEE Conferences"
"People Tracking and Counting using Jetson TX2 Kit with Tracking Algorithm","B. Bangennavar; S. Patil; S. Kudal; B. D. Parmeshachari; R. Latti","Department of Electrical and Electronics Engineering, KLE Technological University's, Dr. M. S. Sheshgiri College of Engineering and Technology, Belagavi, India; Department of Electrical and Electronics Engineering, KLE Technological University's, Dr. M. S. Sheshgiri College of Engineering and Technology, Belagavi, India; Department of Electrical and Electronics Engineering, KLE Technological University's, Dr. M. S. Sheshgiri College of Engineering and Technology, Belagavi, India; Department of Electronics and Communication Engineering, NITTE Meenakshi Institute of Technology, Bengaluru, India; Department of Electrical and Electronics Engineering, KLE Technological University's, Dr. M. S. Sheshgiri College of Engineering and Technology, Belagavi, India","2022 IEEE North Karnataka Subsection Flagship International Conference (NKCon)","26 May 2023","2022","","","1","5","The population growth has risen across the globe. The number of people gathering in public places due to population growth has increased. Based on the timings and number of customer visit, people tracking and counting system give the tally of the number of people in specific place. Here Nvidia Jetson TX2 is utilized with tracking algorithm. Hence this system provides solution to the problem. Understanding the flow of population and generating the heat maps is an important key role. Deep learning models will help to give the better performance with respect to object detection. But especially in crowded areas where the people movement is often more there will be a problem is detection of faces because of occlusion. Here in this paper we have used the deep learning techniques to resolve these issues. We have applied the feature extraction techniques to facilitate the correctness in the detection process. The NVDIA Jetson TX2 board can be used for the real time operation of the people tracking using the embedded board. This method will give the accuracy better than the traditional way of face detection using the facial recognition algorithm.","","978-1-6654-5342-4","10.1109/NKCon56289.2022.10126790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126790","Nvidia Jetson TX2;Crowd segmentation;Jetpack","Deep learning;Tracking;Face recognition;Sociology;Object detection;Feature extraction;Real-time systems","","","","15","IEEE","26 May 2023","","","IEEE","IEEE Conferences"
"People Tracking System Using DeepSORT","M. I. H. Azhar; F. H. K. Zaman; N. M. Tahir; H. Hashim","Faculty of Electrical Engineering, Universiti Teknologi MARA, Shah Alam, Selangor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Shah Alam, Selangor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Shah Alam, Selangor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Shah Alam, Selangor","2020 10th IEEE International Conference on Control System, Computing and Engineering (ICCSCE)","24 Sep 2020","2020","","","137","141","The rapid development of image detection algorithm has led to its widespread application in security, such as facial recognition and crowd surveillance. However, real-time tracking is very challenging, especially in crowded places where the person might be in part or entirely occluded for some period. Hence, this paper objective is to create a people tracking system in crowd surveillance, using Deep SORT framework. Unlike object detection frameworks like CNN, this system does not just detect a person in real-time but on top of that, uses the information it has learned to track the trajectory of the person until they exit the frame of the camera. The system will use You Only Look Once (YOLO) for the person detection, and then use Deep SORT to process the detected person frame by frame to predict its movement path. The system was able to successfully detect and track the person movement path with average 2.59 frames per second (FPS).","","978-1-7281-7243-9","10.1109/ICCSCE50387.2020.9204956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204956","People tracking;Deep SORT framework;deep learning;YOLOv3.","Object detection;Real-time systems;Trajectory;Target tracking;Conferences","","20","","12","IEEE","24 Sep 2020","","","IEEE","IEEE Conferences"
"Integrating Object Detection and Advanced Analytics for Smart City Crowd Management","E. Prezioso; F. Giampaolo; S. Izzo; M. Savoia; F. Piccialli","Dept. of Mathematics and Applications ""R. Caccioppoli"", University of Naples Federico II, Italy; Dept. of Mathematics and Applications ""R. Caccioppoli"", University of Naples Federico II, Italy; Dept. of Mathematics and Applications ""R. Caccioppoli"", University of Naples Federico II, Italy; Dept. of Mathematics and Applications ""R. Caccioppoli"", University of Naples Federico II, Italy; Dept. of Mathematics and Applications ""R. Caccioppoli"", University of Naples Federico II, Italy","2023 IEEE International Conference on Networking, Sensing and Control (ICNSC)","20 Nov 2023","2023","1","","1","6","In the context of rapidly advancing smart cities, efficient crowd analysis plays a crucial role in ensuring public safety, urban planning, and resource management. This paper presents a novel framework that combines the popular You Only Look Once (YOLO) object detection algorithm with advanced crowd analysis techniques, aiming to improve the understanding and management of urban crowd dynamics. The proposed framework leverages YOLO’s real-time object detection capabilities to detect various objects within video frames, with a particular focus on identifying individuals. To initiate the crowd analysis process, the detected persons are isolated and tracked over time, enabling the collection of valuable data for comprehensive crowd behavior analysis. By leveraging this rich dataset, the framework enables the extraction of key crowd characteristics, such as crowd density, crowd flow patterns, crowd distribution, and crowd congestion levels. Moreover, the framework incorporates techniques to analyze the extracted data, offering valuable insights into crowd dynamics.","2766-8665","979-8-3503-6950-2","10.1109/ICNSC58704.2023.10318989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10318989","deep learning;smart city;object detection","Computer vision;Pedestrians;Smart cities;Computational modeling;Heuristic algorithms;Urban planning;Streaming media","","","","15","IEEE","20 Nov 2023","","","IEEE","IEEE Conferences"
"Implementation of Realtime design of crowd Enumeration via tracking using AI system","M. R. Kounte; J. Rishitha; S. S. Setty; S. S","School of Electronics and Communication Engineering, REVA University, Bengaluru, India; School of Electronics and Communication Engineering, REVA University, Bengaluru, India; School of Electronics and Communication Engineering, REVA University, Bengaluru, India; School of Electronics and Communication Engineering, REVA University, Bengaluru, India","2023 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)","10 Apr 2023","2023","","","270","274","Crowd enumeration can help to evaluate and count the number of visitors to a place. There are many reasons that spana wide range of applications, from security considerations, optimization of operations to efficiency in profitability. In the paper, we propose to develop a prototype for implementing a high frame rate, low processing environment, high performance, and highly efficient real-time crowd enumeration system. The latest method for object detection is deep learning. When it comes to deep learning or machine learning, performance and computation are the key parameters. In our model, there is a provision to schedule the model for the required amount of time. In our work, we are using mobilenet SSD as an object detector to detect humans. It is a preprocessed, highly efficient, and light weight model which can run on low power device like jetson nano and is cost-efficient unlike others. The advantage of our model is if there is overcrowding in a specified location with known capacity, alarm is enabled.","","978-1-6654-9260-7","10.1109/IITCEE57236.2023.10090914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10090914","Crowd Enumeration;Deep Learning (DL);Intelligent Machine (IM);Convolution Neural Network (CNN)and Machine learning (ML)","Deep learning;Schedules;Profitability;Computational modeling;Neural networks;Prototypes;Object detection","","","","26","IEEE","10 Apr 2023","","","IEEE","IEEE Conferences"
"TensorFlow Implementation on Analysis of Unusual Behavior in Crowd Using Deep Learning","M. K. D. P; A. Babu J; V. T. S; S. N; R. B; S. Sharma","Dept of CSE, Kalpataru Institute of Technology, Tiptur, Karnataka, India; Dept of ISE, Malnad College of Engineering, Hassan, Karnataka, India; Dept of CSE, Kalpataru Institute of Technology, Tiptur, Karnataka, India; Dept of CSE, Kalpataru Institute of Technology, Tiptur, Karnataka, India; Dept of CSE, Kalpataru Institute of Technology, Tiptur, Karnataka, India; Dept of CSE, Kalpataru Institute of Technology, Tiptur, Karnataka, India","2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)","8 Feb 2024","2023","","","1","6","Image processing and computer vision researchers can effectively use real-time video to identify human behavior. With the use of visuals, it is possible to observe human activity in private and public places including car parks, bus stops, train stations, airports, banks, retail centers, schools, and colleges. It was done to stop crimes, terrorism, theft, fights, chain exploitation, accidents, unauthorized parking, graffiti, and other shady activities. Since it is highly challenging to constantly observe public spaces, there is a need for intelligent video surveillance that can track people's movements in real-time, differentiate between typical and odd activity, and possibly even sound an alarm.","","979-8-3503-0692-7","10.1109/ICRASET59632.2023.10420324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420324","OpenCV;TensorFlow;Dlib;Datasets;Haar Classifier;CNN – Convolutional Neural Network;Flow net – Alexnet – Unet;Crowd Monitoring;Deep Learning","Deep learning;Computer vision;Image processing;Prototypes;Real-time systems;Behavioral sciences;Convolutional neural networks","","","","17","IEEE","8 Feb 2024","","","IEEE","IEEE Conferences"
"Realtime Crowd Monitoring—Estimating Count, Speed and Direction of People Using Hybridized YOLOv4","M. H. K. Khel; K. A. Kadir; S. Khan; M. Noor; H. Nasir; N. Waqas; A. Khan","Electrical Section, Universiti Kuala Lumpur-British Malaysian Institute, Selangor, Gombak, Malaysia; Electrical Section, Universiti Kuala Lumpur-British Malaysian Institute, Selangor, Gombak, Malaysia; Department of Electrical Engineering, College of Engineering and Information Technology, Onaizah Colleges, Onaizah, Saudi Arabia; Computer Engineering Section, Universiti Kuala Lumpur-Malaysian Institute of Information Technology, Kuala Lumpur, Malaysia; Computer Engineering Section, Universiti Kuala Lumpur-Malaysian Institute of Information Technology, Kuala Lumpur, Malaysia; Department of Instrumentation and Control Engineering, Universiti Kuala Lumpur-Malaysian Institute of Industrial Technology, Kuala Lumpur, Malaysia; Electrical Section, Universiti Kuala Lumpur-British Malaysian Institute, Selangor, Gombak, Malaysia","IEEE Access","13 Jun 2023","2023","11","","56368","56379","Researchers are becoming more interested in crowd surveillance because of its several potential applications. These applications may include detecting unusual activity for security purposes, monitoring reasons for archiving records, and conducting inventory for facility planning and extension. Detecting people and tracking them from a security viewpoint and understanding their behavior in places large crowds is highly important because unruly crowds in public spaces can lead to serious health and security concerns. Crowd related accidents happen to cause injuries and deaths, which often occur during events not properly planned. The planning of the organizers relies heavily on exploring the behavior of the few in a crowd of individuals and groups in thousands that create the crowds. It is this focus that provides the main reason for this research. This work proposes a model that can count people in crowds, automatically detect and track people, and then estimate their direction and speed. Deep learning networks have proven costly to run, needing memory and power to perform computations beyond what is possible on edge devices with limited resources. As a result, we propose the use of hybrid YOLOv4 consisting of detection method combined with the training phase pruning and the use the convolution attention module strategy. Accuracy of the Hybrid YOLOv4 is increased by 33%, whereas mAP reached 92.1%. While training on the JHU dataset, the suggested hybrid YOLOv4 strategy decreases the computational memory requirements, all of which closely meet the real-time application conditions. This work will help avoid the threatening situation of crowding gathering around to cause stampedes and thus risking crowds with disastrous consequences.","2169-3536","","10.1109/ACCESS.2023.3272481","Deputyship for Research and Innovation, Ministry of Education, Saudi Arabia, through the project titled “Intelligent Real-Time Crowd Monitoring System Using Unmanned Aerial Vehicle (UAV) Video and Global Positioning Systems (GPS) Data”; Department of Information Technology, College of Computer, Qassim University, Buraydah, Saudi Arabia(grant numbers:QURDO001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10114068","Direction estimation;speed estimation;hybrid YOLOv4;crowd monitoring;crowd management;deep learning","Neural networks;Feature extraction;Deep learning;Security;Training;Safety;Variable speed drives;Estimation;Crowdsourcing","","","","46","CCBYNCND","2 May 2023","","","IEEE","IEEE Journals"
"Uniform Appearance People and Crowd Monitoring Using Drones","A. Elshamy; M. Alansari; A. Abughali; E. Khan; I. M. Zaid; N. Werghi","Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Department of Aerospace Engineering, Khalifa University, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE","2023 21st International Conference on Advanced Robotics (ICAR)","1 Feb 2024","2023","","","492","498","With the rapid increase in crowd gatherings, public safety has become a crucial concern for event organizers. Consequently, the usage of modern technology to monitor crowded locations is necessary. In this work, a challenging dataset with different crowd density scenarios was collected using a camera-equipped drone. The individuals within the crowd were assigned to be dressed uniformly to emulate real challenging scenarios. Unlike the robot, the drone possesses the ability to observe the crowd while having no impact on their mobility, rendering it a more feasible solution in practical applications. The dataset emulates crowded places at different timings and different intruder behaviors. The collected data were annotated manually utilizing Computer Vision Annotation Tool (CVAT). The results show a considerable deterioration in the performance of the State-Of-The-Art (SOTA) visual object trackers which indicates a challenging dataset to track. To enhance the performance of the tracker, STARK-ST50 was fine-tuned using 30 videos for both training and testing, and the tracker has experienced a slight improvement in its performance due to the challenging nature of the dataset.","2572-6919","979-8-3503-4229-1","10.1109/ICAR58858.2023.10406360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10406360","Crowd Monitoring;Deep Learning;Drones;Security;Visual Object Tracking","Training;Visualization;Timing;Monitoring;Videos;Drones;Testing","","","","24","IEEE","1 Feb 2024","","","IEEE","IEEE Conferences"
"Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking","Z. Zou; J. Huang; P. Luo","School of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China","2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","15 Feb 2022","2022","","","2673","2673","Tracking by detection paradigm is one of the most popular object tracking methods. However, it is very dependent on the performance of the detector. When the detector has a behavior of missing detection, the tracking result will be directly affected. In this paper, we analyze the phenomenon of the lost tracking object in real-time tracking model on MOT2020 dataset. Based on simple and traditional methods, we propose a compensation tracker to further alleviate the lost tracking problem caused by missing detection. It consists of a motion compensation module and an object selection module. The proposed method not only can re-track missing tracking objects from lost objects, but also does not require additional networks so as to maintain speed-accuracy trade-off of the real-time model. Our method only needs to be embedded into the tracker to work without retraining the network. Experiments show that the compensation tracker can efficaciously improve the performance of the model and reduce identity switches. With limited costs, the compensation tracker successfully enhances the baseline tracking performance by a large margin and reaches 66% of MOTA and 67% of IDF1 on MOT2020 dataset.","2642-9381","978-1-6654-0915-5","10.1109/WACV51458.2022.00273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706870","Real-time Tracking Datasets;Evaluation and Comparison of Vision Algorithms;Deep Learning","Analytical models;Computer vision;Costs;Tracking;Computational modeling;Detectors;Real-time systems","","5","","60","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Deep Learning and One-class SVM based Anomalous Crowd Detection","M. Yang; S. Rajasegarar; S. M. Erfani; C. Leckie","School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Information Technology, Deakin University, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Anomalous event detection in videos is an important and challenging task. This paper proposes a deep representation approach to the problem, which extracts and represents features in an unsupervised way. This algorithm can detect anomalous activity like standing statically and loitering among a crowd of people. Our proposed framework is a two-channel scheme by using feature channels extracted from the appearance and foreground of the original video. Two hybrid deep learning architectures SDAE-DBN-PSVM (a four-layer Stacked Denoising Auto-encoder with three-layer Deep Belief Nets and Plane-based one class SVM) are implemented for these two channels to learn the high-level feature representation automatically and produce two anomaly scores. Finally, a fusion scheme is proposed for combining anomaly scores and detecting anomalous events. Experimental results on a large real-world dataset (MCG) and two benchmark datasets (UCSD and Subway) demonstrate the effectiveness of this approach. Furthermore, quantitative analyses of the effects of the amount of training data and the illumination conditions of the video on the accuracy of anomaly detection are presented.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852256","anomalous event detection;deep representation;stacked denoising auto-encoder;deep belief nets;video surveillance","Deep learning;Feature extraction;Videos;Tracking;Computer architecture;Event detection;Noise reduction","","11","","27","IEEE","30 Sep 2019","","","IEEE","IEEE Conferences"
"Performance Comparison and Analysis for Large-Scale Crowd Counting Based on Convolutional Neural Networks","R. Alotaibi; B. Alzahrani; R. Wang; T. Alafif; A. Barnawi; L. Hu","Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Computer Science Department, Jamoum University College, Umm Al-Qura University, Makkah, Saudi Arabia; Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Access","18 Nov 2020","2020","8","","204425","204432","Nowadays, crowd analysis is one of the most important concepts that needs be relied upon, it contributes to decision making and ensuring the safety and security of the crowd. There are a variety of interesting research problems within the scope of crowd analysis including crowd tracking, crowd behaviour recognition and crowd counting. Crowd counting based on images and videos has been studied in past years. Nonetheless, estimating and detecting the number of human heads remains a challenging task due to occlusions, resolution, and lighting changes. This paper provides an overview and performance comparison of crowd counting techniques using convolutional neural networks (CNN) based on density map estimation. In this paper, we present a comprehensive analysis and benchmarking of crowd counting based on the UCF-QNRF dataset that contains the largest number of crowd count images and head annotations available in the public domain. We also show the density maps generation and their empirical evaluation along with performance comparison.","2169-3536","","10.1109/ACCESS.2020.3037395","Deputyship for Research and Innovation Ministry of Education Saudi Arabia(grant numbers:227); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256256","Large-scale crowd;crowd counting;computer vision;deep learning;convolutional neural networks;bio-inspired model;density map estimation","Task analysis;Kernel;Head;Estimation;Training;Feature extraction;Brain modeling","","4","","35","CCBY","11 Nov 2020","","","IEEE","IEEE Journals"
"Application of Cognitive Computing for Smart Crowd Management","E. B. Varghese; S. M. Thampi","Indian Institute of Information Technology and Management-Kerala (IIITM-K), Cochin University of Science and Technology; Indian Institute of Information Technology and Management-Kerala (IIITM-K)","IT Professional","17 Jul 2020","2020","22","4","43","50","A crowd can be defined as a large gathering of people at a particular place showing different types of attitudes and behaviors. Monitoring and tracking these wide varieties of people is tedious in a real environment. The crowded scenarios have a high tendency to change into an abnormal condition due to sudden external pressures such as gunshots/fire or internal stress such as overcrowding, where things get often uncontrollable and the consequences are disastrous. Moreover, the use of a large number of monitoring cameras and the limited capability of human operators to analyze the video contents result in an urge to developing smart crowd monitoring systems with humanlike capabilities. This article discusses the human cognition capability and its application for smart crowd management. Cognitive computing facilitates complex task automation, real-time decision-making, predictive analytics, and processing of voluminous structured and unstructured data.","1941-045X","","10.1109/MITP.2020.2985974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143254","","Deep learning;Surveillance;Cameras;Real-time systems;Cognitive systems;Crowdsourcing","","5","","20","IEEE","17 Jul 2020","","","IEEE","IEEE Magazines"
"Research on Algorithm for Multi Object Tracking Based on YOLOv5 and DeepSORT","W. Peng; E. Zhang; G. Lu; X. Zhang","Beijing Institute of Technology, Zhuhai, Zhuhai, China; Beijing Institute of Technology, Zhuhai, Zhuhai, China; Beijing Institute of Technology, Zhuhai, Zhuhai, China; Beijing Institute of Technology, Zhuhai, Zhuhai, China","2023 IEEE 6th International Conference on Automation, Electronics and Electrical Engineering (AUTEEE)","29 Jan 2024","2023","","","1198","1203","Deep learning based object detection technology and multi object tracking technology are the main research branches in the field of machine vision. The research results in this field have a wide range of application scenarios in intelligent driving, video surveillance, and intelligent transportation. This article uses the DeepSORT multi-target tracking algorithm based on YOLOv5 detection to conduct research on pedestrian multi-target tracking and crowd monitoring mask detection. The aim is to provide an efficient automatic detection system to replace epidemic prevention and control in densely populated areas.","2831-4549","979-8-3503-0562-3","10.1109/AUTEEE60196.2023.10408709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10408709","Deep Learning;YOLOv5;DeepSORT;Dataset","YOLO;Deep learning;Visualization;Transportation;Feature extraction;Video surveillance;Object tracking","","","","9","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Passenger Flow Statistics Algorithm of Scenic Spots Based on Multi-Target Tracking","G. Xiangquan; W. Ruipeng; L. Li","College of Computer and Communication, Lanzhou University of Technology, Lanzhou, China; College of Computer and Communication, Lanzhou University of Technology, Lanzhou, China; College of Computer and Communication, Lanzhou University of Technology, Lanzhou, China","2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)","2 Aug 2021","2021","","","525","530","According to the real-time and accuracy requirements of obtaining passenger flow by surveillance videos in scenic spot, a model based on deep learning is proposed. Aided by Yolov4 and Deep Sort, passenger flow is counted by detection and tracking tourists. Aiming at the real-time requirement, the model compression method is used to replace the backbone network of Yolov4 with lightweight network mobileNetv3 to improve the detection speed. For the accuracy of the model, a detection scale is used to Yolov4 for extracting shallow features and the features are concatenated with deep features. Furthermore, Soft-NMS is used to process the detection results. The purpose of these improvements is to solve the dense tourists and small target problems in the surveillance videos. Then Deep Sort tracks the tourists target and obtains passenger flow information in the scenic spot. Through the experiment of the model in the surveillance videos, it is verified that this model meets the real-time requirements and has high accuracy in passenger flow statistics.","","978-1-6654-1867-6","10.1109/ICAICA52286.2021.9497977","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497977","passenger flow statistics;Deep learning;Yolov4;Deep Sort;Lightweight network","Deep learning;Target tracking;Surveillance;Conferences;Computer applications;Feature extraction;Real-time systems","","","","13","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"Suspicious Human Crowd Behaviour Detection - A Transfer Learning Approach","P. Liyanage; P. Fernando","Department of Computing Informatics, Institute of Technology, Colombo, Sri Lanka; Department of Computing Informatics, Institute of Technology, Colombo, Sri Lanka","2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)","16 May 2022","2021","","","63","68","Video surveillance systems play an important role in the public security sector. These systems are used to detect a variety of activities such as suspicious human behaviours, analyze crowd behaviours, manage road traffic and track vehicles. Due to the difficulty in manual monitoring of such activities, several research attempts were carried out to automate information extraction from surveillance systems using machine learning and deep learning approaches. The unavailability of large video data sets for processing purposes, is one of the common barriers in this research domain, since the majority of the existing videos are untrimmed, unannotated, and may contain ambiguous data. The purpose of this research is to propose a machine learning based transfer learning approach, to solve the limitations with the datasets specifically for accurate detection of violent crowd behavior via surveillance systems. Four state-of-the-art models were tested with varied configurations and the proposed prototype achieved highest model accuracy of 97%.","2472-7598","978-1-6654-6686-8","10.1109/ICter53630.2021.9774784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774784","Suspicious crowd behaviour;Video surveillance;Transfer learning;Anomaly detection;Computer vision","Deep learning;Roads;Transfer learning;Prototypes;Manuals;Video surveillance;Information retrieval","","","","25","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"UUCT - HyMP: Towards Tracking Dispersed Crowd Groups from UAVs","T. Deb; M. Rahmun; S. A. Bijoy; M. H. Raha; M. A. Khan","Department of Electrical & Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical & Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical & Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical & Computer Engineering, North South University, Dhaka, Bangladesh; Department of Electrical & Computer Engineering, North South University, Dhaka, Bangladesh","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Aerial tracking of dispersed crowd groups with a single target window is a novel and one of the most challenging problems in Computer Vision and Robotics. Considering crowd group as a multi-object tracking problem can often lead to computational burden and frequent target mismatch due to numerous occlusions, whereas a single window can efficiently focus on the target. Recent progress on single object tracking (SOT) algorithms is achieved by learning a generic discriminator model from object tracking datasets, continuously updated during the testing steps. However, while tracking a group of crowd with a single window, the rigid discriminator can not generalize frequent group reformation, binomial dispersion, and crowd shape changes due to less knowledge about human-to-human interactions. To alleviate the issues, we propose a novel photo-realistic Unreal UAV Crowd Tracking (UUCT) dataset, which benchmarks aerial crowd group movements into several attributes. Second, we formulate a novel algorithm, Hybrid Motion Pooling (HyMP), which extends the existing SOT algorithm, DiMP, by exploiting graph convolutional networks for learning human groups and low-rank bilinear pooling for capturing temporal group reformations end-to-end. Then, we compare HyMP with state-of-the-art (SOTA) trackers on UUCT to demonstrate HyMP's effectiveness in group tracking. Also, we illustrate the generalizability of HyMP by evaluating on the existing benchmarks. On average, HyMP outperforms SOTA approaches by 7.5% on UUCT and 4.3% on related datasets.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533600","","Computer vision;Target tracking;Shape;Computational modeling;Neural networks;Benchmark testing;Generators","","2","","62","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection Approach for Human Detection in Crowd Based Locations","R. Srivastava; G. Chhabra","School of Computer Science, University of Petroleum and Energy Studies, Dehradun; Deptt. of CSE, Graphic Era Hill University, Dehradun","2023 International Conference on Sustainable Emerging Innovations in Engineering and Technology (ICSEIET)","7 Nov 2023","2023","","","150","157","Currently, it is challenging to find a solution for human identification in a busy area. To deal with security issues like theft, fire, or other strange incidents, private organizations also install security cameras on their property. Deep learning has now proven to be effective in a wide range of industries, from audio and video to NLP and image recognition. For Deep Learning techniques like Convolutional Neural Networks (CNNs), Graph Neural Networks (GNNs), etc., abnormal event detection is a typical application case. Modern 3D convolutional neural network (CNN)-based models for anomaly detection will be used in this study. The Avenue collection's footage of both common and atypical crowd behavior is used in experiments. By comparing the percentage of correctly detected frames to the actual data, the model's efficacy is evaluated. In this paper, we present a reliable method for spotting unusual crowd behavior. The input from numerous sensors used by various models is used to calculate accuracy. Finding outliers and giving comparable estimates is the main objective. The proposed model has the maximum accuracy (92.6%), according to the findings of the trials that were carried out.","","979-8-3503-2919-3","10.1109/ICSEIET58677.2023.10303413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10303413","Anomaly Detection;Deep Learning;CNN;Neural Network;Object Detection","Deep learning;Technological innovation;Three-dimensional displays;Image recognition;Convolution;Behavioral sciences;Convolutional neural networks","","1","","24","IEEE","7 Nov 2023","","","IEEE","IEEE Conferences"
"Empirical Study on Real Time People Counting using Deep Learning","H. Nagolu; S. Sahu","Department of CSE, GMR Institute of Technology, Rajam, India; Department of CSE, GMR Institute of Technology, Rajam, India","2023 10th International Conference on Computing for Sustainable Global Development (INDIACom)","4 May 2023","2023","","","1","4","In this digital era, many crowd-counting systems still rely on old-fashioned approaches like keeping registers, using people counters, and using sensors to count people at the door. These strategies are ineffective in situations where people's movement is fully random, extremely unpredictable, and dynamic. Video surveillance plays a key role in monitoring people in several places. Using videos from this video surveillance in algorithms like Median Flow,” Minimum Output Sum of Squared Error” (MOSSE), “Generic Object Tracking Using Regression Networks” (GOTURN), kernelized filters designed with deep learning can track the objects and count the people or customers and correlation filters like “Single Shot Detector” (SSD) to count the number of individuals entering and leaving a location. This paper gives a review of the above algorithms.","","978-93-80544-47-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10112438","Video surveillance;single shot detector;deep learning;counting;line of control","Deep learning;Webcams;Object detection;Filtering algorithms;Streaming media;Video surveillance;Sensor systems","","","","20","","4 May 2023","","","IEEE","IEEE Conferences"
"Visible and Infrared Image Fusion Using Deep Learning","X. Zhang; Y. Demiris","Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, U.K.; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, London, U.K.","IEEE Transactions on Pattern Analysis and Machine Intelligence","30 Jun 2023","2023","45","8","10535","10554","Visible and infrared image fusion (VIF) has attracted a lot of interest in recent years due to its application in many tasks, such as object detection, object tracking, scene segmentation, and crowd counting. In addition to conventional VIF methods, an increasing number of deep learning-based VIF methods have been proposed in the last five years. Different types of methods, such as CNN-based, autoencoder-based, GAN-based, and transformer-based methods, have been proposed. Deep learning-based methods have undoubtedly become dominant methods for the VIF task. However, while much progress has been made, the field will benefit from a systematic review of these deep learning-based methods. In this paper we present a comprehensive review of deep learning-based VIF methods. We discuss motivation, taxonomy, recent development characteristics, datasets, and performance evaluation methods in detail. We also discuss future prospects of the VIF field. This paper can serve as a reference for VIF researchers and those interested in entering this fast-developing field.","1939-3539","","10.1109/TPAMI.2023.3261282","European Union's Horizon 2020 Research and Innovation Programme; Marie Skłodowska-Curie(grant numbers:101025274); Royal Academy of Engineering Chair in Emerging Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10088423","Deep learning;image fusion;multimodal fusion;RGB-T;visible-infrared image fusion","Image fusion;Transformers;Deep learning;Task analysis;Object tracking;Matlab;Learning systems","Deep Learning;Algorithms","16","","200","IEEE","30 Mar 2023","","","IEEE","IEEE Journals"
"Rapid Detection of Pilgrims Whereabouts During Hajj and Umrah by Wireless Communication Framework : An application AI and Deep Learning","M. Alhameed; M. A. Hossain","College of Computer Science & Information Technology, JAZAN UNIVERSITY, Jazan, Kingdom of Saudi Arabia; Department of Computer Science, College of CS & IT, JAZAN UNIVERSITY, Jazan, Kingdom of Saudi Arabia","2023 International Conference on Emerging Smart Computing and Informatics (ESCI)","19 Apr 2023","2023","","","1","6","Human injuries and deaths occur often during public events like concerts, religious services, and political rallies because of a lack of proper crowd safety oversight. A small disaster can trigger panic in a huge crowd. Many intelligent video surveillance solutions can identify things, but despite the recent developments in artificial intelligence approaches and deep learning processes, it is very probable to track congested crowds and their mobility to avoid future detection disasters. Searching for points of interest makes use of movement analytics and classification to provide a superior platform for monitoring large crowds. The purpose of point-of-interest explorations is to aid in the management of the safety of moveable crowd events by assisting in the prediction and prevention of future disasters through the classification and analysis of real-time information gathered from crowds. Current surveillance cameras are insufficient for monitoring large crowds in outdoor locations due to their inability to scale. We believe that by using our proposed crowd analysis strategy, we may help enhance the current state of crowd safety management. Among the many aspects of crowd motion, we pay special attention to the difficulties of determining the identity, velocity, and direction of individuals inside the group. We then used these crowd-level semantics to monitor test POI searches in both a controlled lab environment and a real-world crowd. Findings from this study imply that POI searching can be utilized to help prevent harmful circumstances brought on by the movement of large crowds by recognizing the characteristics of mobile crowds in real time.","","978-1-6654-7524-2","10.1109/ESCI56872.2023.10099969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10099969","crowd congestion tracking;POI searching;artificial intelligence;machine learning;disaster preventive technique","Deep learning;Wireless communication;Tracking;Smart cities;Semantics;Streaming media;Video surveillance","","4","","25","IEEE","19 Apr 2023","","","IEEE","IEEE Conferences"
"Estimation of Social Distance for COVID19 Prevention using K-Nearest Neighbor Algorithm through deep learning","A. Arul Raj; R. Sugumar","Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical And Technical Sciences, Chennai, Tamil Nadu; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical And Technical Sciences, Chennai, Tamil Nadu","2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)","13 Dec 2022","2022","","","1","6","Coronavirus disease has a crisis with high spread throughout the world during the COVID19 pandemic period. This disease can be easily spread to a group of people and increase the spread. Since it is a worldly disease and not plenty of vaccines available, social distancing is the only best approach to defend against the pandemic situation. All the affected countries' governments declared locked-down to implement social distancing. This social separation and persons not being in a mass group can slow down the spread of COVID19. It reduces the physical contact between infected persons and normal healthy persons. Almost every health organization tells that to follow social distancing people should maintain at least 6 feet of distance from each other. This research proposes a deep learning approach for social distancing which is developed for tracking and detecting people who are in indoor as well as outdoor scenarios using YOLO V3 video analytic technique. This approach focuses to inspect whether the people are maintaining social distancing in many areas, using surveillance video with measuring the distance in real-time performance. Most of the early studies of detecting social distance monitoring were based on GPS for tracking the movements of people where the signals could be lost. On the other hand, some countries use drones to detect large gatherings of people who cannot have a clear view at night times [10]. In the future, the proposed system can be used fully for detecting threats in the public crowded or it can detect any person affected by critical situations (ie fainting, Cordia arrest) or planting the crops in the forms evenly with a uniform measurement. This proposal could be used in many fields like crowd analysis, autonomous vehicles, and human action recognition and could help the government authorities to redesign the public place layout and take precautionary action in the risk zones. This system analyses the social distancing of people by calculating the distance between people to slow downing the spread of the COVID 19 virus.","","978-1-6654-9790-9","10.1109/MysuruCon55714.2022.9972422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972422","Social distancing;supervised learning algorithm;Object detection;Crowd analysis;covid-19","COVID-19;Deep learning;Pandemics;Tracking;Visual analytics;Government;Human factors","","1","","11","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"DeepSORT: Real Time & Multi-Object Detection and Tracking with YOLO and TensorFlow","A. Pujara; M. Bhamare","School of Computer Engineering & Technology, MIT World Peace University, Pune, India; School of Computer Engineering & Technology, MIT World Peace University, Pune, India","2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","16 Jan 2023","2022","","","456","460","One of the most significant and challenging areas of computer vision is object recognition and tracking, which is extensively utilised in many industries including health care monitoring, autonomous driving, anomaly detection, etc. The tracking of moving objects in videos is actively researched over the past two decades due to its practical applications in many fields such as event analysis, human-computer interaction, crowd analysis, video surveillance, behaviour analysis, etc. The effectiveness of object trackers and detectors has significantly increased with the rapid advancement of deep learning (DL) networks and GPU processing capability. New methods have been presented for object recognition and tracking in video as a result of extensive study in this field. This article addressed the several processes of object tracking in video sequences: object detection, object classification, and object tracking, in order to comprehensively comprehend the key advancements in the object detection and tracking pipeline. Additionally, we thoroughly examine the various approaches available for object recognition, categorization, and tracking.","","978-1-6654-8962-1","10.1109/ICAISS55157.2022.10011018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10011018","Background subtraction;Human detection;Object detection;Object tracking;Video surveillance","Industries;Video sequences;Pipelines;Object detection;Medical services;Video surveillance;Real-time systems","","4","","22","IEEE","16 Jan 2023","","","IEEE","IEEE Conferences"
"Locating people in Real-World for Assisting Crowd Behaviour Analysis Using SSD and Deep SORT Algorithm","P. Juyal; S. Sharma","Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, India; Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, India","2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","11 May 2021","2021","","","350","353","In security-sensitive areas, tracking individuals can be of high importance or may even be used to understand crowd activity, how people change their movement within the crowd or most common shops. Crowd activity trends can help to determine the most common locations of public places, which can help attract a wider audience in advertising placement. A growing concern has been public safety; it can be a harrowing experience to track these mischievous elements inside the crowd. This paper provides an approach that can map people with a geographical coordinate, which denotes an individual's realtime position in the real world through a camera feed. This data helps us to track the road, the direction of motion and where a person has turned on a map. These insights include descriptions of in-depth crowd movement that can assist with better surveillance and evaluating crowd activity.","","978-1-6654-4086-8","10.1109/WiSPNET51692.2021.9419455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419455","Monitoring;Real-time systems;Image edge detection;Visual analytics;Data visualization;Deep learning","Wireless communication;Tracking;Surveillance;Roads;Image edge detection;Signal processing algorithms;Signal processing","","7","","20","IEEE","11 May 2021","","","IEEE","IEEE Conferences"
"Multi-Scale Occluded Pedestrian Detection Based on Deep Learning","Z. Pan","Liuzhou Railway Vocational Technical College, Liuzhou, Guangxi, India","2023 International Conference on Evolutionary Algorithms and Soft Computing Techniques (EASCT)","22 Jan 2024","2023","","","1","6","With the intensification of urbanization, the number of pedestrians in densely populated areas is showing an explosive growth trend, which brings new challenges to the technological advancement of urban traffic management, intelligent security, and other fields. Pedestrian detection in densely populated areas is an important task aimed at achieving real-time recognition and tracking of all pedestrians in a specific area. This article proposes a multi-scale occluded pedestrian detection method based on deep learning. This method can effectively detect occluded pedestrians by introducing multi-scale feature maps and occlusion detection modules. The experimental results indicate that Faster RCNN has high accuracy in detecting occluded pedestrians and can be applied to pedestrian detection tasks in practical scenarios. Deep learning algorithms can be used to effectively measure the occlusion of pedestrians. Multi-scale detection methods allow for accurate detection of pedestrians at different scales. By using deep learning algorithms, patterns with masked pedestrian features can be automatically learned and judged during the detection process.","","979-8-3503-1341-3","10.1109/EASCT59475.2023.10393467","Guangxi University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10393467","deep learning;multi scale analysis;target detection;pedestrian occlusion processing method","Deep learning;Pedestrians;Satellites;Urban areas;Feature extraction;Robustness;Sensors","","","","20","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"Object tracking and counting in a zone using YOLOv4, DeepSORT and TensorFlow","S. Kumar; Vishal; P. Sharma; N. Pal","Computer Science & Engineering, Delhi Technological University, Delhi, India; Computer Engineering, Delhi Technological University, Delhi, India; Computer Engineering, Delhi Technological University, Delhi, India; Computer Engineering, Delhi Technological University, Delhi, India","2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)","12 Apr 2021","2021","","","1017","1022","The main objective of this research work is to solve multiple object tracking problems in a given frame, wherein the proposed model intends to identify and track various objects. The problem has been solved in three stages viz. detecting, identifying, and tracking the object in a particular zone, i.e., but it is observed that something more could be done in this field, mostly the MOT-A score was not up to the mark; hence the proposed research work utilized Kalman filters for obtaining enhanced results and compared the obtained MOT-A metric with previous works, and the results were good. Object detection and recognition occur via the YOLO algorithm, which enables us to classify the objects into 80 classes. Then, Motion Prediction and feature generation occur in which an estimation model is created, and Kalman filters are used to model these states for capturing moving objects in the frame. Finally, tracking takes place with Kalman filters in the previous frame, and newly detected objects are placed in the current frame, after which an association is made for new detection. All this is done via the DeepSORT algorithm, which is essentially a Deep association metric with the SORT algorithm. Here, Kalman filters are used as they improved the accuracy of the proposed model and yielded better results. On the same lines, YOLO is used to perform object detection and recognition at the same time. It is also a detector, which by applying a single neural network, it can predict the bounding boxes and perform multi-class classification. This problem can have various applications, especially in traffic management. It can also prevent people from gathering during COVID times and raising an alert for all the authorities. Hence, this is a multidisciplinary approach wherein the work of object detection is being used in various fields like crowd assembling, Surveillance, Animal management in Zoo/Biodiversity parks as well as in the case of traffic systems as well. The real motivation behind this work was using the state-of-the-art technology to solve the modern-day problems. Manually human vigilance in large areas is a utopian task and especially when surveillance and security is big threat out there. Adding to it is the COVID Pandemic which has claimed millions of lives and yet vaccination is a still a dream yet to be realized. Hence, cluster identification problem is considered and also the ways to solve this challenge using the state-of-the-art technology. Once it has been achieved, it is initiated further to find more applications of this technology in various other domains and found out how it is applied in various use cases in case of crowd gathering at a single point and how this is a similar problem in case of animal gathering at a point and how forest rangers can solve the problem in a more efficient way.","","978-1-7281-9537-7","10.1109/ICAIS50930.2021.9395971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395971","Kalman Filters;Multiple Object Tracking;DeepSORT;YOLOv4;Target tracking;TensorFlow;Image Processing;Image Segmentation","Measurement;Surveillance;Object detection;Predictive models;Kalman filters;Object recognition;Security","","16","","17","IEEE","12 Apr 2021","","","IEEE","IEEE Conferences"
"Crowd Evacuation Simulation Using Hierarchical Deep Reinforcement Learning","Z. Zhang; D. Lu; J. Li; P. Liu; G. Zhang","School of Information Science and Engineering, Shandong Normal University, Jinan, China; State Key Laboratory of High-end Server & Storage Technology, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; Business School, Guilin University of Electronic Technology, Guilin, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China","2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","28 May 2021","2021","","","563","568","Data-driven crowd evacuation learning methods are often used to enhance the realism of crowd simulation. However, the learning results of traditional methods cannot adapt to the dynamic changes of the simple scene, and thus have the disadvantage of poor generalization. To solve this problem, we propose a data-driven crowd evacuation framework based on hierarchical deep reinforcement learning. The framework consists of: a macro-control layer with path programming function and a micro control layer with collision avoidance function. In this paper, a path programming method combining data-driven and deep reinforcement learning is proposed in the macro-control layer. The method combines the pedestrian motion attributes in the video with the DDPG algorithm to learn the pedestrian track in the video from a macro perspective. In the micro-control layer, the track sequence learned in the macro-control layer is used as the motion target to learn the collision-free motion velocity of individuals using the multiple agent deep reinforcement learning method. When the scene changes, the micro-control layer adaptively adjusts the motion speed without the need for the macro-control layer to repeat the path programming learning. The experimental results demonstrate that the proposed hierarchical crowd evacuation framework can not only simulate the real crowd movement behavior and improve the simulation fidelity, but also flexibly adapt to the dynamic changes of the simple scene and enhance the generalization.","","978-1-7281-6597-4","10.1109/CSCWD49262.2021.9437632","National Natural Science Foundation of China(grant numbers:61972237,61876102,61762029); Natural Science Foundation of Shandong Province(grant numbers:ZR2020LZH003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437632","Crowd evacuation;Route programming;Collision avoidance;Deep reinforcement learning","Training;Learning systems;Adaptation models;Target tracking;Conferences;Computational modeling;Dynamics","","10","","18","IEEE","28 May 2021","","","IEEE","IEEE Conferences"
"Automated Pedestrian Tracking Based on Improved ByteTrack","Q. Zhang; F. Yang; F. Li; Z. Fei; Y. Xie; D. Deng","Systems Engineering Institute, AMS, PLA, Beijing, China; Systems Engineering Institute, AMS, PLA, Beijing, China; Systems Engineering Institute, AMS, PLA, Beijing, China; Systems Engineering Institute, AMS, PLA, Beijing, China; Systems Engineering Institute, AMS, PLA, Beijing, China; Systems Engineering Institute, AMS, PLA, Beijing, China","2023 IEEE 23rd International Conference on Communication Technology (ICCT)","12 Feb 2024","2023","","","552","557","In order to augment the robustness of pedestrian tracking in video sequences, we offer an enhanced automatic pedestrian tracking method that is based on the ByteTrack framework. The objective of the proposed approach is to tackle the issue of missed detections and trajectory loss in pedestrian tracking due to dense occlusion. The achievement of multi-object pedestrian tracking is realized through the integration of YOLOX-CF, an enhanced iteration of YOLOX, in conjunction with the BYTE tracking approach. In order to improve the ability of the network to detect pedestrians in various places, we have incorporated the coordinate attention (CA) module into the feature extraction network of YOLOX. In addition, we want to tackle the complex issue of crowd occlusion in pedestrian objects by proposing the utilization of focus loss as a confidence loss function. The above function aims to achieve weight balance between positive and negative samples, hence enhancing the network's attention on problematic samples. The experimental results obtained from the MOT17 dataset demonstrate a notable enhancement in both the mean Average Precision (mAP) and Multiple Object Tracking Accuracy (MOTA) as compared to the first approach. We observe a notable enhancement of 3.1 percentage points in mAP and 3.4 percentage points in MOTA. Furthermore, with the transformation of the model into TensorRT, the rate of inference improves to 126 frames per second (FPS) when executed on a single 2080Ti GPU. The proposed methodology offers enhanced efficacy in real-time pedestrian tracking within the context of autonomous driving, beyond the capabilities of the original.","2576-7828","979-8-3503-2595-9","10.1109/ICCT59356.2023.10419387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419387","YOLOX;ByteTrack;Deep Learning;Multi-object Tracking","Pedestrians;Video sequences;Graphics processing units;Inference algorithms;Real-time systems;Object tracking;Task analysis","","","","18","IEEE","12 Feb 2024","","","IEEE","IEEE Conferences"
"Multiple Object Tracking algorithm based on cluster cooperative motion constraint","H. Wang; G. Tan; D. Xu","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","2023 35th Chinese Control and Decision Conference (CCDC)","1 Dec 2023","2023","","","2956","2962","Multi-target tracking is one of the key research fields of computer vision. Existing methods mainly focus on inferring robust and discriminative features for data association based on targets generated by existing detectors. However, these methods independently process each target when generating the trajectory. In contrast, we propose a new multi-target tracking algorithm, which utilizes spatiotemporal cooperative motion constraints. Our algorithm makes use of the cooperative effect of crowd movement, which means that objects in close range tend to move in a more consistent way. We group several objects with consistent mobility into a cluster. We introduce an affinity matrix to measure the synergy and similarity of the movement between targets in the same cluster. When the target is occluded, the affinity matrix can be used to recover the lost track. We evaluated our approach on the MOT challenge benchmark and proved its effectiveness.","1948-9447","979-8-3503-3472-2","10.1109/CCDC58219.2023.10326540","National Natural Science Foundation of China; Research and Development; State Key Laboratory of Robotics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10326540","Multi-Object Tracking;cluster cooperative motion constraint;motion state estimation","Target tracking;Sociology;Redundancy;Clustering algorithms;Feature extraction;Trajectory;Spatiotemporal phenomena","","","","23","IEEE","1 Dec 2023","","","IEEE","IEEE Conferences"
"Towards Understanding and Inferring the Crowd: Guided Second Order Attention Networks and Re-identification for Multi-object Tracking","N. Bhujel; L. Jun; Y. W. Yun; H. Wang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; the Institute for Infocomm Research, A*STAR, Singapore; the Institute for Infocomm Research, A*STAR, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","9999","10006","Multi-human tracking in the crowded environment is a challenging problem due to occlusions, pose change, viewpoint variation and cluttered background. In this work, we propose a robust feature learning for tracking-by-detection methods based on second-order attention network that can capture higher-order relationships between salient features at the early stages of Convolutional Neural Network (CNN). Guided Second-Order Attention Network (GSAN) that, unlike the existing attention learning methods which are weakly-supervised, uses a supervisory signal based on the quality of the self-learned attention maps. More specifically, GSAN looks into the attended maps of a person having the highest confidence and supervise itself to look into the correct regions in the images of the person. Attention maps learned this way are spatially aligned and thus robust to camera-view changes and body pose variations. We verify the effectiveness of our approach by comparing with the state-of-the-art methods on challenging person re-identification and multi object tracking (MOT) datasets.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341625","","Learning systems;Benchmark testing;Object tracking;Convolutional neural networks;Clutter;Intelligent robots;Faces","","1","","44","IEEE","10 Feb 2021","","","IEEE","IEEE Conferences"
"REGROUP: A Robot-Centric Group Detection and Tracking System","A. Taylor; L. D. Riek","Computer Science & Engineering, University of California, San Diego; Computer Science & Engineering, University of California, San Diego","2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","29 Sep 2022","2022","","","412","421","To facilitate HRI's transition from dyadic to group interaction, new methods are needed for robots to sense and understand team behavior. We introduce the Robot-Centric Group Detection and Tracking System (REGROUP), a new method that enables robots to detect and track groups of people from an ego-centric perspective using a crowd-aware, tracking-by-detection approach. Our system employs a novel technique that leverages person re-identification deep learning features to address the group data association problem. REGROUP is robust to real-world vision challenges such as occlusion, camera egomotion, shadow, and varying lighting illuminations. Also, it runs in real-time on real-world data. We show that REGROUP outperformed three group detection methods by up to 40% in terms of precision and up to 18 % in terms of recall. Also, we show that REGROUP's group tracking method outperformed three state-of-the-art methods by up to 66% in terms of tracking accuracy and 20% in terms of tracking precision. We plan to publicly release our system to support HRI teaming research and development. We hope this work will enable the development of robots that can more effectively locate and perceive their teammates, particularly in uncertain, unstructured environments.","","978-1-6654-0731-1","10.1109/HRI53351.2022.9889634","National Science Foundation(grant numbers:IIS-1734482,DGE-1650112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889634","human robot interaction;group detection;group tracking;social robot navigation;deep learning","Deep learning;Navigation;Robot vision systems;Lighting;Cameras;Real-time systems;Behavioral sciences","","3","","79","IEEE","29 Sep 2022","","","IEEE","IEEE Conferences"
"Dynamic Gallery for Real-Time Multi-Target Multi-Camera Tracking","Y. -S. Chou; C. -Y. Wang; M. -C. Chen; S. -D. Lin; H. -Y. M. Liao","Graduate Institute of Networking and Multimedia, National Taiwan University; Institute of Information Science, Academia Sinica; Department of Computer Science and Information Engineering, National Taitung University; Graduate Institute of Networking and Multimedia, National Taiwan University; Institute of Information Science, Academia Sinica","2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","25 Nov 2019","2019","","","1","8","For multi-target multi-camera recognition tasks, tracking of objects of interest is one of the essential yet challenging issues due to the fact that the task requires re-identifying identical targets across distinct views. Multi-target multi-camera tracking (MTMCT) applications span a wide range of variety (e.g. crowd behavior analysis, anomaly individual tracking and sport player tracking), so how to make the system perform real-time tracking becomes a crucial research issue. In this paper, we propose an online hierarchical algorithm for extreme clustering based MTMCT framework. The system can automatically create a dynamic gallery with real-time fashion by collecting appearance information of multi-object tracking in single-camera view. We evaluate the effectiveness and efficiency of our framework, and compare the state-of-the-art methods on MOT16 as well as DukeMTMC for single and multiple camera tracking. The high-frame-rate performance and promising tracking results confirm our system can be used in realworld applications.","2643-6213","978-1-7281-0990-9","10.1109/AVSS.2019.8909837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909837","","Target tracking;Cameras;Real-time systems;Task analysis;Object detection;Proposals;Clustering algorithms","","3","","24","IEEE","25 Nov 2019","","","IEEE","IEEE Conferences"
"Learning and Features based Customer Guidance Function for Application of Smart Autonomous Mover","C. -C. Lai; C. -P. Fan","Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan; Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan","2022 5th World Symposium on Communication Engineering (WSCE)","25 Oct 2022","2022","","","84","88","With the development of deep-learning technologies., the combined use of artificial intelligence and embedded platforms has become increasingly prevalent., and smart autonomous mover is a critical technology. How customers in a crowd can be identified has become a major issue. In this study, we employ deep learning and machine learning technologies to distinguish customers from noncustomers on an embedded platform. The customer guidance function for autonomous mover has two stages, including pre-registration and real-time customer tracking mode. The color space technology is used to compare the registered data of customer's clothes with data acquired by the autonomous mover. Furthermore, gender recognition and face recognition are performed through a classifier. After face, clothes, and gender recognition are conducted, the system identifies the target as a customer or noncustomer. By the proposed methodology, the customer tracking performance for accuracy, precision, recall, and Fl-score is 0.924, 0.999, 0.850, and 0.918, respectively.","","978-1-6654-5057-7","10.1109/WSCE56210.2022.9916025","Ministry of Science and Technology(grant numbers:109-2218-E-005-008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9916025","deep learning;color space;gender recognition;clothes recognition;face recognition;autonomous mover;embedded platform","Deep learning;Target tracking;Target recognition;Image color analysis;Face recognition;Space technology;Real-time systems","","","","9","IEEE","25 Oct 2022","","","IEEE","IEEE Conferences"
"R-CNN Model for the Traffic Signal Prediction","A. Kush; P. Soni","Department of Computer Science & Engineering, Chandigarh University, Mohali; Department of Computer Science & Engineering, Chandigarh University, Mohali","2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)","28 Mar 2023","2022","","","1145","1148","The density of crowd is less and the congestion speed is high, the system assumes that there is light congestion in the traffic. In intermediary conditions, traffic is characterized as moderately congested. The subsequent process introduces the process of estimating crowd density and vehicular speed on the premise of crowd segmentation and tracking. The traffic sign prediction techniques have certain steps. The deep learning model is applied for the prediction. The R-CNN is the deep learning which is the transform learning for the prediction of traffic signal. This project implements the new approach in Python software and evaluates it taking into account several performance measures.","","978-1-6654-7436-8","10.1109/ICAC3N56670.2022.10074076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074076","traffic signal;feature extraction;R-CNN;deep learning","Deep learning;Support vector machines;Shape;Computational modeling;Computer architecture;Transforms;Predictive models","","","","14","IEEE","28 Mar 2023","","","IEEE","IEEE Conferences"
"Anomaly and Activity Recognition Using Machine Learning Approach for Video Based Surveillance","A. Mohan; M. Choksi; M. A. Zaveri","Computer Engineering Department, Sardar Vallabhbhai National Institute of Technology, Surat, India; Computer Engineering Department, Sardar Vallabhbhai National Institute of Technology, Surat, India; Computer Engineering Department, Sardar Vallabhbhai National Institute of Technology, Surat, India","2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","30 Dec 2019","2019","","","1","6","In the current era, the majority of public places such as supermarket, public garden, mall, university campus, etc. are under video surveillance. There is a need to provide essential security and monitor unusual anomaly activities at such places. The major drawback in the traditional approach, that there is a need to perform manual operation for 24 * 7 and also there are possibilities of human errors. This paper focuses on anomaly detection and activity recognition of humans in the videos. The anomaly detection system uses principal component analysis network (PCANet) and Convolutional Neural Network (CNN) to solve the problems of manual operation such as the false alarms, missing of anomalous events and locating the position of an anomaly in the video. The frames wise abnormal event is detected using principal component analysis and Support Vector Machines (SVM) classifier. The location of the abnormality in a frame is detected using Convolutional Neural Network.","","978-1-5386-5906-9","10.1109/ICCCNT45670.2019.8944396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944396","Video Surveillance;Activity Recognition;Machine Learning;Anomaly Detection","Feature extraction;Machine learning;Support vector machines;Event detection;Video surveillance;Integrated optics","","12","2","24","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"Pedestrian Detection and Feedback Application Based on YOLOv5s and DeepSORT","L. Ling; J. Tao; G. Wu","School of Artificial Intelligence, Jianghan University, Wuhan; School of Artificial Intelligence, Jianghan University, Wuhan; Educational Administration Office, Jianghan University, Wuhan","2022 34th Chinese Control and Decision Conference (CCDC)","14 Feb 2023","2022","","","5716","5721","To solve the problem of low counting efficiency of people flow supervision in scenic spots and cities, an improved YOLOv5s detection method combined with DeepSORT target tracking is proposed. As the accuracy of DeepSORT multi-target tracking depends on the detection efficiency of the target detection algorithm, the attention module CBAM is integrated with the Neck part of YOLOv5s network to improve the ability of the target detection model to extract small object features, thereby improving the recognition ability. The Market-1501 data set is used to train the pedestrian re-id model, and the images containing pedestrians in the VOC data set are used as the training set to train the detection model so that the model only detects pedestrians. Finally, connect the improved YOLOv5s detector and DeepSORT, and set a virtual detection line in the video to count the flow of people. The experimental results show that the average accuracy of the improved YOLOv5s is 1% higher than that of the original algorithm, and combined with DeepSORT tracking, the detection rate of 34 frames is achieved in the test video.","1948-9447","978-1-6654-7896-0","10.1109/CCDC55256.2022.10033779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10033779","YOLOv5;DeepSORT;Attention mechanism;Target detection;Crowd counting","Training;Target tracking;Target recognition;Urban areas;Object detection;Detectors;Feature extraction","","4","","24","IEEE","14 Feb 2023","","","IEEE","IEEE Conferences"
"Covid-19 crowd detection and alert system using image processing","N. Lodha; H. Singh Gahlaut","Dept. of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India; Dept. of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India","2023 International Conference on Advances in Intelligent Computing and Applications (AICAPS)","27 Mar 2023","2023","","","1","5","In this paper, we aim to help in identifying the people that are violating social distancing norms set by the government (necessary during the COVID-19 pandemic in public places), by providing an efficient real-time deep learning-based framework to automate the process of monitoring the social distancing via object detection and tracking approaches. Our system is divided into two subsystems: one that deals with crowd detection and control, and the other that sends information to the police authorities. Our system technologies, including as IoT, image processing, web cams, BLE, OpenCV, and Cloud, are being considered for inclusion in the proposed framework. The image processing is divided into two sections, the first of which is the extraction of frames from real-time movies, and the second of which is the processing of the frame to determine the number of individuals in the crowd. Even in a crowd, dissemination may be restricted if people adhere to social distancing standards. As a result, the image processing model primarily targets the number of people who do not adhere to social distancing norms and stand too close together.","","979-8-3503-3381-7","10.1109/AICAPS57044.2023.10074221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10074221","IOT;UbiBots;image processing;vectorization;machine learning","COVID-19;Protocols;Webcams;Image processing;Human factors;Object detection;Social factors","","","","15","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"ViewBirdiformer: Learning to Recover Ground-Plane Crowd Trajectories and Ego-Motion From a Single Ego-Centric View","M. Nishimura; S. Nobuhara; K. Nishino","OMRON SINIC X Corporation, Tokyo, Japan; Kyoto University, Kyoto, Japan; Kyoto University, Kyoto, Japan","IEEE Robotics and Automation Letters","9 Dec 2022","2023","8","1","368","375","We introduce a novel learning-based method for view birdification [1], the task of recovering ground-plane trajectories of pedestrians of a crowd and their observer in the same crowd just from the observed ego-centric video. View birdification becomes essential for mobile robot navigation and localization in dense crowds where the static background is hard to see and reliably track. It is challenging mainly for two reasons; i) absolute trajectories of pedestrians are entangled with the movement of the observer which needs to be decoupled from their observed relative movements in the ego-centric video, and ii) a crowd motion model describing the pedestrian movement interactions is specific to the scene yet unknown a priori. For this, we introduce a Transformer-based network referred to as ViewBirdiformer which implicitly models the crowd motion through self-attention and decomposes relative 2D movement observations onto the ground-plane trajectories of the crowd and the camera through cross-attention between views. Most important, ViewBirdiformer achieves view birdification in a single forward pass which opens the door to accurate real-time, always-on situational awareness. Extensive experimental results demonstrate that ViewBirdiformer achieves accuracy similar to or better than state-of-the-art with three orders of magnitude reduction in execution time.","2377-3766","","10.1109/LRA.2022.3221335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944870","Human Detection and Tracking;Localization;Deep Learning for Visual Perception","Trajectory;Cameras;Observers;Three-dimensional displays;Transformers;Simultaneous localization and mapping;Dynamics","","2","","37","IEEE","10 Nov 2022","","","IEEE","IEEE Journals"
"FRoG-MOT: Fast and Robust Generic Multiple-Object Tracking by IoU and Motion-State Associations","T. Ogawa; T. Shibata; T. Hosoi",NEC Corporation; NEC Corporation; NEC Corporation,"2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","9 Apr 2024","2024","","","6549","6558","This paper proposes a generic multi-object tracking (MOT) algorithm that is robust to unexpected motion changes for generic objects. Deep learning has dramatically been improving MOT performances. Nevertheless, state-of-the-art tracking algorithms are still sensitive to unexpected motion changes and the generic object target beyond person tracking. This is because standard MOT benchmark datasets such as MOT17 mainly consist of persons in a crowd, often lacking unexpected shape and motion changes; thus, these issues have yet to be focused on. We propose a simple-yet-effective MOT framework that can dynamically improve tracking continuity by associating each target based on adaptively modified motion states. The keys are 1) to represent the target motions using multiple motion states that have weak correlations with each other and 2) to modify those states that have the lowest similarity to past states as outliers. Our approach can improve trajectory continuity and robustness to unexpected motion changes for generic objects. Comprehensive experiments have confirmed that our framework is comparable to existing state-of-the-art methods on a standard dataset and outperforms those algorithms on the GMOT dataset with an overall 2% improvement in IDF1, a measure of tracking continuity.","2642-9381","979-8-3503-1892-0","10.1109/WACV57701.2024.00643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10483947","Algorithms;Video recognition and understanding;Algorithms;Machine learning architectures;formulations;and algorithms","Deep learning;Computer vision;Target tracking;Correlation;Shape;Benchmark testing;Robustness","","","","55","IEEE","9 Apr 2024","","","IEEE","IEEE Conferences"
"Enhancing Real-Time Human Tracking using YOLONAS-DeepSort Fusion Models","R. Athilakshmi; P. S. Chandan Sainagakrishna; S. S. Chaitanya Chowdary Kota; M. C. Kiran Teja; T. Venkatesh; V. J. Prasad","Department of Computational Intelligence, Faculty of Engineering and Technology, SRM Institute of Science and Technology, KTR Campus, Chennai, India; Department of Computational Intelligence, Faculty of Engineering and Technology, SRM Institute of Science and Technology, KTR Campus, Chennai, India; Department of Computational Intelligence, Faculty of Engineering and Technology, SRM Institute of Science and Technology, KTR Campus, Chennai, India; Department of Computational Intelligence, Faculty of Engineering and Technology, SRM Institute of Science and Technology, KTR Campus, Chennai, India; Department of Computational Intelligence, Faculty of Engineering and Technology, SRM Institute of Science and Technology, KTR Campus, Chennai, India; Department of Information Technology, MNM Jain Engineering College, Thoraipakkam, Chennai, India","2023 7th International Conference on Electronics, Communication and Aerospace Technology (ICECA)","9 Feb 2024","2023","","","1118","1125","Real-time human detection and tracking are dynamic research domains within the computer vision community. While human detection has made significant advancements in recent years, the challenge of detecting humans in highly crowded environments, especially in the presence of occlusions, remains largely unresolved. Over the years, various methods for real-time human detection and tracking have garnered significant attention due to their extensive applications in crime detection, people counting, public event management, disaster management, safety monitoring, and more. In this proposed research, we employ YOLONAS (You Look Only Once Neural Architecture Structure) for the detection and localization of objects within images or video frames of the benchmark crowd-based datasets. Subsequently, we utilize the DeepSORT (Deep Simple Online and Real-time Tracking) algorithm to track objects across frames in video sequences. The research also involves a comparison of the performance of the proposed approach on different datasets, including COCO-Persons, Football Players Image, and CityPersons. Hence, the combination of YOLONAS and Deepsort is a powerful architecture for detecting and tracking humans and achieved above 90% detection accuracy on all the datasets. Experiments were conducted on the Jetson Nano Developer Kit, showcasing the system's ability to process high-resolution sensors and run multiple neural networks simultaneously. The proposed system demonstrates outstanding performance, surpassing state-of-the-art methods in small object detection, localization accuracy, post-training quantization, and real-time edge-device application.","","979-8-3503-4060-0","10.1109/ICECA58529.2023.10394864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10394864","YOLONAS;DeepSORT;COCO-Persons;Object detection;Object tracking","Location awareness;Computer vision;Computational modeling;Computer architecture;Streaming media;Real-time systems;Task analysis","","","","23","IEEE","9 Feb 2024","","","IEEE","IEEE Conferences"
"Monitoring of the Social Distance between Passengers in Real-time through Video Analytics and Deep Learning in Railway Stations for Developing the Highest Efficiency","A. M. Arul Raj.; R. Sugumar","Department of Computer and Science and Engineering, Saveetha School of Engineering (SSE) Saveetha Institute of Medical And Technical Sciences (SIMATS) Saveetha University, Chennai, India; Department of Computer and Science and Engineering, Saveetha School of Engineering (SSE) Saveetha Institute of Medical And Technical Sciences (SIMATS) Saveetha University, Chennai, India","2022 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)","2 Feb 2023","2022","01","","1","7","Near the end of December 2019, the globe was hit with a major crisis, which is nothing but the coronavirus-based pandemic. The authorities at the train station should also keep in mind the need to limit the spread of the covid virus in the event of a global pandemic. When it comes to controlling the COVID-19 epidemic, public transportation facilities like train stations play a pivotal role because of the proximity of so many people who may be exposed to the virus. Using common place CCTV cameras and deep learning with simple online and real-time (DeepSORT) methods, this study develops social distance monitoring using a YOLOv4 identification of a Surveillance Object Model. Based on experiments conducted with a minicomputer equipped with an Intel 11th Gen Intel(R) Core(TM) i3-1115G4 at 3.00GHz, 2995 Mhz, two Core(s), four Logical processor, four gigabytes of random-access memory (RAM), this paper makes use of CCTV surveillance, which was put into practice at the Guindy railway station, Chennai, Tamilnadu in India in order to detect the violation of social distancing.","","979-8-3503-3384-8","10.1109/ICDSAAI55433.2022.10028930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10028930","closed-circuit television;COVID-19;deep learning technology;crowd surveillance.","Deep learning;COVID-19;Visual analytics;Surveillance;Human factors;Cameras;Social factors","","2","","25","IEEE","2 Feb 2023","","","IEEE","IEEE Conferences"
"Video Processing Using Deep Learning Techniques: A Systematic Literature Review","V. Sharma; M. Gupta; A. Kumar; D. Mishra","Centre for Development of Advanced Computing (C-DAC), Pune, India; Department of Computer Science, DST-Center for Interdisciplinary Mathematical Sciences, Institute of Science, Banaras Hindu University, Varanasi, India; Centre for Development of Advanced Computing (C-DAC), Pune, India; Department of Computer Science (IDI), Norwegian University of Science and Technology (NTNU), Gjøvik, Norway","IEEE Access","19 Oct 2021","2021","9","","139489","139507","Studies show lots of advanced research on various data types such as image, speech, and text using deep learning techniques, but nowadays, research on video processing is also an emerging field of computer vision. Several surveys are present on video processing using computer vision deep learning techniques, targeting specific functionality such as anomaly detection, crowd analysis, activity monitoring, etc. However, a combined study is still unexplored. This paper aims to present a Systematic Literature Review (SLR) on video processing using deep learning to investigate the applications, functionalities, techniques, datasets, issues, and challenges by formulating the relevant research questions (RQs). This systematic mapping includes 93 research articles from reputed databases published between 2011 and 2020. We categorize the deep learning technique for video processing as CNN, DNN, and RNN based. We observe significant advancements in video processing between 2017 and 2020, primarily due to the advent of AlexNet, ResNet, and LSTM based deep learning techniques. The prominent fields of video processing research are observed as human action recognition, crowd anomaly detection, and behavior analysis. This SLR is a helpful guide for the researchers to explore the recent literature, available datasets, and existing deep learning techniques for video processing.","2169-3536","","10.1109/ACCESS.2021.3118541","Norwegian University of Science and Technology, Gjøvik, Norway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9563948","Video processing;computer vision;artificial intelligence;deep learning;human action recognition;systematic literature review","Deep learning;Systematics;Bibliographies;Face recognition;Convolutional neural networks;Computer vision;Anomaly detection","","34","","134","CCBY","7 Oct 2021","","","IEEE","IEEE Journals"
"Population Density Estimation using Single Shot Detection Algorithm","G. L. Miraclin; K. Raimond; I. K. Beulah","Dept. of Computer Science and Engineering (Bachelor’s of Technology), Karunya Institute of Technology and Sciences (Deemed to be University), Coimbatore, India; Dept. of Computer Science and Engineering (Bachelor’s of Technology), Karunya Institute of Technology and Sciences (Deemed to be University), Coimbatore, India; Dept. of Computer Science and Engineering (Bachelor’s of Technology), Karunya Institute of Technology and Sciences (Deemed to be University), Coimbatore, India","2023 International Conference on Sustainable Computing and Smart Systems (ICSCSS)","7 Jul 2023","2023","","","695","699","The proposed system consists of an Artificial Intelligent software that is capable of counting the number of people from the user inputs such as images and video frames more accurately. The system uses the advanced MobileNet Single Shot Detection algorithm to detect the human class in the given frame at the given moment. The count of individuals in the frame is dependent on the threshold set by the end-user. The primary goal of the application is to provide an easy-to-use and efficient tool for analyzing images and videos. The model used for object detection is trained on the mall dataset from Kaggle website and is capable of accurately detecting people in real-time, making it suitable for a wide range of applications. The people in the frame are tracked using centroid tracker algorithm, and the tracked classes are counted. The detection algorithm is built using the popular library keras for its versatile usage. This system uses Keras, a high-level deep learning library, and OpenCV, a computer vision library, to perform real-time people counting. The system utilizes object detection algorithms to detect and track individuals, and then increments a count each time a person crosses a designated line. The system is capable of handling multiple people simultaneously and accurately counting them in real-time.","","979-8-3503-3360-2","10.1109/ICSCSS57650.2023.10169157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10169157","Crowd Counting;Open CV;Deep Learning","Training;Sociology;Object detection;Streaming media;Feature extraction;Real-time systems;Libraries","","","","27","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"AerialMPTNet: Multi-Pedestrian Tracking in Aerial Imagery Using Temporal and Graphical Features","M. Kraus; S. M. Azimi; E. Ercelik; R. Bahmanyar; P. Reinartz; A. Knoll","Department of Informatics, Technical University of Munich, Munich, Germany; Department of Aerospace, Aeronautics and Geodesy, Technical University of Munich, Munich, Germany; Department of Informatics, Technical University of Munich, Munich, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute, German Aerospace Center (DLR), Wessling, Germany; Department of Informatics, Technical University of Munich, Munich, Germany","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","2454","2461","Multi-pedestrian tracking in aerial imagery has several applications such as large-scale event monitoring, disaster management, search-and-rescue missions, and as input into predictive crowd dynamic models. Due to the challenges such as the large number and the tiny size of the pedestrians (e.g., 4 × 4 pixels) with their similar appearances as well as different scales and atmospheric conditions of the images with their extremely low frame rates (e.g., 2 fps), current state-of-the-art algorithms including the deep learning-based ones are unable to perform well. In this paper, we propose AerialMPTNet, a novel approach for multi-pedestrian tracking in geo-referenced aerial imagery by fusing appearance features from a Siamese Neural Network, movement predictions from a Long Short-Term Memory, and pedestrian interconnections from a GraphCNN. In addition, to address the lack of diverse aerial pedestrian tracking datasets, we introduce the Aerial Multi-Pedestrian Tracking (AerialMPT) dataset consisting of 307 frames and 44,740 pedestrians annotated. We believe that AerialMPT is the largest and most diverse dataset to this date and will be released publicly. We evaluate AerialMPTNet on AerialMPT and KIT AIS, and benchmark with several state-of-the-art tracking methods. Results indicate that AerialMPTNet significantly outperforms other methods on accuracy and time-efficiency.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9413031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413031","","Image quality;Tracking;Atmospheric modeling;Neural networks;Predictive models;Prediction algorithms;Trajectory","","2","","32","IEEE","5 May 2021","","","IEEE","IEEE Conferences"
"Video Surveillance System in Bank for Analysis of Sentiment, Objects and Crowd Detection using Deep Learning","K. S. Wagh; C. Agarwal; R. Pathan; S. Pathare; M. Sayed","Department of Computer Science, AISSMS IOIT, Aft. by NAAC, Pune, India; Department of Computer Science, AISSMS IOIT, Aft. by NAAC, Pune, India; Department of Computer Science, AISSMS IOIT, Aft. by NAAC, Pune, India; Department of Computer Science, AISSMS IOIT, Aft. by NAAC, Pune, India; Department of Computer Science, AISSMS IOIT, Aft. by NAAC, Pune, India","2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC)","8 Jun 2023","2023","","","911","919","Bank is using video cameras for the purpose of surveillance at many branches, ATM's and digital lobbies. Getting video analytics of different parameters from the video recording will help the bank to resolve many operational issues at the branches. The bank desires to explore video analytics for understand the customer sentiments, recognize the patterns /behaviors/movements in sure branches for proactive surveillance and provide better offerings to customers. The system can be utilized by banks, department shops, restaurants, schools, etc. The web based gadget takes video enter at a sure frequency and analyzes primarily based upon deep mastering algorithms and is expected to enhance the specificity and efficiency of information furnished at the portal. The average accuracy of the whole system is about 60–70 percentage including individual working and result of all algorithms.","","978-1-6654-5630-2","10.1109/ICAAIC56838.2023.10140538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10140538","Video analytics;classification;prediction;training;K-nearest neighbor;Convolutional neural network;VADER Algorithm;Random Forest Algorithm","Support vector machines;Visual analytics;Clustering algorithms;Process control;Video surveillance;Pattern recognition;Security","","1","","24","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"DensePeds: Pedestrian Tracking in Dense Crowds Using Front-RVO and Sparse Features","R. Chandra; U. Bhattacharya; A. Bera; D. Manocha",University of Maryland; University of Maryland; University of North Carolina; University of Maryland,"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","468","475","We present a pedestrian tracking algorithm, DensePeds, that tracks individuals in highly dense crowds (>2 pedestrians per square meter). Our approach is designed for videos captured from front-facing or elevated cameras. We present a new motion model called Front-RVO (FRVO) for predicting pedestrian movements in dense situations using collision avoidance constraints and combine it with state-of-the-art Mask R-CNN to compute sparse feature vectors that reduce the loss of pedestrian tracks (false negatives). We evaluate DensePeds on the standard MOT benchmarks as well as a new dense crowd dataset. In practice, our approach is 4.5 × faster than prior tracking algorithms on the MOT benchmark and we are state-of-the-art in dense crowd videos by over 2.6% on the absolute scale on average.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8968470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968470","","","","12","","48","IEEE","28 Jan 2020","","","IEEE","IEEE Conferences"
"A Comprehensive Survey of Machine Learning Methods for Surveillance Videos Anomaly Detection","N. Choudhry; J. Abawajy; S. Huda; I. Rao","Faculty of Science, Engineering and Built Environment, Deakins University, Burwood VIC, Australia; Faculty of Science, Engineering and Built Environment, Deakins University, Burwood VIC, Australia; Faculty of Science, Engineering and Built Environment, Deakins University, Burwood VIC, Australia; Blue Brackets Technologies, Islamabad, Pakistan","IEEE Access","20 Oct 2023","2023","11","","114680","114713","Video Surveillance Systems (VSSs) are used in a wide range of applications including public safety and perimeter security. They are deployed in places such as markets, hospitals, schools, banks, shopping malls, offices, and smart cities. VSSs generate a massive amount of surveillance data, and significant research has been published on the use of machine learning algorithms to handle surveillance data. In this paper, we present an extensive overview and a thorough analysis of cutting-edge learning methods used in VSSs. Existing surveys on learning approaches in video surveillance have some drawbacks, such as a lack of in-depth analysis of the learning algorithms, omission of certain methodologies, insufficient critical evaluation, and absence of recent learning algorithms. To fill these gaps, this survey provides a thorough examination of the most recent learning algorithms for anomaly detection. A critical assessment of the algorithms including their strengths, weaknesses, and applicability as well as tailored classifications of anomaly types for different domains are provided. Our study also offers insights into the future development of learning techniques in VSS, positioning itself as a valuable resource for both researchers and practitioners in the field. Finally, we share our thoughts on what we learned and how it can help with new developments in the future.","2169-3536","","10.1109/ACCESS.2023.3321800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271300","Machine learning;anomaly detection;video surveillance systems;supervised learning methods;unsupervised learning methods;semi-supervised learning methods","Videos;Anomaly detection;Surveys;Behavioral sciences;Deep learning;Transformers;Forensics;Machine learning;Surveillance;Supervised learning;Unsupervised learning;Semisupervised learning","","","","232","CCBYNCND","4 Oct 2023","","","IEEE","IEEE Journals"
"An Aerial Crowd-Flow Analyzing System for Drone Under YOLOv5 and StrongSort","K. -H. Yeh; I. -C. Hsu; Y. -Z. Chou; G. -Y. Chen; Y. -S. Tsai","department of computer science and engineering, National Taiwan Ocean University, Keelung City, Taiwan; department of computer science and engineering, National Taiwan Ocean University, Keelung City, Taiwan; department of computer science and engineering, National Taiwan Ocean University, Keelung City, Taiwan; department of computer science and engineering, National Taiwan Ocean University, Keelung City, Taiwan; Department of computer science and engineering, National Taiwan Ocean University, Keelung City, Taiwan","2022 International Automatic Control Conference (CACS)","7 Dec 2022","2022","","","1","6","Crowd detection has recently been a critical issue in machine vision. In response to the recent epidemics' impact, people tend to avoid crowded places, such as markets and bazaars. Crowd analysis can significantly solve this issue and help epidemic prevention. In this study, we proposed a deep learning-based crowd-tracking system using YOLOv5 with StrongSort and OSNet for detection and analyzing the obtained data, such as crowd tracking, counting and plotting crowd trajectories, and motion maps, and hotspot maps to analyze crowding levels. Regarding data training, we use LabelGo for semi-automatic annotation and training. We also tested the size of the pixels that can detect the smallest object (1.0 x 20.0 pixels) and the effect of the number of people on the screen on the time we spent detecting, tracking, and plotting. The detection, tracking, and plotting time is less than 3 seconds for a crowd of more than 100 people, so the results can be presented quickly.","","978-1-6654-9646-9","10.1109/CACS55319.2022.9969785","Ministry of Science and Technology(grant numbers:110-2634-F-A49-006,110-2634-F-009-018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9969785","","Training;Epidemics;Target tracking;Annotations;Machine vision;Trajectory;Safety","","1","","20","IEEE","7 Dec 2022","","","IEEE","IEEE Conferences"
"Collision-Line Counting Method Using DeepSORT to Count Pedestrian Flow Density and Hungary Algorithm","Y. Pei; H. Liu; Q. Bei","School of Electrical Engineering and Automation, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; School of Electrical Engineering and Automation, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; School of Electrical Engineering and Automation, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China","2021 IEEE 3rd International Conference on Civil Aviation Safety and Information Technology (ICCASIT)","10 Dec 2021","2021","","","621","626","With the great success of deep learning in the field of machine vision, crowd density statistics based on machine vision have become more and more important in today's world. In order to calculate the density of people flow in a certain area, this paper combines the YOLOv4 objective detection algorithm and the DeepSORT multi-objective tracking algorithm, and uses the Kalman filter algorithm and the Hungarian algorithm for trajectory prediction and data association. And it is proposed to carry out density statistics through the Collision-line counting method. This method uses the ID information and trajectory information of pedestrians in the objective tracking process to count the number of people and directions passing through a certain set line segment, and indirectly count the density of pedestrian flow in the corresponding area. This method can also be used in conjunction with multiple cameras at multiple entrances and exits in a certain area, and has the characteristics of flexible operation and high precision. In addition, this method can also be used to detect traffic flow.","","978-1-6654-2518-6","10.1109/ICCASIT53235.2021.9633356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633356","YOLOv4;Kalman filter;Hungary algorithm;DeepSORT","Switches;Object segmentation;Filtering algorithms;Prediction algorithms;Information filters;Trajectory;Safety","","1","","16","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"Drone Vision and Deep Learning for Infrastructure Inspection","I. Pitas","Department of Informatics, Artificial Intelligence and Information Analysis (AIIA) Lab, Aristotle University of Thessaloniki (AUTH), Greece","2021 IEEE International Conference on Autonomous Systems (ICAS)","6 Oct 2021","2021","","","1","1","This lecture overviews the use of drones for infrastructure inspection and maintenance. Various types of inspection, e.g., using visual cameras, LIDAR or thermal cameras are reviewed. Drone vision plays a pivotal role in drone perception/control for infrastructure inspection and maintenance, because: a) it enhances flight safety by drone localization/mapping, obstacle detection and emergency landing detection; b) performs quality visual data acquisition, and c) allows powerful drone/human interactions, e.g., through automatic event detection and gesture control. The drone should have: a) increased multiple drone decisional autonomy and b) improved multiple drone robustness and safety mechanisms (e.g., communication robustness/safety, embedded flight regulation compliance, enhanced crowd avoidance and emergency landing mechanisms). Therefore, it must be contextually aware and adaptive. Drone vision and machine learning play a very important role towards this end, covering the following topics: a) semantic world mapping b) drone and target localization, c) drone visual analysis for target/obstacle/crowd/point of interest detection, d) 2D/3D target tracking. Finally, embedded on-drone vision (e.g., tracking) and machine learning algorithms are extremely important, as they facilitate drone autonomy, e.g., in communication-denied environments. Primary application area is electric line inspection. Line detection and tracking and drone perching are examined. Human action recognition and co-working assistance are overviewed.The lecture will offer: a) an overview of all the above plus other related topics and will stress the related algorithmic aspects, such as: b) drone localization and world mapping, c) target detection d) target tracking and 3D localization e) gesture control and co-working with humans. Some issues on embedded CNN and fast convolution computing will be overviewed as well.","","978-1-7281-7289-7","10.1109/ICAS49788.2021.9551136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551136","","Location awareness;Visualization;Target tracking;Three-dimensional displays;Target recognition;Inspection;Maintenance engineering","","3","","0","IEEE","6 Oct 2021","","","IEEE","IEEE Conferences"
"Human Detection in crowd using One-stage and Two-stage object detection models","V. N. Rajeshirke; S. C. N.","Department of Computing Technologies, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India; Department of Computing Technologies, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India","2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)","23 Nov 2023","2023","","","1","5","Object detection has various uses for recognition, detection, and tracking. Detecting humans in crowded low-quality images is an emerging topic and is a difficult task. In this paper, different object detection are compared for our purpose. Here we use the two models - YOLO and Faster R-CNN and test their working for human detection on low-quality images. We take a low-quality image collection and utilize pre-processing techniques to improve its quality. Using the same experimental setting, we build YOLO and Faster R-CNN and evaluate their results based on accuracy and speed. After comparing the results it shows that in terms of detection speed, YOLO outperforms Faster R-CNN. And YOLO lags than Faster R-CNN when it comes to accuracy. Further we also discuss the advantages and disadvantages of using these models and which is best suited for the scenario we intend to work on. Our findings give useful insights for the development of low-quality image object detection systems for accurate human detection in crowded images, with practical implications for a variety of applications.","2473-7674","979-8-3503-3509-5","10.1109/ICCCNT56998.2023.10307765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10307765","Crowd detection;Deep Learning;Faster R-CNN;low-resolution images;object detection;YOLO","Training;Image resolution;Hardware;Task analysis;Testing","","","","18","IEEE","23 Nov 2023","","","IEEE","IEEE Conferences"
"Abnormal Behavior Detection in Crowd Scene Using YOLO and Conv-AE","L. Yajing; D. Zhongjian","Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","1720","1725","This paper proposes a weighted convolutional autoencoder (Conv-AE) and a novel regularity score based on the results of You Only Look Once (YOLO) network to detect abnormal behavior in crowd scenarios. The weighted Conv-AE extracts spatial features of video frames. In the training process, a weighted loss function is proposed based on the YOLO detection results, which emphasizes the foreground part, and thus overcomes the impact of complex background. In addition, a novel regularity score is put forward in the anomaly detection process. The regularity score takes into account the three factors of reconstruction errors obtained from weighted Conv-AE, speed information and category of objects detected by YOLO. Three scores respectively based on these factors are integrated to obtain anomaly detection results. The experimental results on UCSD ped1 and ped2 dataset verify that the proposed method achieves better performance than the most of semi-supervised methods.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9602095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602095","abnormal behavior detection;You Only Look Once (YOLO);convolutional autoencoder (Conv-AE);weighted loss function","Training;Feature extraction;Anomaly detection","","2","","26","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Finding Common Image Semantics for Urban Perceived Safety Based on Pairwise Comparisons","G. Costa; C. Soares; M. Marques","Institute for Systems and Robotics Instituto Superior Tecnico, Lisbon, Portugal; Institute for Systems and Robotics Instituto Superior Tecnico, Lisbon, Portugal; Institute for Systems and Robotics Instituto Superior Tecnico, Lisbon, Portugal","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","What influences people’s perception of safety in an urban environment? Does everyone perceive safety the same way or do different people look for different contents in an image, safety-wise? We present a user analysis on a crowd-sourced dataset that contains pairwise comparisons regarding the perceived safety of street imagery from different municipalities in the greater Lisbon area, Portugal. We use state-of-the-art semantic segmentation to extract the contents of images and cluster different people according to what they perceive as safe. Then, we study semantic classes and analyze clusters of users for semantic elements appearing in images classified as safer (or more dangerous). The results show that clusters share a lot of similarities. Our analysis evidences that, for users with more pairwise comparisons, there is only one group, while spurious groupings appear when users contribute less. This result emphasizes that a pairwise image comparison dataset potentiates agreement of users in perceptual tasks, for moderate comparison data size.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903115","Urban perceived safety;Semantic urban segmentation;Crowd-sourced perceptual dataset;Pairwise comparisons.","Semantics;Safety;Image segmentation;Europe;Signal processing;Couplings;Robots","","","","21","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Target Detection and Tracking for Vehicles in Tourist Sites Based on Image Recognition","X. Fang","Wuxi Vocational Institute of Commerce, Wuxi, China","2023 2nd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE)","21 Feb 2024","2023","","","253","258","With the popularization of autonomous vehicles, reliable environment sensing and target recognition are the key to safe navigation of autonomous vehicles in locations with high human and vehicular traffic and many obstacles, such as tourist attractions. This study develops an optimized deep learning model for accurate detection and tracking of pedestrians and objects in complex tourist site environments based on image recognition. The model enhances the feature extraction capability of convolutional neural networks by incorporating an improved scene similarity perception module. A compact parallax map depth representation is utilized to identify targets and motion trajectories. The model is validated on a tourist site dataset and shows superior performance in dense crowd scenarios compared to existing methods. The reliable identification of pedestrians, vehicles and obstacles in various lighting and weather conditions ensures the safe navigation of autonomous vehicles and protects tourist safety.","","979-8-3503-3144-8","10.1109/CBASE60015.2023.10439101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439101","Tourism Safety;Traffic information Recognition;Target detection;Automatic control","Target tracking;Image recognition;Target recognition;Semantic segmentation;Semantics;Trajectory;Autonomous vehicles","","","","14","IEEE","21 Feb 2024","","","IEEE","IEEE Conferences"
"On the Fine-Grained Crowd Analysis Via Passive WiFi Sensing","L. Hao; B. Huang; B. Jia; G. Mao","Engineering Research Center of Ecological Big Data, Ministry of Education, the Inner Mongolia A.R. Key Laboratory of Wireless Networking and Mobile Computing, College of Computer Science, Inner Mongolia University, Hohhot, China; Engineering Research Center of Ecological Big Data, Ministry of Education, the Inner Mongolia A.R. Key Laboratory of Wireless Networking and Mobile Computing, College of Computer Science, Inner Mongolia University, Hohhot, China; Engineering Research Center of Ecological Big Data, Ministry of Education, the Inner Mongolia A.R. Key Laboratory of Wireless Networking and Mobile Computing, College of Computer Science, Inner Mongolia University, Hohhot, China; Research Institute of Smart Transportation, Xidian University, Xi'an, China","IEEE Transactions on Mobile Computing","","2023","PP","99","1","15","Regarding the passive WiFi sensing based crowd analysis, this paper first theoretically investigates its limitations, and then proposes a deep learning based scheme targeted for returning fine-grained crowd states in large surveillance areas. To this end, three key challenges are coped with: to relieve the influences of the randomness and sparsity induced by passive WiFi sensing, an attention-based deep convolutional autoencoder model is designed to recover accurate crowd density maps in a way similar to image reconstruction; to combat the anonymity caused by MAC randomization, following the identification of local high-density crowds (LHDCs) with the density clustering algorithm, i.e. DM-DBSCAN, a bidirectional convolutional LSTM based model is employed to infer LHDC speeds; to overcome the absence of passive WiFi sensing datasets for model training, three semi-synthetic datasets are produced by emulating passive WiFi sensing with practical pedestrian tracking datasets. Extensive experiments confirm that, the proposed scheme significantly outperforms existing WiFi-based methods in terms of crowd density estimation and provides superior crowd speed estimation. More importantly, the scheme can also produce consistent crowd states on a real-world dataset, revealing that it has the ability to support accurate, visualized and real-time crowd monitoring in large surveillance areas.","1558-0660","","10.1109/TMC.2023.3324334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10285068","Crowd analysis;crowd density regression;dataset;passive WiFi sensing;speed estimation","Wireless fidelity;Sensors;Estimation;Surveillance;Pedestrians;Mobile computing;Location awareness","","","","","IEEE","13 Oct 2023","","","IEEE","IEEE Early Access Articles"
"Detection and Tracking the Criminal Activity using Network of CCTV cameras","N. Y. Katkar; V. K. Garg","School Of Computer Science and Engineering, Lovely Professional University, Phagwara, Punjab, India; School Of Computer Science and Engineering, Lovely Professional University, Phagwara, Punjab, India","2022 3rd International Conference on Smart Electronics and Communication (ICOSEC)","22 Nov 2022","2022","","","664","668","In recent years, the number of troublesome people with provocative behaviour has been increased. This necessitates the need to increase the public security. CCTV cameras are gradually being deployed on streets, banks, and other areas to protect people’s safety in public areas like shopping malls. Since it is practically impossible to continuously monitor the security cameras, the crowd monitoring system must be computerized with high accuracy. Moreover, if a criminal is running, it is difficult to detect and track down by only using the capture CCTV image is a time-consuming process. To solve these challenges, the proposed system will scan real-time CCTV surveillance footage and use criminal reference information to identify the criminals. To recognize the uniqueness, it is highly required to precisely automate this activity. It is also necessary to show which frames and sections of the recording contain the unexpected behaviour.","","978-1-6654-9764-0","10.1109/ICOSEC54921.2022.9952104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952104","Criminal Activity;CNN;LSTM;Classification;Detection","Target tracking;Terrorism;Surveillance;Cameras;Real-time systems;Safety;Behavioral sciences","","1","","15","IEEE","22 Nov 2022","","","IEEE","IEEE Conferences"
"An Autonomous UAV-Assisted Distance-Aware Crowd Sensing Platform Using Deep ShuffleNet Transfer Learning","K. Rezaee; S. J. Mousavirad; M. R. Khosravi; M. K. Moghimi; M. Heidari","Department of Biomedical Engineering, Meybod University, Meybod, Iran; Computer Engineering Department, Hakim Sabzevari University, Sabzevar, Iran; Department of Computer Engineering, Persian Gulf University, Bushehr, Iran; Department of Communication Engineering, University of Sistan and Baluchestan, Zahedan, Iran; School of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","IEEE Transactions on Intelligent Transportation Systems","11 Jul 2022","2022","23","7","9404","9413","Autonomous unmanned aerial vehicles (UAVs) are essential for detecting and tracking specific events, such as automatic navigation. The intelligent monitoring of people’s social distances in crowds is one of the most significant events caused by the coronavirus. The virus is spreading more quickly among the crowds, and the disease cycle continues in congested areas. Due to the error that occurs when humans monitor their activity, an automated model is required to alert to social distance violations in crowds. As a result, this article proposes a two-step framework based on autonomous UAV videos, including human tracking and deep learning-based recognition of the crowd’s social distance. The deep architecture is a modified-fast and lightweight ShuffleNet learning structure. First, the Kalman filter is used to determine the positions of individuals, and then the modified ShuffleNet is used to refine the bounding boxes obtained and determine the social distance. The social distance is calculated using the initial refinement of the bounding box obtained during the tracking step and the scale in frames of the human body. The observed average accuracy, average processing time (APT), and processed frame per second (FPS) for three congestion datasets were 97.5%, 84 milliseconds, and 11.5 FPS, respectively. Real-time decision-making was achieved by reducing the size and resolution of the frames. Additionally, the frames were re-labeled to reduce the computational complexity associated with detecting social distancing. The experimental results demonstrated that the proposed method could operate more quickly and accurately on various resolution frames of UAV videos with difficult conditions.","1558-0016","","10.1109/TITS.2021.3119855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9592689","Unmanned aerial vehicle (UAV);COVID-19;social distancing;deep transfer learning;tracking;modified ShuffleNet","Social factors;Human factors;Monitoring;Videos;COVID-19;Kalman filters;Unmanned aerial vehicles","","24","","46","IEEE","28 Oct 2021","","","IEEE","IEEE Journals"
"People Counting Based on YOLO","G. Vasavi; H. H. Diddi; E. Haritha; G. Arun Kumar; G. Harsha Varma","Department of CSE, B V Raju Institute of Technology, Narsapur, Telangana, India; Department of CSE, B V Raju Institute of Technology, Narsapur, Telangana, India; Department of CSE, B V Raju Institute of Technology, Narsapur, Telangana, India; Department of CSE, B V Raju Institute of Technology, Narsapur, Telangana, India; Department of CSE, B V Raju Institute of Technology, Narsapur, Telangana, India","2023 4th IEEE Global Conference for Advancement in Technology (GCAT)","19 Dec 2023","2023","","","1","6","People counting is an important undertaking with many uses in areas including crowd control, transit, and retail. The final purpose of this project is to create a system that uses video footage to precisely count the number of persons entering and exiting a specified region. The method tracks and detects people in the video using object detection techniques, notably the YOLO (You Only Look Once) algorithm. There are various crucial phases in the project. In order to identify persons in the video frames, the YOLO model is first used. This model has been trained on a sizable dataset and comes with pre-trained weights. For each individual who is detected, the model returns bounding box coordinates, confidence scores, and class labels. The algorithm calculates the number of persons entering and departing the area of interest by comparing the quantity of individuals recognised in the most recent and earlier frames. Based on the change in the count, it is decided whether to go inward or outward. In addition to giving current updates on the population. And their movement status, the created system also combines visual feedback by presenting video frames with bounding boxes around detected individuals. Applications for this data include occupancy management, crowd management, and security surveillance. Experiments with various video datasets serve to confirm the system’s efficacy and accuracy. The results show that even under challenging and busy conditions, the system can reliably measure the number of persons entering and exiting. Overall, this study provides a reliable method for object-based video counting of individuals.","","979-8-3503-0525-8","10.1109/GCAT59970.2023.10353287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10353287","Deep Learning;YOLO;CNN(Convolution Neural Network);Object Detection;Machine Learning;Computer vision;peopele counting","YOLO;Visualization;Surveillance;Sociology;Sensor fusion;Sensors;Security","","","","10","IEEE","19 Dec 2023","","","IEEE","IEEE Conferences"
"A Hybrid Transfer Learning Approach to Migratable Disaster Assessment in Social Media Sensing","Y. Zhang; R. Zong; D. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","24 Mar 2021","2020","","","131","138","Social media sensing has emerged as a powerful sensing paradigm to collect the observations of the physical world by exploring the “wisdom of crowd”. In this paper, we focus on a migratable disaster damage assessment problem in social media sensing applications. Our goal is to accurately identify the damage severity of affected areas in an unfolding disaster event using unlabeled social media data feeds (e.g., image posts on social media). Two fundamental challenges exist in solving our problem: i) different disaster events often have distinct characteristics (e.g., damage types, affected areas) that cannot be easily migrated; ii) it is non-trivial to modify a damage assessment model from a previous event to adapt to a new event without using the labeled data from the new event. To address the above challenges, we develop SocialTrans, a hybrid deep transfer learning framework, to enable effective model migration for accurate damage assessment without using any training data from the studied disaster event. The evaluation results on four real-world disaster events show that SocialTrans consistently outperforms the state-of-the-art baselines in accurately assessing the damage level of disasters.","2473-991X","978-1-7281-1056-1","10.1109/ASONAM49781.2020.9381433","National Science Foundation(grant numbers:CNS-1845639,CNS-1831669); Army Research Office(grant numbers:W911NF-17-1-0409); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381433","","Adaptation models;Target tracking;Social networking (online);Transfer learning;Training data;Data models;Sensors","","10","","34","IEEE","24 Mar 2021","","","IEEE","IEEE Conferences"
"DenseCAvoid: Real-time Navigation in Dense Crowds using Anticipatory Behaviors","A. J. Sathyamoorthy; J. Liang; U. Patel; T. Guan; R. Chandra; D. Manocha","University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","11345","11352","We present DenseCAvoid, a novel algorithm for navigating a robot through dense crowds and avoiding collisions by anticipating pedestrian behaviors. Our formulation uses visual sensors and a pedestrian trajectory prediction algorithm to track pedestrians in a set of input frames and compute bounding boxes that extrapolate to the pedestrian positions in a future time. Our hybrid approach combines this trajectory prediction with a Deep Reinforcement Learning-based collision avoidance method to train a policy to generate smoother, safer, and more robust trajectories during run-time. We train our policy in realistic 3-D simulations of static and dynamic scenarios with multiple pedestrians. In practice, our hybrid approach generalizes well to unseen, real-world scenarios and can navigate a robot through dense crowds (~1-2 humans per square meter) in indoor scenarios, including narrow corridors and lobbies. As compared to cases where prediction was not used, we observe that our method reduces the occurrence of the robot freezing in a crowd by up to 48%, and performs comparably with respect to trajectory lengths and mean arrival times to goal.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197379","","Collision avoidance;Navigation;Trajectory;Robot sensing systems;Robustness;Tracking","","39","","58","IEEE","15 Sep 2020","","","IEEE","IEEE Conferences"
"Abnormal Behavior Detection Based on Optical Flow Trajectory of Human Joint Points","Y. DOU; C. Fudong; J. LI; C. Wei","Shandong Provincial Key Laboratory of Network Based Intelligent Computing, University of Jinan, Jinan, China; Shandong Senter Electronic Co., Ltd, Zibo, Shandong, China; Shandong Provincial Key Laboratory of Network Based Intelligent Computing, University of Jinan, Jinan, China; Laser Institute of Shandong Academy of Sciences, Jinan, China","2019 Chinese Control And Decision Conference (CCDC)","12 Sep 2019","2019","","","653","658","Detection of abnormal behavior of pedestrians in public places is always one of the key issues for public security. Video surveillance is an effective approach to address the issue. Considering the characteristics of multi-person poses, we propose an effective and practical method to detect the abnormality based on the optical flow trajectory of joint points for each human body. There are 4 basic steps in the proposed method: firstly, estimate the posture of each individual in the crowd to determine the corresponding joint points; secondly, compute the optical flow field of the joint points for each person; thirdly, making use of the trajectory constraints for the computed optical flow field, extract feature vectors after noise removal and vector trajectories synthesis of the joint points of each pedestrian; finally, use SVM (Support Vector Machine) to determine abnormal behavior. Experimental results show this method can effectively detect the abnormal behavior of pedestrians in the crowd.","1948-9447","978-1-7281-0106-4","10.1109/CCDC.2019.8833188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833188","Intelligent monitoring;abnormal behavior detection;optical flow field;pose estimation","Optical flow;Trajectory;Target tracking;Pose estimation;Real-time systems;Feature extraction;Support vector machines","","5","","21","IEEE","12 Sep 2019","","","IEEE","IEEE Conferences"
"Real-Time Pedestrian Detection using YOLO","S. Mishra; S. Jabin","Department of Computer Science, Faculty of Natural Sciences, Jamia Millia Islamia, New Delhi, India; Department of Computer Science, Faculty of Natural Sciences, Jamia Millia Islamia, New Delhi, India","2023 International Conference on Recent Advances in Electrical, Electronics & Digital Healthcare Technologies (REEDCON)","16 Jun 2023","2023","","","84","88","Detecting pedestrians in a crowded scene in real time is a challenging task in monitoring and managing crowd. Many researchers around the world have addressed this task and managed to achieve satisfactory results. However, the problem of automating detection of pedestrians in the crowd is still an open issue depending on the density of crowd in a scene. To ensure safety and security, automating the crowd detection and tracking process in real time is necessary in designing a robust and secure system. Detecting and localizing objects has successfully aided in identifying the major problems with detecting pedestrians and has been a major step forward in managing crowd automatically. In this paper, we have used tiny YOLOv4. YOLO (You Only Look Once) has proved quite useful in detecting and localizing objects in an image with impressive response speed. YOLO network usually scales an entire image into fixed sized grids and then identifies and detects the region into these grids using bounding boxes. Using transfer learning on an already trained YOLO inception model on COCO dataset, detection of pedestrians in surveillance videos is handled. The paper discusses the implementation and detection performance of the proposed YOLOv4 tiny model on the UCSD pedestrian Detection dataset with promising results.","","978-1-6654-9382-6","10.1109/REEDCON57544.2023.10151150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151150","Pedestrian Detection;YOLO;Deep Learning;COCO dataset","Training;Surveillance;Transfer learning;Predictive models;Real-time systems;Safety;Security","","3","","36","IEEE","16 Jun 2023","","","IEEE","IEEE Conferences"
"Estimation of Collision Priority on Traffic Videos using Deep Learning","G. Madhumitha; R. Senthilnathan; K. M. Ayaz; J. Vignesh; K. Madhu","Dept. of Mechatronics Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India; Dept. of Mechatronics Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India; Dept. of Mechatronics Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India; Dept. of Mechatronics Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India; Dept. of Mechatronics Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India","2020 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT)","23 Feb 2021","2020","","","1","6","With the advancement in technology, autonomous vehicles will have a great impact on the near future and share the road space with human beings. For ensuring safer navigation, a robust collision mitigation system becomes mandatory which in general is deployed with multi-modal approaches. In this paper, a novel heuristic unimodal approach based on the vision system is presented to estimate the collision priority of vehicles on road. The priorities are estimated from the perspective of an ego vehicle that may be equipped with a vision based driver-assist system or a fully autonomous vehicle. Crowd-sourced videos from YouTube involving vehicular collisions captured by the dashboard camera of vehicles are considered. To detect the moving vehicles in the video, a deep learning-based pre-trained object detection model and a tracking algorithm are used. From the bounding box output, an estimate of collision priority of detected vehicles concerning the ego vehicle is obtained using an empirical heuristic-based approach. A simpler collision warning and navigation suggestion is also incorporated as a credible advanced driver assistance system element. The proposed qualitative approach performs well for input videos and a more robust estimate can be achieved by combining with other quantitative semantics of traffic parameters.","","978-1-7281-8885-0","10.1109/ICMLANT50963.2020.9355992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355992","collision estimation;object detection;autonomous vehicles","Navigation;Roads;Machine vision;Semantics;Estimation;Object detection;Videos","","3","","16","IEEE","23 Feb 2021","","","IEEE","IEEE Conferences"
"A Comparative Study of Detecting Violation of Face Mask and Social Distancing using Different Deep Learning Models","A. Rahman; A. A. Hasib; M. Khabir; M. B. M. Sourov; S. M. Shahriar","Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh","2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)","8 Jun 2023","2023","","","28","34","The growing pandemic caused by COVID-19 has been making headlines recently, causing a global disaster with an unavoidable spread. The WHO recommends wearing a face mask and maintaining physical distance. This research can assist in keeping track of social distance and it can also spot face masks. The entire system is set up in public settings. Images and videos are used by this system to identify persons. Frame by frame processing is done on the video. People are recognized by image processing with TensorFlow and OpenCV. MobileNetV2 and ResNet50 are used for detecting the face mask violation. It first recognizes the crowd’s presence before calculating the centroid distances between individuals using an object tracking algorithm and a distance algorithm. In order to assess the social distance between people, the Euclidean distance is typically employed to calculate how far off each pair of centroids of the bounding box is identified from one another. At a distance of six feet, the program can determine the number of pixels in an image. The detection models MobileNetV2 and ResNet50, respectively, obtained accuracy of 97% and 98% with the large dataset, which contains 12000 samples with and without masked faces.","2768-5330","979-8-3503-9725-3","10.1109/ICICCS56967.2023.10142273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142273","Covid-19;Deep Learning;OpenCV;Tensorflow;Mobilenetv2;Resnet50;YOLOv3 (You Only Look Once)","Training;Face recognition;Atmospheric modeling;Human factors;Feature extraction;Social factors;Robustness","","","","15","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Smart Video Survillance Based Weapon Identification Using Yolov5","S. Nikkath Bushra; G. Shobana; K. Uma Maheswari; N. Subramanian","Department of Information Technology, St. Joseph's Institute of Technology, Chennai, Tamil Nadu, India; Department of Computer Application, Madras Christian College, Chennai, Tamil Nadu, India; Department of Computer Science, Bharathi Women's College, Chennai, Tamil Nadu, India; Department of Information Technolog, Rajalakshmi Engineering College, Chennai, Tamil Nadu, India","2022 International Conference on Electronic Systems and Intelligent Computing (ICESIC)","2 Jun 2022","2022","","","351","357","Video Surveillance plays an important role in every aspect of life like theft detection, unusual happenings in crowded places, monitoring the suspicious activities of each individual to provide a secure and hassle free environment. Footage of closed circuit television (CCTV) camera is taken as an evidence to track the suspicious act. It is very tough to operate surveillance cameras with human intervention to detect abnormal activities. Fully automating surveillance with smart video capturing capabilities using deep learning technique is one of the most advanced means of remotely monitoring strange activities with exact location, time of event occurred along with facial recognition of criminal. Finding misdemeanor activity in a public place is very difficult to observe, as many objects are involved in the real time scenario. An uncommon or doubtful incidents in public places are captured in CCTV cameras which promotes police force to safeguard people before any mishap happens. It helps police to reach that spot on time and rescue victim. All these are meant to be achieved by using YOLO (You Only Look Once) object detection models and its variants like YOLO V1, V2, V3, V4 and latest V5 which is 88% faster than yolov4 in Deep Learning. This proposed system helps in identifying weapons held by a person as well as face recognition to identify the suspicious user. Using YOLO v5, it is very simple to track objects like weapons in a crowd. Low resolution images, far away and out of focus in the scene can also be captured and identified accurately","","978-1-6654-8385-8","10.1109/ICESIC53714.2022.9783499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783499","YOLO;CCTV;Weapon Detection;Real time Surveillance;Anomaly Activities","Deep learning;TV;Image resolution;Law enforcement;Weapons;Face recognition;Object detection","","4","","14","IEEE","2 Jun 2022","","","IEEE","IEEE Conferences"
"Developing An Automated Face Mask Detection Using Computer Vision and Artificial Intelligence","S. M. Tedjojuwono; S. L. Sulaiman","Business Information Systems Program, Information Systems Department, Faculty of Computing and Media, Bina Nusantara University, Jakarta, Indonesia; Business Information Systems Program, Information Systems Department, Faculty of Computing and Media, Bina Nusantara University, Jakarta, Indonesia","2021 1st International Conference on Computer Science and Artificial Intelligence (ICCSAI)","24 Nov 2021","2021","1","","109","114","As the number of people affected by COVID-19 keeps on rising. Importance of wearing masks and washing hands has been the most important protocol right now to prevent the spread of COVID-19. As the pandemic has been going on for almost a year now, people have already started to go around to public places whether it is to eat out, work, or grocery shopping. Many people, however, have not been wearing masks properly by only putting them below their nose or putting it down until their chin. Hence, in this project a mask detection system is made to detect people live time who are wearing or not wearing a mask and can generate a business intelligence report for the shop owner to be aware of the number of people not wearing a mask per day. This system can detect the percentage of the mask is worn properly or not. The more proper it is worn (full up to nose), the higher the percentage will be. This system is useful in a pandemic like this as it is hard to keep track of the number of people who are not wearing masks, especially in a big crowd or in a large space as one person not wearing a mask can greatly affect others.","","978-1-6654-4002-8","10.1109/ICCSAI53272.2021.9609768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609768","Augmented Reality;User Experience;Furniture Shop","COVID-19;Computer science;Computer vision;Protocols;Pandemics;Nose;Business intelligence","","","","10","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Towards Safe Navigation Through Crowded Dynamic Environments","Z. Xie; P. Xin; P. Dames","Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","4934","4940","This paper proposes a novel neural network-based control policy to enable a mobile robot to navigate safety through environments filled with both static obstacles, such as tables and chairs, and dense crowds of pedestrians. The network architecture uses early fusion to combine a short history of lidar data with kinematic data about nearby pedestrians. This kinematic data is key to enable safe robot navigation in these uncontrolled, human-filled environments. The network is trained in a supervised setting, using expert demonstrations to learn safe navigation behaviors. A series of experiments in detailed simulated environments demonstrate the efficacy of this policy, which is able to achieve a higher success rate than either standard model-based planners or state-of-the-art neural network control policies that use only raw sensor data.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636102","National Science Foundation; Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636102","","Training;Laser radar;Navigation;Neural networks;Kinematics;Robot sensing systems;Data models","","5","","31","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Group Tracking for Video Monitoring Systems: A Spatio-Temporal Query Processing Approach","H. Yoon; D. Choi; Y. D. Chung","Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea","IEEE Access","2 Mar 2023","2023","11","","19969","19987","Recently, many video monitoring systems utilize deep learning technologies to recognize locations and trajectories of people in video data. In video monitoring systems, a fast discovery of human groups is an important task for several applications, for example, crime surveillance, contact tracing, and customer behavior analysis. To tackle the demand, we propose a group tracking method. First, we propose a spatial proximity definition and define a novel query type, a group tracking query that considers characteristics of video data. A group tracking query retrieves the groups that travel for more than a certain amount of video frame within a certain distance. We propose an efficient query processing method that exploits the spatio-temporal characteristics of groups. Through extensive experiments using real-world datasets, we verify the efficiency and effectiveness of our query definition and query processing method.","2169-3536","","10.1109/ACCESS.2023.3249190","National Research Foundation of Korea (NRF); Korean Government [Ministry of Science and ICT (MIST)](grant numbers:2020R1A2C2013286); Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:NRF-2021R1A6A1A13044830); MSIT under the Information and Communications Technology (ICT) Creative Consilience Program Supervised by the Institute for Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2023-2020-0-01819); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054033","Spatio-temporal query processing;spatial data management;spatial databases;video query processing;video monitoring systems","Spatiotemporal phenomena;Data processing;Query processing;Spatial databases;Video coding","","1","","28","CCBYNCND","27 Feb 2023","","","IEEE","IEEE Journals"
"Modeling Noisy Annotations for Point-Wise Supervision","J. Wan; Q. Wu; A. B. Chan","Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","3 Nov 2023","2023","45","12","15065","15080","Point-wise supervision is widely adopted in computer vision tasks such as crowd counting and human pose estimation. In practice, the noise in point annotations may affect the performance and robustness of algorithm significantly. In this paper, we investigate the effect of annotation noise in point-wise supervision and propose a series of robust loss functions for different tasks. In particular, the point annotation noise includes spatial-shift noise, missing-point noise, and duplicate-point noise. The spatial-shift noise is the most common one, and exists in crowd counting, pose estimation, visual tracking, etc, while the missing-point and duplicate-point noises usually appear in dense annotations, such as crowd counting. In this paper, we first consider the shift noise by modeling the real locations as random variables and the annotated points as noisy observations. The probability density function of the intermediate representation (a smooth heat map generated from dot annotations) is derived and the negative log likelihood is used as the loss function to naturally model the shift uncertainty in the intermediate representation. The missing and duplicate noise are further modeled by an empirical way with the assumption that the noise appears at high density region with a high probability. We apply the method to crowd counting, human pose estimation and visual tracking, propose robust loss functions for those tasks, and achieve superior performance and robustness on widely used datasets.","1939-3539","","10.1109/TPAMI.2023.3299753","Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CityU 11212518,CityU 11215820); Strategic Research Grant from City University of Hong Kong(grant numbers:7005665); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10197253","Noisy point annotations;crowd counting;object counting;tracking;pose estimation;deep learning","Annotations;Pose estimation;Noise measurement;Visualization;Uncertainty;Predictive models;Prediction algorithms","","1","","91","IEEE","28 Jul 2023","","","IEEE","IEEE Journals"
"Propounding First Artificial Intelligence Approach for Predicting Robbery Behavior Potential in an Indoor Security Camera","S. Pouyan; M. Charmi; A. Azarpeyvand; H. Hassanpoor","Department of Electrical Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, Iran; Medical Engineering Department, Energy Institute of Higher Education, Saveh, Iran","IEEE Access","23 Jun 2023","2023","11","","60471","60489","Crime prediction in video-surveillance systems is required to prevent incident and protect assets. In this sense, our article proposes first artificial intelligence approach for Robbery Behavior Potential (RBP) prediction and detection in an indoor camera. Our method is based on three detection modules including head cover, crowd and loitering detection modules for timely actions and preventing robbery. The two first modules are implemented by retraining YOLOV5 model with our gathered dataset which is annotated manually. In addition, we innovate a novel definition for loitering detection module which is based on DeepSORT algorithm. A fuzzy inference machine renders an expert knowledge as rules and then makes final decision about predicted robbery potential. This is laborious due to: different manner of robber, different angle of surveillance camera and low resolution of video images. We accomplished our experiment on real world video surveillance images and reaching the F1-score of 0.537. Hence, to make an experimental comparison with the other related works, we define threshold value for RBP to evaluate video images as a robbery detection problem. Under this assumption, the experimental results show that the proposed method performs significantly better in detecting the robbery as compared to the robbery detection methods by distinctly report with F1-score of 0.607. We strongly believe that the application of the proposed method could cause reduction of robbery detriment in a control center of surveillance cameras by predicting and preventing incident of robbery. On the other hand, situational awareness of human operator enhances and more cameras can be managed.","2169-3536","","10.1109/ACCESS.2023.3284472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10147209","Surveillance videos;low resolution;RBP prediction;deep learning method;fuzzy inference machine","Behavioral sciences;Prediction algorithms;Cameras;Feature extraction;Security;Magnetic heads;Surveillance;Deep learning;Fuzzy systems;Inference","","4","","56","CCBYNCND","9 Jun 2023","","","IEEE","IEEE Journals"
"Research on Evaluation Model of Advertising Design Effectiveness Based on Expression Recognition Algorithm","J. Liu","Liaoning Institute of Science and Technology, Benxi, China","2023 IEEE 3rd International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)","7 Jul 2023","2023","","","375","378","Advertising and publicity work in public places is essential for product promotion, but there is a lack of efficient automatic methods for evaluating the effectiveness of advertising and publicity. Therefore, in response to this situation, a computer vision analysis-based advertising effectiveness evaluation system is proposed. The system collects images of the activity scene of the crowd in front of the advertisement, measures and tracks people who are staring at the advertisement in the images, records their gaze time and conducts a quantitative evaluation of the consumer response to the advertisement through the analysis of the number of gaze groups, gaze duration, and attention level. For facial detection, the AdaBoost classifier is used with particle filters for facial tracking. Face detection and tracking compensate and adjust each other, enhancing the credibility of face tracking. The research results demonstrate the rationality of the proposed technology.","","979-8-3503-3386-2","10.1109/ICEIB57887.2023.10170338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10170338","Expression Recognition;Algorithm;Advertisement;Design Effect","Data analysis;Face recognition;Big Data;Time measurement;Particle filters;Classification algorithms;Face detection","","","","15","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Video Object Segmentation by Latent Outcome Regression","L. Zhang; Y. Lu","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China","IEEE Access","17 Feb 2020","2020","8","","30355","30367","This paper presents a novel algorithm for unsupervised video object segmentation (UVOS) in unconstrained scenarios. Although a large variety of methods have been proposed in the literature, segmenting generic objects is still challenging because different methods often perform well in different situations, and no single method can outperform the others in all cases. To address this, we propose to solve the problem of UVOS in a crowd-sourcing setting. We claim that one can achieve superior results by aggregating the predictions of multiple imperfect methods in a reasonable way. Specifically, we propose a latent regression algorithm for ensemble-based segmentation by jointly labelling pixels in a sequence and learning an adaptive weight for each single method in an ensemble. The pixel labellings offer the outcome (pseudo groundtruth) for regression and thus promote the procedure of weight learning, while the learnt weights could provide better shape priors for labelling, resulting in more accurate segmentation. Besides, Laplacian regularization is introduced into the regression to facilitate a stable learning of the weights. The most distinct feature of our algorithm is that it adaptively learns the contributions of different single methods for each test sequence, thus is capable of capturing the advantages of those methods while avoiding their weaknesses. In the experiments, our algorithm is built on 14 non-deep learning segmentation methods which are based on handcrafted features and require no training data. Experimental results on popular benchmarks show that our algorithm achieves compelling performance, even in comparison with deep learning-based methods. Furthermore, benefiting from the adaptive weight learning mechanism, our algorithm can achieve good flexibility and usability by choosing the most complementary single methods without losing too much performance.","2169-3536","","10.1109/ACCESS.2020.2971964","National Natural Science Foundation of China(grant numbers:61273273); National Key Research and Development Plan of China(grant numbers:2017YFC0112001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8985334","Video object segmentation;latent regression;appearance modelling;unsupervised","Object segmentation;Task analysis;Motion segmentation;Training data;Optical imaging;Tracking;Shape","","2","","71","CCBY","6 Feb 2020","","","IEEE","IEEE Journals"
"Fake News Detection Model for Regional Language","J. Nair; S. S. Akhil; V. Harisankar","Department of Computer Science and Applications, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Applications, Amrita Vishwa Vidyapeetham, Amritapuri, India; Department of Computer Science and Applications, Amrita Vishwa Vidyapeetham, Amritapuri, India","2022 IEEE 7th International conference for Convergence in Technology (I2CT)","18 Jul 2022","2022","","","1","7","Social media has expanded far and wide in the past few years, which has led to the ease of circulating any kind of news and posts all over the network. The work that we are pursuing currently focuses on the prevention of the circulation of large, misinformed news over the network. The different machine and deep learning techniques incorporated with certain Natural Language Processing techniques can result in achieving such good models to filter the fake news and real news apart from themselves. The social media spectrum is active in other low-resource language domains like Malayalam exactly how it prevails in other languages which currently aids in the inflation of rumors and false accusations among the masses. The main objective is to classify the incoming Malayalam contextual news and other rumors to aid humans in fast-tracking the manual verification or detection process of the news. The introduction of the classifier with an additional front-end interface to assist the people in the time of a crisis would help the crowd to a great degree with dynamic regular feeding of real-time data to the language model.","","978-1-6654-2168-3","10.1109/I2CT54291.2022.9824641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824641","CNN;LSTM;Web Crawling;Data Mining;traditional news;Malayalam","Deep learning;Social networking (online);Conferences;Manuals;Real-time systems;Natural language processing;Data models","","2","","16","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Action4D: Online Action Recognition in the Crowd and Clutter","Q. You; H. Jiang","Microsoft Cloud & AI, Redmond, WA; Microsoft Cloud & AI, Redmond, WA","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","11849","11858","Recognizing every person's action in a crowded and cluttered environment is a challenging task in computer vision. We propose to tackle this challenging problem using a holistic 4D ``scan'' of a cluttered scene to include every detail about the people and environment. This leads to a new problem, i.e., recognizing multiple people's actions in the cluttered 4D representation. At the first step, we propose a new method to track people in 4D, which can reliably detect and follow each person in real time. Then, we build a new deep neural network, the Action4DNet, to recognize the action of each tracked person. Such a model gives reliable and accurate results in the real-world settings. We also design an adaptive 3D convolution layer and a novel discriminative temporal feature learning objective to further improve the performance of our model. Our method is invariant to camera view angles, resistant to clutter and able to handle crowd. The experimental results show that the proposed method is fast, reliable and accurate. Our method paves the way to action recognition in the real-world applications and is ready to be deployed to enable smart homes, smart factories and smart stores.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954340","RGBD sensors and analytics;Action Recognition;Deep Learning","Representation learning;Adaptation models;Computer vision;Solid modeling;Three-dimensional displays;Convolution;Computer network reliability","","6","","30","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Interfacing a Flying Robot with OpenCV","P. Abirami; K. R. S. Vadivu; R. H. Lalitha; M. Pushpavalli; P. Sivagami; R. Harikrishnan; I. S. Ahmed","EEE / B S Abdur Rahman Crescent Institute of Science and Technology, Chennai, India; EEE / B S Abdur Rahman Crescent Institute of Science and Technology, Chennai, India; EEE / B S Abdur Rahman Crescent Institute of Science and Technology, Chennai, India; EEE / Sathyabama Institute of Science and Technology, Chennai, India; EEE / Sathyabama Institute of Science and Technology, Chennai, India; ETC / Symbiosis Institute of Technology, Symbiosis International Deemed University, Pune, India; EEE / B S Abdur Rahman Crescent Institute of Science and Technology, Chennai, India","2023 IEEE International Conference on ICT in Business Industry & Government (ICTBIG)","19 Mar 2024","2023","","","1","11","This research work is carried out to satisfy the requirements of developing industries. As per our today's requirements, safety plays a vital role in all industries. Also, a cost-effective system is required to maintain safety around our workplaces. By considering all the factors in mind, a flying robot system is made to instruct the employees to safeguard themselves by identifying near misses in the industries. The main aim of the work is to design a flying robot system with a camera to identify persons without safety equipment. So, every half an hour the images will be automatically captured by the surveillance drone and sent to the ground station which is operated by the OpenCV library for tracking objects like monitoring the crowd, detecting fire, and near misses to safeguard the employees from accidents. Here, a functional prototype is developed to achieve the goals and implement it in industrial applications.","","979-8-3503-4327-4","10.1109/ICTBIG59752.2023.10456011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10456011","Open CV;Pixhawk microcontroller;Path Mapping","Industries;Surveillance;Robot vision systems;Prototypes;Crops;Cameras;Libraries","","","","10","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"The Effect of Virtual Reality and Heart Rate Variability Using Deep Learning for Reducing Stage Fright- Glossophobia","J. M. Khurpade; A. A. Gangawane; G. S. Ostwal; D. M. Lalwani; R. G. Vidye","Department of Computer Engg, MIT Polytechnic, Pune, Maharashtra, India; Department of Computer Engg, MIT Polytechnic, Pune, Maharashtra, India; Department of Computer Engg, MIT Polytechnic, Pune, Maharashtra, India; Department of Computer Engg, MIT Polytechnic, Pune, Maharashtra, India; Department of Computer Engg, MIT Polytechnic, Pune, Maharashtra, India","2020 International Conference on Industry 4.0 Technology (I4Tech)","28 May 2020","2020","","","195","198","Glossophobia is the most common problem in today's world. Glossophobia leads to the problem of lack of confidence, high blood pressure, depression and dry mouth. In this project we plan to create system that will help all these brilliant minds in making their voices heard. The major fear while public speaking is the crowd and the thought of messing up in front of so many people. We plan to overcome both these problems by using Virtual Reality. It is quite a new technology and therefore is still in a developmental stage, its potential is hidden. We think by creating an auditorium full of people in Virtual Reality will help people develop the stage confidence public speaking needs. We will develop a system to keep track of the users fumbling and his heart rate to understand how confident the person is. With all this information, the system will give him, a grade to make it engage, a few pointers and constructive criticism. In this system user's Speech will be recorded, then it will be converted to text. Converted text will be compared using different text comparison algorithm to develop a result vector which will be used to generate result statistics and thus help user to know his/her skills.","","978-1-7281-5003-1","10.1109/I4Tech48345.2020.9102645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102645","Virtual;Reality;learning;recognition;voice;Artificial;Intelligence","Heart rate;Virtual reality;Biological neural networks;Solid modeling;Training;Biomedical monitoring;Artificial intelligence","","1","","12","IEEE","28 May 2020","","","IEEE","IEEE Conferences"
"The Indoor People Tracking and Counting System","H. -P. Lin; C. -C. Han; J. -W. Liao; C. -H. Ciou; Y. -C. Hong; M. -L. Tan","Ph. D. Program in Material and Chemical Engineering, National United University, MiaoLi, Taiwan; Department of Computer Science and Information Engineering, National United University, MiaoLi, Taiwan; Department of Computer Science and Information Engineering, National United University, MiaoLi, Taiwan; Department of Computer Science and Information Engineering, National United University, MiaoLi, Taiwan; Department of Computer Science and Information Engineering, National United University, MiaoLi, Taiwan; Department of Computer Science and Information Engineering, National United University, MiaoLi, Taiwan","2023 International Automatic Control Conference (CACS)","27 Nov 2023","2023","","","1","6","COVID-19 outbreaks and becomes serious from 2019 winter. Taking body temperature, wearing masks, recording footprint and avoiding crowds become important tasks and require a lot of manpower support for the prevention of the epidemic in every. In this study, we have integrated the infrared thermometer devices to measure people temperature and the people identities through RGB images at the entrance of buildings. Using the computer vision and deep learning methods, we would like to build a 24/7 and region-wide coverage assistance system to automatically record the footprint of a specific people in the building. We also detect if people taking off their masks in the yard at any time. The processing videos are grabbed from the existing CCTV systems. The developed system also locates the crowd and calculate the number of people in a specified area, and the manager can know the number of people and control the access in real time. It will reduce the burden of manpower. In addition, we have optimized the system performance to handle multiple camera videos and to reduce the hardware cost at the same time.","2473-7259","979-8-3503-0635-4","10.1109/CACS60074.2023.10326194","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10326194","","Temperature measurement;Epidemics;Thermometers;System performance;Buildings;Real-time systems;Hardware","","","","21","IEEE","27 Nov 2023","","","IEEE","IEEE Conferences"
"Deep Learning based Customer Count/Flow Monitoring System for Social Distancing","P. Zamorski; M. N. Asghar; L. Cooke; S. Daly; J. Francis; N. Kanwal; M. S. Ansari; E. Fallon","Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland; Department of Electronics Engineering, Aligarh Muslim University, India; Department of Computer and Software Engineering, Athlone Institute of Technology, Ireland","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","831","836","Despite the COVID-19 vaccination drives, use of preventative measures such as masks and social distancing are still deemed essential. This paper presents an application that will allow businesses/enterprises to monitor the flow of customers by detecting people as objects, counting the number of people, tracking the safe distance between them to maintain the two-meter distance norm. The proposed solution is set up to generate an alarm when the customers reach the allowed limit as per shop dimensions or overcrowding is detected. For the implementation, YOLOv4 and YOLOv3-Tiny were used for the task of object detection and transfer learning is used to set up weights. The models were evaluated using MSCOCO API with 100 image instances per class. The results of the YOLOv4 model are also compared with YOLOv3-Tiny in terms of calculating mean, average precision (AP), frames per second (FPS), and identification of groups (crowd). Experimental results (on several video clips from a shopping center CCTV) show that the YOLOv3-Tiny maintains real-time performance even on modest hardware. It is further demonstrated that if a high-end GPU is available, the overall detection of objects and cluster identification is much more accurate and clearer using YOLOv4.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730405","COVID-19;Deep learning;Person detection;Physical distancing;YOLOv4;YOLOv3-Tiny","COVID-19;Transfer learning;Human factors;Streaming media;Social factors;Real-time systems;Vaccines","","","","22","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Advertising Machine System Design Based on RK3399Pro","M. Wang; Q. Hou; A. Peng","College of Artificial Intelligence, Jianghan University, Wuhan, China; College of Artificial Intelligence, Jianghan University, Wuhan, China; College of Artificial Intelligence, Jianghan University, Wuhan, China","2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","1 Feb 2024","2023","11","","1066","1072","With the rapid advancement of public information dissemination technology, an increasing number of public venues, such as malls, stations, and airports, are facing complex crowd dynamics and information dissemination needs. To address these challenges more effectively, this study introduces a smart advertising system based on the $RK3399Pro$ embedded platform. This system not only serves primary information display purposes but also incorporates security surveillance and crowd counting functions. $Specifically:1$. Given the security needs of public places, we've integrated a network communication module and OV13850 camera into the advertising system for real-time surveillance.2. The system, leveraging the hardware decoding capabilities of the video processor and using FFmpeg transcoding, supports $4K$ video playback encoded with H.265-hevc, ensuring high-definition and latency-free visuals.3. To address data collection in high-footfall areas, we designed a crowdcounting feature by integrating YOLOv7 and DeepSORT algorithms. Experimental results indicate that the system maintains a refresh rate of $25FPS$ when playing videos of $3840\times 2160$ resolution encoded in H.265 format, ensuring smooth visuals. Surveillance videos, after optimized encoding, are reduced to a fifth of their original size, significantly saving storage space. Moreover, in multiple crowd counting tests, the system achieved an impressive recognition accuracy rate of 92.2%, underlining its utility and stability.","2693-2865","979-8-3503-3366-4","10.1109/ITAIC58329.2023.10409108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10409108","YOLO;optimized encoding;RK3399Pro;crowed-counting;advertising system;H.265","Pedestrians;Surveillance;Transcoding;Object detection;Streaming media;Security;Advertising","","","","11","IEEE","1 Feb 2024","","","IEEE","IEEE Conferences"
"Real-Time Aerial Suspicious Analysis (ASANA) System for the Identification and Re-Identification of Suspicious Individuals using the Bayesian ScatterNet Hybrid (BSH) Network","A. Singh; K. Kiran G.V.; O. Harsh; R. Kumar; K. Singh Rajput; C. S .S. Vamsi","Skylark Labs LLC., San Francisco, USA; NIT Warangal; Skylark Labs LLP., Warangal, India; Skylark Labs LLP., Warangal, India; Skylark Labs LLP, Warangal, India; Skylark Labs LLP, Warangal, India","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","73","81","Video monitoring and safety systems have been used to keep track of hostiles, conduct border control operations as well as to monitor the suspicious entities in public spaces. However, these systems are inadequate for the monitoring of large crowds due to the limited field of view of cameras. This paper introduces the Aerial Suspicious Analysis (ASANA) System for the Identification and Re-Identification of suspicious Individuals in large public areas using the Bayesian ScatterNet Hybrid (BSH) Network. The BSH network first estimates the human pose in each frame. Next, a batch of frames is used by the Bayesian 3D ResNext to identify individuals with suspicious postures. The system can also re-identify the identified suspicious individuals as they tend to move after committing the suspicious event. The proposed architecture is advantageous as it can learn meaningful representations quickly using the ScatterNet with fewer labelled examples. This is of great importance as real-life annotated training samples are hard to collect, especially for these applications. The pose estimation, suspicious individual identification, and re-identification performance of the proposed framework is compared with the state-of-the-art techniques. The proposed dataset is also made public which may encourage other researchers who are interested in using the deep learning technique for aerial visual crowd monitoring.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022217","Drone;Suspicious Analysis;Suspicious Individuals;Identification;Re identification;Bayesian;ScatterNet;Deep Learning","Personal area networks;Drones;Feature extraction;Bayes methods;Monitoring;Real-time systems;Training","","3","1","27","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"A Review on Unconstrained Real-Time Rotation-Invariant Face Detection","S. L. Agrwal; S. K. Sharma; V. Kant","Department of Computer Science & Engineering, Manipal University Jaipur, LNM Institute of Information Technology, Jaipur, India; Department of Computer Science & Engineering, LNM Institute of Information Technology, Jaipur, India; Department of Computer Science & Engineering RGSC, Banaras Hindu University, Varanasi, India","2023 3rd International Conference on Intelligent Communication and Computational Techniques (ICCT)","27 Mar 2023","2023","","","1","7","With the amazing growth of image and video databases, there is a vast need for intelligent systems to automatically understand and look at information since doing it by hand is getting very hard. Faces are significant in social interactions because they show the feelings and identity of a person. People are not much better than machines at recognizing different faces. The automatic face detection system is a key in head pose tracking, face verification, face recognition, face tracking, face animation, face modeling, facial expression recognition, age and gender recognition, and behavior analysis in a crowd. Face detection is a way for a computer to find out the size and location of a face in an image. Face detection has been an outstanding issue in computer vision literature. This paper provides an overview of pose and rotation invariant face detection approaches with architecture designs and performance on popular benchmark datasets. The benchmark datasets used for face detection are listed as their key features. This paper also talks about different applications and challenges with face detection. Also, we set up special discussions on the practical aspects of making a face-detection system that works well. We end this paper by suggesting a few promising directions for future research.","","978-1-6654-5357-8","10.1109/ICCT56969.2023.10076222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10076222","Face detection;Rotation and pose invariant face detection;Deep learning","Databases;Face recognition;Computer architecture;Benchmark testing;Feature extraction;Real-time systems;Magnetic heads","","","","39","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"SR-LSTM: State Refinement for LSTM Towards Pedestrian Trajectory Prediction","P. Zhang; W. Ouyang; P. Zhang; J. Xue; N. Zheng","Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, China; SenseTime Computer Vision Research Group, The University of Sydney, Australia; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, China; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, China; Institute of Artificial Intelligence and Robotics, Xian Jiaotong University, China","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","12077","12086","In crowd scenarios, reliable trajectory prediction of pedestrians requires insightful understanding of their social behaviors. These behaviors have been well investigated by plenty of studies, while it is hard to be fully expressed by hand-craft rules. Recent studies based on LSTM networks have shown great ability to learn social behaviors. However, many of these methods rely on previous neighboring hidden states but ignore the important current intention of the neighbors. In order to address this issue, we propose a data-driven state refinement module for LSTM network (SR-LSTM), which activates the utilization of the current intention of neighbors, and jointly and iteratively refines the current states of all participants in the crowd through a message passing mechanism. To effectively extract the social effect of neighbors, we further introduce a social-aware information selection mechanism consisting of an element-wise motion gate and a pedestrian-wise attention to select useful message from neighboring pedestrians. Experimental results on two public datasets, i.e. ETH and UCY, demonstrate the effectiveness of our proposed SR-LSTM and we achieve state-of-the-art results.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954402","Motion and Tracking;Deep Learning","","","295","","55","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"An Integrated Number Plate Recognition System through images using Threshold-based methods and KNN","V. Uma Maheswari; R. Aluvalu; S. Mudrakola","Vardhaman College of Engineering, Hyderabad, India; Chaitanya Bharathi Institute of Technology(A), Hyderabad, India; Matrusri Engineering College, Hyderabad, India","2022 International Conference on Decision Aid Sciences and Applications (DASA)","2 May 2022","2022","","","493","497","In the last few decades, the use of vehicles in our daily life has become mandatory and increased drastically. Sometimes, controlling traffic and identifying vehicle owners manually becomes tedious due to crowd signals, which disobey the traffic rules and drive fast and abnormal. This demands an efficient and automatic system to solve the problem these days. Still, it is challenging in such cases as moving vehicles fast, font on number plate, illumination, etc. This led to developing efficient and automatic number plate detection as the solution. This paper presents automatic number plate detection with number diagnosis and tracking by applying various methods such as thresholding, morphological methods, contour detection, etc. Later, KNN is used for classification to improve accuracy. The proposed method tested on datasets DB1 and DB2 proves better in terms of accuracy, recognition rate, and retrieval rate.","","978-1-6654-9501-1","10.1109/DASA54658.2022.9765218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765218","Image feature extraction;Morphological operations;Thresholding;Contour detection;KNN","Support vector machines;Deep learning;Image edge detection;Lighting;Drives;Benchmark testing;Feature extraction","","5","","30","IEEE","2 May 2022","","","IEEE","IEEE Conferences"
"Single-Frame-Based Deep View Synchronization for Unsynchronized Multicamera Surveillance","Q. Zhang; A. B. Chan","Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China","IEEE Transactions on Neural Networks and Learning Systems","30 Nov 2023","2023","34","12","10653","10667","Multicamera surveillance has been an active research topic for understanding and modeling scenes. Compared to a single camera, multicameras provide larger field-of-view and more object cues, and the related applications are multiview counting, multiview tracking, 3-D pose estimation or 3-D reconstruction, and so on. It is usually assumed that the cameras are all temporally synchronized when designing models for these multicamera-based tasks. However, this assumption is not always valid, especially for multicamera systems with network transmission delay and low frame rates due to limited network bandwidth, resulting in desynchronization of the captured frames across cameras. To handle the issue of unsynchronized multicameras, in this article, we propose a synchronization model that works in conjunction with existing deep neural network (DNN)-based multiview models, thus avoiding the redesign of the whole model. We consider two variants of the model, based on where in the pipeline the synchronization occurs, scene-level synchronization and camera-level synchronization. The view synchronization step and the task-specific view fusion and prediction step are unified in the same framework and trained in an end-to-end fashion. Our view synchronization models are applied to different DNNs-based multicamera vision tasks under the unsynchronized setting, including multiview counting and 3-D pose estimation, and achieve good performance compared to baselines.","2162-2388","","10.1109/TNNLS.2022.3170642","Research Grant Council of Hong Kong Special Administrative Region (SAR), China(grant numbers:TR32-101/15-R,CityU 11212518,CityU SRG 7005665,GRF CityU 11215820); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9775149","Crowd counting;deep learning;image matching;pose estimation;surveillance","Synchronization;Cameras;Task analysis;Pose estimation;Computational modeling;Surveillance;Geometry;Crowdsourcing;Image matching","","1","","57","IEEE","16 May 2022","","","IEEE","IEEE Journals"
"Multi-Agent Tensor Fusion for Contextual Trajectory Prediction","T. Zhao; Y. Xu; M. Monfort; W. Choi; C. Baker; Y. Zhao; Y. Wang; Y. N. Wu",Peking University; ISEE.AI; ISEE.AI; ISEE.AI; ISEE.AI; ISEE.AI; Peking University; ISEE.AI,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","12118","12126","Accurate prediction of others' trajectories is essential for autonomous driving. Trajectory prediction is challenging because it requires reasoning about agents' past movements, social interactions among varying numbers and kinds of agents, constraints from the scene context, and the stochasticity of human behavior. Our approach models these interactions and constraints jointly within a novel Multi-Agent Tensor Fusion (MATF) network. Specifically, the model encodes multiple agents' past trajectories and the scene context into a Multi-Agent Tensor, then applies convolutional fusion to capture multiagent interactions while retaining the spatial structure of agents and the scene context. The model decodes recurrently to multiple agents' future trajectories, using adversarial loss to learn stochastic predictions. Experiments on both highway driving and pedestrian crowd datasets show that the model achieves state-of-the-art prediction accuracy.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953520","Motion and Tracking;Deep Learning ; Robotics + Driving; Scene Analysis and Understanding; Vision Applications and System","","","253","1","32","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Real-time based Violence Detection from CCTV Camera using Machine Learning Method","S. D. J; M. T. Ahammed; U. M. Boppana; M. Afroj; S. Ghosh; S. Hossain; P. Balaji","Department of ECE, St. Joseph's Institute of Technology Semmancheri, Chennai, Tamil Nadu, India; Department of ECE, Khulna University of Engineering and Technology, Khulna, Bangladesh; Universiti Tun Hussein Onn Malaysia, Johor, Malaysia; Department of CSE, Bangladesh University of Business and Technology, Dhaka, Bangladesh; Department of CSE, Bangladesh University of Business and Technology, Dhaka, Bangladesh; Department of CSE, Bangladesh University of Business and Technology, Dhaka, Bangladesh; Department of Electrical and Electronics Engineering, Jeppiaar Engineering College, Chennai, Tamil Nadu, India","2022 International Conference on Industry 4.0 Technology (I4Tech)","24 Nov 2022","2022","","","1","6","Based on deep-learning approaches, we developed a real-time violence detector for surveillance video systems. In the model given here (overall generality-accuracy-fast response time), CNN serves as a space feature extractor, while LSTM is used to learn time-related relationships. Due to the large number of devices that can record video from camera systems, like those used in surveillance systems, body-worn webcams, and phones, it has become hard to keep track of video footage from many surveillance devices. Using crowd-based video footage, we analyzes and alerts possible those who are affected by violent material is found in the clip. Keeping an eye on huge crowds during social gatherings, especially those where there is a possibility of violence becomes very difficult. The speed, accuracy, and generality of violent event detectors across a variety of video sources and formats are all factors that go into determining their usefulness. Intelligent monitoring technology has been extensively deployed in the nation in recent years to continually support the development of a safe city. Behavioral intelligence analysis is becoming more popular in the realm of intelligent image analysis. Currently, complex activities such as fighting or violence are rarely studied in behavior analysis techniques; instead, they focus on basic movements such as running or leaping. To preserve social order and safeguard people's lives and property, competent and intelligent analysis of violence through video surveillance is vital. To that end, we've put up an overview of the most recent techniques for spotting violent scenes in recorded video.","","978-1-6654-7196-1","10.1109/I4Tech55392.2022.9952805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952805","CNN;LSTM;Surveillance;Video Signal Processing;ConvLSTM;Conv3D etc","Webcams;Urban areas;Detectors;Machine learning;Streaming media;Feature extraction;Video surveillance","","3","","31","IEEE","24 Nov 2022","","","IEEE","IEEE Conferences"
"Technologies for Observing and Monitoring Plastics in the Oceans","R. Garello; H. -P. Plag; A. SHAPIRO; S. Martinez; J. Pearlman; L. Pendleton","Lab-STICC UMR 6285, IMT Atlantique, Brest, France; Mitigation & Adaptation Res. Institute, Old Dominion University, Norfolk, Virginia, USA; Space+Science, WWF, Berlin, Germany; Energy & Engineering, LEITAT, Barcelona, Spain; Four Bridges, Port Angeles, WA, USA; IUEM, WWF, Brest, France","OCEANS 2019 - Marseille","14 Oct 2019","2019","","","1","6","Massive and rapidly increasing use of plastics in modern society with short average use times and poor reuse and recycling options has resulted in a global threat with potentially devastating impacts on human and non-human life. Knowledge on the impacts of plastics in all forms on the planetary life-support system is rapidly accumulating and it underlines the scale of the risk humanity is taking. While quantitative information on production and use of plastics is to a large extent available, the fate of plastics discarded or leaked into the environment is highly uncertain. In particular, knowledge of how much plastic at different scales down to micro and nano levels reaches the ocean and the trajectories of the plastic in the ocean remain poorly known. Based on the mounting evidence, the United Nations have recognized the threat and are coordinating the many efforts to limit the amount of plastic that enters the environment uncontrolled. However, the Earth observation community so far has not managed to establish a global tracking and information system that would provide quantitative information on where and how plastics move in the ocean and allow the identification of the points where marine plastic pollution could be reduced most effectively. There are a number of independent projects focused on better monitoring plastics in the environment, including the ocean. In particular, projects in the EU, USA, and Japan have participated in working groups initiated by UN Environment. These projects are focusing on the monitoring of marine litter and plastics, management of information and knowledge, risks assessments, exploitation of opportunities and synergies, and, as far as possible, estimation of relevant costs and benefits. Measurements proposed include satellite and airborne remote sensing, surface and underwater in situ measurements, and crowd-sourcing observations. The need for extensive data processing and the use of deep learning techniques is acknowledged. The sensors considered range from multi- and hyperspectral sensing or other optical sensing to radar imaging aiming at a wide geo-spatial coverage. There is a need to develop global coordination mechanisms to ensure that societal knowledge needs are met and decisions on reducing plastic pollution in the ocean are informed by this knowledge. OES in collaboration with the Blue Planet Initiative of the Group on Earth Observations (GEO) and the UN environment, is leading an initiative aiming at this coordination.","","978-1-7281-1450-7","10.1109/OCEANSE.2019.8867401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867401","marine debris;plastics;remote sensing;tracking","Plastics;Oceans;Monitoring;Sea measurements;Rivers;Pollution;Trajectory","","1","","40","IEEE","14 Oct 2019","","","IEEE","IEEE Conferences"
"Selective face de-identification scheme using multiple face recognition and classification techniques","S. -M. Bae; J. -S. Park; C. -Y. Ju; D. -H. Lee","Computer Science and Engineering Major in Bio Artificial Intelligence, Hanyang Univ., Ansan, Republic of Korea; Applied Artificial Intelligence Major in Bio Artificial Intelligence, Hanyang Univ., Ansan, Republic of Korea; Applied Artificial Intelligence Major in Bio Artificial Intelligence, Hanyang Univ., Ansan, Republic of Korea; Applied Artificial Intelligence Major in Bio Artificial Intelligence, Hanyang Univ., Ansan, Republic of Korea","2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)","15 Aug 2022","2022","","","1","8","Social media is rapidly growing through platforms that provide live-streaming service, video sharing service, etc. But, as the social media grows, the cases where faces of people in the media are indiscreetly exposed are also increasing. Personal sensitive information may be included in a photo and video, and representative data that can identify an individual is face. So, various face de-identification methods have been proposed. However, most face de-identification methods have tried to obfuscate every face in an image or video and tend to focus on minimizing the loss of facial features due to obfuscation for utilizing the rest of facial features as data except for features that can identify individuals. Therefore, those methods are not adequate for face de-identification in social media service because main characters' faces like media producers, creators or actors need to be exposed on purpose, whereas the other targets' faces like pedestrians or crowd should not be exposed in the videos. Selectively obfuscating targets' faces by classifying all faces in the video into exposing targets and obfuscating targets is necessary for improving the privacy in social media service. In this paper, we propose a selective face de-identification system that exposes main characters' faces and obfuscates the other targets' faces by recognizing and classifying all faces appeared in a video. Our system detects and tracks multiple faces using a deep learning-based face recognition, and classifies main characters' faces and the obfuscating targets' faces, and finally de-identifies only the faces of the obfuscating targets on purpose. We also propose an efficient pipelining scheme for batch processing of face de-identification that rearranges the order of faces to be identified in each frame by matching faces existing in continuous frames of a video.","","978-1-6654-5872-6","10.1109/CTISC54888.2022.9849764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849764","face de-identification;face recognition;artificial intelligence;computer vision;image/video processing","Privacy;Information science;Target tracking;Social networking (online);Target recognition;Face recognition;Media","","1","","26","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Autonomous Navigation System in Pedestrian Scenarios Using a Dreamer-Based Motion Planner","W. Zhu; M. Hayashibe","Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Japan","IEEE Robotics and Automation Letters","15 May 2023","2023","8","6","3836","3843","Navigation among pedestrians is a crucial capability of service robots; however, it is a challenge to manage time-varying environments stably. Recent deep reinforcement learning (DRL)-based approaches to crowd navigation have yielded numerous promising applications. However, they rely heavily on initial imitation learning and colossal positive datasets. Moreover, the difficulties in accurately localizing robots, detecting and tracking humans, representing and generalizing reciprocal human relationships restrict their deployment in real-world problems. We propose a Dreamer-based motion planner for collision-free navigation in diverse pedestrian scenarios. Our RL framework can completely learn from zero experience via a model-based DRL. The robot and humans are first projected onto a map, which is subsequently decoded into low-dimensional latent state. A predictive dynamic model in the latent space is jointly created to efficiently optimize the navigation policy. Additionally, we leverage the techniques of system identification, domain randomization, clustering and LiDAR SLAM for practical deployment. Simulation ablations and real implementations demonstrate that our motion planner outperforms state-of-the-art methods, and that the navigation system can be physically implemented in the real world.","2377-3766","","10.1109/LRA.2023.3273514","Japan Society for the Promotion of Science(grant numbers:JP20KK0256); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10120930","Autonomous vehicle navigation;human-aware motion planning;reinforcement learning","Robots;Navigation;Planning;Collision avoidance;Reinforcement learning;Predictive models;Vehicle dynamics","","1","","35","CCBY","8 May 2023","","","IEEE","IEEE Journals"
"Deep Diamond Re-ID","F. De Feyter; D. Hulens; B. Claes; T. Goedeme","KU Leuven, EAVISE, Mechelen, Belgium; KU Leuven, EAVISE, Mechelen, Belgium; Antwerp Labs, Antwerp, Belgium; EAVISE, KU Leuven, Mechelen, Belgium","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","2020","2025","Re-identification neural networks are widely used in numerous applications such as crowd control, crime investigations, safety systems and even in most smartphones to unlock the phone with a picture of the owner. These techniques are mostly used to re-identify faces or persons but in this paper we investigate the possibility to adapt these to also re-identify similar looking objects such as diamonds. Since polished diamonds are very similar to the naked eye, it is difficult to distinguish one diamond from another. We have indications that diamonds are sometimes switched by trained switchers with fake or less expensive stones, while they pretend to inspect the stone. A solution to this is diamond fingerprinting. We therefore propose a technique to generate a unique ID for each stone, which allows to re-identify the diamond solely based on an image of the gem. Since each diamond is assigned a unique ID it is even possible to keep track of the diamonds over time. This allows the seller to verify his stones before and after trading while switchers don't stand a chance. For this task we trained and adapted a classification network optimized for both speed and accuracy.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999045","re-identification;neural network;deep learning;diamonds","Diamond;Training;Task analysis;Image color analysis;Optical switches;Optical imaging","","","","22","IEEE","17 Feb 2020","","","IEEE","IEEE Conferences"
