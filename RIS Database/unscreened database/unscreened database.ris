TY  - CONF
TI  - Dual-Rank Attention Module for Fine-Grained Vehicle Model Recognition
AU  - Cai, Wen
AU  - Zhu, Wenjia
AU  - Cheng, Bo
AU  - Xu, Longdao
AU  - Yu, Ye
AU  - Lu, Qiang
AU  - Jia, Wei
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Vehicle fine-grained recognition is an important task in the field of intelligent transportation. However, due to the subtle differences between different vehicle models, and the tremendous difference caused by the different pose of the same vehicle model, the effect of vehicle recognition is less successful and still require further research. In this paper, we propose a dual-rank attention module (DRAM), which can reduce visual interference caused by vehicle multi-pose. In addition, combined with the attention mechanism, our method can not only mine the discriminative features of the vehicle model but also increase the feature richness and improve the accuracy of vehicle model recognition. In this paper, in the initial stage of the network, the STN is used to transform the vehicle pose, meanwhile, the whole image is weighted by the global attention to mine the subtle discriminant features. At the high part of the network, after fusing multi-level feature maps top-down, we designed a fused channel attention module to enhance the feature response of the current category. It achieves 94.1% and 96.9% top-1 accuracy on the Stanford Cars and CompCars datasets, which is more than 2.1% higher than the original baseline network VGG19 but only adds a few parameters. Experimental results show that the DRAM can effectively improve the accuracy of vehicle fine-grained recognition.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_2
DP  - Springer Link
SP  - 17
EP  - 28
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_2.pdf
KW  - Dual-rank attention
KW  - Feature fusion in top-down
KW  - Vehicle model recognition
KW  - Vehicle pose transform
ER  - 

TY  - CONF
TI  - Temporal Correlation-Diversity Representations for Video-Based Person Re-Identification
AU  - Gong, Litong
AU  - Zhang, Ruize
AU  - Tang, Sheng
AU  - Cao, Juan
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Video-based person re-identification is a challenging task due to illuminations, occlusions, viewpoint changes, and pedestrian misalignment. Most previous works focus more on temporal correlation features, which leads to a lack of detailed information. In this paper, we emphasize the importance of keeping both correlation and diversity of multi-frame features simultaneously. Thus, we propose a Temporal Correlation-Diversity Representation (TCDR) network to enhance the representation of frame-level pedestrian features and the temporal feature aggregation abilities. Specifically, in order to capture correlated but diverse temporal features, we propose a Temporal-Guided Frame Feature Enhancement (TGFE) module, which explores the temporal correlation with a global perspective and enhances frame-level features to achieve the temporal diversity. Furthermore, we propose a Temporal Feature Integration (TFI) module to aggregate multi-frame features. Finally, we propose a novel progressive smooth loss to alleviate the influence of noisy frames. Extensive experiments show that our method achieves the state-of-the-art performance on MARS, DukeMTMC-VideoReID and LS-VID datasets.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_8
DP  - Springer Link
SP  - 94
EP  - 105
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_8.pdf
KW  - Deep learning
KW  - Feature enhancement
KW  - Person re-identification
ER  - 

TY  - CONF
TI  - Multi-view Geometry Distillation for Cloth-Changing Person ReID
AU  - Yu, Hanlei
AU  - Liu, Bin
AU  - Lu, Yan
AU  - Chu, Qi
AU  - Yu, Nenghai
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Most person re-identification (ReID) methods aim at retrieving people with unchanged clothes. Meanwhile, fewer studies work on the cloth-inconsistency problem, which is more challenging but useful in the real intelligent surveillance scenario. We propose a novel method, named Multi-View Geometry Distillation (MVGD), taking advantage of 3D priors to explore cloth-unrelated multi-view human information. Specifically, a 3D Grouping Geometry Graph Convolution Network (3DG$$^{3}$$3) is proposed to extract ReID-specific geometry representation from the 3D reconstructed body mesh, which encodes shape, pose, and other geometry patterns from the 3D perspective. Then, we design a 3D-Guided Appearance Learning scheme to extract more accurate part features. Furthermore, we also adopt a Multi-View Interactive Learning module (MVIL) to fuse the different types of features together and extract high-level multi-view geometry representation. Finally, these discriminative features are treated as the teacher to guide the backbone by the distillation mechanism for better representations. Extensive experiments on three popular cloth-changing ReID datasets demonstrate the effectiveness of our method. The proposed method brings 9$$\%$$%and 7.5$$\%$$%gains in average in terms of rank-1 and mAP metrics against the baseline, respectively.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_3
DP  - Springer Link
SP  - 29
EP  - 41
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_3.pdf
KW  - 3D priors
KW  - Person re-identification
ER  - 

TY  - CONF
TI  - FIMF Score-CAM: Score-CAM Based Visual Explanations via Fast Integrating Multiple Features of Local Space for Deep Networks
AU  - Li, Jing
AU  - Zhang, Dongbo
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - The interpretability of deep networks is a hot issue in the field of computer vision. This paper proposes a FIMF Score-CAM model that fast integrates multiple features of local space. The model only needs to perform a forward convolution calculation on the image once to extract the feature maps, and then the feature selection template is introduced to integrate the features of different channels in local space to improve the ability of model interpretation. The FIMF Score-CAM model is superior to the existing mainstream models in interpreting the visual performance and fairness indicators of the decision-making, having more complete explanation of the target class and the advantage of fast calculation speed. Meanwhile, in some network models requiring larger convolution calculation, the operation time is reduced by more than 90% compared to Score-CAM.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_9
DP  - Springer Link
SP  - 106
EP  - 117
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
ST  - FIMF Score-CAM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_9.pdf
KW  - Class activation mapping
KW  - Deep network
KW  - Model interpretation
ER  - 

TY  - CONF
TI  - Architecture Colorization via Self-supervised Learning and Instance Segmentation
AU  - Liu, Sen
AU  - Chen, Hang
AU  - Li, Li
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - In recent years, building coloring has become one of the hot spots in computer vision. In this paper, we design an instance segmentation module consisting of a region proposal network (RPN) and a backbone network, which can effectively avoid the effect of coloring between multiple objects. At the same time, we combine the feature map and the weights of the separated parts for fusion to avoid the coloring position error caused by segmentation. Meanwhile, we propose a self-supervised architectural coloring model that can construct positive and negative samples to achieve contrast constraints to solve the problem of unlabeled datasets. The model filters out unnecessary image noise based on architectural features and improves the effectiveness of the loss function by obtaining more accurate structural details. We provide a dataset and perform segmentation to help train the coloring weights for all seasons. We conducted extensive ablation experiments with multiple datasets. The experimental results visually demonstrate the excellent performance of our model.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_1
DP  - Springer Link
SP  - 3
EP  - 16
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_1.pdf
KW  - Architecture colorization
KW  - GANs
KW  - Instance segmentation
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - TFAtrack: Temporal Feature Aggregation for UAV Tracking and a Unified Benchmark
AU  - Zhao, Xiaowei
AU  - Zhang, Youhua
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Research on object detection and tracking has achieved remarkable progress in recent years. Due to the superior viewing angle and maneuverability advantages of unmanned aerial vehicles (UAVs), the application of UAV-based tracking is also undergoing rapid development. But since the targets captured by UAVs are tiny and all have similarities and low recognition, this leads to the great challenge of multiple-object tracking (MOT). To solve the two problems mentioned above, We propose TFATracking, a comprehensive framework that fully exploits temporal context for UAV tracking. To further reflect the effectiveness of the algorithm and promote the development of UAV object tracking, we present a large-scale, high-diversity benchmark for short-term UAV multi-object tracking named T2UAV in this work. It contains 20 UAV-captured video sequences with a total number of frames over 12k and an average video length of over 600 frames. We conduct a comprehensive performance evaluation of 8 MOT algorithms on the dataset and present a detailed analysis. We will release the dataset for free academic use.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_5
DP  - Springer Link
SP  - 55
EP  - 66
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
ST  - TFAtrack
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_5.pdf
KW  - Benchmark datasets
KW  - Mutil-object tracking
KW  - UAV tracking
ER  - 

TY  - CONF
TI  - Rider Re-identification Based on Pyramid Attention
AU  - Li, Jiaze
AU  - Liu, Bin
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - In recent years, object re-identification (ReID) based on deep learning has made great progress, and research in this field mainly focuses on person and vehicle. However, the researchers ignore an important target: riders. Electric bikes are an essential part of modern transportation scenarios, so identifying riders and monitoring their behavior on a large scale is critical to public safety management. To bridge the research gap of rider ReID, this paper proposes a pyramid attention network (PANet), which utilizes the pyramid structure to capture multi-scale clues and discovers key regional features from fine to coarse. PANet first learns fine-grained attention in local small regions, then gradually aggregates local regions to expand the scope of attention exploration, and finally conducts global coarse-grained attention learning. We implement two different dimensional attention computations in the pyramid attention network: spatial attention and channel attention. Experiments on BPReID and MoRe datasets demonstrate the effectiveness of this network design, which can achieve better performance with limited computational overhead.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_7
DP  - Springer Link
SP  - 81
EP  - 93
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_7.pdf
KW  - Deep learning
KW  - Pyramid attention
KW  - Rider re-identification
ER  - 

TY  - CONF
TI  - Correlated Matching and Structure Learning for Unsupervised Domain Adaptation
AU  - Luo, Xingping
AU  - Lu, Yuwu
AU  - Wen, Jiajun
AU  - Lai, Zhihui
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - For cross-domain tasks in real-world, a source domain and a target domain often have different marginal probability distribution and conditional probability distribution. To leverage the distribution difference between the source and target domain, domain adaptation has been applied in many fields. Unfortunately, as most of the existing domain adaptation methods only focus on eliminating the distribution discrepancy between the two domains, they do not make full use of the correlation information and data distribution structure between the two domains. In this paper, we put forward a novel domain adaptation method named correlated matching and structure learning (CMSL), which considers the association information between source and target domains, and extracts the feature representation and thus can learn the maximization correlation features between the two domains. Simultaneously, the class centroids of the source data are used to cluster the target data, and a local manifold self-learning strategy is introduced to the target domain to preserve the underlying structure of the data. Experimental results on six data benchmarks show that our proposed method achieves good classification performance and outperforms several state-of-the-art unsupervised domain adaptation methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_6
DP  - Springer Link
SP  - 67
EP  - 80
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_6.pdf
KW  - Correlated matching
KW  - Cross-domain learning
KW  - Domain adaptation
KW  - Structure learning
ER  - 

TY  - CONF
TI  - Learning Adaptive Progressive Representation for Group Re-identification
AU  - Deng, Kuoyu
AU  - Feng, Zhanxiang
AU  - Lai, Jian-Huang
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Group re-identification (re-id) aims to retrieve a group of people across different surveillance cameras. Due to the change of group layout and membership, group re-id is much more difficult than person re-id. How to address these problems for group re-id is under-explored. In this paper, we propose the Adaptive Progressive group representation Learning Network (APLN) which consists of three innovations: First, we propose a progressive group representation method which fuses individual features together with relation features. Second, we propose a member mask to ignore the impact of changes in the number of members. The member mask is beneficial to getting a more robust group representation from volatile group samples. Third, we propose to use group proxy node as the global representation of the group context graph to obtain precise group context graph information by focusing on more significant individuals. Experimental results demonstrate that our proposed method outperforms the state-of-the-art performance on several group re-id datasets. Compared with the previous methods, the parameters of our model are much fewer and the inference speed is faster.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_10
DP  - Springer Link
SP  - 118
EP  - 129
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_10.pdf
KW  - Group re-identification
KW  - Person re-identification
KW  - Transformer
ER  - 

TY  - CONF
TI  - General High-Pass Convolution: A Novel Convolutional Layer for Image Manipulation Detection
AU  - Tang, Zecheng
AU  - Liu, Yang
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Image Manipulation Detection is different from most computer vision tasks, such as Image Classification. The latter pays more attention to image content, while the former focuses more on manipulation trace. However, plain convolutional layer tends to learn features that represent image content rather than features that represent manipulation trace, which degrades the performance of traditional CNNs on Image Manipulation Detection. Inspired by constrained convolutional layer proposed by Bayar et al., we propose General High-Pass Convolution, a new form of convolutional layer which is capable of motivating CNNs to learn manipulation trace features. General High-Pass Convolution is designed to simulate a set of learnable high-pass filters to suppress the image content, thus motivating the CNNs to learn manipulation trace features which are mainly present in the high-frequency components of the image. We conduct comprehensive experiments to evaluate the effectiveness of General High-Pass Convolution. The experimental results show that General High-Pass Convolution achieves better performance than Bayar et al.’s constrained convolutional layer, and can be combined with CNN backbone networks to improve their performance on Image Manipulation Detection, such as VGG and ResNet.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_11
DP  - Springer Link
SP  - 130
EP  - 145
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
ST  - General High-Pass Convolution
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_11.pdf
KW  - CNN
KW  - Image manipulation detection
KW  - Learnable high-pass filter
ER  - 

TY  - CONF
TI  - Thangka Mural Line Drawing Based on Dense and Dual-Residual Architecture
AU  - Wang, Nianyi
AU  - Wang, Weilan
AU  - Hu, Wenjin
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Thangka murals are precious cultural heritage for Tibetan history, literature, and art. Digital line drawing of Thangka murals plays a vital role as a fundamental digital resource for Thangka protection. Digital Thangka line drawing can be categorized as image edge detection to extract visually salient edges from images. Although existing edge detection methods have progressed, they failed to generate semantically plausible edges, especially in-object edges. We propose a novel deep supervised edge detection solution to generate line drawings of Thangka mural images. Compared to existing studies, firstly a new Dense and Dual-Residual architecture (DDR) is proposed to propagate correct edge features effectively in CNN layers by using both short-range and long-range feature memory; Secondly, a new 2-phase loss function strategy is designed to focus on in-object edge detection. Experiments on different datasets (BIPED and Thangka) show that the proposed method is able to produce more richer edge maps comparing to the existing methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_12
DP  - Springer Link
SP  - 149
EP  - 160
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_12.pdf
KW  - Edge detection
KW  - Line drawings
KW  - Thangka mural
ER  - 

TY  - CONF
TI  - Driver Behavior Decision Making Based on Multi-Action Deep Q Network in Dynamic Traffic Scenes
AU  - Zhao, Kai
AU  - Li, Yaochen
AU  - Gao, Yuan
AU  - Liu, Hujun
AU  - Li, Anna
AU  - Guo, Jiaxin
AU  - Liu, Yuehu
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Driving behavior decision-making takes an essential part in autonomous driving. The training process of recent deep reinforcement learning methods is slow when faced with large state spaces of dynamic traffic scenes. In this paper, a driving behavior decision-making framework based on Multi-Action deep Q network (Multi-Action DQN) is proposed. The Multi-Action DQN can optimize the value of multiple actions in each training step and learn the relativity between actions, to achieve better convergence speed and stability. Besides, an improved vehicle training method is designed to construct a series of road environments with increasing complexity, so that the trained vehicle can imitate the human learning process from easy to difficult, and gradually learn stronger abilities. In order to alleviate blind exploration, the curiosity exploration strategy is applied to motivate vehicle exploration the state with a higher curiosity reward. The proposed Multi-Action DQN is evaluated in the Atari game environment of OpenAI GYM. The experiments on Carla simulation platform demonstrate the effectiveness of the proposed driving behavior decision-making framework.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_14
DP  - Springer Link
SP  - 174
EP  - 186
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_14.pdf
KW  - Deep reinforcement learning
KW  - Driving behavior decision-making
KW  - Multi-Action deep Q network
KW  - Temporal difference
ER  - 

TY  - CONF
TI  - Self-supervised Adaptive Kernel Nonnegative Matrix Factorization
AU  - Deng, Furong
AU  - Zhao, Yang
AU  - Pei, Jihong
AU  - Yang, Xuan
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - The kernel function to imply nonlinear mapping is crucial for kernel nonnegative matrix factorizations (KNMF), which determines whether the model can properly represent the data. However, the analysis and adaptive learning of parameters in the kernel function are lacking in existing methods. The kernel parameters of most methods are randomly selected, and the purpose and motivation of kernel function construction is weak. To address this problem, a self-supervised adaptive kernel nonnegative matrix factorization (SAKNMF) is proposed to handle image recognition tasks. Kernel methods are used to achieve non-linearization. Firstly, the data is devided into multiple clusters by fuzzy clustering as self-supervised information. Then, according to the self-supervision information, the discriminative constraints that can adaptively learn the kernel parameters are constructed in the objective function. Based on the new objective function, the Gaussian kernel function parameters, basis matrix and coefficient matrix are jointly optimized. The kernel function constructed by the learned parameters enables the nonlinear mapped basis images to cover the mapped samples in the same cluster and distinguish other different clusters. So that the model can finally learn features that reflect the sample difference and have good generalization. Experiments show that our method can learn appropriate kernel width in different datasets, and the recognition accuracy is better than the state-of-the-art methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_13
DP  - Springer Link
SP  - 161
EP  - 173
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_13.pdf
KW  - Adaptive Gaussian kernel
KW  - Kernel method
KW  - Nonnegative matrix factorization
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Federated Twin Support Vector Machine
AU  - Yang, Zhou
AU  - Chen, Xiaoyun
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - TSVM is designed to solve binary classification problems with less computational overhead by finding two hyperplanes and has been widely used to solve real-world problems. However, in real scenarios, the data used for learning is always scattered in different institutions or users. At the same time, people pay more attention to the issue of personal privacy leakage. Due to the complex privacy protection issues, simply collecting all the data for model training is no longer acceptable. Federated learning has recently been proposed to solve this problem. It completes model training by sharing model parameter updates in the form of data that remains local. But there is still no algorithm for twin support vector machines under the framework of federated learning. Combining the characteristics of twin support vector machine and federated learning, this paper proposes a federated twin support vector machine algorithm (FTSVM) and extends the twin support vector machine based on stochastic gradient descent into a federated support vector machine. We propose a unique initialization algorithm and integration algorithm to ensure the accuracy of the algorithm and the effectiveness of privacy protection. Accuracy experiments are carried out on five datasets, and the accuracy is basically the same as that of the TSVM based on gradient descent. Ablation experiments show that as the number of participants increases, the accuracy of the FTSVM is significantly higher than the average accuracy of the Stand-alone TSVM. Time experiments show that the time overhead of FTSVM increases linearly with the number of participants. These experiments demonstrate the accuracy, effectiveness, and possibility of application in real-world scenarios of our proposed FTSVM.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_15
DP  - Springer Link
SP  - 187
EP  - 204
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_15.pdf
KW  - Federated learning
KW  - Stochastic gradient descent
KW  - Twin Support Vector Machine
ER  - 

TY  - CONF
TI  - Triplet Ratio Loss for Robust Person Re-identification
AU  - Hu, Shuping
AU  - Wang, Kan
AU  - Cheng, Jun
AU  - Tan, Huan
AU  - Pang, Jianxin
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Triplet loss has been proven to be useful in the task of person re-identification (ReID). However, it has limitations due to the influence of large intra-pair variations and unreasonable gradients. In this paper, we propose a novel loss to reduce the influence of large intra-pair variations and improve optimization gradients via optimizing the ratio of intra-identity distance to inter-identity distance. As it also requires a triplet of pedestrian images, we call this new loss as triplet ratio loss. Experimental results on four widely used ReID benchmarks, i.e., Market-1501, DukeMTMC-ReID, CUHK03, and MSMT17, demonstrate that the triplet ratio loss outperforms the previous triplet loss.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_4
DP  - Springer Link
SP  - 42
EP  - 54
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_4.pdf
KW  - Metric learning
KW  - Person re-identification
KW  - Triplet ratio loss
ER  - 

TY  - CONF
TI  - Fuzzy Twin Bounded Large Margin Distribution Machines
AU  - Jin, Qiang
AU  - Fan, Shuangyi
AU  - Dong, Denghao
AU  - Zhang, Libo
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Twin bounded large distribution machine (TBLDM) considers structural risk and marginal distribution issues, obtaining good efficiency, robustness, and generalization performance. However, it ignores the influence of noise and uncertainty of the input data, which is inevitable in reality. Aiming at the problem, this paper introduces the idea of fuzzy set theory and proposes a novel fuzzy TBLDM (FTBLDM). The fuzzy membership function is set to be related to the distance of the sample to the class center, which describes its importance and credibility level. By incorporating the membership degree into the object function, FTBLDM reduces the influence of outliers and noise on the optimal hyperplane. The effectiveness of our method is validated by experiments on a synthetic dataset and UCI benchmark datasets. Besides, to verify the anti-noise performance of the model, we conduct experiments on UCI datasets with noise. The results show that FTBLDM is able to produce promising results compared to several benchmark and state-of-the-art algorithms.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_17
DP  - Springer Link
SP  - 220
EP  - 231
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_17.pdf
KW  - Classification
KW  - Fuzzy membership
KW  - Large margin distribution
KW  - Twin support vector machine
ER  - 

TY  - CONF
TI  - Adversarial VAE with Normalizing Flows for Multi-Dimensional Classification
AU  - Zhang, Wenbo
AU  - Gou, Yunhao
AU  - Jiang, Yuepeng
AU  - Zhang, Yu
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Exploiting correlations among class variables and using them to facilitate the learning process are a key challenge of Multi-Dimensional Classification (MDC) problems. Label embedding is an efficient strategy towards MDC problems. However, previous methods for MDC only use this technique as a way of feature augmentation and train a separate model for each class variable in MDC problems. Such two-stage approaches may cause unstable results and achieve suboptimal performance. In this paper, we propose an end-to-end model called Adversarial Variational AutoEncoder with Normalizing Flow (ADVAE-Flow), which encodes both features and class variables to probabilistic latent spaces. Specifically, considering the heterogeneity of class spaces, we introduce a normalizing flows module to increase the capacity of probabilistic latent spaces. Then adversarial training is adopted to help align transformed latent spaces obtained by normalizing flows. Extensive experiments on eight MDC datasets demonstrate the superiority of the proposed ADVAE-Flow model over state-of-the-art MDC models.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18907-4_16
DP  - Springer Link
SP  - 205
EP  - 219
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-18907-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18907-4_16.pdf
KW  - Multi-Dimensional Classification
KW  - Normalizing flows
KW  - VAE
ER  - 

TY  - CONF
TI  - CAWNet: A Channel Attention Watermarking Attack Network Based on CWABlock
AU  - Wang, Chunpeng
AU  - Tian, Pengfei
AU  - Wei, Ziqi
AU  - Li, Qi
AU  - Xia, Zhiqiu
AU  - Ma, Bin
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In recent years, watermarking technology has been widely used as a common information hiding technique in the fields of copyright protection, authentication, and data privacy protection in digital media. However, the development of watermark attack techniques has lagged behind. Improving the efficiency of watermark attack techniques and effectively attacking watermarks has become an urgent problem to be solved. Therefore, this paper proposes a watermark attack network called CAWNet. Firstly, this paper designs a convolution-based watermark attack module (CWABlock), which introduces channel attention mechanism. By replacing fully connected layers with global average pooling layers, the parameter quantity of the network is reduced and the computational efficiency is improved, enabling effective attacks on watermark information. Secondly, in the training phase, we utilize a large-scale real-world image dataset for training and employ data augmentation strategies to enhance the robustness of the network. Finally, we conduct ablation experiments on CWABlock, attention mechanism, and other modules, as well as comparative experiments on different watermark attack methods. The experimental results demonstrate significant improvements in the effectiveness of the proposed watermark attack approach.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_4
DP  - Springer Link
SP  - 41
EP  - 52
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
ST  - CAWNet
KW  - attention mechanism
KW  - CWABlock
KW  - deep learning
KW  - Imperceptible
KW  - Robustness
KW  - watermarking attack
ER  - 

TY  - CONF
TI  - Quadratic Polynomial Residual Network for No-Reference Image Quality Assessment
AU  - Fan, Xiaodong
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Residual connection has become an essential structure of deep neural networks. In residual connection, shallow features are directly superimposed to deep features without any processing. In this paper, a quadratic polynomial residual module is designed to increase the nonlinear fitting ability of the network. As the name suggests, this module superimposes quadratic polynomials of shallow features onto deep features. In this way, the series of two modules has the fitting ability of a quartic polynomial. The fitting ability of the network increases exponentially with the number of layers. According to Taylor’s theorem, it can be concluded that this module effectively improves the fitting ability of the network. Meanwhile, the image patches containing more information have greater contribution to image quality assessment. The patches are screened according to the two-dimensional information entropy, which reflects the information amount of patches. Based on the above two points, a quadratic polynomial residual network with entropy weighting and multi-receptive field structure is proposed for no-reference image quality assessment. The experimental results show that the proposed algorithm achieves high accuracy and more effectively fits the human visual system.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_11
DP  - Springer Link
SP  - 133
EP  - 144
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Deep learning
KW  - Image quality assessment
KW  - Residual network
ER  - 

TY  - CONF
TI  - MFNet: A Channel Segmentation-Based Hierarchical Network for Multi-food Recognition
AU  - Jin, Kelei
AU  - Chen, Jing
AU  - Song, Tingting
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Due to significant differences between foods from different regions, there is a relative lack of publicly available multi-food image datasets, which is particularly evident in the field of Chinese cuisine. To alleviate this issue, we create a large-scale Chinese food image dataset, JNU FoodNet, which contains 17,128 original images. Although a considerable amount of prior research has focused on single food image recognition, such methods are not suitable for recognizing multiple food items in one image. Moreover, in a food image, there are usually multiple food regions, and the key features of each region tend to gradually disperse from the center to the edges, leading to cumulative errors. To overcome this difficulty, we design a selective discriminative feature constrained module, SGC, which restricts model attention to regions from a global information perspective. Furthermore, we propose a progressive hierarchical network, MFNet, based on channel segmentation from both the whole image and local region perspectives, combined with the SGC branch. Experimental results show that MFNet achieves state-of-the-art mAP values on JNU FoodNet, UEC Food-100, and UEC Food-256.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_2
DP  - Springer Link
SP  - 16
EP  - 28
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
ST  - MFNet
KW  - Food computing
KW  - Hierarchical structure
KW  - Multi-food recognition
ER  - 

TY  - CONF
TI  - Adaptive and Compact Graph Convolutional Network for Micro-expression Recognition
AU  - Ba, Renwei
AU  - Li, Xiao
AU  - Yang, Ruimin
AU  - Li, Chunlei
AU  - Liu, Zhoufeng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Micro-expression recognition (MER) is a very challenging task since the motion of Micro-expressions (MEs) is subtle, transient and often occurs in tiny regions of face. To build discriminative representation from tiny regions, this paper proposes a novel two stream network, namely Adaptive and Compact Graph Convolutional Network (ACGCN). To be specific, we propose a novel Cheek Included Facial Graph to build more effective structural graph. Then, we propose the Tightly Connected Strategy to adaptively select structural graph to build compact and discriminative facial graph and adjacency matrix. We design the Small Region module to enlarge the interested feature in tiny regions and extract effective feature to build strong and effective node representations. We also adopt the spatial attention to make the network focus on the visual feature of salient regions. Experiments conducted on two micro-expressions datasets (CASME II, SAMM) show our approach outperforms the previous works.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_13
DP  - Springer Link
SP  - 158
EP  - 169
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Adjacency Matrix
KW  - Graph convolutional Network
KW  - Micro-expressions Recognition
KW  - Tightly Connected Strategy
ER  - 

TY  - CONF
TI  - Improving the Adversarial Robustness of Object Detection with Contrastive Learning
AU  - Zeng, Weiwei
AU  - Gao, Song
AU  - Zhou, Wei
AU  - Dong, Yunyun
AU  - Wang, Ruxin
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Object detection plays a crucial role and has wide-ranging applications in computer vision. Nevertheless, object detectors are susceptible to adversarial examples. Some works have been presented to improve the adversarial robustness of object detectors, which, however, often come at the loss of some prediction accuracy. In this paper, we propose a novel adversarial training method that integrates the contrastive learning into the training process to reduce the loss of accuracy. Specifically, we add a contrastive learning module to the primary feature extraction backbone of the target object detector to extract contrastive features. During the training process, the contrastive loss and detection loss are used together to guide the training of detectors. Contrastive learning ensures that clean and adversarial examples are more clustered and are further away from decision boundaries in the high-level feature space, thus increasing the cost of adversarial examples crossing decision boundaries. Numerous experiments on PASCAL-VOC and MS-COCO have shown that our proposed method achieves significantly superior defense performance.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_3
DP  - Springer Link
SP  - 29
EP  - 40
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - adversarial robustness
KW  - adversarial training
KW  - contrastive learning
KW  - Object detection
ER  - 

TY  - CONF
TI  - Decoupled Contrastive Learning for Long-Tailed Distribution
AU  - Chen, Xiaohua
AU  - Zhou, Yucan
AU  - Wang, Lin
AU  - Wu, Dayan
AU  - Zhang, Wanqian
AU  - Li, Bo
AU  - Wang, Weiping
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Self-supervised contrastive learning is popularly used to obtain powerful representation models. However, unlabeled data in the real world naturally exhibits a long-tailed distribution, making the traditional instance-wise contrastive learning unfair to tail samples. Recently, some improvements have been made from the perspective of model, loss, and data to make tail samples highly evaluated during training, but most of them explicitly or implicitly assume that the sample with a large loss is the tail. We argue that due to the lack of hard negatives, tail samples usually occupy a small loss at the initial stage of training, which will make them eliminated at the beginning of training. To address this issue, we propose a simple but effective two-stage learning scheme that decouples traditional contrastive learning to discover and enhance tail samples. Specifically, we identify the sample with a small loss in Stage I while a large loss in Stage II as the tail. With the discovered tail samples, we generate hard negatives for them based on their neighbors, which will balance the distribution of the hard negatives in training and help learn better representation. Additionally, we design the weight inversely proportional or proportional to the loss in each stage to achieve fairer training by reweighting. Extensive experiments on multiple unlabeled long-tailed datasets demonstrate the superiority of our DCL compared with the state-of-the-art methods. The code will be released soon.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Hard negative samples generation
KW  - Long-tailed distribution
KW  - Unsupervised contrastive learning
ER  - 

TY  - CONF
TI  - Global Consistency Enhancement Network for Weakly-Supervised Semantic Segmentation
AU  - Jiang, Le
AU  - Yang, Xinhao
AU  - Ma, Liyan
AU  - Li, Zhenglin
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Generation methods for reliable class activation maps (CAMs) are essential for weakly-supervised semantic segmentation. These methods usually face the challenge of incomplete and inaccurate CAMs due to intra-class inconsistency of final features and inappropriate use of deep-level ones. To alleviate these issues, we propose the Global Consistency Enhancement Network (GCENet) that consists of Middle-level feature Auxiliary Module (MAM), Intra-class Consistency Enhancement Module (ICEM), and Critical Region Suppression Module (CRSM). Specifically, MAM uses middle-level features which carry clearer edges information and details to enhance output features. Then, for the problem of incomplete class activation maps caused by the high variance of local context of the image, ICEM is proposed to enhance the representation of features. It takes into account the intra-class global consistency and the local particularity. Furthermore, CRSM is proposed to solve the problem of excessive CAMs caused by the over-activation of features. It activates the low-discriminative regions appropriately, thus improving the quality of class activation maps. Through our comprehensive experiments, our method outperforms all other competitors and well demonstrates its effectiveness on the PASCAL VOC2012 dataset.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_5
DP  - Springer Link
SP  - 53
EP  - 65
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Intra-class consistency
KW  - Semantic segmentation
KW  - Weakly-supervised semantic segmentation
ER  - 

TY  - CONF
TI  - Federated Learning Based on Diffusion Model to Cope with Non-IID Data
AU  - Zhao, Zhuang
AU  - Yang, Feng
AU  - Liang, Guirong
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Federated learning is a distributed machine learning paradigm that allows model training without centralizing sensitive data in a single place. However, non independent and identical distribution (non-IID) data can lead to degraded learning performance in federated learning. Data augmentation schemes have been proposed to address this issue, but they often require sharing clients’ original data, which poses privacy risks. To address these challenges, we propose FedDDA, a data augmentation-based federated learning architecture that uses diffusion models to generate data conforming to the global class distribution and alleviate the non-IID data problem. In FedDDA, a diffusion model is trained through federated learning and then used for data augmentation, thus mitigating the degree of non-IID data without disclosing clients’ original data. Our experiments on non-IID settings with various configurations show that FedDDA significantly outperforms FedAvg, with up to 43.04% improvement on the Cifar10 dataset and up to 20.05% improvement on the Fashion-MNIST dataset. Additionally, we find that relatively low-quality generated samples that conform to the global class distribution still improve federated learning performance considerably.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_18
DP  - Springer Link
SP  - 220
EP  - 231
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Data augmentation
KW  - Diffusion model
KW  - Federated learning
KW  - Non-IID data
ER  - 

TY  - CONF
TI  - DeCAB: Debiased Semi-supervised Learning for Imbalanced Open-Set Data
AU  - Huang, Xiaolin
AU  - Li, Mengke
AU  - Lu, Yang
AU  - Wang, Hanzi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Semi-supervised learning (SSL) has received significant attention due to its ability to use limited labeled data and various unlabeled data to train models with high generalization performance. However, the assumption of a balanced class distribution in traditional SSL approaches limits a wide range of real applications, where the training data exhibits long-tailed distributions. As a consequence, the model is biased towards head classes and disregards tail classes, thereby leading to severe class-aware bias. Additionally, since the unlabeled data may contain out-of-distribution (OOD) samples without manual filtering, the model will be inclined to assign OOD samples to non-tail classes with high confidence, which further overwhelms the tail classes. To alleviate this class-aware bias, we propose an end-to-end semi-supervised method Debias Class-Aware Bias (DeCAB). DeCAB introduces positive-pair scores for contrastive learning instead of positive-negative pairs based on unreliable pseudo-labels, avoiding false negative pairs negatively impacts the feature space. At the same time, DeCAB utilizes class-aware thresholds to select more tail samples and selective sample reweighting for feature learning, preventing OOD samples from being misclassified as head classes and accelerating the convergence speed of the model. Experimental results demonstrate that DeCAB is robust in various semi-supervised benchmarks and achieves state-of-the-art performance. Our code is temporarily available at https://github.com/xlhuang132/decab.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_9
DP  - Springer Link
SP  - 104
EP  - 119
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
ST  - DeCAB
KW  - Contrastive Learning
KW  - Imbalanced Learning
KW  - Semi-supervised Learning
ER  - 

TY  - CONF
TI  - Event Sparse Net: Sparse Dynamic Graph Multi-representation Learning with Temporal Attention for Event-Based Data
AU  - Li, Dan
AU  - Huang, Teng
AU  - Hong, Jie
AU  - Hong, Yile
AU  - Wang, Jiaqi
AU  - Wang, Zhen
AU  - Zhang, Xi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Graph structure data has seen widespread utilization in modeling and learning representations, with dynamic graph neural networks being a popular choice. However, existing approaches to dynamic representation learning suffer from either discrete learning, leading to the loss of temporal information, or continuous learning, which entails significant computational burdens. Regarding these issues, we propose an innovative dynamic graph neural network called Event Sparse Net (ESN). By encoding time information adaptively as snapshots and there is an identical amount of temporal structure in each snapshot, our approach achieves continuous and precise time encoding while avoiding potential information loss in snapshot-based methods. Additionally, we introduce a lightweight module, namely Global Temporal Attention, for computing node representations based on temporal dynamics and structural neighborhoods. By simplifying the fully-connected attention fusion, our approach significantly reduces computational costs compared to the currently best-performing methods. We assess our methodology on four continuous/discrete graph datasets for link prediction to assess its effectiveness. In comparison experiments with top-notch baseline models, ESN achieves competitive performance with faster inference speed.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_17
DP  - Springer Link
SP  - 208
EP  - 219
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
ST  - Event Sparse Net
KW  - dynamic graph representations
KW  - light sparse temporal model
KW  - link prediction
KW  - self-attention mechanism
ER  - 

TY  - CONF
TI  - Consistency Guided Multiview Hypergraph Embedding Learning with Multiatlas-Based Functional Connectivity Networks Using Resting-State fMRI
AU  - Wang, Wei
AU  - Xiao, Li
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Recently, resting-state functional connectivity network (FCN) analysis via graph convolutional networks (GCNs) has greatly boosted diagnostic performance of brain diseases in a manner that can refine FCN embeddings by treating FCN as irregular graph-structured data. In this paper, we propose a Consistency Guided Multiview HyperGraph Embedding Learning (CG-MHGEL) framework to integrate FCNs based on multiple brain atlases in multisite studies. First, we model brain network as a hypergraph and develop a multiview hypergraph convolutional network (HGCN) to extract a multiatlas-based FCN embedding for each subject. Here, we employ HGCN rather than GCN to capture more complex information in brain networks, due to the fact that a hypergraph can characterize higher-order relations among multiple vertexes than a widely used graph. Moreover, in order to preserve between-subject associations to promote optimal FCN embeddings, we impose a class-consistency regularization in the embedding space to minimize intra-class dissimilarities while maximizing inter-class dissimilarities for subjects, as well as a site-consistency regularization to further penalize the dissimilarities between intra-class but inter-site subjects. The learned multiatlas-based FCN embeddings are finally fed into fully connected layers followed by the soft-max classifier for brain disease diagnosis. Experimental results on the ABIDE demonstrate the effectiveness of our method for autism spectrum disorder (ASD) identification. Furthermore, the detected ASD-relevant brain regions can be easily traced back with biological interpretability.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_14
DP  - Springer Link
SP  - 170
EP  - 181
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Autism
KW  - embedding
KW  - functional connectivity
KW  - graph convolution networks
KW  - hypergraph
ER  - 

TY  - CONF
TI  - FGPTQ-ViT: Fine-Grained Post-training Quantization for Vision Transformers
AU  - Liu, Caihua
AU  - Shi, Hongyang
AU  - He, Xinyu
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The complex architecture and high training cost of Vision Transformers (ViTs) have prompted the exploration of post-training quantization (PTQ). However, introducing previous PTQ into ViTs performed worse because the activation values after processing by the softmax and GELU functions were extremely unbalanced distributed and not the common Gaussian distribution. To solve this problem, we propose a fine-grained ViT quantization method to fit this special distribution and reduce the quantization error of the activation values. We also design an adaptive piecewise point search algorithm that can automatically find the optimal piecewise point. Both the piecewise point and its search process are in the form of a power of two, making it possible to be implemented on general-purpose hardware with a simple shift operation. Experiments show that the quantization algorithm requires only 32 calibration images and achieves nearly lossless prediction accuracy in the classification task of ImageNet dataset. (The accuracy degradation for 8-bit quantization does not exceed 0.45%, and the average degradation is 0.17%).
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_7
DP  - Springer Link
SP  - 79
EP  - 90
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
ST  - FGPTQ-ViT
KW  - Adaptive search algorithm
KW  - Piecewise quantization
KW  - Post-training quantization
KW  - Vision transformer quantization
ER  - 

TY  - CONF
TI  - A Diffusion Simulation User Behavior Perception Attention Network for Information Diffusion Prediction
AU  - Shao, Yuanming
AU  - He, Hui
AU  - Tai, Yu
AU  - Wu, Xinglong
AU  - Yang, Hongwei
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Information diffusion prediction is an essential task in understanding the dissemination of information on social networks. Its objective is to predict the next user infected with a piece of information. While previous work focuses primarily on the analysis of diffusion sequences, recent work shifts towards examining social network connections between users. During the diffusion of information, users are expected to send and receive information. However, few works analyze the sending and receiving behavior of users during information diffusion. We design a Diffusion Simulation User Behavior Perception Attention Network (DSUBPAN). First, based on the social network graph, we construct a diffusion simulation heterogeneous network graph, which simulates diffusion, and obtain the sending and receiving behavior of users during information diffusion. Second, we utilize a user behavior fuse transformer to fuse different user behaviors. Then, we employ an attention network to perceive the time information and user sequence information in the information diffusion sequence. Finally, we utilize a dense layer and a softmax layer to predict the next infected user. Our model outperforms baseline methods on two real-world datasets, demonstrating its effectiveness.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_15
DP  - Springer Link
SP  - 182
EP  - 194
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Graph convolutional network
KW  - Information diffusion prediction
KW  - Social network
ER  - 

TY  - CONF
TI  - Learning Hierarchical Representations in Temporal and Frequency Domains for Time Series Forecasting
AU  - Zhang, Zhipeng
AU  - Zhang, Yiqun
AU  - Zeng, An
AU  - Pan, Dan
AU  - Zhang, Xiaobo
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Long-term time series forecasting is a critical task in many domains, including finance, healthcare, and weather forecasting. While Transformer-based models have made significant progress in time series forecasting, their high computational complexity often leads to compromises in model design, limiting the full utilization of temporal information. To address this issue, we propose a novel hierarchical decomposition framework that disentangles latent temporal variation patterns. Specifically, we decompose time series into trend and seasonal modes and further decompose seasonal temporal changes into coarse- and fine-grained states to capture different features of temporal sequences at different granularities. We use linear layers to embed local information for capturing fine-grained temporal changes and Fourier-domain attention to capture multi-periodic seasonal patterns to extract coarse-grained temporal dependency information. This forms a time series forecasting modeling from fine to coarse, and from local to global. Extensive experimental evaluation demonstrates that the proposed approach outperforms state-of-the-art methods on real-world benchmark datasets.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_8
DP  - Springer Link
SP  - 91
EP  - 103
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - deep learning
KW  - fourier-domain attention
KW  - hierarchical decomposition
KW  - supervised learning
KW  - Time series forecasting
ER  - 

TY  - CONF
TI  - A Representation Learning Link Prediction Approach Using Line Graph Neural Networks
AU  - Tai, Yu
AU  - Yang, Hongwei
AU  - He, Hui
AU  - Wu, Xinglong
AU  - Zhang, Weizhe
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Link prediction problem aims to infer the potential future links between two nodes in the network. Most of the existing methods exhibit limited universality and are only effective in specific scenarios, while also neglecting the issue of information loss during model training. To address such issues, we propose a link prediction method based on the line graph neural network (NLG-GNN). Firstly, we employ Node2Vector to learn the latent feature representation vector of each node in the network. Secondly, we extract the local subgraphs surrounding the target link and transform them into the corresponding line graphs. Then, we design a Graph Convolutional Network (GCN) to learn the structural feature representation vector of the node through the line graph. Finally, we combine the latent and structural features through the output layer to predict the target links. We execute extensive experiments on 17 diverse datasets, demonstrating the superior performance and faster convergence of our NLG-GNN method over all baseline methods.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_16
DP  - Springer Link
SP  - 195
EP  - 207
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Graph neural networks
KW  - Line graph
KW  - Link prediction
KW  - Node embedding
ER  - 

TY  - CONF
TI  - An Effective Visible-Infrared Person Re-identification Network Based on Second-Order Attention and Mixed Intermediate Modality
AU  - Tao, Haiyun
AU  - Zhang, Yukang
AU  - Lu, Yang
AU  - Wang, Hanzi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Visible-infrared person re-identification (VI-ReID) is a challenging cross-modality pedestrian retrieval problem. Due to the significant cross-modality discrepancy, it is difficult to learn discriminative features. Attention-based methods have been widely utilized to extract discriminative features for VI-ReID. However, the existing methods are confined by first-order structures that just exploit simple and coarse information. The existing approach lacks the sufficient capability to learn both modality-irrelevant and modality-relevant features. In this paper, we extract the second-order information from mid-level features to complement the first-order cues. Specifically, we design a flexible second-order module, which considers the correlations between the common features and learns refined feature representations for pedestrian images. Additionally, the visible and infrared modality has a significant gap. Therefore, we propose a plug-and-play mixed intermediate modality module to generate intermediate modality representations to reduce the modality discrepancy between the visible and infrared features. Extensive experimental results on two challenging datasets SYSU-MM01 and RegDB demonstrate that our method considerably achieves competitive performance compared to the state-of-the-art methods.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_10
DP  - Springer Link
SP  - 120
EP  - 132
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Attention Mechanism
KW  - Intermediate Modality
KW  - Person re-identification
KW  - Second-Order Information
KW  - VI-ReID
ER  - 

TY  - CONF
TI  - Interactive Learning for Interpretable Visual Recognition via Semantic-Aware Self-Teaching Framework
AU  - Jiang, Hao
AU  - Li, Haowei
AU  - Chen, Junhao
AU  - Wan, Wentao
AU  - Wang, Keze
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Aimed at tracing back the decision-making process of deep neural networks on the fine-grained image recognition task, various interpretable methods have been proposed and obtained promising results. However, the existing methods still have limited interpretability in aligning the abstract semantic concepts with the concrete image regions, due to the lack of human guidance during the model training. Attempting to address this issue and inspired by the machine teaching techniques, we formulate the training process of interpretable methods as an interactive learning manner by concisely simulating the human learning mechanism. Specifically, we propose a semantic-aware self-teaching framework to progressively improve the given neural network through an interactive teacher-student learning protocol. After initialing from the well-trained parameters of the given model, the teacher model focuses on minimally providing informative image regions to train the student model to generate interpretable predictions (i.e., semantic image regions) as good feedback. These feedback can encourage the teacher model to further refine the alignment of semantic concepts and image regions. Besides, our proposed framework is compatible with most of the existing network architectures. Extensive and comprehensive comparisons with the existing state-of-the-art interpretable approaches on the public benchmarks demonstrate that our interactive learning manner showcases an improved interpretability, a higher classification accuracy, and a greater degree of generality.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_12
DP  - Springer Link
SP  - 145
EP  - 157
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Interactive learning
KW  - Interpretable visual recognition
KW  - Semantic-aware self-teaching
ER  - 

TY  - CONF
TI  - Enhancing Model Robustness Against Adversarial Attacks with an Anti-adversarial Module
AU  - Qin, Zhiquan
AU  - Liu, Guoxing
AU  - Lin, Xianming
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Due to the rapid development of artificial intelligence technologies, such as deep neural networks in recent years, the subsequent emergence of adversarial samples poses a great threat to the security of deep neural network models. In order to defend threats brought by adversarial attacks, the recent mainstream method is to use adversarial training methods to add adversarial samples into model’s training process. Although such a type of method can defend against adversarial attacks, it requires increased computing resources and time, and reduces the accuracy of the original samples. Adversarial defense method that conduct anti-adversity in the inference stage. Inspired by adversarial example generation methods, we propose a defense against adversarial in the inference phase of the model. The adversarial sample generation is to add disturbances in the direction of maximizing the loss function after obtaining the sample gradient. Therefore, we add a perturbation in the opposite direction of the adversarial example generated before the sample is fed into the network. The main advantages of our method are that the method requires less computing resources and time; and our method can effectively improve the robust accuracy of the model against adversarial attacks. As a summary, the research content in this paper can stabilize adversarial training, alleviate the high resource consumption of adversarial training, and improve the overall robust performance of the model, which is of great significance to adversarial defense.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8546-3_6
DP  - Springer Link
SP  - 66
EP  - 78
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-46-3
KW  - Adversarial attack
KW  - Adversarial defense
KW  - Adversarial training
KW  - Deep neural network
ER  - 

TY  - CONF
TI  - DGMLP: Deformable Gating MLP Sharing for Multi-Task Learning
AU  - Xu, Yangyang
AU  - Zhang, Lefei
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - With the development of deep learning, many dense prediction tasks have been significantly improved. In this work, we introduce a DGMLP model that jointly learns multiple dense prediction tasks in a unified multi-task learning architecture that is trained end-to-end. Specifically, the DGMLP consists of (i) a spatial deformable MLP to capture the valuable spatial information for different tasks and (ii) a spatial gating MLP to learn the shared feature across all the tasks. Deformable MLP can adaptively adjust the receptive field and sample valuable locations in this approach. In addition, the Gating MLP is adopted to learn task-relevant features for each task. We take advantage of the spatial deformable MLP and spatial gating MLP to build a new MLP-like architecture that is especially simple and effective for multiple visual dense prediction tasks. We provide extensive experiments and evaluations to verify the advantages of our approach, and the extensive experiments demonstrate the superiority of the proposed framework over state-of-the-art methods.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_10
DP  - Springer Link
SP  - 117
EP  - 128
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - DGMLP
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_10.pdf
KW  - Dense prediction
KW  - Multi-task learning
KW  - Scene understanding
ER  - 

TY  - CONF
TI  - Unsupervised Domain Adaptation for Semantic Segmentation with Global and Local Consistency
AU  - Shan, Xiangxuan
AU  - Yin, Zijin
AU  - Gao, Jiayi
AU  - Liang, Kongming
AU  - Ma, Zhanyu
AU  - Guo, Jun
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Unsupervised domain adaptation(UDA) for semantic segmentation aims to learn from labeled synthetic data to segment the unlabeled real data. Many recent methods use generative networks to acquire real-like images for mitigating domain shift. However, these methods only ensure global style consistency between two domains and fail to impose pixel-wise constraint which is also referred to as local content consistency. To address the above problem, we propose a global and local consistency network to reduce the domain gap in unsupervised domain adaptation for semantic segmentation. To this end, we first constrain global style consistency through a generative adversarial network to acquire real-like latent domain images. Then we enhance local content consistency based on pixel-wise entropy minimization. Experimental results show that our method has superiority over other competitive methods on GTA5 $$\rightarrow $$→Cityscapes.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_13
DP  - Springer Link
SP  - 154
EP  - 165
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_13.pdf
KW  - Semantic segmentation
KW  - Style transfer
KW  - Unsupervised domain adaptation
ER  - 

TY  - CONF
TI  - SASD: A Shape-Aware Saliency Object Detection Approach for RGB-D Images
AU  - Zi, Lingling
AU  - Cong, Xin
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Saliency object detection is a fundamental problem in the field of computer vision. With the commercial success of consumer-grade depth sensors such as Microsoft Kinect, the captured RGB-D images provide users with a higher viewing experience, but also pose a higher challenge to the current saliency detection technology. In this paper, we propose a shape-aware saliency object detection approach SASD, manifesting in two aspects: 1) obtaining high quality saliency maps, especially the salient details; 2) displaying irregular salient regions, such as circles, ellipses, and splines. The proposed SASD approach consists of three steps. First, the initial saliency map is obtained by combing depth information and edge details. On this basis, the rules for the dominant factors of saliency detection are designed and the method of enhanced saliency map calculation is proposed. Finally, an irregular shape display method is demonstrated, the purpose of which is to fit the obtained saliency map to different shapes. The experiment demonstrates the effectiveness of our approach in subjective and objective aspects.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_15
DP  - Springer Link
SP  - 179
EP  - 190
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - SASD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_15.pdf
KW  - Depth information
KW  - Irregular shapes
KW  - RGB-D images
KW  - Saliency detection
ER  - 

TY  - CONF
TI  - Dual Windows Are Significant: Learning from Mediastinal Window and Focusing on Lung Window
AU  - Wang, Qiuli
AU  - Tan, Xin
AU  - Ma, Lizhuang
AU  - Liu, Chen
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Since the pandemic of COVID-19, several deep learning methods were proposed to analyze the chest Computed Tomography (CT) for diagnosis. In the current situation, the disease course classification is significant for medical personnel to decide the treatment. Most previous deep-learning-based methods extract features observed from the lung window. However, it has been proved that some appearances related to diagnosis can be observed better from the mediastinal window rather than the lung window, e.g., the pulmonary consolidation happens more in severe symptoms. In this paper, we propose a novel Dual Window RCNN Network (DWRNet), which mainly learns the distinctive features from the successive mediastinal window. Regarding the features extracted from the lung window, we introduce the Lung Window Attention Block (LWA Block) to pay additional attention to them for enhancing the mediastinal-window features. Moreover, instead of picking up specific slices from the whole CT slices, we use a Recurrent CNN and analyze successive slices as videos. Experimental results show that the fused and representative features improve the predictions of disease course by reaching the accuracy of 90.57%, against the baseline with an accuracy of 84.86%. Ablation studies demonstrate that combined dual window features are more efficient than lung-window features alone, while paying attention to lung-window features can improve the model’s stability.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_16
DP  - Springer Link
SP  - 191
EP  - 203
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - Dual Windows Are Significant
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_16.pdf
KW  - Chest computed tomography
KW  - COVID-19
KW  - Mediastinal window
ER  - 

TY  - CONF
TI  - Attentive Cascaded Pyramid Network for Online Video Stabilization
AU  - Xu, Yufei
AU  - Zhang, Qiming
AU  - Zhang, Jing
AU  - Tao, Dacheng
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Online video stabilization is important for hand-held camera shooting or remote robots control. Existing methods either need use the whole video to perform offline stabilization and result in long latency, or dismiss the nonuniform motion field in each frame and lead to large distortion. The non-uniform motion includes dynamic foreground motion and non-planar background motion. To better describe the shaky motion field online, we propose a novel attentive and multi-scale regression and refinement framework called ACP-Net. It exploits the idea of modeling camera motion on progressive levels, consisting of a flow-guided quiescent attention (FQA) module and a cascaded pyramid prediction (CPP) module. FQA module takes optical flow as an extra input and generates a soft mask to remedy the disturbance from dynamic foreground objects. Based on the attentive feature, the CPP module utilizes a multi-scale residual pyramid structure to do coarse to fine stabilization. Experimental results on public benchmarks show that our proposed method can achieve state-of-the-art performance both qualitatively and quantitatively, comparing to both online and offline methods.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_2
DP  - Springer Link
SP  - 18
EP  - 29
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_2.pdf
ER  - 

TY  - CONF
TI  - Lightweight Image Compression Based on Deep Learning
AU  - Li, Mengyao
AU  - Wang, Zhengyong
AU  - Shen, Liquan
AU  - Ding, Qing
AU  - Yu, Liangwei
AU  - Jiang, Xuhao
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Deep learning based image compression (DLIC) algorithms have achieved higher compression gain than conventional algorithms. However, the large parameters and float-point operations (FLOPs) of DLIC severely limit their application on mobile devices. To reduce the parameters and FLOPs while maintaining the superior compression gain, this paper proposes lightweight algorithms especially for the feature analysis, synthesis, and fusion modules in DLIC networks. Firstly, based on the observation that there are highly correlated pairing convolution kernels in the analysis/synthesis modules, a new Dynamic Concatenated Convolution (DCC) is proposed to discard half of pairing convolution kernels, which are then restored by the affine transformation of the remaining convolution kernels. Secondly, a novel Depthwise Separable Residual Block (DSRB), utilizing improved depthwise separable convolutions and skipped connections, is proposed to simplify the stacks of residual blocks in feature fusion modules, significantly reducing parameters and FLOPs. Extensive experimental results demonstrate that the proposed lightweight algorithms have fewer parameters/FLOPs and better image compression gain compared with the existing state-of-the-art lightweight algorithms.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_9
DP  - Springer Link
SP  - 106
EP  - 116
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_9.pdf
KW  - Depthwise separable convolution
KW  - Image compression
KW  - Lightweight network
ER  - 

TY  - CONF
TI  - Research on Multi-temporal Cloud Removal Using D-S Evidence Theory and Cloud Segmentation Model
AU  - Wang, Xinwei
AU  - Sun, Kailai
AU  - Zhao, Qianchuan
AU  - Zou, Jianhong
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Satellite remote sensing technology is widely applied for real-time drawing maps, forecasting weather, and predicting natural disasters. However, many remote sensing satellite images contain cloud noise, resulting in difficulties in practical applications. Existing cloud removal methods are limited when an image contains lots of clouds or thick clouds. Besides, most methods need a cloudless image as a reference. Our study proposes an advanced algorithm to remove cloud noise (especially thick clouds) in remote sensing images, including a cloud segmentation model, prior knowledge refinement, and Dempster-Shafer (D-S) evidence theory. Firstly, we trained a Cloud-net model to segment cloud regions. RGB and Near Infrared (NIR) images are fed into the Cloud-net model. Then it outputs coarse segmentation images. Secondly, we introduced the prior knowledge to refine and recover segmentation results. Finally, we designed cloud removal rules based on D-S evidence theory to fuse muti-temporal remote sensing images. Our method achieves a surprising performance on GaoFen-4 (GF-4) satellite images, reducing the average percentage of cloud noise from 30$$\%$$%–40$$\%$$%to 2$$\%$$%–8$$\%$$%per image.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_14
DP  - Springer Link
SP  - 166
EP  - 178
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_14.pdf
KW  - Cloud segmentation model
KW  - D-S evidence theory
KW  - Multi-temporal denoising
KW  - Satellite remote sensing image
ER  - 

TY  - CONF
TI  - Spatial-Aware GAN for Instance-Guided Cross-Spectral Face Hallucination
AU  - Xiao, Wenpeng
AU  - Xu, Cheng
AU  - Zhang, Huaidong
AU  - Xu, Xuemiao
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - An efficient strategy to solve the Heterogeneous Face Recognition (HFR) is to translate the probes to the same spectrum domain of the galleries using generative models. However, without or with only globally-pooled appearance representation from a reference, the low-quality generated images restrict the recognition accuracy. The intuition of our paper is the spatially-distributed appearance contains details beneficial to higher-quality image synthesis. Particularly, we propose a semantic spatial adaptive alignment module to solve the inevitable misalignment between the content from the near-infrared (NIR) image and the appearance from the visible (VIS) reference. In this way, arbitrary VIS reference can provide appearance with sufficient details to assist the NIR-to-VIS translation. Based on this, we propose an unsupervised spatial-aware instance-guided cross-spectral facial hallucination network (SICFH) for visual-pleasing and identity-preserved VIS image translation. Qualitative and quantitative experiments on three challenging NIR-VIS datasets demonstrate the synthesized VIS images address the HFR problem effectively and achieve state-of-the-art recognition accuracy.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_8
DP  - Springer Link
SP  - 93
EP  - 105
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_8.pdf
KW  - Cross-spectral face synthesis
KW  - Generative adversarial network
KW  - Heterogeneous face recognition
ER  - 

TY  - CONF
TI  - Cross-domain Trajectory Prediction with CTP-Net
AU  - Huang, Pingxuan
AU  - Cui, Zhenhua
AU  - Li, Jing
AU  - Gao, Shenghua
AU  - Hu, Bo
AU  - Fang, Yanyan
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Most pedestrian trajectory prediction methods rely on a huge amount of trajectories annotation, which is time-consuming and expensive. Moreover, a well-trained model may not effectively generalize to a new scenario captured by another camera. Therefore, it is desirable to adapt the model trained on an annotated source domain to the target domain. To achieve domain adaptation for trajectory prediction, we propose a Cross-domain Trajectory Prediction Network (CTP-Net). In this framework, encoders are used in both domains to encode the observed trajectories, then their features are aligned by a cross-domain feature discriminator. Further, considering the consistency between the observed and the predicted trajectories, a target domain offset discriminator is utilized to adversarially regularize the future trajectory predictions to be in line with the observed trajectories. Extensive experiments demonstrate the effectiveness of our method on domain adaptation for pedestrian trajectory prediction.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_7
DP  - Springer Link
SP  - 80
EP  - 92
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_7.pdf
KW  - Cross-domain feature discriminator
KW  - Domain adaptation
KW  - Trajectory prediction
ER  - 

TY  - CONF
TI  - Monocular 3D Face Reconstruction with Joint 2D and 3D Constraints
AU  - Cui, Huili
AU  - Yang, Jing
AU  - Lai, Yu-Kun
AU  - Li, Kun
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - 3D face reconstruction from a single image is a challenging problem, especially under partial occlusions and extreme poses. This is because the uncertainty of the estimated 2D landmarks will affect the quality of face reconstruction. In this paper, we propose a novel joint 2D and 3D optimization method to adaptively reconstruct 3D face shapes from a single image, which combines the depths of 3D landmarks to solve the uncertain detections of invisible landmarks. The strategy of our method involves two aspects: a coarse-to-fine pose estimation using both 2D and 3D landmarks, and an adaptive 2D and 3D re-weighting based on the refined pose parameters to recover accurate 3D faces. Experimental results on multiple datasets demonstrate that our method can generate high-quality reconstruction from a single color image and is robust for self-occlusions and large poses.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_11
DP  - Springer Link
SP  - 129
EP  - 141
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_11.pdf
KW  - Coarse-to-fine
KW  - Face reconstruction
KW  - Joint 2D and 3D
KW  - Occlusion
KW  - Re-weighting
ER  - 

TY  - CONF
TI  - Scene Text Recognition with Single-Point Decoding Network
AU  - Chen, Lei
AU  - Qin, Haibo
AU  - Zhang, Shi-Xue
AU  - Yang, Chun
AU  - Yin, Xucheng
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - In recent years, attention-based scene text recognition methods have been very popular and attracted the interest of many researchers. Attention-based methods can adaptively focus attention on a small area or even single point during decoding, in which the attention matrix is nearly one-hot distribution. Furthermore, the whole feature maps will be weighted and summed by all attention matrices during inference, causing huge redundant computations. In this paper, we propose an efficient attention-free Single-Point Decoding Network (dubbed SPDN) for scene text recognition, which can replace the traditional attention-based decoding network. Specifically, we propose Single-Point Sampling Module (SPSM) to efficiently sample one key point on the feature map for decoding one character. In this way, our method can not only precisely locate the key point of each character but also remove redundant computations. Based on SPSM, we design an efficient and novel single-point decoding network to replace the attention-based decoding network. Extensive experiments on publicly available benchmarks verify that our SPDN can greatly improve decoding efficiency without sacrificing performance.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_12
DP  - Springer Link
SP  - 142
EP  - 153
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_12.pdf
KW  - Attention
KW  - Scene text recognition
KW  - Single-point
ER  - 

TY  - CONF
TI  - Triple GNN: A Pedestrian-Scene-Object Joint Model for Pedestrian Trajectory Prediction
AU  - Huang, Xinshengzi
AU  - Liu, Qiong
AU  - Yang, You
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Pedestrian trajectory prediction is an amazing but challenging task for vision guided applications, including autonomous driving, intelligent surveillance system, etc. Practically, the trajectory is a result of interaction among pedestrian’s surrounding people, scenes and related objects, which can be represented by a triple. In previous works, limited interactions have been exploited, such as pedestrian-pedestrian and pedestrian-object. These works are facing challenges when comprehensive interactions in natural scenes are involved. In this paper, we propose a triple graph neural network (Triple GNN) where interactions among pedestrians, scenes and objects are all taken into the prediction of pedestrian trajectory. Based on that, spatial relation is exploited to describe the mutual interaction among triple elements, and a two-stage optimization scheme is proposed on weights of the interaction aggregation for better relation exploitation and prediction. Furthermore, temporal relation is also exploited for compact representation and effective computation of future trajectories based on the spatial relation. Our method is verified via ETH and UCY datasets and achieves the state-of-the-art performance.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_6
DP  - Springer Link
SP  - 67
EP  - 79
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - Triple GNN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_6.pdf
KW  - Graph neural network
KW  - Interaction modeling
KW  - Trajectory prediction
ER  - 

TY  - CONF
TI  - BSAM: Bidirectional Scene-Aware Mixup for Unsupervised Domain Adaptation in Semantic Segmentation
AU  - Xing, Congying
AU  - Li, Gao
AU  - Zhang, Lefei
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Unsupervised domain adaptation for semantic segmentation aims to transfer the knowledge from the labeled source domain to the unlabeled target domain. Existing mixup methods usually paste parts of the source domain images onto the target domain images. However, they often neglect the scene consistency of the generated images, which will result in wrong semantic relationships. To address this issue, we propose a Bidirectional Scene-Aware Mixup (BSAM) method in this paper. BSAM adopts a bi-directional pasting strategy to ensure scene awareness between the two domains, and takes the correctness of semantic relationships into account. Specifically, BSAM selects some contextually related classes from each domain to another domain, and generates bidirectional fused images for training. BSAM ensures the correct scene layout, facilitating the model to adapt to the different scenario characteristics. Extensive experiments on two benchmarks (GTA5 to Cityscapes and SYNTHIA to Cityscapes) demonstrate that BSAM achieves state-of-the-art performance.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_5
DP  - Springer Link
SP  - 54
EP  - 66
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - BSAM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_5.pdf
KW  - Domain adaption
KW  - Semantic segmentation
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - MHPro: Multi-hypothesis Probabilistic Modeling for Human Mesh Recovery
AU  - Xuan, Haibiao
AU  - Zhang, Jinsong
AU  - Li, Kun
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Recovering 3D human meshes from monocular images is an inherently ambiguous and challenging task due to depth ambiguity, joint occlusion and truncation. However, most recent works avoid modeling uncertainty, typically obtaining a single reconstruction for a given input. In contrast, this paper presents the ambiguity of reception reconstruction and considers the problem as an inverse problem for which multiple feasible solutions exist. Our method, MHPro, first constructs a probability distribution and obtains a set of feasible recovery results (i.e. multi-hypotheses), from monocular images. Intra-hypothesis refinement is then performed to achieve independent feature enhancement. Finally, the multi-hypothesis features are aggregated by inter-hypothesis communication to recover the final 3D human mesh. The effectiveness of our method is validated on two benchmark datasets, Human3.6M and 3DPW, where experimental results show that our method achieves state-of-the-art performance and recovers more accurate human meshes. Our results validate the importance of intra-hypothesis refinement and inter-hypothesis communication in probabilistic modeling and show optimal performance across a variety of settings. Our source code will be available at http://cic.tju.edu.cn/faculty/likun/projects/MHPro.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_18
DP  - Springer Link
SP  - 216
EP  - 228
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - MHPro
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_18.pdf
KW  - Human mesh recovery
KW  - Monocular images
KW  - Multi-hypothesis
KW  - Probabilistic modeling
ER  - 

TY  - CONF
TI  - Cross-Camera Deep Colorization
AU  - Zhao, Yaping
AU  - Zheng, Haitian
AU  - Ji, Mengqi
AU  - Huang, Ruqi
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - In this paper, we consider the color-plus-mono dual-camera system and propose an end-to-end convolutional neural network to align and fuse images from it in an efficient and cost-effective way. Our method takes cross-domain and cross-scale images as input, and consequently synthesizes HR colorization results to facilitate the trade-off between spatial-temporal resolution and color depth in the single-camera imaging system. In contrast to the previous colorization methods, ours can adapt to color and monochrome cameras with distinctive spatial-temporal resolutions, rendering the flexibility and robustness in practical applications. The key ingredient of our method is a cross-camera alignment module that generates multi-scale correspondences for cross-domain image alignment. Through extensive experiments on various datasets and multiple settings, we validate the flexibility and effectiveness of our approach. Remarkably, our method consistently achieves substantial improvements, i.e., around 10dB PSNR gain, upon the state-of-the-art methods. Code is at: https://github.com/THU-luvision.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_1
DP  - Springer Link
SP  - 3
EP  - 17
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_1.pdf
KW  - Computational imaging
KW  - Image colorization
KW  - Image fusion
ER  - 

TY  - CONF
TI  - Exploring Hierarchical Prototypes for Few-Shot Segmentation
AU  - Chen, Yaozong
AU  - Cao, Wenming
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - Few-shot segmentation has recently attracted much attention due to its effectiveness in segmenting unseen object classes using a few annotated images. Many existing methods employ a global prototype generated by global average pooling (GAP) to preserve general support information. However, a single prototype inevitably creates ambiguity due to its limited representation capability. In order to alleviate this problem, we explore hierarchical prototypes for few-shot segmentation in this paper. Specifically, we propose feature interaction clustering (FIC) to extract local prototypes to contain detailed support information, fully mining the relationships among support features, prototypes, and query features. In addition, to compare query features with multiple prototypes, we propose a simple but effective prototype attention module (PAM) that fuses support information from different prototypes. Our method enhances the robustness of the prototypes and improves the utilization of support information. Extensive experiments on common datasets (PASCAL-$$5^i$$5iand COCO-$$20^i$$20i) demonstrate the effectiveness of our method.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_4
DP  - Springer Link
SP  - 42
EP  - 53
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_4.pdf
KW  - Feature interaction clustering
KW  - Few-shot segmentation
KW  - Hierarchical prototypes
KW  - Prototype attention
ER  - 

TY  - CONF
TI  - Amodal Layout Completion in Complex Outdoor Scenes
AU  - Wu, Jingyu
AU  - Li, Zejian
AU  - Zhang, Shengyuan
AU  - Sun, Lingyun
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - A layout is a group of bounding boxes with labels annotating objects in complex scenes. However, manually labelled layouts often annotate only visible parts of objects (modal layout) instead of the whole body including both visible and invisible parts (amodal layout). Modal layouts are caused by occlusion in scenes, while amodal layouts contain more accurate information of objects’ relative positions and sizes. In this paper, we investigate the influence of modal layout on the layout-to-image generation. Specifically, to recover an amodal layout from a modal layout and improve the generation quality, we propose Amodal Layout Completion Network (ALCN) regressing amodal bounding boxes from potential occluded boxes. Following a divide-and-conquer strategy, we divide the modal layout of a scene into occlusion groups of bounding boxes, which are processed by ALCN individually. Furthermore, we propose four challenging IoU variants to measure completion performances for different completion conditions. Experiment results show the ALCN achieves state-of-the-art layout completion performances in most cases and improves the layout-to-image generation performance.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_3
DP  - Springer Link
SP  - 30
EP  - 41
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_3.pdf
KW  - Amodal layout completion
KW  - IoU various indicators
KW  - Layout-to-image generation
ER  - 

TY  - CONF
TI  - CDNeRF: A Multi-modal Feature Guided Neural Radiance Fields
AU  - Zhang, Qi
AU  - Liu, Qiaoqiao
AU  - Zou, Hang
A2  - Fang, Lu
A2  - Povey, Daniel
A2  - Zhai, Guangtao
A2  - Mei, Tao
A2  - Wang, Ruiping
T3  - Lecture Notes in Computer Science
AB  - We present CDNeRF, a simple yet powerful learning framework that creates novel view synthesis by reconstructing neural radiance fields from a single view RGB image. Novel view synthesis by neural radiance fields has achieved great improvement with the development of deep learning. However, how to make the method generic across scenes has always been a challenging task. A good idea is to introduce 2D image features as prior knowledge for adaptive modeling, yet RGB features (C) lack geometry and 3D spacial information. To compensate, we introduce depth features into the model. Our method uses a variant depth estimation network to extract depth features (D) without the need for additional input. In addition, we also introduce the transformer module to effectively fuse the multi-modal features of RGB and depth. Extensive experiments are carried out on two categories specific benchmarks (i.e., Chair, Car) and two category agnostic benchmarks (i.e., ShapeNet, DTU). The results demonstrate that our CDNeRF outperforms the previous methods, and achieves state-of-the-art neural rendering performance.
C1  - Cham
C3  - Artificial Intelligence
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20497-5_17
DP  - Springer Link
SP  - 204
EP  - 215
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20497-5
ST  - CDNeRF
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20497-5_17.pdf
KW  - 3D implicit reconstruction
KW  - Neural rendering
KW  - Novel view synthesis
KW  - Vision transformer
ER  - 

TY  - CONF
TI  - License Plate Detection and Recognition Based on Light-Yolov7
AU  - Li, Shangyuan
AU  - Ma, Nan
AU  - Wu, Zhixuan
AU  - Lin, Qiang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - A license plate detection and recognition system is one of the practical applications of computer vision technology in the field of unmanned vehicles. In this paper, we proposed a Light-yolov7 for license plate detection and recognition model, which is applied to unmanned vehicles. The model contains three improvements: a lightweight neural network ShuffleNet2 is used for feature extraction, a depth-separable convolution is added to reduce the number of parameters, then this paper uses late fusion to connect features. Finally, CRNN is used to learn the obtained features. Experiments on a large Chinese license plate dataset (CCPD+CRPD) show that the model is feasible for mobile deployment and efficient for license plate detection and recognition.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_8
DP  - Springer Link
SP  - 83
EP  - 91
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_8.pdf
KW  - Computer vision
KW  - Feature recognition lightweight
KW  - License plate recognition
KW  - YOLO
ER  - 

TY  - CONF
TI  - Efficient Partitioning Method of Large-Scale Public Safety Spatio-Temporal Data Based on Information Loss Constraints
AU  - Gao, Jie
AU  - Li, Yawen
AU  - Xue, Zhe
AU  - Guan, Zeli
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The storage, management, and application of massive spatio-temporal data are widely applied in various practical scenarios, including public safety. However, due to the unique spatio-temporal distribution characteristics of real-world data, most existing methods have limitations in terms of the spatio-temporal proximity of data and load balancing in distributed storage. Therefore, this paper proposes an efficient partitioning method of large-scale public safety spatio-temporal data based on information loss constraints (IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal point data by combining the spatio-temporal partitioning module (STPM) with the graph partitioning module (GPM). This approach can significantly reduce the scale of data while maintaining the model’s accuracy, in order to improve the partitioning efficiency. It can also ensure the load balancing of distributed storage while maintaining spatio-temporal proximity of the data partitioning results. This method provides a new solution for distributed storage of massive spatio-temporal data. The experimental results on multiple real-world datasets demonstrate the effectiveness and superiority of IFL-LSTP.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_9
DP  - Springer Link
SP  - 92
EP  - 100
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_9.pdf
KW  - data partitioning
KW  - graph partitioning
KW  - information loss
KW  - load balancing
KW  - spatial-temporal proximity
ER  - 

TY  - CONF
TI  - An Online Game Platform for Intangible Cultural Heritage Tibetan Jiu Chess
AU  - Li, Xiali
AU  - Zhang, Yanyin
AU  - Wu, Licheng
AU  - Chen, Yandong
AU  - Liu, Bo
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Tibetan Jiu Chess is a treasure of Tibetan culture. In order to make this intangible cultural heritage bloom, the Jiu Chess online battle platform has been developed. The platform is developed based on Cocos Creator development engine, and the language used are JavaScript and TypeScript. The SDK of Huawei Technologies Co. Ltd online battle engine is embedded to help the platform realize online battle function. It has successfully completed online game competition task for Tibetan Jiu chess in 2022 Uni versity Computer Games Championship & National Computer Games Tournament in China and can satisfy about 200 people to play online games stably.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_3
DP  - Springer Link
SP  - 23
EP  - 30
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_3.pdf
KW  - board game
KW  - intangible cultural heritage
KW  - online game platform
KW  - Tibetan Jiu chess
ER  - 

TY  - CONF
TI  - Research and Application of Comprehensive Health Assessment Based on Production Equipment of Bulk Cargo Terminal
AU  - Li, Xin
AU  - Tang, Xuliang
AU  - Chen, Renhui
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - As the main productivity of a port, the health status of production equipment in bulk cargo terminals will directly affect the stability and economic benefits of the equipment. Through research and application of comprehensive health assessment for production equipment, comprehensive, accurate, and timely grasp of the comprehensive health status of equipment. This study will establish a LIFEO device health evaluation model through factor analysis and weight allocation through key indicators from the five dimensions of the device life cycle, inspection, failure, environment, and operation. Analyze, summarize, and summarize the historical and existing data of bulk cargo terminal equipment, and verify the effectiveness and feasibility of the model based on actual conditions, providing a dynamic and sustainable entire process. Provide scientific basis and decision support for the management and maintenance of production equipment in bulk cargo terminals.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_16
DP  - Springer Link
SP  - 163
EP  - 171
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_16.pdf
KW  - Bulk Cargo Terminal
KW  - Data Analysis
KW  - Equipment Health Assessment
KW  - Production Equipment
KW  - Sustainability
ER  - 

TY  - CONF
TI  - Research and Application of Intelligent Monitoring and Diagnosis System for Rail Transit Emergency Power Supply Equipment
AU  - Chen, Liang
AU  - Zhou, Lin
AU  - Tang, Xuliang
AU  - Wan, Heng
AU  - Cao, Yanao
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Emergency power supply equipment is an important part of the rail transit system. In order to master and adapt to the safe and reliable operation of the rail transit emergency power supply equipment, it is urgent to carry out intelligent monitoring, early warning and prediction of the equipment operation status, rapid and accurate fault location and provide effective fault handling guidance measures. This paper proposes a set of fault monitoring, diagnosis, location and disposal methods based on emergency power supply equipment, Through the intelligent monitoring platform for emergency power supply, the equipment life cycle health management and refined operation and maintenance management are realized, and the service life and operation reliability of emergency power supply equipment are effectively improved.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_10
DP  - Springer Link
SP  - 101
EP  - 108
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_10.pdf
KW  - Emergency Supply
KW  - Fault Analysis
KW  - Intelligent Monitoring
KW  - Rail Transit
ER  - 

TY  - CONF
TI  - An Anti-interference Mechanical Fault Diagnosis Method Based on CNN and Attention Mechanism
AU  - Zhang, Zhen-Jun
AU  - Liu, Ying-Yuan
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - In order to solve the problem of low accuracy in traditional fault diagnosis methods under practical working conditions and noisy environments, a convolutional neural network (CNN) fault diagnosis method was proposed with a high anti-interference ability based on attention mechanism. In this method, CNN and Long Short-Term Memory (LSTM) were used to learn the spatial and temporal features of data and the attention mechanism was selected to enhance important features for improving the resistance of the fault diagnosis model to interference. Meanwhile, simulation experiments on the bearing fault dataset of Case Western Reserve University (CWRU) were conducted for verification. Results show that the fault diagnosis method proposed in this paper achieves an average diagnostic accuracy of 97.55% on multiple load datasets and an average accuracy of 96.58% on noisy data. Furthermore, T-SNE algorithm was used to visualize the output of every layer for better understanding the proposed method during the fault diagnosis process.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_6
DP  - Springer Link
SP  - 61
EP  - 68
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_6.pdf
KW  - Attention Mechanism
KW  - CNN
KW  - LSTM
KW  - Mechanical fault Diagnosis
ER  - 

TY  - CONF
TI  - Predicting TUG Score from Gait Characteristics with Video Analysis and Machine Learning
AU  - Ma, Jian
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Fall is a leading cause of death which suffers the elderly and society. Timed Up and Go (TUG) test is a common tool for fall risk assessment. In this paper, we propose a method for predicting TUG score from gait characteristics extracted from video with computer vision and machine learning technologies. First, 3D pose is estimated from video captured with 2D and 3D cameras during human motion and then a group of gait characteristics are computed from 3D pose series. After that, copula entropy is used to select those characteristics which are mostly associated with TUG score. Finally, the selected characteristics are fed into the predictive models to predict TUG score. Experiments on real world data demonstrated the effectiveness of the proposed method. As a byproduct, the associations between TUG score and several gait characteristics are discovered, which laid the scientific foundation of the proposed method and make the predictive models such built interpretable to clinical users.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_1
DP  - Springer Link
SP  - 1
EP  - 12
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_1.pdf
KW  - copula entropy
KW  - fall risk assessment
KW  - gait characteristics
KW  - linear regression
KW  - support vector regression
KW  - Timed Up and Go
ER  - 

TY  - CONF
TI  - Research on Intelligent Monitoring of Big Data Processes Based on Radar Map and Residual Convolutional Network
AU  - Yu, Jianli
AU  - Wang, Yixiang
AU  - Jia, Zhiao
AU  - Xie, Benkai
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problem that traditional convolutional neural network is difficult to extract fine features of images, a big data process monitoring method based on radar map and convolutional block attention residual network is proposed. According to the sampling frequency of equipment sensors, the radar map is used to visually present the process operation status, and a residual network incorporating the convolutional block attention mechanism is constructed for adaptive feature extraction to carry out intelligent state monitoring of complex processes in big data, and finally the operation status of a high-pressure roller mill is studied empirically. The results show that the proposed method is capable of real-time intelligent monitoring of the five operating states of the high-pressure roller mill, and has higher diagnostic accuracy and generalization capability than other deep learning methods.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_19
DP  - Springer Link
SP  - 196
EP  - 204
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_19.pdf
KW  - attention module
KW  - big data
KW  - intelligent monitoring
KW  - residual convolutional network
ER  - 

TY  - CONF
TI  - Refining Object Localization from Dialogues
AU  - Kang, Xueze
AU  - Wu, Lei
AU  - Lu, Lingyun
AU  - Liu, Huaping
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The ability to locate objects accurately is crucial for robots’ application in large-scale environments. However, objects’ location changes constantly in practical scenes, so the robot’s knowledge of objects’ distribution needs to update correspondingly. We propose a method to refine objects’ location from dialogues between humans and robots. When a robot is searching for an object, if the information about the object’s location is insufficient, it constantly raises questions to a human informer until it acquires adequate location information. Furthermore, every possible target object found during the searching process is photographed and sent back to the human informer for judgment. If all possible locations have been searched and the target is not found, the robot requests more specific location information and starts a new search attempt after attaining the information. The interaction process repeats iteratively until the robot finally finds the target. The interactions with humans ensure the success and accuracy of searching. We deploy our method on a mobile robot and conduct language parsing experiment and locating objects experiment to evaluate the performance of our method. Moreover, we compare our method with a one-time message method from a previous work to demonstrate our advantage.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_7
DP  - Springer Link
SP  - 69
EP  - 82
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_7.pdf
KW  - human-robot interaction
KW  - mapping
KW  - robot localization
ER  - 

TY  - CONF
TI  - Federated Topic Model and Model Pruning Based on Variational Autoencoder
AU  - Ma, Chengjie
AU  - Li, Yawen
AU  - Liang, Meiyu
AU  - Li, Ang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Topic modeling can uncover themes and patterns in large documents. However, when cross-analysis involves multiple parties, data privacy becomes a key issue. Federated learning allows multiple parties to jointly train models while protecting privacy. But there are gains and losses, and in the case of federation, there are communication and performance challenges. In order to solve the above problems, this paper proposes a method to establish a federated topic model while ensuring the privacy of each node, and use neural network model pruning to accelerate the model. In addition, to handle the tradeoff between model training time and inference accuracy, two different methods are proposed to determine the model pruning rate. The first method involves slow pruning throughout the entire model training process, which has limited acceleration effect on the model training process, but can ensure that the pruned model achieves higher accuracy. The second strategy is to quickly reach the target pruning rate in the early stage of model training, and then continue to train the model with a smaller model size. This approach may lose more useful information but can complete the model training faster. Experimental results show that the federated topic model pruning based on the variational autoencoder proposed in this paper can greatly accelerate the model training speed and inference speed while ensuring the model’s performance.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_5
DP  - Springer Link
SP  - 51
EP  - 60
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_5.pdf
KW  - Federated Learning
KW  - Topic Model
KW  - Variational Autoencoder
ER  - 

TY  - CONF
TI  - Unsupervised Multidimensional Time Series Anomaly Detection Based on Federation Learning
AU  - Deng, Ying
AU  - Li, Yaogen
AU  - Liao, Yingqi
AU  - Ma, Nan
AU  - Yuan, Chengyu
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Efficient and accurate prediction of electricity data is an important task in electricity data research. Convolutional neural networks have excellent performance in electricity data prediction problems but require large amounts of data to train the models. The major power companies are not willing to share their power data due to privacy and security concerns, making it impossible to train more accurate models. Moreover, the huge amount of data uploading to the central server for training the federated model generates huge network resource overhead. To address these problems, this paper proposes a federation learning algorithm (FedFLA) for unsupervised multidimensional time series anomaly detection based on existing artificial intelligence techniques such as federation learning, time-domain convolutional neural networks, and self-attentive mechanisms, in combination with existing federation learning algorithms. This algorithm uses time-domain convolutional networks and self-attentive mechanisms to fully consider time series local data dependence and global data correlation, and fuses time series model parameters with information on features through cross-stitch units and obtains anomaly scores for each time stamp, so as to determine whether the data is anomalous.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_13
DP  - Springer Link
SP  - 128
EP  - 135
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_13.pdf
KW  - Electrical power data
KW  - Federated learning
KW  - Self-attentive mechanisms
KW  - Time-domain convolutional neural networks
ER  - 

TY  - CONF
TI  - Reinforcement Federated Learning Method Based on Adaptive OPTICS Clustering
AU  - Zhao, Tianyu
AU  - Du, Junping
AU  - Shao, Yingxia
AU  - Guan, Zeli
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Federated learning is a distributed machine learning technology, which realizes the balance between data privacy protection and data sharing computing. To protect data privacy, federated learning learns shared models by locally executing distributed training on participating devices and aggregating local models into global models. There is a problem in federated learning, that is, the negative impact caused by the non-independent and identical distribution of data across different user terminals. In order to alleviate this problem, this paper proposes a strengthened federation aggregation method based on adaptive OPTICS clustering. Specifically, this method perceives the clustering environment as a Markov decision process, and models the adjustment process of parameter search direction, so as to find the best clustering parameters to achieve the best federated aggregation method. The core contribution of this paper is to propose an adaptive OPTICS clustering algorithm for federated learning. The algorithm combines OPTICS clustering and adaptive learning technology, and can effectively deal with the problem of non-independent and identically distributed data across different user terminals. By perceiving the clustering environment as a Markov decision process, the goal is to find the best parameters of the OPTICS cluster without artificial assistance, so as to obtain the best federated aggregation method and achieve better performance. The reliability and practicability of this method have been verified on the experimental data, and its effectiveness and superiority have been proved.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_14
DP  - Springer Link
SP  - 136
EP  - 144
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_14.pdf
KW  - Clustering
KW  - Federated learning
KW  - Non-independent identically distributed
KW  - OPTICS algorithm
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - Review of Human Target Detection and Tracking Based on Multi-view Information Fusion
AU  - Wang, Liuwang
AU  - Liu, Haojun
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - With the increasing availability and affordability of cameras, pedestrian detection and tracking technology have become widely used in various applications such as intelligent monitoring, behavioral analysis, and traffic control. However, traditional single-view detection methods have limitations, including susceptibility to occlusion and a limited field of view. Multi-view detection and tracking methods have gained significant attention from both academia and industry, as they can overcome the limitations of single-view methods by leveraging complementary information from multiple views, resulting in improved algorithm performance. This paper presents a systematic review of multi-view information fusion for human target detection and tracking, focusing on three dimensions: dataset, multi-view detection, and multi-view tracking. Furthermore, it discusses potential applications of these methods in the power field and suggests future directions for development.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_4
DP  - Springer Link
SP  - 31
EP  - 50
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_4.pdf
KW  - Deep Learning
KW  - Multi-View
KW  - Visual Detection
KW  - Visual Tracking
ER  - 

TY  - CONF
TI  - An Improved Adaptive Median Filtering Algorithm Based on Star Map Denoising
AU  - Cao, Hancheng
AU  - Shen, Naijun
AU  - Qian, Chen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - In order to improve the filtering performance of salt and pepper noise in starry sky images, an improved adaptive median filtering algorithm is proposed. Firstly, the algorithm performs adaptive median filtering on the noise image. Instead of pixel median replacement, it obtains the set of suspected noise points. Then, it uses a neighbourhood differential noise template for secondary detection of the suspected noise points to obtain the real noise points. Finally, a weighted mean value is calculated based on the distance weights, and the noise points are replaced. The proposed algorithm is used to filter the star maps containing 20%–90% salt and pepper noise. The experimental results show that the denoising effect of this algorithm is better than other algorithms, while preserving the image details and edge information better.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_18
DP  - Springer Link
SP  - 184
EP  - 195
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_18.pdf
KW  - adaptive
KW  - median filter
KW  - salt and pepper noise
KW  - weighted mean
ER  - 

TY  - CONF
TI  - Simulation and Implementation of Extended Kalman Filter Observer for Sensorless PMSM
AU  - Ma, Ke
AU  - Gao, ChaoJun
AU  - Wang, Jun
AU  - Zhang, Qiang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This article utilizes the Extended Kalman Filter algorithm as an observer for the entire motor control system to estimate the angle and speed of the motor rotor. This algorithm can achieve precise tracking of motor rotor position and speed, especially in low-speed or startup scenarios. It has good low-speed performance and can quickly achieve closed-loop control of the motor angle loop. Furthermore, the FOC vector control strategy was employed to achieve dual-loop control of the motor control system, thereby realizing control of the position-Sensorless permanent magnet synchronous motor. In this paper, we design and construct a simulation model for vector control of permanent magnet synchronous motor based on Extended Kalman filter algorithm, and design a hardware experimental platform to compare the experimental results with those of the Sliding Mode Observer-based control algorithm for verification.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_15
DP  - Springer Link
SP  - 145
EP  - 162
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_15.pdf
KW  - Angle loop
KW  - Extended Kalman filter
KW  - Permanent magnet synchronous motor
KW  - Sensorless control
ER  - 

TY  - CONF
TI  - A Pose Control Algorithm for Simulating Robotic Fish
AU  - Wang, Gang
AU  - Ding, Simin
AU  - Zhao, Qiang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problems of low control accuracy an slow response speed of the position and orientation (position and direction) of the simulated robot fish, this paper proposes a position and attitude control algorithm for the simulated robot fish. Firstly, this paper introduces the simplified dynamics and kinematics model; Secondly, the first coordinate system is established based on the expected position and pose, and the position and pose error model of robot fish is constructed; Thirdly, the angular velocity controller, linear velocity controller and fuzzy controller are designed. Finally, Microsoft Visual Studio 2010 software is used to write the corresponding strategy, and it is applied to the simulation platform of URWPGSim2D software for simulation experiments. The experimental results show that compared to time-varying feedback control algorithm and cascade PID algorithm, this algorithm improves control accuracy while accelerating response speed.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_12
DP  - Springer Link
SP  - 118
EP  - 127
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_12.pdf
KW  - Fuzzy Adaptive Cascade PID Algorithm
KW  - Pose Control
KW  - URWPGSim2D Software Simulation Platform
ER  - 

TY  - CONF
TI  - Reliability-Based Dynamic Positioning Control for Turret-Moored Vessels with Prescribed Performance
AU  - Tuo, Yulong
AU  - Feng, Guilin
AU  - Liang, Xiao
AU  - Wang, Shasha
AU  - Guo, Chen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - To consider the safety of mooring lines and transient performance of system, a reliability-based dynamic surface controller with prescribed performance is proposed for the dynamic positioning (DP) system of turret-moored vessels. The descriptions are given for the vessel model and the reliability of mooring lines at first. Then, a dynamic surface controller is presented on the basis of reliability of mooring lines and prescribed performance function. The performance specifications are imposed in advance on the reliability and heading tracking errors according to the actual demands. By adjusting the reliability, the ability of mooring system can be fully used within the safe range of mooring lines. Therefore, less energy consumption is needed for the DP system. Finally, the numerical simulations illustrate the performance of the presented DP controller.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_11
DP  - Springer Link
SP  - 109
EP  - 117
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_11.pdf
KW  - dynamic positioning control
KW  - prescribed performance
KW  - reliability of mooring lines
KW  - turret-moored vessels
ER  - 

TY  - CONF
TI  - Enhancing Resilience of Microgrid-Integrated Power Systems in Disaster Events Using Reinforcement Learning
AU  - Zha, Zhongyi
AU  - Wang, Bo
AU  - Liu, Lei
AU  - Fan, Huijin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Enhancing the resilience of power systems has become increasingly important to mitigate the negative impact of risk attacks. Integrating microgrids, which are small-scale power grids that can operate independently or in conjunction with the main grid, has emerged as an effective energy source for emergency situations and can avoid power outages. Typhoons, which are inevitable and relatively easy to predict risk attacks, have become one of the contexts to examine power system resilience. In this paper, we propose a reinforcement learning algorithm that combines graph theory knowledge to make decisions for optimizing power system resilience with microgrids under the Typhoon event. The algorithm effectively utilizes graph theory knowledge and reduces the number of decisions required in the optimization process. Numerical experimental results show that compared to traditional methods, the reinforcement learning algorithm can more effectively respond to typhoon changes, achieve flexible economic control, and enhance the resilience of power systems with microgrids.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_17
DP  - Springer Link
SP  - 172
EP  - 183
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_17.pdf
KW  - microgrid
KW  - power system
KW  - reinforcement learning
KW  - resilience
ER  - 

TY  - CONF
TI  - Task-Space Finite-Time Prescribed Performance Tracking Control for Free-Flying Space Robots Under Input Saturation
AU  - Zhang, Xuewen
AU  - Jia, Yingmin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This paper investigates the task-space finite-time prescribed performance tracking control for a free-flying space robot subjected to input saturation. The proposed control law involves utilizing a modified barrier Lyapunov function, the backstepping technique, the dynamic surface control technique, and the adaptive approach. The closed-loop errors for both manipulator end-effector pose and base attitude are steered, converging in finite time with prescribed performance. Numerical simulations are carried out to illustrate the proposed control law.
C1  - Singapore
C3  - Proceedings of 2023 Chinese Intelligent Automation Conference
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-6187-0_2
DP  - Springer Link
SP  - 13
EP  - 22
LA  - en
PB  - Springer Nature
SN  - 978-981-9961-87-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-6187-0_2.pdf
KW  - Backstepping
KW  - Finite-time stability
KW  - Free-flying space robot
KW  - Input saturation
KW  - Prescribed performance control
ER  - 

TY  - CONF
TI  - Adaptive Channel Pruning for Trainability Protection
AU  - Liu, Jiaxin
AU  - Zhang, Dazong
AU  - Liu, Wei
AU  - Li, Yongming
AU  - Hu, Jun
AU  - Cheng, Shuai
AU  - Yang, Wenxing
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Pruning is a widely used method for compressing neural networks, reducing their computational requirements by removing unimportant connections. However, many existing pruning methods prune pre-trained models by using the same pruning rate for each layer, neglecting the protection of model trainability and damaging accuracy. Additionally, the number of redundant parameters per layer in complex models varies, necessitating adjustment of the pruning rate according to model structure and training data. To overcome these issues, we propose a trainability-preserving adaptive channel pruning method that prunes during training. Our approach utilizes a model weight-based similarity calculation module to eliminate unnecessary channels while protecting model trainability and correcting output feature maps. An adaptive sparsity control module assigns pruning rates for each layer according to a preset target and aids network training. We performed experiments on CIFAR-10 and Imagenet classification datasets using networks of various structures. Our technique outperformed comparison methods at different pruning rates. Additionally, we confirmed the effectiveness of our technique on the object detection datasets VOC and COCO.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_12
DP  - Springer Link
SP  - 137
EP  - 148
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Convolutional neural networks
KW  - Model compression
KW  - Pruning
KW  - Trainability preservation
ER  - 

TY  - CONF
TI  - Dual-Stream Context-Aware Neural Network for Survival Prediction from Whole Slide Images
AU  - Gao, Junxiu
AU  - Jin, Shan
AU  - Wang, Ranran
AU  - Wang, Mingkang
AU  - Wang, Tong
AU  - Xu, Hongming
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Whole slide images (WSI) encompass a wealth of information about the tumor micro-environment, which holds prognostic value for patients’ survival. While significant progress has been made in predicting patients’ survival risks from WSI, existing studies often overlook the importance of incorporating multi-resolution and multi-scale histological image features, as well as their interactions, in the prediction process. This paper introduces the dual-stream context-aware (DSCA) model, which aims to enhance survival risk prediction by leveraging multi-resolution histological images and multi-scale feature maps, along with their contextual information. The DSCA model comprises three prediction branches: two ResNet50 branches that learn features from multi-resolution images, and one feature fusion branch that aggregates multi-scale features by exploring their interactions. The feature fusion branch of the DSCA model incorporates a mixed attention module, which performs adaptive spatial fusion to enhance the multi-scale feature maps. Subsequently, the self-attention mechanism is developed to learn contextual and interactive information from the enhanced feature maps. The ordinal Cox loss is employed to optimize the model for generating patch-level predictions. Patient-level predictions are obtained by mean-pooling patch-level results. Experimental results conducted on colorectal cancer cohorts demonstrate that the proposed DSCA model achieves significant improvements over state-of-the-art methods in survival prognosis.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Attention mechanism
KW  - Colorectal Cancer
KW  - Multi-scale features
KW  - Survival risk prediction
KW  - Whole slide images
ER  - 

TY  - CONF
TI  - Cascaded-Scoring Tracklet Matching for Multi-object Tracking
AU  - Xie, Yixian
AU  - Wang, Hanzi
AU  - Lu, Yang
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Multi-object tracking (MOT) aims at locating the object of interest in a successive video sequence and associating the same moving object frame by frame. Most existing approaches to MOT lack the integration of both motion and appearance information, which limits the effectiveness of tracklet association. The conventional approaches for tracklet association often struggle when dealing with scenarios involving multiple objects with indistinguishable appearances and irregular motions, leading to suboptimal performance. In this paper, we introduce an appearance-assisted feature warper (AFW) module and a motion-guided based target aware (MTA) module to efficiently utilize the appearance and motion information. Additionally, we introduce a cascaded-scoring tracklet matching (CSTM) strategy that seamlessly integrates the two modules, combining appearance features with motion information. Our proposed online MOT tracker is called CSTMTrack. Through extensive quantitative and qualitative results, we demonstrate that our tracker achieves efficient and favorable performance compared to several other state-of-the-art trackers on the MOTChallenge benchmark.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_14
DP  - Springer Link
SP  - 161
EP  - 173
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Cascaded Matching
KW  - Detection
KW  - Multiple Object Tracking
KW  - Tracklet Association
ER  - 

TY  - CONF
TI  - Exploiting Adaptive Crop and Deformable Convolution for Road Damage Detection
AU  - Bai, Yingduo
AU  - Fu, Chenhao
AU  - Li, Zhaojia
AU  - Wang, Liyang
AU  - Su, Li
AU  - Jiang, Na
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Road damage detection (RDD) based on computer vision plays an important role in road maintenance. Unlike conventional object detection, it is very challenging due to the irregular shape distribution and high similarity with the background. To address this issue, we propose a novel road damage detection algorithm from the perspective of optimizing data and enhancing feature learning. It consists of adaptive cropping, feature learning with deformable convolution, and a diagonal intersection over union loss function (XIOU). Adaptive cropping uses vanishing point estimation (VPE) to obtain the pavement reference position, and then effectively removes the redundant information of interference detection by cutting the raw image above the reference position. The feature learning module introduces deformable convolution to adjust the receptive field of road damage with irregular shape distribution, which will help enhance feature differentiation. The designed diagonal IOU loss function (XIOU) optimizes the road damage location by weighted calculation of the intersection and comparison between the predicted proposal and the groundtruth. Compared with existing methods, the proposed algorithm is more suitable for road damage detection task and has achieved excellent performance on authoritative RDD and CNRDD datasets.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_13
DP  - Springer Link
SP  - 149
EP  - 160
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Adaptive Image Cropping
KW  - Diagonal IOU Loss Function
KW  - Road Damage Detection
ER  - 

TY  - CONF
TI  - Few-Shot Object Detection via Classify-Free RPN
AU  - Yu, Songlin
AU  - Yang, Zhiyu
AU  - Zhang, Shengchuan
AU  - Cao, Liujuan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The research community has shown great interest in few-shot object detection, which focuses on detecting novel objects with only a small number of annotated examples. Most of the works are based on the Faster R-CNN framework. However, due to the absence of annotated data for novel instances, models are prone to base class bias, which can result in misclassifying novel instances as background or base instances. Our analysis reveals that although the RPN is class-agnostic in form, the binary classification loss possesses class-awareness capabilities, which can lead to the base class bias issue. Therefore, we propose a simple yet effective classify-free RPN. We replace the binary classification loss of the RPN with Smooth L1 loss and adjust the ratio of positive and negative samples for computing the loss. This avoids treating anchors matched with novel instances as negative samples in loss calculation, thereby mitigating the base class bias issue. Without any additional computational cost or parameters, our method achieves significant improvements compared to other methods on the PASCAL VOC and MS-COCO benchmarks, establishing state-of-the-art performance.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_9
DP  - Springer Link
SP  - 101
EP  - 112
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Few-shot object detection
KW  - Object detection
KW  - RPN
ER  - 

TY  - CONF
TI  - Infrared and Visible Image Fusion via Test-Time Training
AU  - Zheng, Guoqing
AU  - Fu, Zhenqi
AU  - Lin, Xiaopeng
AU  - Chu, Xueye
AU  - Huang, Yue
AU  - Ding, Xinghao
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Infrared and visible image fusion (IVIF) is a widely used technique in instrument-related fields. It aims at extracting contrast information from the infrared image and texture details from the visible image and combining these two kinds of information into a single image. Most auto-encoder-based methods train the network on natural images, such as MS-COCO, and test the model on IVIF datasets. This kind of method suffers from domain shift issues and cannot generalize well in real-world scenarios. To this end, we propose a self-supervised test-time training (TTT) approach to facilitate learning a better fusion result. Specifically, a new self-supervised loss is developed to evaluate the quality of the fusion result. This loss function directs the network to improve the fusion quality by optimizing model parameters with a small number of iterations in the test time. Besides, instead of manually designing fusion strategies, we leverage a fusion adapter to automatically learn fusion rules. Experimental comparisons on two public IVIF datasets validate that the proposed method outperforms existing methods subjectively and objectively.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_7
DP  - Springer Link
SP  - 77
EP  - 88
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Deep learning
KW  - Domain shift
KW  - Image fusion
KW  - Infrared image
KW  - Test-time training
ER  - 

TY  - CONF
TI  - A Complex-Valued Neural Network Based Robust Image Compression
AU  - Luo, Can
AU  - Bao, Youneng
AU  - Tan, Wen
AU  - Li, Chao
AU  - Meng, Fanyang
AU  - Liang, Yongsheng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Recent works on learned image compression (LIC) based on convolutional neural networks (CNNs) have achieved great improvement with superior rate-distortion performance. However, the robustness of LIC has received little investigation. In this paper, we proposes a complex-valued learned image compression model based on complex-valued convolutional neural networks (CVCNNs) to enhance its robustness. Firstly, we design a complex-valued neural image compression framework, which realizes compression with complex-valued feature maps. Secondly, we build a module named modSigmoid to implement a complex-valued nonlinear transform and a split-complex entropy model to compress complex-valued latent. The experiment results show that the proposed model performs comparable compression performance with a large parameter drop. Moreover, we adopt the adversarial attack method to examine robustness, and the proposed model shows better robustness to adversarial input compared with its real-valued counterpart.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_5
DP  - Springer Link
SP  - 53
EP  - 64
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - complex-valued convolutional neural networks
KW  - Deep learning
KW  - image compression
KW  - robustness
ER  - 

TY  - CONF
TI  - IPFR: Identity-Preserving Face Reenactment with Enhanced Domain Adversarial Training and Multi-level Identity Priors
AU  - Zhu, Lei
AU  - Li, Ge
AU  - Chen, Yuanqi
AU  - Li, Thomas H.
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In the face reenactment task, identity preservation is challenging due to the leakage of driving identity and the complexity of source identity. In this paper, we propose an Identity-Preserving Face Reenactment (IPFR) framework with impressive expression and pose transfer. To address the leakage of driving identity, we develop an enhanced domain discriminator to eliminate the undesirable identity in the generated image. Considering the complexity of source identity, we inject multi-level source identity priors to keep the identity domain of generated image close to that of source. In detail, firstly, we utilize a 3D geometric prior from the 3D morphable face model (3DMM) to control face shape and reduce artifacts caused by occlusion in the module of generating motion field; secondly, we use an identity texture prior extracted by face recognition network to supervise the final stage, aiming to make the identity domain of the generated close to that of source. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art methods on image quality and identity preservation. Ablation studies are also conducted to further validate the effectiveness of our individual components.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_10
DP  - Springer Link
SP  - 113
EP  - 124
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
ST  - IPFR
KW  - 3D shape-aware identity
KW  - Attention mechanism
KW  - Enhanced domain adversarial training
ER  - 

TY  - CONF
TI  - Hierarchical Spatial-Temporal Network for Skeleton-Based Temporal Action Segmentation
AU  - Tan, Chenwei
AU  - Sun, Tao
AU  - Fu, Talas
AU  - Wang, Yuhan
AU  - Xu, Minjie
AU  - Liu, Shenglan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Skeleton-based Temporal Action Segmentation (TAS) plays an important role in analyzing long videos of motion-centered human actions. Recent approaches perform spatial and temporal information modeling simultaneously in the spatial-temporal topological graph, leading to high computational costs due to the large graph magnitude. Additionally, multi-modal skeleton data has sufficient semantic information, which has not been fully explored. This paper proposes a Hierarchical Spatial-Temporal Network (HSTN) for skeleton-based TAS. In HSTN, the Multi-Branch Transfer Fusion (MBTF) module utilizes a multi-branch graph convolution structure with an attention mechanism to capture spatial dependencies in multi-modal skeleton data. In addition, the Multi-Scale Temporal Convolution (MSTC) module aggregates spatial information and performs multi-scale temporal information modeling to capture long-range dependencies. Extensive experiments on two challenging datasets are performed and our proposed method outperforms the State-of-the-Art (SOTA) methods.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_3
DP  - Springer Link
SP  - 28
EP  - 39
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Graph convolution
KW  - Multi-modal fusion
KW  - Temporal action segmentation
ER  - 

TY  - CONF
TI  - Self-guided Transformer for Video Super-Resolution
AU  - Xue, Tong
AU  - Wang, Qianrui
AU  - Huang, Xinyi
AU  - Li, Dengshi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The challenge of video super-resolution (VSR) is to leverage the long-range spatial-temporal correlation between low-resolution (LR) frames to generate high-resolution (LR) video frames. However, CNN-based video super-resolution approaches show limitations in modeling using long-range dependencies and non-local self-similarity. In this paper. For further spatio-temporal learning, we propose a novel self-guided transformer for video super-resolution (SGTVSR). In this framework, we customize a multi-headed self-attention based on offset-guided window (OGW-MSA). For each query element on a low-resolution reference frame, the OGW-MSA enjoys offset guidance to globally sample highly relevant key elements throughout the video. In addition, we propose a feature aggregation module that aggregates the favorable spatial information of adjacent frame features at different scales as a way to improve the video reconstruction quality. Comprehensive experiments show that our proposed self-guided transformer for video super-resolution outperforms the state-of-the-art (SOTA) method on several public datasets and produces good results visually.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_16
DP  - Springer Link
SP  - 186
EP  - 198
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Feature aggregation
KW  - Multi-headed self-attention based on offset-guided window
KW  - Self-guided transformer
KW  - Video super-resolution
ER  - 

TY  - CONF
TI  - Binarizing Super-Resolution Neural Network Without Batch Normalization
AU  - Li, Xunchao
AU  - Chao, Fei
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In this paper, our objective is to propose a model binarization method aimed at addressing the challenges posed by over-parameterized super-resolution (SR) models. Our analysis reveals that binary SR models experience significant performance degradation, primarily attributed to their sensitivity towards weight/activation distributions, particularly when devoid of Batch Normalization (BN) layers. Consequently, we undertake the following endeavors in this study: First, we conduct a comprehensive analysis to examine the impact of BN layers on SR models based on Binary Neural Networks (BNNs). Second, we propose an asymmetric binarizer that can be reparameterized to adaptively adjust the transition point for activation binarization. Third, we introduce a progressive gradient estimator that modifies weight smoothness and controls weight flipping to stabilize the training procedure in the absence of BN layers. Through extensive experiments, we demonstrate that our proposed method exhibits significant performance improvements. For instance, when binarizing EDSR and scaling up input images by a factor of $$\times 4$$×4, our approach achieves a PSNR decrease of less than 0.4dB on the Urban100 benchmark.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_6
DP  - Springer Link
SP  - 65
EP  - 76
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Binary neural network
KW  - Model compression and Acceleration
KW  - Super-Resolution
ER  - 

TY  - CONF
TI  - SAMP: Sub-task Aware Model Pruning with Layer-Wise Channel Balancing for Person Search
AU  - Wu, Zimeng
AU  - Chen, Jiaxin
AU  - Wang, Yunhong
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The deep convolutional neural network (CNN) has recently become the prevailing framework for person search. Nevertheless, these approaches suffer from the high computational cost, raising the necessity of compressing deep models for applicability on resource-restrained platforms. Despite of the promising performance achieved in boosting efficiency for general vision tasks, current model compression methods are not specifically designed for person search, thus leaving much room for improvement. In this paper, we make the first attempt in investigating model pruning for person search, and propose a novel loss-based channel pruning approach, namely Sub-task Aware Model Pruning with Layer-wise Channel Balancing (SAMP). It firstly develops a Sub-task aware Channel Importance (SaCI) estimation to deal with the inconsistent sub-tasks, i.e. person detection and re-identification, of person search. Subsequently, a Layer-wise Channel Balancing (LCB) mechanism is employed to progressively assign a minimal number of channels to be preserved for each layer, thus avoiding over-pruning. Finally, an Adaptive OIM (AdaOIM) loss is presented for pruning and post-training via dynamically refining the degraded class-wise prototype features by leveraging the ones from the full model. Experiments on CUHK-SYSU and PRW demonstrate the effectiveness of our method, by comparing with the state-of-the-art channel pruning approaches.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_17
DP  - Springer Link
SP  - 199
EP  - 211
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
ST  - SAMP
KW  - Channel importance estimation
KW  - Channel pruning
KW  - Model compression
KW  - Person search
ER  - 

TY  - CONF
TI  - Multi-behavior Enhanced Graph Neural Networks for Social Recommendation
AU  - Wu, Xinglong
AU  - Huang, Anfeng
AU  - Yang, Hongwei
AU  - He, Hui
AU  - Tai, Yu
AU  - Zhang, Weizhe
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Social recommendation has gained more and more attention by utilizing the social relationships among users, alleviating the data sparsity problem in collaborative filtering. Most existing social recommendation approaches treat the preference propagation process coarse-grained, ignoring the different diffusion patterns targeting corresponding interaction behaviors. However, this may be inappropriate because of the interplay between multi-behavior and social relations. Therefore, in this paper, we propose a novel framework, MB-Soc, for Multi-Behavior Enhanced Social Recommender, to model the mutual effect between users’ multiple behaviors and social connections. In MB-Soc, we first devise a single behavior-based social diffusion module to depict behavioral trust propagation. Moreover, to support behavior integration, we propose an intent embedding to ensure behavior independency. In addition, we design a Self-Supervised Learning-based behavior integration module to capture the correlations among multiple behaviors. Extensive experiments conducted on two real-world datasets demonstrate the effectiveness of our model.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_4
DP  - Springer Link
SP  - 40
EP  - 52
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Graph Neural Networks
KW  - Multi-behavior Recommendation
KW  - Self-Supervised Learning
KW  - Social Recommendation
ER  - 

TY  - CONF
TI  - MKB: Multi-Kernel Bures Metric for Nighttime Aerial Tracking
AU  - He, Yingjie
AU  - Kang, Peipei
AU  - Hu, Qintai
AU  - Fang, Xiaozhao
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In recent years, many advanced visual object tracking algorithms have achieved significant performance improvements in daytime scenes. However, when these algorithms are applied at night on unmanned aerial vehicles, they often exhibit poor tracking accuracy due to the domain shift. Therefore, designing an effective and stable domain adaptation tracking framework is in great demand. Besides, as the complexity of the tracking task scene and a large number of samples, it is difficult to accurately characterize the feature differences. Moreover, the method should avoid excessive manual parameters. To solve above three challenges, this study proposes a metric-based domain alignment framework for nighttime object tracking of unmanned aerial vehicles. It achieves transfer learning from daytime to nighttime by introducing a multi-kernel Bures metric (MKB). MKB quantifies the distribution distance by calculating the difference between two domain covariance operators in the latent space. MKB also uses a linear combination of a series of kernel functions to accommodate complex samples of different scenes and categories, enhancing the ability of the metric to represent various sequences in the latent space. Besides, we introduce an alternating update mechanism to optimize the weights of kernels avoiding manual parameters. Experimental results demonstrate that the proposed method has significant advantages in improving tracking accuracy and robustness at nighttime.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_18
DP  - Springer Link
SP  - 212
EP  - 224
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
ST  - MKB
KW  - Aerial Tracking
KW  - Cross-domain
KW  - Domain Adaptation
KW  - Kernel Bures Metric
KW  - Visual Tracking
ER  - 

TY  - CONF
TI  - Boosting Generalization Performance in Person Re-identification
AU  - Cheng, Lidong
AU  - Kuang, Zhenyu
AU  - Zhang, Hongyang
AU  - Ding, Xinghao
AU  - Huang, Yue
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Generalizable person re-identification (ReID) has gained significant attention in recent years as it poses greater challenges in recognizing individuals across different domains and unseen scenarios. Existing methods are typically limited to a single visual modality, making it challenging to capture rich semantic information across different domains. Recently, pre-trained vision-language models like CLIP have shown promising performances in various tasks by linking visual representations with their corresponding text descriptions. This enables them to capture diverse high-level semantics from the accompanying text and obtain transferable features. However, the adoption of CLIP has been hindered in person ReID due to the labels being typically index-based rather than descriptive texts. To address this limitation, we propose a novel Cross-modal framework wIth Conditional Prompt (CICP) framework based on CLIP involving the Description Prompt Module (DPM) that pre-trains a set of prompts to tackle the lack of textual information in person ReID. In addition, we further propose the Prompt Generalization Module (PGM) incorporates a lightweight network that generates a conditional token for each image. This module shifts the focus from being limited to a class set to being specific to each input instance, thereby enhancing domain generalization capability for the entire task. Through extensive experiments, we show that our proposed method outperforms state-of-the-art (SOTA) approaches on popular benchmark datasets.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_15
DP  - Springer Link
SP  - 174
EP  - 185
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Domain generalization
KW  - Person re-identification
KW  - Vision-language model
ER  - 

TY  - CONF
TI  - L2MNet: Enhancing Continual Semantic Segmentation with Mask Matching
AU  - Zhang, Wenbo
AU  - Li, Bocen
AU  - Wang, Yifan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Continual semantic segmentation (CSS) aims to continuously learn a semantic segmentation model that incorporates new categories while avoiding forgetting the previously seen categories. However, CSS faces a significant challenge known as weight shift, which leads to the network mistakenly predicting masks belonging to new categories instead of their actual categories. To mitigate this phenomenon, we propose a novel module named mask matching module, which transfers pixel-level prediction task into a mask-level feature matching task by computing the similarity between mask features and prototypes. Further, we introduce a new paradigm and a network called Learn-to-Match (L2M) Net, which alleviates weight shift and gains remarkable improvements on long settings by leveraging mask-level feature matching. Our method can be easily integrated into various network architectures without extra memory and data cost. Experiments conducted on the Pascal-VOC 2012 and ADE20K datasets demonstrate that, particularly on long settings where CSS encounters more challenging settings, our method achieves a remarkable $$10.6\%$$10.6%improvement in terms of all mean Intersection over Union (mIoU) and establishes a new state-of-the-art performance in the demanding CSS settings.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_11
DP  - Springer Link
SP  - 125
EP  - 136
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
ST  - L2MNet
KW  - Class-incremental semantic segmentation
KW  - Continual semantic segmentation
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - A Multi-label Image Recognition Algorithm Based on Spatial and Semantic Correlation Interaction
AU  - Cheng, Jing
AU  - Ji, Genlin
AU  - Yang, Qinkai
AU  - Hao, Junzhao
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Multi-Label Image Recognition (MLIR) approaches usually exploit label correlations to achieve good performance. Two types of label correlations principally studied, i.e., the spatial and semantic correlations. However, most of the existing algorithms for multi-label image recognition consider semantic correlations and spatial correlations respectively, and often require additional information support. Although some algorithms simultaneously capture the semantic and spatial correlations of labels, they ignore the intrinsic relationship between the two. Specifically, only considering spatial correlations will misidentify some difficult objects in the image. For example, different categories of objects with similar appearance and close distance are mistaken for the same category, and semantic correlations can constrain the error caused by spatial correlations. In this work, we propose a multi-label image recognition algorithm based on transformer, named Spatial and Semantic Correlation Interaction (SSCI). Transformer is used to model the internal relationship between spatial correlations and semantic correlations to improve the recognition ability of the model for difficult objects. Experiments on the public datasets MS-COCO, VOC2007 and VOC2012 show that the mAP values reach 84.1%, 95.0% and 95.4%, respectively. Compared with other MLIR algorithms, the proposed algorithm can significantly improve the recognition performance of multi-label images.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_2
DP  - Springer Link
SP  - 15
EP  - 27
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - multi-label image recognition
KW  - semantic correlations
KW  - spatial correlations
KW  - transformer
ER  - 

TY  - CONF
TI  - Graph-Based Dependency-Aware Non-Intrusive Load Monitoring
AU  - Zheng, Guoqing
AU  - Hu, Yuming
AU  - Xiao, Zhenlong
AU  - Ding, Xinghao
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Non-intrusive load monitoring (NILM) is able to analyze and predict users’ power consumption behaviors for further improving the power consumption efficiency of the grid. Neural network-based techniques have been developed for NILM. However, the dependencies of multiple appliances working simultaneously were ignored or implicitly characterized in their models for disaggregation. To improve the performance of NILM, we employ a graph structure to explicitly characterize the temporal dependencies among different appliances. Specially, we consider the prior temporal knowledge between the appliances in the working state, construct a weighted adjacency matrix to represent their dependencies. We also introduce hard dependencies of each appliance to prevent the sparsity of the weighted adjacency matrix. Furthermore, the non-sequential dependencies are learned among appliances using a graph attention network based on the weighted adjacency matrix. An encoder-decoder architecture based on dilated convolutions is developed for power estimation and state detection at the same time. We demonstrate the proposed model on the UKDALE dataset, which outperforms several state-of-the-art results for NILM.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8549-4_8
DP  - Springer Link
SP  - 89
EP  - 100
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-49-4
KW  - Graph neural network
KW  - Graph structure learning
KW  - Non-intrusive load monitoring
KW  - Time series
ER  - 

TY  - CONF
TI  - ByteTrack: Multi-object Tracking by Associating Every Detection Box
AU  - Zhang, Yifu
AU  - Sun, Peize
AU  - Jiang, Yi
AU  - Yu, Dongdong
AU  - Weng, Fucheng
AU  - Yuan, Zehuan
AU  - Luo, Ping
AU  - Liu, Wenyu
AU  - Wang, Xinggang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Multi-object tracking (MOT) aims at estimating bounding boxes and identities of objects in videos. Most methods obtain identities by associating detection boxes whose scores are higher than a threshold. The objects with low detection scores, e.g. occluded objects, are simply thrown away, which brings non-negligible true object missing and fragmented trajectories. To solve this problem, we present a simple, effective and generic association method, tracking by associating almost every detection box instead of only the high score ones. For the low score detection boxes, we utilize their similarities with tracklets to recover true objects and filter out the background detections. When applied to 9 different state-of-the-art trackers, our method achieves consistent improvement on IDF1 score ranging from 1 to 10 points. To put forwards the state-of-the-art performance of MOT, we design a simple and strong tracker, named ByteTrack. For the first time, we achieve 80.3 MOTA, 77.3 IDF1 and 63.1 HOTA on the test set of MOT17 with 30 FPS running speed on a single V100 GPU. ByteTrack also achieves state-of-the-art performance on MOT20, HiEve and BDD100K tracking benchmarks. The source code, pre-trained models with deploy versions and tutorials of applying to other trackers are released at https://github.com/ifzhang/ByteTrack.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_1
DP  - Springer Link
SP  - 1
EP  - 21
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - ByteTrack
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_1.pdf
KW  - Data association
KW  - Detection boxes
KW  - Multi-object tracking
ER  - 

TY  - CONF
TI  - Social ODE: Multi-agent Trajectory Forecasting with Neural Ordinary Differential Equations
AU  - Wen, Song
AU  - Wang, Hao
AU  - Metaxas, Dimitris
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Multi-agent trajectory forecasting has recently attracted a lot of attention due to its widespread applications including autonomous driving. Most previous methods use RNNs or Transformers to model agent dynamics in the temporal dimension and social pooling or GNNs to model interactions with other agents; these approaches usually fail to learn the underlying continuous temporal dynamics and agent interactions explicitly. To address these problems, we propose Social ODE which explicitly models temporal agent dynamics and agent interactions. Our approach leverages Neural ODEs to model continuous temporal dynamics, and incorporates distance, interaction intensity, and aggressiveness estimation into agent interaction modeling in latent space. We show in extensive experiments that our Social ODE approach compares favorably with state-of-the-art, and more importantly, can successfully avoid sudden obstacles and effectively control the motion of the agent, while previous methods often fail in such cases.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_13
DP  - Springer Link
SP  - 217
EP  - 233
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - Social ODE
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_13.pdf
KW  - Multi-agent modeling
KW  - Ordinary differential equations
KW  - Social ODEs
ER  - 

TY  - CONF
TI  - AiATrack: Attention in Attention for Transformer Visual Tracking
AU  - Gao, Shenyuan
AU  - Zhou, Chunluan
AU  - Ma, Chao
AU  - Wang, Xinggang
AU  - Yuan, Junsong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Transformer trackers haveachieved impressive advancements recently, where the attention mechanism plays an important role. However, the independent correlation computation in the attention mechanism could result in noisy and ambiguous attention weights, which inhibits further performance improvement. To address this issue, we propose an attention in attention (AiA) module, which enhances appropriate correlations and suppresses erroneous ones by seeking consensus among all correlation vectors. Our AiA module can be readily applied to both self-attention blocks and cross-attention blocks to facilitate feature aggregation and information propagation for visual tracking. Moreover, we propose a streamlined Transformer tracking framework, dubbed AiATrack, by introducing efficient feature reuse and target-background embeddings to make full use of temporal references. Experiments show that our tracker achieves state-of-the-art performance on six tracking benchmarks while running at a real-time speed. Code and models are publicly available at https://github.com/Little-Podi/AiATrack.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_9
DP  - Springer Link
SP  - 146
EP  - 164
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - AiATrack
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_9.pdf
KW  - Attention mechanism
KW  - Vision transformer
KW  - Visual tracking
ER  - 

TY  - CONF
TI  - CMT: Context-Matching-Guided Transformer for 3D Tracking in Point Clouds
AU  - Guo, Zhiyang
AU  - Mao, Yunyao
AU  - Zhou, Wengang
AU  - Wang, Min
AU  - Li, Houqiang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - How to effectively match the target template features with the search area is the core problem in point-cloud-based 3D single object tracking. However, in the literature, most of the methods focus on devising sophisticated matching modules at point-level, while overlooking the rich spatial context information of points. To this end, we propose Context-Matching-Guided Transformer (CMT), a Siamese tracking paradigm for 3D single object tracking. In this work, we first leverage the local distribution of points to construct a horizontally rotation-invariant contextual descriptor for both the template and the search area. Then, a novel matching strategy based on shifted windows is designed for such descriptors to effectively measure the template-search contextual similarity. Furthermore, we introduce a target-specific transformer and a spatial-aware orientation encoder to exploit the target-aware information in the most contextually relevant template points, thereby enhancing the search feature for a better target proposal. We conduct extensive experiments to verify the merits of our proposed CMT and report a series of new state-of-the-art records on three widely-adopted datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_6
DP  - Springer Link
SP  - 95
EP  - 111
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - CMT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_6.pdf
KW  - 3D single object tracking
KW  - Context match
KW  - Point clouds
ER  - 

TY  - CONF
TI  - Disentangling Architecture and Training for Optical Flow
AU  - Sun, Deqing
AU  - Herrmann, Charles
AU  - Reda, Fitsum
AU  - Rubinstein, Michael
AU  - Fleet, David J.
AU  - Freeman, William T.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - How important are training details and datasets to recent optical flow architectures like RAFT? And do they generalize? To explore these questions, rather than develop a new architecture, we revisit three prominent architectures, PWC-Net, IRR-PWC and RAFT, with a common set of modern training techniques and datasets, and observe significant performance gains, demonstrating the importance and generality of these training details. Our newly trained PWC-Net and IRR-PWC show surprisingly large improvements, up to 30% versus original published results on Sintel and KITTI 2015 benchmarks. Our newly trained RAFT obtains an Fl-all score of 4.31% on KITTI 2015 and an avg. rank of 1.7 for end-point error on Middlebury. Our results demonstrate the benefits of separating the contributions of architectures, training techniques and datasets when analyzing performance gains of optical flow methods. Our source code is available at https://autoflow-google.github.io.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_10
DP  - Springer Link
SP  - 165
EP  - 182
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_10.pdf
KW  - Architecture
KW  - Evaluation
KW  - Optical flow
KW  - Training
ER  - 

TY  - CONF
TI  - Robust Landmark-Based Stent Tracking in X-ray Fluoroscopy
AU  - Huang, Luojie
AU  - Liu, Yikang
AU  - Chen, Li
AU  - Chen, Eric Z.
AU  - Chen, Xiao
AU  - Sun, Shanhui
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In clinical procedures of angioplasty (i.e., open clogged coronary arteries), devices such as balloons and stents need to be placed and expanded in arteries under the guidance of X-ray fluoroscopy. Due to the limitation of X-ray dose, the resulting images are often noisy. To check the correct placement of these devices, typically multiple motion-compensated frames are averaged to enhance the view. Therefore, device tracking is a necessary procedure for this purpose. Even though angioplasty devices are designed to have radiopaque markers for the ease of tracking, current methods struggle to deliver satisfactory results due to the small marker size and complex scenes in angioplasty. In this paper, we propose an end-to-end deep learning framework for single stent tracking, which consists of three hierarchical modules: a U-Net for landmark detection, a ResNet for stent proposal and feature extraction, and a graph convolutional neural network for stent tracking that temporally aggregates both spatial information and appearance features. The experiments show that our method performs significantly better in detection compared with the state-of-the-art point-based tracking models. In addition, its fast inference speed satisfies clinical requirements.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_12
DP  - Springer Link
SP  - 201
EP  - 216
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_12.pdf
KW  - Graph neural network
KW  - Landmark tracking
KW  - Stent enhancement
ER  - 

TY  - CONF
TI  - PolarMOT: How Far Can Geometric Relations Take us in 3D Multi-object Tracking?
AU  - Kim, Aleksandr
AU  - Brasó, Guillem
AU  - Ošep, Aljoša
AU  - Leal-Taixé, Laura
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Most (3D) multi-object tracking methods rely on appearance-based cues for data association. By contrast, we investigate how far we can get by only encoding geometric relationships between objects in 3D space as cues for data-driven data association. We encode 3D detections as nodes in a graph, where spatial and temporal pairwise relations among objects are encoded via localized polar coordinates on graph edges. This representation makes our geometric relations invariant to global transformations and smooth trajectory changes, especially under non-holonomic motion. This allows our graph neural network to learn to effectively encode temporal and spatial interactions and fully leverage contextual and motion cues to obtain final scene interpretation by posing data association as edge classification. We establish a new state-of-the-art on nuScenes dataset and, more importantly, show that our method, PolarMOT, generalizes remarkably well across different locations (Boston, Singapore, Karlsruhe) and datasets (nuScenes and KITTI).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_3
DP  - Springer Link
SP  - 41
EP  - 58
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - PolarMOT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_3.pdf
KW  - 3D multi-object tracking
KW  - Graph neural networks
KW  - Lidar scene understanding
ER  - 

TY  - CONF
TI  - Social-SSL: Self-supervised Cross-Sequence Representation Learning Based on Transformers for Multi-agent Trajectory Prediction
AU  - Tsao, Li-Wu
AU  - Wang, Yan-Kai
AU  - Lin, Hao-Siang
AU  - Shuai, Hong-Han
AU  - Wong, Lai-Kuan
AU  - Cheng, Wen-Huang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Earlier trajectory prediction approaches focus on ways of capturing sequential structures among pedestrians by using recurrent networks, which is known to have some limitations in capturing long sequence structures. To address this limitation, some recent works proposed Transformer-based architectures, which are built with attention mechanisms. However, these Transformer-based networks are trained end-to-end without capitalizing on the value of pre-training. In this work, we propose Social-SSL that captures cross-sequence trajectory structures via self-supervised pre-training, which plays a crucial role in improving both data efficiency and generalizability of Transformer networks for trajectory prediction. Specifically, Social-SSL models the interaction and motion patterns with three pretext tasks: interaction type prediction, closeness prediction, and masked cross-sequence to sequence pre-training. Comprehensive experiments show that Social-SSL outperforms the state-of-the-art methods by at least 12% and 20% on ETH/UCY and SDD datasets in terms of Average Displacement Error and Final Displacement Error (code available at https://github.com/Sigta678/Social-SSL.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_14
DP  - Springer Link
SP  - 234
EP  - 250
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - Social-SSL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_14.pdf
KW  - Representation learning
KW  - Self-supervised learning
KW  - Trajectory prediction
KW  - Transformer
ER  - 

TY  - CONF
TI  - Towards Generic 3D Tracking in RGBD Videos: Benchmark and Baseline
AU  - Yang, Jinyu
AU  - Zhang, Zhongqun
AU  - Li, Zhe
AU  - Chang, Hyung Jin
AU  - Leonardis, Aleš
AU  - Zheng, Feng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Tracking in 3D scenes is gaining momentum because of its numerous applications in robotics, autonomous driving, and scene understanding. Currently, 3D tracking is limited to specific model-based approaches involving point clouds, which impedes 3D trackers from applying in natural 3D scenes. RGBD sensors provide a more reasonable and acceptable solution for 3D object tracking due to their readily available synchronised color and depth information. Thus, in this paper, we investigate a novel problem: is it possible to track a generic (class-agnostic) 3D object in RGBD videos and predict 3D bounding boxes of the object of interest? To inspire research on this topic, we newly construct a standard benchmark for generic 3D object tracking, ‘Track-it-in-3D’, which contains 300 RGBD video sequences with dense 3D annotations and corresponding evaluation protocols. Furthermore, we propose an effective tracking baseline to estimate 3D bounding boxes for arbitrary objects in RGBD videos, by fusing appearance and spatial information effectively. Resources are available on https://github.com/yjybuaa/Track-it-in-3D.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_7
DP  - Springer Link
SP  - 112
EP  - 128
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - Towards Generic 3D Tracking in RGBD Videos
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_7.pdf
KW  - 3D object tracking
KW  - Object tracking
KW  - RGBD data
ER  - 

TY  - CONF
TI  - Sequential Multi-view Fusion Network for Fast LiDAR Point Motion Estimation
AU  - Zhang, Gang
AU  - Li, Xiaoyan
AU  - Wang, Zhenhua
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The LiDAR point motion estimation, including motion state prediction and velocity estimation, is crucial for understanding a dynamic scene in autonomous driving. Recent 2D projection-based methods run in real-time by applying the well-optimized 2D convolution networks on either the bird’s-eye view (BEV) or the range view (RV) but suffer from lower accuracy due to information loss during the 2D projection. Thus, we propose a novel sequential multi-view fusion network (SMVF), composed of a BEV branch and an RV branch, in charge of encoding the motion information and spatial information, respectively. By looking from distinct views and integrating with the original LiDAR point features, the SMVF produces a comprehensive motion prediction, while keeping its efficiency. Moreover, to generalize the motion estimation well to the objects with fewer training samples, we propose a sequential instance copy-paste (SICP) for generating realistic LiDAR sequences for these objects. The experiments on the SemanticKITTI moving object segmentation (MOS) and Waymo scene flow benchmarks demonstrate that our SMVF outperforms all existing methods by a large margin.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_17
DP  - Springer Link
SP  - 290
EP  - 305
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_17.pdf
KW  - Generalization of motion estimation
KW  - Motion state prediction
KW  - Multi-view fusion
KW  - Velocity estimation
ER  - 

TY  - CONF
TI  - Hierarchical Latent Structure for Multi-modal Vehicle Trajectory Forecasting
AU  - Choi, Dooseop
AU  - Min, KyoungWook
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Variational autoencoder (VAE) has widely been utilized for modeling data distributions because it is theoretically elegant, easy to train, and has nice manifold representations. However, when applied to image reconstruction and synthesis tasks, VAE shows the limitation that the generated sample tends to be blurry. We observe that a similar problem, in which the generated trajectory is located between adjacent lanes, often arises in VAE-based trajectory forecasting models. To mitigate this problem, we introduce a hierarchical latent structure into the VAE-based forecasting model. Based on the assumption that the trajectory distribution can be approximated as a mixture of simple distributions (or modes), the low-level latent variable is employed to model each mode of the mixture and the high-level latent variable is employed to represent the weights for the modes. To model each mode accurately, we condition the low-level latent variable using two lane-level context vectors computed in novel ways, one corresponds to vehicle-lane interaction and the other to vehicle-vehicle interaction. The context vectors are also used to model the weights via the proposed mode selection network. To evaluate our forecasting model, we use two large-scale real-world datasets. Experimental results show that our model is not only capable of generating clear multi-modal trajectory distributions but also outperforms the state-of-the-art (SOTA) models in terms of prediction accuracy. Our code is available at https://github.com/d1024choi/HLSTrajForecast.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_8
DP  - Springer Link
SP  - 129
EP  - 145
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_8.pdf
ER  - 

TY  - CONF
TI  - Point Cloud Compression with Range Image-Based Entropy Model for Autonomous Driving
AU  - Wang, Sukai
AU  - Liu, Ming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - For autonomous driving systems, the storage cost and transmission speed of the large-scale point clouds become an important bottleneck because of their large volume. In this paper, we propose a range image-based three-stage framework to compress the scanning LiDAR’s point clouds using the entropy model. In our three-stage framework, we refine the coarser range image by converting the regression problem into the limited classification problem to improve the performance of generating accurate point clouds. And in the feature extraction part, we propose a novel attention Conv layer to fuse the voxel-based 3D features in the 2D range image. Compared with the Octree-based compression methods, the range image compression with the entropy model performs better in the autonomous driving scene. Experiments on LiDARs with different lines and in different scenarios show that our proposed compression scheme outperforms the state-of-the-art approaches in reconstruction quality and downstream tasks by a wide margin.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_19
DP  - Springer Link
SP  - 323
EP  - 340
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_19.pdf
KW  - Autonomous driving
KW  - Entropy encoding
KW  - Point cloud compression
ER  - 

TY  - CONF
TI  - Diverse Human Motion Prediction Guided by Multi-level Spatial-Temporal Anchors
AU  - Xu, Sirui
AU  - Wang, Yu-Xiong
AU  - Gui, Liang-Yan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Predicting diverse human motions given a sequence of historical poses has received increasing attention. Despite rapid progress, existing work captures the multi-modal nature of human motions primarily through likelihood-based sampling, where the mode collapse has been widely observed. In this paper, we propose a simple yet effective approach that disentangles randomly sampled codes with a deterministic learnable component named anchors to promote sample precision and diversity. Anchors are further factorized into spatial anchors and temporal anchors, which provide attractively interpretable control over spatial-temporal disparity. In principle, our spatial-temporal anchor-based sampling (STARS) can be applied to different motion predictors. Here we propose an interaction-enhanced spatial-temporal graph convolutional network (IE-STGCN) that encodes prior knowledge of human motions (e.g., spatial locality), and incorporate the anchors into it. Extensive experiments demonstrate that our approach outperforms state of the art in both stochastic and deterministic prediction, suggesting it as a unified framework for modeling human motions. Our code and pretrained models are available at https://github.com/Sirui-Xu/STARS.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_15
DP  - Springer Link
SP  - 251
EP  - 269
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_15.pdf
KW  - Generative models
KW  - Graph neural networks
KW  - Stochastic human motion prediction
ER  - 

TY  - CONF
TI  - Particle Video Revisited: Tracking Through Occlusions Using Point Trajectories
AU  - Harley, Adam W.
AU  - Fang, Zhaoyuan
AU  - Fragkiadaki, Katerina
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Tracking pixels in videos is typically studied as an optical flow estimation problem, where every pixel is described with a displacement vector that locates it in the next frame. Even though wider temporal context is freely available, prior efforts to take this into account have yielded only small gains over 2-frame methods. In this paper, we revisit Sand and Teller’s “particle video” approach, and study pixel tracking as a long-range motion estimation problem, where every pixel is described with a trajectory that locates it in multiple future frames. We re-build this classic approach using components that drive the current state-of-the-art in flow and object tracking, such as dense cost maps, iterative optimization, and learned appearance updates. We train our models using long-range amodal point trajectories mined from existing optical flow data that we synthetically augment with multi-frame occlusions. We test our approach in trajectory estimation benchmarks and in keypoint label propagation tasks, and compare favorably against state-of-the-art optical flow and feature tracking methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_4
DP  - Springer Link
SP  - 59
EP  - 75
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - Particle Video Revisited
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_4.pdf
ER  - 

TY  - CONF
TI  - A Perturbation-Constrained Adversarial Attack for Evaluating the Robustness of Optical Flow
AU  - Schmalfuss, Jenny
AU  - Scholze, Philipp
AU  - Bruhn, Andrés
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recent optical flow methods are almost exclusively judged in terms of accuracy, while their robustness is often neglected. Although adversarial attacks offer a useful tool to perform such an analysis, current attacks on optical flow methods focus on real-world attacking scenarios rather than a worst case robustness assessment. Hence, in this work, we propose a novel adversarial attack—the Perturbation-Constrained Flow Attack (PCFA)—that emphasizes destructivity over applicability as a real-world attack. PCFA is a global attack that optimizes adversarial perturbations to shift the predicted flow towards a specified target flow, while keeping the $$L_2$$L2norm of the perturbation below a chosen bound. Our experiments demonstrate PCFA’s applicability in white- and black-box settings, and show it finds stronger adversarial samples than previous attacks. Based on these strong samples, we provide the first joint ranking of optical flow methods considering both prediction quality and adversarial robustness, which reveals state-of-the-art methods to be particularly vulnerable. Code is available at https://github.com/cv-stuttgart/PCFA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_11
DP  - Springer Link
SP  - 183
EP  - 200
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_11.pdf
KW  - \(L_2\)  constrained perturbation
KW  - Global adversarial attack
KW  - Optical flow
KW  - Robustness
ER  - 

TY  - CONF
TI  - Tracking Objects as Pixel-Wise Distributions
AU  - Zhao, Zelin
AU  - Wu, Ze
AU  - Zhuang, Yueqing
AU  - Li, Boxun
AU  - Jia, Jiaya
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Multi-object tracking (MOT) requires detecting and associating objects through frames. Unlike tracking via detected bounding boxes or center points, we propose tracking objects as pixel-wise distributions. We instantiate this idea on a transformer-based architecture named P3AFormer, with pixel-wise propagation, prediction, and association. P3AFormer propagates pixel-wise features guided by flow information to pass messages between frames. Further, P3AFormer adopts a meta-architecture to produce multi-scale object feature maps. During inference, a pixel-wise association procedure is proposed to recover object connections through frames based on the pixel-wise prediction. P3AFormer yields 81.2% in terms of MOTA on the MOT17 benchmark – highest among all transformer networks to reach 80% MOTA in literature. P3AFormer also outperforms state-of-the-arts on the MOT20 and KITTI benchmarks. The code is at https://github.com/dvlab-research/ECCV22-P3AFormer-Tracking-Objects-as-Pixel-wise-Distributions.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_5
DP  - Springer Link
SP  - 76
EP  - 94
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_5.pdf
KW  - Multi-object tracking
KW  - Pixel-wise tracking
KW  - Transformer
ER  - 

TY  - CONF
TI  - Learning Pedestrian Group Representations for Multi-modal Trajectory Prediction
AU  - Bae, Inhwan
AU  - Park, Jin-Hwi
AU  - Jeon, Hae-Gon
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Modeling the dynamics of people walking is a problem of long-standing interest in computer vision. Many previous works involving pedestrian trajectory prediction define a particular set of individual actions to implicitly model group actions. In this paper, we present a novel architecture named GP-Graph which has collective group representations for effective pedestrian trajectory prediction in crowded environments, and is compatible with all types of existing approaches. A key idea of GP-Graph is to model both individual-wise and group-wise relations as graph representations. To do this, GP-Graph first learns to assign each pedestrian into the most likely behavior group. Using this assignment information, GP-Graph then forms both intra- and inter-group interactions as graphs, accounting for human-human relations within a group and group-group relations, respectively. To be specific, for the intra-group interaction, we mask pedestrian graph edges out of an associated group. We also propose group pooling &unpooling operations to represent a group with multiple pedestrians as one graph node. Lastly, GP-Graph infers a probability map for socially-acceptable future trajectories from the integrated features of both group interactions. Moreover, we introduce a group-level latent vector sampling to ensure collective inferences over a set of possible future trajectories. Extensive experiments are conducted to validate the effectiveness of our architec ture, which demonstrates consistent performance improvements with publicly available benchmarks. Code is publicly available at https://github.com/inhwanbae/GPGraph.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_16
DP  - Springer Link
SP  - 270
EP  - 289
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_16.pdf
KW  - Group representation
KW  - Pedestrian trajectory prediction
ER  - 

TY  - CONF
TI  - E-Graph: Minimal Solution for Rigid Rotation with Extensibility Graphs
AU  - Li, Yanyan
AU  - Tombari, Federico
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Minimal solutions for relative rotation and translation estimation tasks have been explored in different scenarios, typically relying on the so-called co-visibility graphs. However, how to build direct rotation relationships between two frames without overlap is still an open topic, which, if solved, could greatly improve the accuracy of visual odometry. In this paper, a new minimal solution is proposed to solve relative rotation estimation between two images without overlapping areas by exploiting a new graph structure, which we call Extensibility Graph (E-Graph). Differently from a co-visibility graph, high-level landmarks, including vanishing directions and plane normals, are stored in our E-Graph, which are geometrically extensible. Based on E-Graph, the rotation estimation problem becomes simpler and more elegant, as it can deal with pure rotational motion and requires fewer assumptions, e.g. Manhattan/Atlanta World, planar/vertical motion. Finally, we embed our rotation estimation strategy into a complete camera tracking and mapping system which obtains 6-DoF camera poses and a dense 3D mesh model. Extensive experiments on public benchmarks demonstrate that the proposed method achieves state-of-the-art tracking performance.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_18
DP  - Springer Link
SP  - 306
EP  - 322
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
ST  - E-Graph
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_18.pdf
ER  - 

TY  - CONF
TI  - Robust Multi-object Tracking by Marginal Inference
AU  - Zhang, Yifu
AU  - Wang, Chunyu
AU  - Wang, Xinggang
AU  - Zeng, Wenjun
AU  - Liu, Wenyu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Multi-object tracking in videos requires to solve a fundamental problem of one-to-one assignment between objects in adjacent frames. Most methods address the problem by first discarding impossible pairs whose feature distances are larger than a threshold, followed by linking objects using Hungarian algorithm to minimize the overall distance. However, we find that the distribution of the distances computed from Re-ID features may vary significantly for different videos. So there isn’t a single optimal threshold which allows us to safely discard impossible pairs. To address the problem, we present an efficient approach to compute a marginal probability for each pair of objects in real time. The marginal probability can be regarded as a normalized distance which is significantly more stable than the original feature distance. As a result, we can use a single threshold for all videos. The approach is general and can be applied to the existing trackers to obtain about one point improvement in terms of IDF1 metric. It achieves competitive results on MOT17 and MOT20 benchmarks. In addition, the computed probability is more interpretable which facilitates subsequent post-processing operations.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20047-2_2
DP  - Springer Link
SP  - 22
EP  - 40
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20047-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20047-2_2.pdf
KW  - Data association
KW  - Marginal probability
KW  - Multi-object tracking
ER  - 

TY  - CONF
TI  - A-OKVQA: A Benchmark for Visual Question Answering Using World Knowledge
AU  - Schwenk, Dustin
AU  - Khandelwal, Apoorv
AU  - Clark, Christopher
AU  - Marino, Kenneth
AU  - Mottaghi, Roozbeh
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The Visual Question Answering (VQA) task aspires to provide a meaningful testbed for the development of AI models that can jointly reason over visual and natural language inputs. Despite a proliferation of VQA datasets, this goal is hindered by a set of common limitations. These include a reliance on relatively simplistic questions that are repetitive in both concepts and linguistic structure, little world knowledge needed outside of the paired image, and limited reasoning required to arrive at the correct answer. We introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about 25K questions requiring a broad base of commonsense and world knowledge to answer. In contrast to existing knowledge-based VQA datasets, the questions generally cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning about the scene depicted in the image. We demonstrate the potential of this new dataset through a detailed analysis of its contents and baseline performance measurements over a variety of state-of-the-art vision–language models.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_9
DP  - Springer Link
SP  - 146
EP  - 162
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - A-OKVQA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_9.pdf
ER  - 

TY  - CONF
TI  - Capturing, Reconstructing, and Simulating: The UrbanScene3D Dataset
AU  - Lin, Liqiang
AU  - Liu, Yilin
AU  - Hu, Yue
AU  - Yan, Xingguang
AU  - Xie, Ke
AU  - Huang, Hui
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present UrbanScene3D, a large-scale data platform for research of urban scene perception and reconstruction. UrbanScene3D contains over 128k high-resolution images covering 16 scenes including large-scale real urban regions and synthetic cities with 136 km$$^2$$2area in total. The dataset also contains high-precision LiDAR scans and hundreds of image sets with different observation patterns, which provide a comprehensive benchmark to design and evaluate aerial path planning and 3D reconstruction algorithms. In addition, the dataset, which is built on Unreal Engine and Airsim simulator together with the manually annotated unique instance label for each building in the dataset, enables the generation of all kinds of data, e.g., 2D depth maps, 2D/3D bounding boxes, and 3D point cloud/mesh segmentations, etc. The simulator with physical engine and lighting system not only produce variety of data but also enable users to simulate cars or drones in the proposed urban environment for future research. The dataset with aerial path planning and 3D reconstruction benchmark is available at: https://vcc.tech/UrbanScene3D.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_6
DP  - Springer Link
SP  - 93
EP  - 109
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - Capturing, Reconstructing, and Simulating
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_6.pdf
KW  - 3D acquisition
KW  - 3D reconstruction
KW  - Aerial path planning
KW  - City simulation
KW  - UAV
KW  - Urban scene dataset
ER  - 

TY  - CONF
TI  - ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO
AU  - Chun, Sanghyuk
AU  - Kim, Wonjae
AU  - Park, Song
AU  - Chang, Minsuk
AU  - Oh, Seong Joon
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Image-Text matching (ITM) is a common task for evaluating the quality of Vision and Language (VL) models. However, existing ITM benchmarks have a significant limitation. They have many missing correspondences, originating from the data construction process itself. For example, a caption is only matched with one image although the caption can be matched with other similar images and vice versa. To correct the massive false negatives, we construct the Extended COCO Validation (ECCV) Caption dataset by supplying the missing associations with machine and human annotators. We employ five state-of-the-art ITM models with diverse properties for our annotation process. Our dataset provides $$\times $$×3.6 positive image-to-caption associations and $$\times $$×8.5 caption-to-image associations compared to the original MS-COCO. We also propose to use an informative ranking-based metric mAP@R, rather than the popular Recall@K (R@K). We re-evaluate the existing 25 VL models on existing and proposed benchmarks. Our findings are that the existing benchmarks, such as COCO 1K R@K, COCO 5K R@K, CxC R@1 are highly correlated with each other, while the rankings change when we shift to the ECCV mAP@R. Lastly, we delve into the effect of the bias introduced by the choice of machine annotator. Source code and dataset are available at https://github.com/naver-ai/eccv-caption
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_1
DP  - Springer Link
SP  - 1
EP  - 19
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - ECCV Caption
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_1.pdf
ER  - 

TY  - CONF
TI  - 3D CoMPaT: Composition of Materials on Parts of 3D Things
AU  - Li, Yuchen
AU  - Upadhyay, Ujjwal
AU  - Slim, Habib
AU  - Abdelreheem, Ahmed
AU  - Prajapati, Arpit
AU  - Pothigara, Suhail
AU  - Wonka, Peter
AU  - Elhoseiny, Mohamed
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present 3D CoMPaT, a richly annotated large-scale dataset of more than 7.19 million rendered compositions of Materials on Parts of 7262 unique 3D Models; 990 compositions per model on average. 3D CoMPaT covers 43 shape categories, 235 unique part names, and 167 unique material classes that can be applied to parts of 3D objects. Each object with the applied part-material compositions is rendered from four equally spaced views as well as four randomized views, leading to a total of 58 million renderings (7.19 million compositions $$\times 8{}$$×8views). This dataset primarily focuses on stylizing 3D shapes at part-level with compatible materials. We introduce a new task, called Grounded CoMPaT Recognition (GCR), to collectively recognize and ground compositions of materials on parts of 3D objects. We present two variations of this task and adapt state-of-art 2D/3D deep learning methods to solve the problem as baselines for future research. We hope our work will help ease future research on compositional 3D Vision. The dataset and code are publicly available at https://www.3dcompat-dataset.org/.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_7
DP  - Springer Link
SP  - 110
EP  - 127
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - 3D CoMPaT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_7.pdf
ER  - 

TY  - CONF
TI  - MOTCOM: The Multi-Object Tracking Dataset Complexity Metric
AU  - Pedersen, Malte
AU  - Haurum, Joakim Bruslund
AU  - Dendorfer, Patrick
AU  - Moeslund, Thomas B.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - There exists no comprehensive metric for describing the complexity of Multi-Object Tracking (MOT) sequences. This lack of metrics decreases explainability, complicates comparison of datasets, and reduces the conversation on tracker performance to a matter of leader board position. As a remedy, we present the novel MOT dataset complexity metric (MOTCOM), which is a combination of three sub-metrics inspired by key problems in MOT: occlusion, erratic motion, and visual similarity. The insights of MOTCOM can open nuanced discussions on tracker performance and may lead to a wider acknowledgement of novel contributions developed for either less known datasets or those aimed at solving sub-problems.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_2
DP  - Springer Link
SP  - 20
EP  - 37
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - MOTCOM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_2.pdf
ER  - 

TY  - CONF
TI  - A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility
AU  - Burns, Andrea
AU  - Arsan, Deniz
AU  - Agrawal, Sanjna
AU  - Kumar, Ranjitha
AU  - Saenko, Kate
AU  - Plummer, Bryan A.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Vision-language navigation (VLN), in which an agent follows language instruction in a visual environment, has been studied under the premise that the input command is fully feasible in the environment. Yet in practice, a request may not be possible due to language ambiguity or environment changes. To study VLN with unknown command feasibility, we introduce a new dataset Mobile app Tasks with Iterative Feedback (MoTIF), where the goal is to complete a natural language command in a mobile app. Mobile apps provide a scalable domain to study real downstream uses of VLN methods. Moreover, mobile app commands provide instruction for interactive navigation, as they result in action sequences with state changes via clicking, typing, or swiping. MoTIF is the first to include feasibility annotations, containing both binary feasibility labels and fine-grained labels for why tasks are unsatisfiable. We further collect follow-up questions for ambiguous queries to enable research on task uncertainty resolution. Equipped with our dataset, we propose the new problem of feasibility prediction, in which a natural language instruction and multimodal app environment are used to predict command feasibility. MoTIF provides a more realistic app dataset as it contains many diverse environments, high-level goals, and longer action sequences than prior work. We evaluate interactive VLN methods using MoTIF, quantify the generalization ability of current approaches to new app environments, and measure the effect of task feasibility on navigation performance.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_18
DP  - Springer Link
SP  - 312
EP  - 328
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_18.pdf
KW  - Mobile apps
KW  - Task feasibility
KW  - Vision-language navigation
ER  - 

TY  - CONF
TI  - BRACE: The Breakdancing Competition Dataset for Dance Motion Synthesis
AU  - Moltisanti, Davide
AU  - Wu, Jinyi
AU  - Dai, Bo
AU  - Loy, Chen Change
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Generative models for audio-conditioned dance motion synthesis map music features to dance movements. Models are trained to associate motion patterns to audio patterns, usually without an explicit knowledge of the human body. This approach relies on a few assumptions: strong music-dance correlation, controlled motion data and relatively simple poses and movements. These characteristics are found in all existing datasets for dance motion synthesis, and indeed recent methods can achieve good results. We introduce a new dataset aiming to challenge these common assumptions, compiling a set of dynamic dance sequences displaying complex human poses. We focus on breakdancing which features acrobatic moves and tangled postures. We source our data from the Red Bull BC One competition videos. Estimating human keypoints from these videos is difficult due to the complexity of the dance, as well as the multiple moving cameras recording setup. We adopt a hybrid labelling pipeline leveraging deep estimation models as well as manual annotations to obtain good quality keypoint sequences at a reduced cost. Our efforts produced the BRACE dataset, which contains over 3 h and 30 min of densely annotated poses. We test state-of-the-art methods on BRACE, showing their limitations when evaluated on complex sequences. Our dataset can readily foster advance in dance motion synthesis. With intricate poses and swift movements, models are forced to go beyond learning a mapping between modalities and reason more effectively about body structure and movements.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_19
DP  - Springer Link
SP  - 329
EP  - 344
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - BRACE
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_19.pdf
ER  - 

TY  - CONF
TI  - FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in Context
AU  - Chowdhury, Pinaki Nath
AU  - Sain, Aneeshan
AU  - Bhunia, Ayan Kumar
AU  - Xiang, Tao
AU  - Gryaditskaya, Yulia
AU  - Song, Yi-Zhe
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We advance sketch research to scenes with the first dataset of freehand scene sketches, FS-COCO. With practical applications in mind, we collect sketches that convey scene content well but can be sketched within a few minutes by a person with any sketching skills. Our dataset comprises 10, 000 freehand scene vector sketches with per point space-time information by 100 non-expert individuals, offering both object- and scene-level abstraction. Each sketch is augmented with its text description. Using our dataset, we study for the first time the problem of fine-grained image retrieval from freehand scene sketches and sketch captions. We draw insights on: (i) Scene salience encoded in sketches using the strokes temporal order; (ii) Performance comparison of image retrieval from a scene sketch and an image caption; (iii) Complementarity of information in sketches and image captions, as well as the potential benefit of combining the two modalities. In addition, we extend a popular vector sketch LSTM-based encoder to handle sketches with larger complexity than was supported by previous work. Namely, we propose a hierarchical sketch decoder, which we leverage at a sketch-specific “pretext” task. Our dataset enables for the first time research on freehand scene sketch understanding and its practical applications. We release the dataset under CC BY-NC 4.0 license: FS-COCO dataset (https://github.com/pinakinathc/fscoco).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_15
DP  - Springer Link
SP  - 253
EP  - 270
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - FS-COCO
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_15.pdf
ER  - 

TY  - CONF
TI  - Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset
AU  - Van Horn, Grant
AU  - Qian, Rui
AU  - Wilber, Kimberly
AU  - Adam, Hartwig
AU  - Mac Aodha, Oisin
AU  - Belongie, Serge
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present a new benchmark dataset, Sapsucker Woods 60 (SSW60), for advancing research on audiovisual fine-grained categorization. While our community has made great strides in fine-grained visual categorization on images, the counterparts in audio and video fine-grained categorization are relatively unexplored. To encourage advancements in this space, we have carefully constructed the SSW60 dataset to enable researchers to experiment with classifying the same set of categories in three different modalities: images, audio, and video. The dataset covers 60 species of birds and is comprised of images from existing datasets, and brand new, expert curated audio and video datasets. We thoroughly benchmark audiovisual classification performance and modality fusion experiments through the use of state-of-the-art transformer methods. Our findings show that performance of audiovisual fusion methods is better than using exclusively image or audio based methods for the task of video classification. We also present interesting modality transfer experiments, enabled by the unique construction of SSW60 to encompass three different modalities. We hope the SSW60 dataset and accompanying baselines spur research in this fascinating area.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_16
DP  - Springer Link
SP  - 271
EP  - 289
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_16.pdf
KW  - Audio
KW  - Fine-grained
KW  - Multi-modal learning
KW  - Video
ER  - 

TY  - CONF
TI  - StyleBabel: Artistic Style Tagging and Captioning
AU  - Ruta, Dan
AU  - Gilbert, Andrew
AU  - Aggarwal, Pranav
AU  - Marri, Naveen
AU  - Kale, Ajinkya
AU  - Briggs, Jo
AU  - Speed, Chris
AU  - Jin, Hailin
AU  - Faieta, Baldo
AU  - Filipkowski, Alex
AU  - Lin, Zhe
AU  - Collomosse, John
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present StyleBabel, a unique open access dataset of natural language captions and free-form tags describing the artistic style of over 135K digital artworks, collected via a novel participatory method from experts studying at specialist art and design schools. StyleBabel was collected via an iterative method, inspired by ‘Grounded Theory’: a qualitative approach that enables annotation while co-evolving a shared language for fine-grained artistic style attribute description. We demonstrate several downstream tasks for StyleBabel, adapting the recent ALADIN architecture for fine-grained style similarity, to train cross-modal embeddings for: 1) free-form tag generation; 2) natural language description of artistic style; 3) fine-grained text search of style. To do so, we extend ALADIN with recent advances in Visual Transformer (ViT) and cross-modal representation learning, achieving a state of the art accuracy in fine-grained style retrieval.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_13
DP  - Springer Link
SP  - 219
EP  - 236
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - StyleBabel
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_13.pdf
KW  - Datasets and evaluation
KW  - Image and video retrieval
KW  - Vision + language
KW  - Vision applications and systems
ER  - 

TY  - CONF
TI  - PANDORA: A Panoramic Detection Dataset for Object with Orientation
AU  - Xu, Hang
AU  - Zhao, Qiang
AU  - Ma, Yike
AU  - Li, Xiaodong
AU  - Yuan, Peng
AU  - Feng, Bailan
AU  - Yan, Chenggang
AU  - Dai, Feng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Panoramic images have become increasingly popular as omnidirectional panoramic technology has advanced. Many datasets and works resort to object detection to better understand the content of the panoramic image. These datasets and detectors use a Bounding Field of View (BFoV) as a bounding box in panoramic images. However, we observe that the object instances in panoramic images often appear with arbitrary orientations. It indicates that BFoV as a bounding box is inappropriate, limiting the performance of detectors. This paper proposes a new bounding box representation, Rotated Bounding Field of View (RBFoV), for the panoramic image object detection task. Then, based on the RBFoV, we present a PANoramic Detection dataset for Object with oRientAtion (PANDORA). Finally, based on PANDORA, we evaluate the current state-of-the-art panoramic image object detection methods and design an anchor-free object detector called R-CenterNet for panoramic images. Compared with these baselines, our R-CenterNet shows its advantages in terms of detection performance. Our PANDORA dataset and source code are available at https://github.com/tdsuper/SphericalObjectDetection.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_14
DP  - Springer Link
SP  - 237
EP  - 252
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - PANDORA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_14.pdf
KW  - Object detection
KW  - PANDORA
KW  - Panoramic
KW  - RBFoV
ER  - 

TY  - CONF
TI  - How to Synthesize a Large-Scale and Trainable Micro-Expression Dataset?
AU  - Liu, Yuchi
AU  - Wang, Zhongdao
AU  - Gedeon, Tom
AU  - Zheng, Liang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper does not contain technical novelty but introduces our key discoveries in a data generation protocol, a database and insights. We aim to address the lack of large-scale datasets in micro-expression (MiE) recognition due to the prohibitive cost of data collection, which renders large-scale training less feasible. To this end, we develop a protocol to automatically synthesize large scale MiE training data that allow us to train improved recognition models for real-world test data. Specifically, we discover three types of Action Units (AUs) that can constitute trainable MiEs. These AUs come from real-world MiEs, early frames of macro-expression videos, and the relationship between AUs and expression categories defined by human expert knowledge. With these AUs, our protocol then employs large numbers of face images of various identities and an off-the-shelf face generator for MiE synthesis, yielding the MiE-X dataset. MiE recognition models are trained or pre-trained on MiE-X and evaluated on real-world test sets, where very competitive accuracy is obtained. Experimental results not only validate the effectiveness of the discovered AUs and MiE-X dataset but also reveal some interesting properties of MiEs: they generalize across faces, are close to early-stage macro-expressions, and can be manually defined. (This work was supported by the ARC Discovery Early Career Researcher Award (DE200101283) and the ARC Discovery Project (DP210102801).)
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_3
DP  - Springer Link
SP  - 38
EP  - 55
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_3.pdf
KW  - Action units
KW  - Facial expression generation
KW  - Micro-expression
ER  - 

TY  - CONF
TI  - PartImageNet: A Large, High-Quality Dataset of Parts
AU  - He, Ju
AU  - Yang, Shuo
AU  - Yang, Shaokang
AU  - Kortylewski, Adam
AU  - Yuan, Xiaoding
AU  - Chen, Jie-Neng
AU  - Liu, Shuai
AU  - Yang, Cheng
AU  - Yu, Qihang
AU  - Yuille, Alan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - It is natural to represent objects in terms of their parts. This has the potential to improve the performance of algorithms for object recognition and segmentation but can also help for downstream tasks like activity recognition. Research on part-based models, however, is hindered by the lack of datasets with per-pixel part annotations. This is partly due to the difficulty and high cost of annotating object parts so it has rarely been done except for humans (where there exists a big literature on part-based models). To help address this problem, we propose PartImageNet, a large, high-quality dataset with part segmentation annotations. It consists of 158 classes from ImageNet with approximately 24, 000 images. PartImageNet is unique because it offers part-level annotations on a general set of classes including non-rigid, articulated objects, while having an order of magnitude larger size compared to existing part datasets (excluding datasets of humans). It can be utilized for many vision tasks including Object Segmentation, Semantic Part Segmentation, Few-shot Learning and Part Discovery. We conduct comprehensive experiments which study these tasks and set up a set of baselines.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_8
DP  - Springer Link
SP  - 128
EP  - 145
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - PartImageNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_8.pdf
ER  - 

TY  - CONF
TI  - A Real World Dataset for Multi-view 3D Reconstruction
AU  - Shrestha, Rakesh
AU  - Hu, Siqi
AU  - Gou, Minghao
AU  - Liu, Ziyuan
AU  - Tan, Ping
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present a dataset of 998 3D models of everyday tabletop objects along with their 847,000 real world RGB and depth images. Accurate annotation of camera pose and object pose for each image is performed in a semi-automated fashion to facilitate the use of the dataset in a myriad 3D applications like shape reconstruction, object pose estimation, shape retrieval etc. We primarily focus on learned multi-view 3D reconstruction due to the lack of appropriate real world benchmark for the task and demonstrate that our dataset can fill that gap. The entire annotated dataset along with the source code for the annotation tools and evaluation baselines is available at http://www.ocrtoc.org/3d-reconstruction.html.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_4
DP  - Springer Link
SP  - 56
EP  - 73
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_4.pdf
KW  - Dataset
KW  - Multi-view 3D reconstruction
ER  - 

TY  - CONF
TI  - REALY: Rethinking the Evaluation of 3D Face Reconstruction
AU  - Chai, Zenghao
AU  - Zhang, Haoxian
AU  - Ren, Jing
AU  - Kang, Di
AU  - Xu, Zhengzhuo
AU  - Zhe, Xuefei
AU  - Yuan, Chun
AU  - Bao, Linchao
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The evaluation of 3D face reconstruction results typically relies on a rigid shape alignment between the estimated 3D model and the ground-truth scan. We observe that aligning two shapes with different reference points can largely affect the evaluation results. This poses difficulties for precisely diagnosing and improving a 3D face reconstruction method. In this paper, we propose a novel evaluation approach with a new benchmark REALY, consists of 100 globally aligned face scans with accurate facial keypoints, high-quality region masks, and topology-consistent meshes. Our approach performs region-wise shape alignment and leads to more accurate, bidirectional correspondences during computing the shape errors. The fine-grained, region-wise evaluation results provide us detailed understandings about the performance of state-of-the-art 3D face reconstruction methods. For example, our experiments on single-image based reconstruction methods reveal that DECA performs the best on nose regions, while GANFit performs better on cheek regions. Besides, a new and high-quality 3DMM basis, HIFI3D$$^{\pmb {+}\pmb {+}}$$++, is further derived using the same procedure as we construct REALY to align and retopologize several 3D face datasets. We will release REALY, HIFI3D$$^{\pmb {+}\pmb {+}}$$++, and our new evaluation pipeline at https://realy3dface.com.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_5
DP  - Springer Link
SP  - 74
EP  - 92
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - REALY
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_5.pdf
KW  - 3D Face Reconstruction
KW  - 3DMM
KW  - Benchmark
KW  - Evaluation
ER  - 

TY  - CONF
TI  - Facial Depth and Normal Estimation Using Single Dual-Pixel Camera
AU  - Kang, Minjun
AU  - Choe, Jaesung
AU  - Ha, Hyowon
AU  - Jeon, Hae-Gon
AU  - Im, Sunghoon
AU  - Kweon, In So
AU  - Yoon, Kuk-Jin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recently, Dual-Pixel (DP) sensors have been adopted in many imaging devices. However, despite their various advantages, DP sensors are used just for faster auto-focus and aesthetic image captures, and research on their usage for 3D facial understanding has been limited due to the lack of datasets and algorithmic designs that exploit parallax in DP images. It is also because the baseline of sub-aperture images is extremely narrow, and parallax exists in the defocus blur region. In this paper, we introduce a DP-oriented Depth/Normal estimation network that reconstructs the 3D facial geometry. In addition, to train the network, we collect DP facial data with more than 135K images for 101 persons captured with our multi-camera structured light systems. It contains ground-truth 3D facial models including depth map and surface normal in metric scale. Our dataset allows the proposed network to be generalized for 3D facial depth/normal estimation. The proposed network consists of two novel modules: Adaptive Sampling Module (ASM) and Adaptive Normal Module (ANM), which are specialized in handling the defocus blur in DP images. Finally, we demonstrate that the proposed method achieves state-of-the-art performances over recent DP-based depth/normal estimation methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_11
DP  - Springer Link
SP  - 181
EP  - 200
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_11.pdf
KW  - Depth/Normal estimation
KW  - Dual-Pixel
ER  - 

TY  - CONF
TI  - The Anatomy of Video Editing: A Dataset and Benchmark Suite for AI-Assisted Video Editing
AU  - Argaw, Dawit Mureja
AU  - Heilbron, Fabian Caba
AU  - Lee, Joon-Young
AU  - Woodson, Markus
AU  - Kweon, In So
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Machine learning is transforming the video editing industry. Recent advances in computer vision have leveled-up video editing tasks such as intelligent reframing, rotoscoping, color grading, or applying digital makeups. However, most of the solutions have focused on video manipulation and VFX. This work introduces the Anatomy of Video Editing, a dataset, and benchmark, to foster research in AI-assisted video editing. Our benchmark suite focuses on video editing tasks, beyond visual effects, such as automatic footage organization and assisted video assembling. To enable research on these fronts, we annotate more than 1.5M tags, with relevant concepts to cinematography, from 196176 shots sampled from movie scenes. We establish competitive baseline methods and detailed analyses for each of the tasks. We hope our work sparks innovative research towards underexplored areas of AI-assisted video editing. Code is available at: https://github.com/dawitmureja/AVE.git.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_12
DP  - Springer Link
SP  - 201
EP  - 218
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - The Anatomy of Video Editing
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_12.pdf
ER  - 

TY  - CONF
TI  - OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images
AU  - Zhao, Bingchen
AU  - Yu, Shaozuo
AU  - Ma, Wufei
AU  - Yu, Mingxin
AU  - Mei, Shenxiao
AU  - Wang, Angtian
AU  - He, Ju
AU  - Yuille, Alan
AU  - Kortylewski, Adam
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Enhancing the robustness of vision algorithms in real-world scenarios is challenging. One reason is that existing robustness benchmarks are limited, as they either rely on synthetic data or ignore the effects of individual nuisance factors. We introduce OOD-CV , a benchmark dataset that includes out-of-distribution examples of 10 object categories in terms of pose, shape, texture, context and the weather conditions, and enables benchmarking models for image classification, object detection, and 3D pose estimation. In addition to this novel dataset, we contribute extensive experiments using popular baseline methods, which reveal that: 1) Some nuisance factors have a much stronger negative effect on the performance compared to others, also depending on the vision task. 2) Current approaches to enhance robustness have only marginal effects, and can even reduce robustness. 3) We do not observe significant differences between convolutional and transformer architectures. We believe our dataset provides a rich testbed to study robustness and will help push forward research in this area.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_10
DP  - Springer Link
SP  - 163
EP  - 180
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - OOD-CV
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_10.pdf
ER  - 

TY  - CONF
TI  - The Caltech Fish Counting Dataset: A Benchmark for Multiple-Object Tracking and Counting
AU  - Kay, Justin
AU  - Kulits, Peter
AU  - Stathatos, Suzanne
AU  - Deng, Siqi
AU  - Young, Erik
AU  - Beery, Sara
AU  - Van Horn, Grant
AU  - Perona, Pietro
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present the Caltech Fish Counting Dataset (CFC ), a large-scale dataset for detecting, tracking, and counting fish in sonar videos. We identify sonar videos as a rich source of data for advancing low signal-to-noise computer vision applications and tackling domain generalization in multiple-object tracking (MOT) and counting. In comparison to existing MOT and counting datasets, which are largely restricted to videos of people and vehicles in cities, CFC is sourced from a natural-world domain where targets are not easily resolvable and appearance features cannot be easily leveraged for target re-identification. With over half a million annotations in over 1,500 videos sourced from seven different sonar cameras, CFC allows researchers to train MOT and counting algorithms and evaluate generalization performance at unseen test locations. We perform extensive baseline experiments and identify key challenges and opportunities for advancing the state of the art in generalization in MOT and counting.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20074-8_17
DP  - Springer Link
SP  - 290
EP  - 311
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20074-8
ST  - The Caltech Fish Counting Dataset
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20074-8_17.pdf
KW  - Counting
KW  - Detection
KW  - Tracking
KW  - Video dataset
ER  - 

TY  - CONF
TI  - RayTran: 3D Pose Estimation and Shape Reconstruction of Multiple Objects from Videos with Ray-Traced Transformers
AU  - Tyszkiewicz, Michał J.
AU  - Maninis, Kevis-Kokitsi
AU  - Popov, Stefan
AU  - Ferrari, Vittorio
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We propose a transformer-based neural network architecture for multi-object 3D reconstruction from RGB videos. It relies on two alternative ways to represent its knowledge: as a global 3D grid of features and an array of view-specific 2D grids. We progressively exchange information between the two with a dedicated bidirectional attention mechanism. We exploit knowledge about the image formation process to significantly sparsify the attention weight matrix, making our architecture feasible on current hardware, both in terms of memory and computation. We attach a DETR-style head [9] on top of the 3D feature grid in order to detect the objects in the scene and to predict their 3D pose and 3D shape. Compared to previous methods, our architecture is single stage, end-to-end trainable, and it can reason holistically about a scene from multiple video frames without needing a brittle tracking step. We evaluate our method on the challenging Scan2CAD dataset [3], where we outperform (1) state-of-the-art methods [15, 34, 35, 39] for 3D object pose estimation from RGB videos; and (2) a strong alternative method combining Multi-View Stereo [17] with RGB-D CAD alignment [4].
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_13
DP  - Springer Link
SP  - 211
EP  - 228
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - RayTran
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_13.pdf
ER  - 

TY  - CONF
TI  - Cornerformer: Purifying Instances for Corner-Based Detectors
AU  - Wei, Haoran
AU  - Chen, Xin
AU  - Xie, Lingxi
AU  - Tian, Qi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Corner-based object detectors enjoy the potential of detecting arbitrarily-sized instances, yet the performance is mainly harmed by the accuracy of instance construction. Specifically, there are three factors, namely, 1) the corner keypoints are prone to false-positives; 2) incorrect matches emerge upon corner keypoint pull-push embeddings; and 3) the heuristic NMS cannot adjust the corners pull-push mechanism. Accordingly, this paper presents an elegant framework named Cornerformer that is composed of two factors. First, we build a Corner Transformer Encoder (CTE, a self-attention module) in a 2D-form to enhance the information aggregated by corner keypoints, offering stronger features for the pull-push loss to distinguish instances from each other. Second, we design an Attenuation-Auto-Adjusted NMS (A3-NMS) to maximally leverage the semantic outputs and avoid true objects from being removed. Experiments on object detection and human pose estimation show the superior performance of Cornerformer in terms of accuracy and inference speed.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_2
DP  - Springer Link
SP  - 18
EP  - 34
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - Cornerformer
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_2.pdf
KW  - Attenuation-Auto-Adjusted NMS
KW  - Corner Transformer Encoder
KW  - Corner-based
KW  - Object detection
ER  - 

TY  - CONF
TI  - Robust Object Detection with Inaccurate Bounding Boxes
AU  - Liu, Chengxin
AU  - Wang, Kewei
AU  - Lu, Hao
AU  - Cao, Zhiguo
AU  - Zhang, Ziming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Learning accurate object detectors often requires large-scale training data with precise object bounding boxes. However, labeling such data is expensive and time-consuming. As the crowd-sourcing labeling process and the ambiguities of the objects may raise noisy bounding box annotations, the object detectors will suffer from the degenerated training data. In this work, we aim to address the challenge of learning robust object detectors with inaccurate bounding boxes. Inspired by the fact that localization precision suffers significantly from inaccurate bounding boxes while classification accuracy is less affected, we propose leveraging classification as a guidance signal for refining localization results. Specifically, by treating an object as a bag of instances, we introduce an Object-Aware Multiple Instance Learning approach (OA-MIL), featured with object-aware instance selection and object-aware instance extension. The former aims to select accurate instances for training, instead of directly using inaccurate box annotations. The latter focuses on generating high-quality instances for selection. Extensive experiments on synthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy wheat head dataset demonstrate the effectiveness of our OA-MIL. Code is available at https://github.com/cxliu0/OA-MIL.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_4
DP  - Springer Link
SP  - 53
EP  - 69
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_4.pdf
KW  - Inaccurate bounding boxes
KW  - Multiple instance learning
KW  - Noisy labels
KW  - Object detection
ER  - 

TY  - CONF
TI  - Open Vocabulary Object Detection with Pseudo Bounding-Box Labels
AU  - Gao, Mingfei
AU  - Xing, Chen
AU  - Niebles, Juan Carlos
AU  - Li, Junnan
AU  - Xu, Ran
AU  - Liu, Wenhao
AU  - Xiong, Caiming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Despite great progress in object detection, most existing methods work only on a limited set of object categories, due to the tremendous human effort needed for bounding-box annotations of training data. To alleviate the problem, recent open vocabulary and zero-shot detection methods attempt to detect novel object categories beyond those seen during training. They achieve this goal by training on a pre-defined base categories to induce generalization to novel objects. However, their potential is still constrained by the small set of base categories available for training. To enlarge the set of base classes, we propose a method to automatically generate pseudo bounding-box annotations of diverse objects from large-scale image-caption pairs. Our method leverages the localization ability of pre-trained vision-language models to generate pseudo bounding-box labels and then directly uses them for training object detectors. Experimental results show that our method outperforms the state-of-the-art open vocabulary detector by 8% AP on COCO novel categories, by 6.3% AP on PASCAL VOC, by 2.3% AP on Objects365 and by 2.8% AP on LVIS. Code is available here.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_16
DP  - Springer Link
SP  - 266
EP  - 282
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_16.pdf
KW  - Open vocabulary detection
KW  - Pseudo bounding-box labels
ER  - 

TY  - CONF
TI  - Cross-Modality Knowledge Distillation Network for Monocular 3D Object Detection
AU  - Hong, Yu
AU  - Dai, Hang
AU  - Ding, Yong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Leveraging LiDAR-based detectors or real LiDAR point data to guide monocular 3D detection has brought significant improvement, e.g., Pseudo-LiDAR methods. However, the existing methods usually apply non-end-to-end training strategies and insufficiently leverage the LiDAR information, where the rich potential of the LiDAR data has not been well exploited. In this paper, we propose the Cross-Modality Knowledge Distillation (CMKD) network for monocular 3D detection to efficiently and directly transfer the knowledge from LiDAR modality to image modality on both features and responses. Moreover, we further extend CMKD as a semi-supervised training framework by distilling knowledge from large-scale unlabeled data and significantly boost the performance. Until submission, CMKD ranks $$1^{st}$$1stamong the monocular 3D detectors with publications on both KITTI test set and Waymo val set with significant performance gains compared to previous state-of-the-art methods. Our code will be released at https://github.com/Cc-Hy/CMKD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_6
DP  - Springer Link
SP  - 87
EP  - 104
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_6.pdf
ER  - 

TY  - CONF
TI  - UC-OWOD: Unknown-Classified Open World Object Detection
AU  - Wu, Zhiheng
AU  - Lu, Yue
AU  - Chen, Xingyu
AU  - Wu, Zhengxing
AU  - Kang, Liwen
AU  - Yu, Junzhi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Open World Object Detection (OWOD) is a challenging computer vision problem that requires detecting unknown objects and gradually learning the identified unknown classes. However, it cannot distinguish unknown instances as multiple unknown classes. In this work, we propose a novel OWOD problem called Unknown-Classified Open World Object Detection (UC-OWOD). UC-OWOD aims to detect unknown instances and classify them into different unknown classes. Besides, we formulate the problem and devise a two-stage object detector to solve UC-OWOD. First, unknown label-aware proposal and unknown-discriminative classification head are used to detect known and unknown objects. Then, similarity-based unknown classification and unknown clustering refinement modules are constructed to distinguish multiple unknown classes. Moreover, two novel evaluation protocols are designed to evaluate unknown-class detection. Abundant experiments and visualizations prove the effectiveness of the proposed method. Code is available at https://github.com/JohnWuzh/UC-OWOD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_12
DP  - Springer Link
SP  - 193
EP  - 210
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - UC-OWOD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_12.pdf
KW  - Clustering
KW  - Object detection
KW  - OWOD
KW  - UC-OWOD
ER  - 

TY  - CONF
TI  - Bagging Regional Classification Activation Maps for Weakly Supervised Object Localization
AU  - Zhu, Lei
AU  - Chen, Qian
AU  - Jin, Lujia
AU  - You, Yunfei
AU  - Lu, Yanye
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Classification activation map (CAM), utilizing the classification structure to generate pixel-wise localization maps, is a crucial mechanism for weakly supervised object localization (WSOL). However, CAM directly uses the classifier trained on image-level features to locate objects, making it prefers to discern global discriminative factors rather than regional object cues. Thus only the discriminative locations are activated when feeding pixel-level features into this classifier. To solve this issue, this paper elaborates a plug-and-play mechanism called BagCAMs to better project a well-trained classifier for the localization task without refining or re-training the baseline structure. Our BagCAMs adopts a proposed regional localizer generation (RLG) strategy to define a set of regional localizers and then derive them from a well-trained classifier. These regional localizers can be viewed as the base learner that only discerns region-wise object factors for localization tasks, and their results can be effectively weighted by our BagCAMs to form the final localization map. Experiments indicate that adopting our proposed BagCAMs can improve the performance of baseline WSOL methods to a great extent and obtains state-of-the-art performance on three WSOL benchmarks. Code are released at https://github.com/zh460045050/BagCAMs.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_11
DP  - Springer Link
SP  - 176
EP  - 192
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_11.pdf
KW  - Object localization
KW  - Weakly supervised learning
ER  - 

TY  - CONF
TI  - ReAct: Temporal Action Detection with Relational Queries
AU  - Shi, Dingfeng
AU  - Zhong, Yujie
AU  - Cao, Qiong
AU  - Zhang, Jing
AU  - Ma, Lin
AU  - Li, Jia
AU  - Tao, Dacheng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This work aims at advancing temporal action detection (TAD) using an encoder-decoder framework with action queries, similar to DETR, which has shown great success in object detection. However, the framework suffers from several problems if directly applied to TAD: the insufficient exploration of inter-query relation in the decoder, the inadequate classification training due to a limited number of training samples, and the unreliable classification scores at inference. To this end, we first propose a relational attention mechanism in the decoder, which guides the attention among queries based on their relations. Moreover, we propose two losses to facilitate and stabilize the training of action classification. Lastly, we propose to predict the localization quality of each action query at inference in order to distinguish high-quality queries. The proposed method, named ReAct, achieves the state-of-the-art performance on THUMOS14, with much lower computational costs than previous methods. Besides, extensive ablation studies are conducted to verify the effectiveness of each proposed component. The code is available at https://github.com/sssste/React.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_7
DP  - Springer Link
SP  - 105
EP  - 121
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - ReAct
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_7.pdf
ER  - 

TY  - CONF
TI  - DFNet: Enhance Absolute Pose Regression with Direct Feature Matching
AU  - Chen, Shuai
AU  - Li, Xinghui
AU  - Wang, Zirui
AU  - Prisacariu, Victor A.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We introduce a camera relocalization pipeline that combines absolute pose regression (APR) and direct feature matching. By incorporating exposure-adaptive novel view synthesis, our method successfully addresses photometric distortions in outdoor environments that existing photometric-based methods fail to handle. With domain-invariant feature matching, our solution improves pose regression accuracy using semi-supervised learning on unlabeled data. In particular, the pipeline consists of two components: Novel View Synthesizer and DFNet. The former synthesizes novel views compensating for changes in exposure and the latter regresses camera poses and extracts robust features that close the domain gap between real images and synthetic ones. Furthermore, we introduce an online synthetic data generation scheme. We show that these approaches effectively enhance camera pose estimation both in indoor and outdoor scenes. Hence, our method achieves a state-of-the-art accuracy by outperforming existing single-image APR methods by as much as 56%, comparable to 3D structure-based methods. (The code is available in https://code.active.vision.)
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_1
DP  - Springer Link
SP  - 1
EP  - 17
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - DFNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_1.pdf
KW  - Absolute pose regression
KW  - Feature matching
KW  - NeRF
ER  - 

TY  - CONF
TI  - PillarNet: Real-Time and High-Performance Pillar-Based 3D Object Detection
AU  - Shi, Guangsheng
AU  - Li, Ruifeng
AU  - Ma, Chao
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Real-time and high-performance 3D object detection is of critical importance for autonomous driving. Recent top-performing 3D object detectors mainly rely on point-based or 3D voxel-based convolutions, which are both computationally inefficient for onboard deployment. In contrast, pillar-based methods use solely 2D convolutions, which consume less computation resources, but they lag far behind their voxel-based counterparts in detection accuracy. In this paper, by examining the primary performance gap between pillar- and voxel-based detectors, we develop a real-time and high-performance pillar-based detector, dubbed PillarNet. The proposed PillarNet consists of a powerful encoder network for effective pillar feature learning, a neck network for spatial-semantic feature fusion and the commonly used detect head. Using only 2D convolutions, PillarNet is flexible to an optional pillar size and compatible with classical 2D CNN backbones, such as VGGNet and ResNet. Additionally, PillarNet benefits from our designed orientation-decoupled IoU regression loss along with the IoU-aware prediction branch. Extensive experimental results on the large-scale nuScenes Dataset and Waymo Open Dataset demonstrate that the proposed PillarNet performs well over state-of-the-art 3D detectors in terms of effectiveness and efficiency. Code is available at https://github.com/VISION-SJTU/PillarNet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_3
DP  - Springer Link
SP  - 35
EP  - 52
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - PillarNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_3.pdf
KW  - 3D object detection
KW  - Autonomous driving
KW  - Point cloud
ER  - 

TY  - CONF
TI  - 3D Object Detection with a Self-supervised Lidar Scene Flow Backbone
AU  - Erçelik, Emeç
AU  - Yurtsever, Ekim
AU  - Liu, Mingyu
AU  - Yang, Zhijie
AU  - Zhang, Hanzhen
AU  - Topçam, Pınar
AU  - Listl, Maximilian
AU  - Çaylı, Yılmaz Kaan
AU  - Knoll, Alois
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - State-of-the-art lidar-based 3D object detection methods rely on supervised learning and large labeled datasets. However, annotating lidar data is resource-consuming, and depending only on supervised learning limits the applicability of trained models. Self-supervised training strategies can alleviate these issues by learning a general point cloud backbone model for downstream 3D vision tasks. Against this backdrop, we show the relationship between self-supervised multi-frame flow representations and single-frame 3D detection hypotheses. Our main contribution leverages learned flow and motion representations and combines a self-supervised backbone with a supervised 3D detection head. First, a self-supervised scene flow estimation model is trained with cycle consistency. Then, the point cloud encoder of this model is used as the backbone of a single-frame 3D object detection head model. This second 3D object detection model learns to utilize motion representations to distinguish dynamic objects exhibiting different movement patterns. Experiments on KITTI and nuScenes benchmarks show that the proposed self-supervised pre-training increases 3D detection performance significantly. https://github.com/emecercelik/ssl-3d-detection.git.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_15
DP  - Springer Link
SP  - 247
EP  - 265
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_15.pdf
KW  - 3D detection
KW  - Lidar point clouds
KW  - Scene flow
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Efficient Decoder-Free Object Detection with Transformers
AU  - Chen, Peixian
AU  - Zhang, Mengdan
AU  - Shen, Yunhang
AU  - Sheng, Kekai
AU  - Gao, Yuting
AU  - Sun, Xing
AU  - Li, Ke
AU  - Shen, Chunhua
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Vision transformers (ViTs) are changing the landscape of object detection approaches. A natural usage of ViTs in detection is to replace the CNN-based backbone with a transformer-based backbone, which is straightforward and effective, with the price of bringing considerable computation burden for inference. More subtle usage is the DETR family, which eliminates the need for many hand-designed components in object detection but introduces a decoder demanding an extra-long time to converge. As a result, transformer-based object detection can not prevail in large-scale applications. To overcome these issues, we propose a novel decoder-free fully transformer-based (DFFT) object detector, achieving high efficiency in both training and inference stages, for the first time. We simplify objection detection into an encoder-only single-level anchor-based dense prediction problem by centering around two entry points: 1) Eliminate the training-inefficient decoder and leverage two strong encoders to preserve the accuracy of single-level feature map prediction; 2) Explore low-level semantic features for the detection task with limited computational resources. In particular, we design a novel lightweight detection-oriented transformer backbone that efficiently captures low-level features with rich semantics based on a well-conceived ablation study. Extensive experiments on the MS COCO benchmark demonstrate that DFFTSMALL outperforms DETR by $$2.5\%$$2.5%AP with $$28\%$$28%computation cost reduction and more than $$10\times $$10×fewer training epochs. Compared with the cutting-edge anchor-based detector RetinaNet, DFFTSMALL obtains over $$5.5\%$$5.5%AP gain while cutting down $$70\%$$70%computation cost. The code is available at https://github.com/peixianchen/DFFT.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_5
DP  - Springer Link
SP  - 70
EP  - 86
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_5.pdf
KW  - Efficient network
KW  - Object detector
KW  - Transformers
ER  - 

TY  - CONF
TI  - SALISA: Saliency-Based Input Sampling for Efficient Video Object Detection
AU  - Ehteshami Bejnordi, Babak
AU  - Habibian, Amirhossein
AU  - Porikli, Fatih
AU  - Ghodrati, Amir
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - High-resolution images are widely adopted for high-performance object detection in videos. However, processing high-resolution inputs comes with high computation costs, and naive down-sampling of the input to reduce the computation costs quickly degrades the detection performance. In this paper, we propose SALISA, a novel non-uniform SALiency-based Input SAmpling technique for video object detection that allows for heavy down-sampling of unimportant background regions while preserving the fine-grained details of a high-resolution image. The resulting image is spatially smaller, leading to reduced computational costs while enabling a performance comparable to a high-resolution input. To achieve this, we propose a differentiable resampling module based on a thin plate spline spatial transformer network (TPS-STN). This module is regularized by a novel loss to provide an explicit supervision signal to learn to “magnify” salient regions. We report state-of-the-art results in the low compute regime on the ImageNet-VID and UA-DETRAC video object detection datasets. We demonstrate that on both datasets, the mAP of an EfficientDet-D1 (EfficientDet-D2) gets on par with EfficientDet-D2 (EfficientDet-D3) at a much lower computational cost. We also show that SALISA significantly improves the detection of small objects. In particular, SALISA with an EfficientDet-D1 detector improves the detection of small objects by 77%, and remarkably also outperforms EfficientDet-D3 baseline.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_18
DP  - Springer Link
SP  - 300
EP  - 316
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - SALISA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_18.pdf
KW  - Efficient object detection
KW  - Resampling
KW  - Saliency
KW  - Spatial transformer
KW  - Video object detection
ER  - 

TY  - CONF
TI  - ECO-TR: Efficient Correspondences Finding via Coarse-to-Fine Refinement
AU  - Tan, Dongli
AU  - Liu, Jiang-Jiang
AU  - Chen, Xingyu
AU  - Chen, Chao
AU  - Zhang, Ruixin
AU  - Shen, Yunhang
AU  - Ding, Shouhong
AU  - Ji, Rongrong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Modeling sparse and dense image matching within a unified functional correspondence model has recently attracted increasing research interest. However, existing efforts mainly focus on improving matching accuracy while ignoring its efficiency, which is crucial for real-world applications. In this paper, we propose an efficient structure named Efficient Correspondence Transformer ($${\textbf {ECO-TR}}$$ECO-TR) by finding correspondences in a coarse-to-fine manner, which significantly improves the efficiency of functional correspondence model. To achieve this, multiple transformer blocks are stage-wisely connected to gradually refine the predicted coordinates upon a shared multi-scale feature extraction network. Given a pair of images and for arbitrary query coordinates, all the correspondences are predicted within a single feed-forward pass. We further propose an adaptive query-clustering strategy and an uncertainty-based outlier detection module to cooperate with the proposed framework for faster and better predictions. Experiments on various sparse and dense matching tasks demonstrate the superiority of our method in both efficiency and effectiveness against existing state-of-the-arts. Project page: https://dltan7.github.io/ecotr/.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_19
DP  - Springer Link
SP  - 317
EP  - 334
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - ECO-TR
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_19.pdf
KW  - Coarse-to-fine
KW  - Correspondence
KW  - Functional method
KW  - Image matching
KW  - Transformer
ER  - 

TY  - CONF
TI  - Improving the Intra-class Long-Tail in 3D Detection via Rare Example Mining
AU  - Jiang, Chiyu Max
AU  - Najibi, Mahyar
AU  - Qi, Charles R.
AU  - Zhou, Yin
AU  - Anguelov, Dragomir
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Continued improvements in deep learning architectures have steadily advanced the overall performance of 3D object detectors to levels on par with humans for certain tasks and datasets, where the overall performance is mostly driven by common examples. However, even the best performing models suffer from the most naive mistakes when it comes to rare examples that do not appear frequently in the training data, such as vehicles with irregular geometries. Most studies in the long-tail literature focus on class-imbalanced classification problems with known imbalanced label counts per class, but they are not directly applicable to the intra-class long-tail examples in problems with large intra-class variations such as 3D object detection, where instances with the same class label can have drastically varied properties such as shapes and sizes. Other works propose to mitigate this problem using active learning based on the criteria of uncertainty, difficulty, or diversity. In this study, we identify a new conceptual dimension - rareness - to mine new data for improving the long-tail performance of models. We show that rareness, as opposed to difficulty, is the key to data-centric improvements for 3D detectors, since rareness is the result of a lack in data support while difficulty is related to the fundamental ambiguity in the problem. We propose a general and effective method to identify the rareness of objects based on density estimation in the feature space using flow models, and propose a principled cost-aware formulation for mining rare object tracks, which improves overall model performance, but more importantly - significantly improves the performance for rare objects (by 30.97%).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_10
DP  - Springer Link
SP  - 158
EP  - 175
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_10.pdf
KW  - Active learning
KW  - Intra-class long tail
KW  - Rare example
ER  - 

TY  - CONF
TI  - Camera Pose Auto-encoders for Improving Pose Regression
AU  - Shavit, Yoli
AU  - Keller, Yosi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Absolute pose regressor (APR) networks are trained to estimate the pose of the camera given a captured image. They compute latent image representations from which the camera position and orientation are regressed. APRs provide a different tradeoff between localization accuracy, runtime, and memory, compared to structure-based localization schemes that provide state-of-the-art accuracy. In this work, we introduce Camera Pose Auto-Encoders (PAEs), multilayer perceptrons that are trained via a Teacher-Student approach to encode camera poses using APRs as their teachers. We show that the resulting latent pose representations can closely reproduce APR performance and demonstrate their effectiveness for related tasks. Specifically, we propose a light-weight test-time optimization in which the closest train poses are encoded and used to refine camera position estimation. This procedure achieves a new state-of-the-art position accuracy for APRs, on both the CambridgeLandmarks and 7Scenes benchmarks. We also show that train images can be reconstructed from the learned pose encoding, paving the way for integrating visual information from the train set at a low memory cost. Our code and pre-trained models are available at https://github.com/yolish/camera-pose-auto-encoders.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_9
DP  - Springer Link
SP  - 140
EP  - 157
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_9.pdf
ER  - 

TY  - CONF
TI  - Few-Shot Object Detection by Knowledge Distillation Using Bag-of-Visual-Words Representations
AU  - Pei, Wenjie
AU  - Wu, Shuang
AU  - Mei, Dianwen
AU  - Chen, Fanglin
AU  - Tian, Jiandong
AU  - Lu, Guangming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - While fine-tuning based methods for few-shot object detection have achieved remarkable progress, a crucial challenge that has not been addressed well is the potential class-specific overfitting on base classes and sample-specific overfitting on novel classes. In this work we design a novel knowledge distillation framework to guide the learning of the object detector and thereby restrain the overfitting in both the pre-training stage on base classes and fine-tuning stage on novel classes. To be specific, we first present a novel Position-Aware Bag-of-Visual-Words model for learning a representative bag of visual words (BoVW) from a limited size of image set, which is used to encode general images based on the similarities between the learned visual words and an image. Then we perform knowledge distillation based on the fact that an image should have consistent BoVW representations in two different feature spaces. To this end, we pre-learn a feature space independently from the object detection, and encode images using BoVW in this space. The obtained BoVW representation for an image can be considered as distilled knowledge to guide the learning of object detector: the extracted features by the object detector for the same image are expected to derive the consistent BoVW representations with the distilled knowledge. Extensive experiments validate the effectiveness of our method and demonstrate the superiority over other state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_17
DP  - Springer Link
SP  - 283
EP  - 299
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_17.pdf
KW  - Bag of visual words
KW  - Few-shot object detection
KW  - Knowledge distillation
ER  - 

TY  - CONF
TI  - Towards Accurate Active Camera Localization
AU  - Fang, Qihang
AU  - Yin, Yingda
AU  - Fan, Qingnan
AU  - Xia, Fei
AU  - Dong, Siyan
AU  - Wang, Sheng
AU  - Wang, Jue
AU  - Guibas, Leonidas J.
AU  - Chen, Baoquan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this work, we tackle the problem of active camera localization, which controls the camera movements actively to achieve an accurate camera pose. The past solutions are mostly based on Markov Localization, which reduces the position-wise camera uncertainty for localization. These approaches localize the camera in the discrete pose space and are agnostic to the localization-driven scene property, which restricts the camera pose accuracy in the coarse scale. We propose to overcome these limitations via a novel active camera localization algorithm, composed of a passive and an active localization module. The former optimizes the camera pose in the continuous pose space by establishing point-wise camera-world correspondences. The latter explicitly models the scene and camera uncertainty components to plan the right path for accurate camera pose estimation. We validate our algorithm on the challenging localization scenarios from both synthetic and scanned real-world indoor scenes. Experimental results demonstrate that our algorithm outperforms both the state-of-the-art Markov Localization based approach and other compared approaches on the fine-scale camera pose accuracy. Code and data are released at https://github.com/qhFang/AccurateACL.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_8
DP  - Springer Link
SP  - 122
EP  - 139
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_8.pdf
ER  - 

TY  - CONF
TI  - GTCaR: Graph Transformer for Camera Re-localization
AU  - Li, Xinyi
AU  - Ling, Haibin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Camera re-localization or absolute pose regression is the centerpiece in numerous computer vision tasks such as visual odometry, structure from motion (SfM) and SLAM. In this paper we propose a neural network approach with a graph Transformer backbone, namely GTCaR (Graph Transformer for Camera Re-localization), to address the multi-view camera re-localization problem. In contrast with prior work where the pose regression is mainly guided by photometric consistency, GTCaR effectively fuses the image features, camera pose information and inter-frame relative camera motions into encoded graph attributes. Moreover, GTCaR is trained towards the graph consistency and pose accuracy combined instead, yielding significantly higher computational efficiency. By leveraging graph Transformer layers with edge features and enabling the adjacency tensor, GTCaR dynamically captures the global attention and thus endows the pose graph with evolving structures to achieve improved robustness and accuracy. In addition, optional temporal Transformer layers actively enhance the spatiotemporal inter-frame relation for sequential inputs. Evaluation of the proposed network on various public benchmarks demonstrates that GTCaR outperforms state-of-the-art approaches.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20080-9_14
DP  - Springer Link
SP  - 229
EP  - 246
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20080-9
ST  - GTCaR
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20080-9_14.pdf
ER  - 

TY  - CONF
TI  - FFD Augmentor: Towards Few-Shot Oracle Character Recognition from Scratch
AU  - Zhao, Xinyi
AU  - Liu, Siyuan
AU  - Wang, Yikai
AU  - Fu, Yanwei
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Recognizing oracle characters, the earliest hieroglyph discovered in China, is recently addressed with more and more attention. Due to the difficulty of collecting labeled data, recognizing oracle characters is naturally a Few-Shot Learning (FSL) problem, which aims to tackle the learning problem with only one or a few training data. Most current FSL methods assume a disjoint but related big dataset can be utilized such that one can transfer the related knowledge to the few-shot case. However, unlike common phonetic words like English letters, oracle bone inscriptions are composed of radicals representing graphic symbols. Furthermore, as time goes, the graphic symbols to represent specific objects were significantly changed. Hence we can hardly find plenty of prior knowledge to learn without negative transfer. Another perspective to solve this problem is to use data augmentation algorithms to directly enlarge the size of training data to help the training of deep models. But popular augment strategies, such as dividing the characters into stroke sequences, break the orthographic units of Chinese characters and destroy the semantic information. Thus simply adding noise to strokes perform weakly in enhancing the learning capacity.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_3
DP  - Springer Link
SP  - 37
EP  - 53
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - FFD Augmentor
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_3.pdf
KW  - Data augmentation
KW  - Few-shot learning
KW  - Free form deformation
KW  - Oracle character recognition
ER  - 

TY  - CONF
TI  - Cross-Domain Local Characteristic Enhanced Deepfake Video Detection
AU  - Liu, Zihan
AU  - Wang, Hanyi
AU  - Wang, Shilin
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - As ultra-realistic face forgery techniques emerge, deepfake detection has attracted increasing attention due to security concerns. Many detectors cannot achieve accurate results when detecting unseen manipulations despite excellent performance on known forgeries. In this paper, we are motivated by the observation that the discrepancies between real and fake videos are extremely subtle and localized, and inconsistencies or irregularities can exist in some critical facial regions across various information domains. To this end, we propose a novel pipeline, Cross-Domain Local Forensics (XDLF), for more general deepfake video detection. In the proposed pipeline, a specialized framework is presented to simultaneously exploit local forgery patterns from space, frequency, and time domains, thus learning cross-domain features to detect forgeries. Moreover, the framework leverages four high-level forgery-sensitive local regions of a human face to guide the model to enhance subtle artifacts and localize potential anomalies. Extensive experiments on several benchmark datasets demonstrate the impressive performance of our method, and we achieve superiority over several state-of-the-art methods on cross-dataset generalization. We also examined the factors that contribute to its performance through ablations, which suggests that exploiting cross-domain local characteristics is a noteworthy direction for developing more general deepfake detectors.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_12
DP  - Springer Link
SP  - 196
EP  - 214
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_12.pdf
ER  - 

TY  - CONF
TI  - PS-ARM: An End-to-End Attention-Aware Relation Mixer Network for Person Search
AU  - Fiaz, Mustansar
AU  - Cholakkal, Hisham
AU  - Narayan, Sanath
AU  - Anwer, Rao Muhammad
AU  - Khan, Fahad Shahbaz
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Person search is a challenging problem with various real-world applications, that aims at joint person detection and re-identification of a query person from uncropped gallery images. Although, previous study focuses on rich feature information learning, it’s still hard to retrieve the query person due to the occurrence of appearance deformations and background distractors. In this paper, we propose a novel attention-aware relation mixer (ARM) module for person search, which exploits the global relation between different local regions within RoI of a person and make it robust against various appearance deformations and occlusion. The proposed ARM is composed of a relation mixer block and a spatio-channel attention layer. The relation mixer block introduces a spatially attended spatial mixing and a channel-wise attended channel mixing for effectively capturing discriminative relation features within an RoI. These discriminative relation features are further enriched by introducing a spatio-channel attention where the foreground and background discriminability is empowered in a joint spatio-channel space. Our ARM module is generic and it does not rely on fine-grained supervisions or topological assumptions, hence being easily integrated into any Faster R-CNN based person search methods. Comprehensive experiments are performed on two challenging benchmark datasets: CUHK-SYSU and PRW. Our PS-ARM achieves state-of-the-art performance on both datasets. On the challenging PRW dataset, our PS-ARM achieves an absolute gain of 5% in the mAP score over SeqNet, while operating at a comparable speed. The source code and pre-trained models are available at https://github.com/mustansarfiaz/PS-ARM.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_14
DP  - Springer Link
SP  - 234
EP  - 250
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - PS-ARM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_14.pdf
KW  - Channel attention
KW  - Person search
KW  - Spatial attention
KW  - Transformer
ER  - 

TY  - CONF
TI  - LatentGaze: Cross-Domain Gaze Estimation Through Gaze-Aware Analytic Latent Code Manipulation
AU  - Lee, Isack
AU  - Yun, Jun-Seok
AU  - Kim, Hee Hyeon
AU  - Na, Youngju
AU  - Yoo, Seok Bong
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Although recent gaze estimation methods lay great emphasis on attentively extracting gaze-relevant features from facial or eye images, how to define features that include gaze-relevant components has been ambiguous. This obscurity makes the model learn not only gaze-relevant features but also irrelevant ones. In particular, it is fatal for the cross-dataset performance. To overcome this challenging issue, we propose a gaze-aware analytic manipulation method, based on a data-driven approach with generative adversarial network inversion’s disentanglement characteristics, to selectively utilize gaze-relevant features in a latent code. Furthermore, by utilizing GAN-based encoder-generator process, we shift the input image from the target domain to the source domain image, which a gaze estimator is sufficiently aware. In addition, we propose gaze distortion loss in the encoder that prevents the distortion of gaze information. The experimental results demonstrate that our method achieves state-of-the-art gaze estimation accuracy in a cross-domain gaze estimation tasks. This code is available at https://github.com/leeisack/LatentGaze/.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_10
DP  - Springer Link
SP  - 161
EP  - 178
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - LatentGaze
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_10.pdf
ER  - 

TY  - CONF
TI  - Content-Aware Hierarchical Representation Selection for Cross-View Geo-Localization
AU  - Lu, Zeng
AU  - Pu, Tao
AU  - Chen, Tianshui
AU  - Lin, Liang
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Cross-view geo-localization (CVGL) aims to retrieve the images that contain the same geographic target content and are from different views. However, the target content usually scatters over the whole image, and they are indiscernible from the background. Thus, it is difficult to learn feature representation that focuses on these contents, rendering CVGL a challenging and unsolved task. In this work, we design a Content-Aware Hierarchical Representation Selection (CA-HRS) module, which can be seamlessly integrated into current deep networks to facilitate CVGL. This module can help focus more on the target content while ignoring the background region, thus as to learn more discriminative feature representation. Specifically, this module learns hierarchical important factors to each location of the feature maps according to their importance and enhances the feature representation based on the learned factors. We conduct experiments on several large-scale datasets (i.e., University-1652, CVUSA and CVACT), and the experiment results show the proposed module can obtain obvious performance improvement over current competing algorithms. Codes are available at https://github.com/Allen-lz/CA-HRS.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_16
DP  - Springer Link
SP  - 267
EP  - 280
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_16.pdf
KW  - Feature selection
KW  - Geo localization
KW  - Image retrieval
ER  - 

TY  - CONF
TI  - Improving Few-shot Learning by Spatially-aware Matching and CrossTransformer
AU  - Zhang, Hongguang
AU  - Torr, Philip H. S.
AU  - Koniusz, Piotr
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Current few-shot learning models capture visual object relations in the so-called meta-learning setting under a fixed-resolution input. However, such models have a limited generalization ability under the scale and location mismatch between objects, as only few samples from target classes are provided. Therefore, the lack of a mechanism to match the scale and location between pairs of compared images leads to the performance degradation. The importance of image contents varies across coarse-to-fine scales depending on the object and its class label, e.g., generic objects and scenes rely on their global appearance while fine-grained objects rely more on their localized visual patterns. In this paper, we study the impact of scale and location mismatch in the few-shot learning scenario, and propose a novel Spatially-aware Matching (SM) scheme to effectively perform matching across multiple scales and locations, and learn image relations by giving the highest weights to the best matching pairs. The SM is trained to activate the most related locations and scales between support and query data. We apply and evaluate SM on various few-shot learning models and backbones for comprehensive evaluations. Furthermore, we leverage an auxiliary self-supervisory discriminator to train/predict the spatial- and scale-level index of feature vectors we use. Finally, we develop a novel transformer-based pipeline to exploit self- and cross-attention in a spatially-aware matching process. Our proposed design is orthogonal to the choice of backbone and/or comparator.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_1
DP  - Springer Link
SP  - 3
EP  - 20
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_1.pdf
KW  - Few-shot
KW  - Multi-scale
KW  - Self-supervision
KW  - Transformer
ER  - 

TY  - CONF
TI  - Weighted Contrastive Hashing
AU  - Yu, Jiaguo
AU  - Qiu, Huming
AU  - Chen, Dubing
AU  - Zhang, Haofeng
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - The development of unsupervised hashing is advanced by the recent popular contrastive learning paradigm. However, previous contrastive learning-based works have been hampered by (1) insufficient data similarity mining based on global-only image representations, and (2) the hash code semantic loss caused by the data augmentation. In this paper, we propose a novel method, namely Weighted Contrative Hashing (WCH), to take a step towards solving these two problems. We introduce a novel mutual attention module to alleviate the problem of information asymmetry in network features caused by the missing image structure during contrative augmentation. Furthermore, we explore the fine-grained semantic relations between images, i.e., we divide the images into multiple patches and calculate similarities between patches. The aggregated weighted similarities, which reflect the deep image relations, are distilled to facilitate the hash codes learning with a distillation loss, so as to obtain better retrieval performance. Extensive experiments show that the proposed WCH significantly outperforms existing unsupervised hashing methods on three benchmark datasets. Code is available at: http://github.com/RosieYuu/WCH.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_15
DP  - Springer Link
SP  - 251
EP  - 266
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_15.pdf
KW  - Contrastive learning
KW  - Deep hashing
KW  - Mutual attention
KW  - Unsupervised image retrieval
KW  - Weighted similarities
ER  - 

TY  - CONF
TI  - 3D Shape Temporal Aggregation for Video-Based Clothing-Change Person Re-identification
AU  - Han, Ke
AU  - Huang, Yan
AU  - Gong, Shaogang
AU  - Huang, Yan
AU  - Wang, Liang
AU  - Tan, Tieniu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - 3D shape of human body can be both discriminative and clothing-independent information in video-based clothing-change person re-identification (Re-ID). However, existing Re-ID methods usually generate 3D body shapes without considering identity modelling, which severely weakens the discriminability of 3D human shapes. In addition, different video frames provide highly similar 3D shapes, but existing methods cannot capture the differences among 3D shapes over time. They are thus insensitive to the unique and discriminative 3D shape information of each frame and ineffectively aggregate many redundant framewise shapes in a videowise representation for Re-ID. To address these problems, we propose a 3D Shape Temporal Aggregation (3STA) model for video-based clothing-change Re-ID. To generate the discriminative 3D shape for each frame, we first introduce an identity-aware 3D shape generation module. It embeds the identity information into the generation of 3D shapes by the joint learning of shape estimation and identity recognition. Second, a difference-aware shape aggregation module is designed to measure inter-frame 3D human shape differences and automatically select the unique 3D shape information of each frame. This helps minimise redundancy and maximise complementarity in temporal shape aggregation. We further construct a Video-based Clothing-Change Re-ID (VCCR) dataset to address the lack of publicly available datasets for video-based clothing-change Re-ID. Extensive experiments on the VCCR dataset demonstrate the effectiveness of the proposed 3STA model. The dataset is available at https://vhank.github.io/vccr.github.io.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_5
DP  - Springer Link
SP  - 71
EP  - 88
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_5.pdf
KW  - 3D body shape
KW  - Clothing-change person re-identification
KW  - Temporal aggregation
ER  - 

TY  - CONF
TI  - CLUE: Consolidating Learned and Undergoing Experience in Domain-Incremental Classification
AU  - Cai, Chengyi
AU  - Liu, Jiaxin
AU  - Yu, Wendi
AU  - Guo, Yuchen
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Deep neural networks tend to be vulnerable to catastrophic forgetting when learning new tasks. To address it, continual learning has become a promising and popular research field in recent years. It is noticed that plentiful research predominantly focuses on class-incremental (CI) settings. However, another practical setting, domain-incremental (DI) learning, where the domain distribution shifts in new tasks, also suffers from deteriorating rigidity and should be emphasized. Concentrating on the DI setting, in which the learned model is overwritten by new domains and is no longer valid for former tasks, a novel method named Consolidating Learned and Undergoing Experience (CLUE) is proposed in this paper. In particular, CLUE consolidates former and current experiences by setting penalties on feature extractor distortion and sample outputs alteration. CLUE is highly applicable to classification models as neither extra parameters nor processing steps are introduced. It is observed through extensive experiments that CLUE achieves significant performance improvement compared with other baselines in the three benchmarks. In addition, CLUE is robust even with fewer replay samples. Moreover, its feasibility is supported by both theoretical derivation and model interpretability visualization. The code is available at: https://github.com/Multiplied-by-1/CLUE.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_17
DP  - Springer Link
SP  - 281
EP  - 296
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - CLUE
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_17.pdf
ER  - 

TY  - CONF
TI  - IoU-Enhanced Attention for End-to-End Task Specific Object Detection
AU  - Zhao, Jing
AU  - Wu, Shengjian
AU  - Sun, Li
AU  - Li, Qingli
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Without densely tiled anchor boxes or grid points in the image, sparse R-CNN achieves promising results through a set of object queries and proposal boxes updated in the cascaded training manner. However, due to the sparse nature and the one-to-one relation between the query and its attending region, it heavily depends on the self attention, which is usually inaccurate in the early training stage. Moreover, in a scene of dense objects, the object query interacts with many irrelevant ones, reducing its uniqueness and harming the performance. This paper proposes to use IoU between different boxes as a prior for the value routing in self attention. The original attention matrix multiplies the same size matrix computed from the IoU of proposal boxes, and they determine the routing scheme so that the irrelevant features can be suppressed. Furthermore, to accurately extract features for both classification and regression, we add two lightweight projection heads to provide the dynamic channel masks based on object query, and they multiply with the output from dynamic convs, making the results suitable for the two different tasks. We validate the proposed scheme on different datasets, including MS-COCO and CrowdHuman, showing that it significantly improves the performance and increases the model convergence speed. Codes are available at https://github.com/bravezzzzzz/IoU-Enhanced-Attention.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_8
DP  - Springer Link
SP  - 124
EP  - 141
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_8.pdf
ER  - 

TY  - CONF
TI  - Three-Stage Bidirectional Interaction Network for Efficient RGB-D Salient Object Detection
AU  - Wang, Yang
AU  - Zhang, Yanqing
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - The addition of depth maps improves the performance of salient object detection (SOD). However, most existing RGB-D SOD methods are inefficient. We observe that existing models take into account the respective advantages of the two modalities but do not fully explore the roles of cross-modality features of various levels. To this end, we remodel the relationship between RGB features and depth features from a new perspective of the feature encoding stage and propose a three-stage bidirectional interaction network (TBINet). Specifically, to obtain robust feature representations, we propose three interaction strategies: bidirectional attention guidance (BAG), bidirectional feature supplement (BFS), and shared network, and use them for the three stages of feature encoder, respectively. In addition, we propose a cross-modality feature aggregation (CFA) module for feature aggregation and refinement. Our model is lightweight (3.7 M parameters) and fast (329 ms on CPU). Experiments on six benchmark datasets show that TBINet outperforms other SOTA methods. Our model achieves the best performance and efficiency trade-off.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_13
DP  - Springer Link
SP  - 215
EP  - 233
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_13.pdf
ER  - 

TY  - CONF
TI  - Cross-Architecture Knowledge Distillation
AU  - Liu, Yufan
AU  - Cao, Jiajiong
AU  - Li, Bing
AU  - Hu, Weiming
AU  - Ding, Jingting
AU  - Li, Liang
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Transformer attracts much attention because of its ability to learn global relations and superior performance. In order to achieve higher performance, it is natural to distill complementary knowledge from Transformer to convolutional neural network (CNN). However, most existing knowledge distillation methods only consider homologous-architecture distillation, such as distilling knowledge from CNN to CNN. They may not be suitable when applying to cross-architecture scenarios, such as from Transformer to CNN. To deal with this problem, a novel cross-architecture knowledge distillation method is proposed. Specifically, instead of directly mimicking output/intermediate features of the teacher, partially cross attention projector and group-wise linear projector are introduced to align the student features with the teacher’s in two projected feature spaces. And a multi-view robust training scheme is further presented to improve the robustness and stability of the framework. Extensive experiments show that the proposed method outperforms 14 state-of-the-arts on both small-scale and large-scale datasets.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_11
DP  - Springer Link
SP  - 179
EP  - 195
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_11.pdf
KW  - Cross architecture
KW  - Knowledge distillation
KW  - Model compression
ER  - 

TY  - CONF
TI  - Robustizing Object Detection Networks Using Augmented Feature Pooling
AU  - Shibata, Takashi
AU  - Tanaka, Masayuki
AU  - Okutomi, Masatoshi
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - This paper presents a framework to robustize object detection networks against large geometric transformation. Deep neural networks rapidly and dramatically have improved object detection performance. Nevertheless, modern detection algorithms are still sensitive to large geometric transformation. Aiming at improving the robustness of the modern detection algorithms against the large geometric transformation, we propose a new feature extraction called augmented feature pooling. The key is to integrate the augmented feature maps obtained from the transformed images before feeding it to the detection head without changing the original network architecture. In this paper, we focus on rotation as a simple-yet-influential case of geometric transformation, while our framework is applicable to any geometric transformations. It is noteworthy that, with only adding a few lines of code from the original implementation of the modern object detection algorithms and applying simple fine-tuning, we can improve the rotation robustness of these original detection algorithms while inheriting modern network architectures’ strengths. Our framework overwhelmingly outperforms typical geometric data augmentation and its variants used to improve robustness against appearance changes due to rotation. We construct a dataset based on MS COCO to evaluate the robustness of the rotation, called COCO-Rot. Extensive experiments on three datasets, including our COCO-Rot, demonstrate that our method can improve the rotation robustness of state-of-the-art algorithms.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_6
DP  - Springer Link
SP  - 89
EP  - 106
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_6.pdf
ER  - 

TY  - CONF
TI  - AONet: Attentional Occlusion-Aware Network for Occluded Person Re-identification
AU  - Gao, Guangyu
AU  - Wang, Qianxiang
AU  - Ge, Jing
AU  - Zhang, Yan
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Occluded person Re-identification (Occluded ReID) aims to verify the identity of a pedestrian with occlusion across non-overlapping cameras. Previous works for this task often rely on external tasks, e.g., pose estimation, or semantic segmentation, to extract local features over fixed given regions. However, these external models may perform poorly on Occluded ReID, since they are still open problems with no reliable performance guarantee and are not oriented towards ReID tasks to provide discriminative local features. In this paper, we propose an Attentional Occlusion-aware Network (AONet) for Occluded ReID that does not rely on any external tasks. AONet adaptively learns discriminative local features over latent landmark regions by the trainable pattern vectors, and softly weights the summation of landmark-wise similarities based on the occlusion awareness. Also, as there are no ground truth occlusion annotations, we measure the occlusion of landmarks by the awareness scores, when referring to a memorized dictionary storing average landmark features. These awareness scores are then used as a soft weight for training and inferring. Meanwhile, the memorized dictionary is momenta updated according to the landmark features and the awareness scores of each input image. The AONet achieves $$53.1\%$$53.1%mAP and $$66.5\%$$66.5%Rank1 on the Occluded-DukeMTMC, significantly outperforming state-of-the-arts without any bells and whistles, and also shows obvious improvements on the holistic datasets Market-1501 and DukeMTMC-reID, as well as the partial datasets Partial-REID and Partial-iLIDS. The code and pre-trained models will be released online soon.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_2
DP  - Springer Link
SP  - 21
EP  - 36
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - AONet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_2.pdf
KW  - Landmark
KW  - Occluded ReID
KW  - Occlusion-aware
KW  - Orthogonal
ER  - 

TY  - CONF
TI  - HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images
AU  - Yun, Jun-Seok
AU  - Na, Youngju
AU  - Kim, Hee Hyeon
AU  - Kim, Hyung-Il
AU  - Yoo, Seok Bong
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Although gaze estimation methods have been developed with deep learning techniques, there has been no such approach as aim to attain accurate performance in low-resolution face images with a pixel width of 50 pixels or less. To solve a limitation under the challenging low-resolution conditions, we propose a high-frequency attentive super-resolved gaze estimation network, i.e., HAZE-Net. Our network improves the resolution of the input image and enhances the eye features and those boundaries via a proposed super-resolution module based on a high-frequency attention block. In addition, our gaze estimation module utilizes high-frequency components of the eye as well as the global appearance map. We also utilize the structural location information of faces to approximate head pose. The experimental results indicate that the proposed method exhibits robust gaze estimation performance even in low-resolution face images with 28$$\times $$×28 pixels. The source code of this work is available at https://github.com/dbseorms16/HAZE_Net/.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_9
DP  - Springer Link
SP  - 142
EP  - 160
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - HAZE-Net
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_9.pdf
ER  - 

TY  - CONF
TI  - Reading Arbitrary-Shaped Scene Text from Images Through Spline Regression and Rectification
AU  - Chen, Long
AU  - Su, Feng
AU  - Shi, Jiahao
AU  - Qian, Ye
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Scene text in natural images contains a wealth of valuable semantic information. To read scene text from the image, various text spotting techniques that jointly detect and recognize scene text have been proposed in recent years. In this paper, we present a novel end-to-end text spotting network SPRNet for arbitrary-shaped scene text. We propose a parametric B-spline centerline-based representation model to describe the distinctive global shape characteristics of the text, which helps to effectively deal with interferences such as local connection and tight spacing of text and other object, and a text is detected by regressing its shape parameters. Further, exploiting the text’s shape cues, we employ adaptive projection transformations to rectify the feature representation of an irregular text, which improves the accuracy of the subsequent text recognition network. Our method achieves competitive text spotting performance on standard benchmarks through a simple architecture equipped with the proposed text representation and rectification mechanism, which demonstrates the effectiveness of the method in detecting and recognizing scene text with arbitrary shapes.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_7
DP  - Springer Link
SP  - 107
EP  - 123
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_7.pdf
KW  - Rectification
KW  - Regression
KW  - Scene text spotting
KW  - Spline
ER  - 

TY  - CONF
TI  - Continuous Self-study: Scene Graph Generation with Self-knowledge Distillation and Spatial Augmentation
AU  - Lv, Yuan
AU  - Xu, Yajing
AU  - Wang, Shusen
AU  - Ma, Yingjian
AU  - Wang, Dengke
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - As an extension of visual detection tasks, scene graph generation (SGG) has drawn increasing attention with the achievement of complex image understanding. However, it still faces two challenges: one is the distinguishing of objects with high visual similarity, the other is the discriminating of relationships with long-tailed bias. In this paper, we propose a Continuous Self-Study model (CSS) with self-knowledge distillation and spatial augmentation to refine the detection of hard samples. We design a long-term memory structure for CSS to learn its own behavior with the context feature, which can perceive the hard sample of itself and focus more on similar targets in different scenes. Meanwhile, a fine-grained relative position encoding method is adopted to augment spatial features and supplement relationship information. On the Visual Genome benchmark, experiments show that the proposed CSS achieves obvious improvements over the previous state-of-the-art methods. Our code is available at https://github.com/LINYE1998/Continuous_Self_Study.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_18
DP  - Springer Link
SP  - 297
EP  - 315
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - Continuous Self-study
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_18.pdf
ER  - 

TY  - CONF
TI  - Few-shot Metric Learning: Online Adaptation of Embedding for Retrieval
AU  - Jung, Deunsol
AU  - Kang, Dahyun
AU  - Kwak, Suha
AU  - Cho, Minsu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Metric learning aims to build a distance metric typically by learning an effective embedding function that maps similar objects into nearby points in its embedding space. Despite recent advances in deep metric learning, it remains challenging for the learned metric to generalize to unseen classes with a substantial domain gap. To tackle the issue, we explore a new problem of few-shot metric learning that aims to adapt the embedding function to the target domain with only a few annotated data. We introduce three few-shot metric learning baselines and propose the Channel-Rectifier Meta-Learning (CRML), which effectively adapts the metric space online by adjusting channels of intermediate layers. Experimental analyses on miniImageNet, CUB-200-2011, MPII, as well as a new dataset, miniDeepFashion, demonstrate that our method consistently improves the learned metric by adapting it to target classes and achieves a greater gain in image retrieval when the domain gap from the source classes is larger.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26348-4_4
DP  - Springer Link
SP  - 54
EP  - 70
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26348-4
ST  - Few-shot Metric Learning
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26348-4_4.pdf
ER  - 

TY  - CONF
TI  - Pacific Oyster Gonad Identification and Grayscale Calculation Based on Unapparent Object Detection
AU  - Chen, Yifei
AU  - Yue, Jun
AU  - Li, Zhenbo
AU  - Yang, Jianmin
AU  - Wang, Weijun
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The plumpness of the Pacific oyster gonad, the reproductive organs of both male and female oysters which are buried within the flesh of the oyster in the shell, has important implications for the quality and breeding of subsequent parents. At present, only the conventional method of breaking their shells allows for the observation and study of the interior tissues of Pacific oysters. In this paper, the gonad of Pacific oyster was observed by small animal Magnetic Resonance Imaging (MRI), and a multi-effective feature fusion network algorithm R-SINet was proposed for the detection of unapparent target, in Nuclear Magnetic Resonance (NMR) images, which can effectively solve the problem that the gonads of Pacific oysters are difficult to identify from the background images. In addition, the gray histogram of the segmented gonad region was calculated, and it was found that the female and male had differences in gray value. The sex of oyster was nondestructively detecting by this task. Firstly, established the Oyster gonad datasets; secondly, a compact pyramid refinement module that combines with high-level semantic features and low-level semantic features was proposed, designed a lightweight decoder to improve the accuracy of feature fusion; thirdly, a switchable excitation model capable of adaptive recalibration is proposed to obtain an attention map. Experimental results on the Oyster gonad datasets demonstrate the effectiveness of the method. Comparing R-SINet’s experimental findings to those of popular algorithm models, such as the benchmark algorithm SINet_v2, revealed promising results.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_8
DP  - Springer Link
SP  - 94
EP  - 106
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Gray value calculation
KW  - Pacific oyster gonad
KW  - R-SINet
KW  - Unapparent object detection
ER  - 

TY  - CONF
TI  - OKGR: Occluded Keypoint Generation and Refinement for 3D Object Detection
AU  - Ji, Mingqian
AU  - Yang, Jian
AU  - Zhang, Shanshan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Lidar-based 3D object detectors utilize point clouds to detect objects in autonomous driving. However, the point clouds are sparse and incomplete, which affects the detectors’ learning of shape knowledge and limits the 3D detection performance. Previous works improve performance through completing object shape at the point level or representation level, such as voxel. The former increases computational burden, while the latter has poor generalization ability to point-based detectors. In this paper, we present an approach, namely Occluded Keypoint Generation and Refinement (OKGR), which is effective to improve 3D detection performance by completing object features at the keypoint level. Specifically, Occluded Keypoint Generation (OKG) generates occluded keypoints to densify raw keypoints and learns the offsets between the generated keypoints and prototypes, while retaining the raw keypoints unchanged. Occluded Keypoint Refinement (OKR) assigns weights to the generated keypoints and conducts these weights to features to obtain high-quality complete features for detection. We apply our approach to two representative detectors, PV-RCNN++ and PDV, and evaluate the detectors on KITTI and Waymo Open Dataset. The experiments show significant performance improvement. Particularly, our OKGR applied on PV-RCNN++ achieves improvements of Pedestrian and Cyclist of +3.19%, +2.53% AP on average difficulty levels on KITTI, and +2.18%, +2.29% mAPH on Waymo Open Dataset. For more information, the supplementary material and code are available at https://github.com/Mingqj/OKGR.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - OKGR
KW  - 3D Object Detection
KW  - Object Shape Completion
KW  - Point Clouds
ER  - 

TY  - CONF
TI  - Improved Detection Method for SODL-YOLOv7 Intensive Juvenile Abalone
AU  - Liu, Chengying
AU  - Yue, Jun
AU  - Kou, Guangjie
AU  - Zou, Zhanming
AU  - Li, Zhenbo
AU  - Dai, Changyi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Achieving rapid and accurate detection of juvenile abalone is a prerequisite for estimating the number, density and size of juvenile abalone. Juvenile abalone are densely distributed in the breeding process, and the intra-class occlusion between each other is serious. Microorganisms in the water form inter-class occlusion for juvenile abalone, resulting in incomplete detection information. There is a lack of effective detection methods for juvenile abalone. To address the above problems, this paper proposed the SODL-YOLOv7 juvenile abalone detection method based on the establishment of the JAD (Juvenile abalone detection) dataset. First, the SODL backbone network for dense small target detection is proposed to improve the attention to small targets by incorporating null convolution kernels and pooling kernels with different sampling rates in the spatial null convolution and pooling layers; then, the ACBAM (Adaptive convolutional block attention module) is established to apply the adaptive pooling layer of channel space attention module, so that the network can pay more attention to the young abalone occlusion region and further improve the detection effect. Finally, the method of used in this paper was tested on the JAD dataset, with the results that the AP (average precision) reached 99.4%, an increase of 4.1% compared with the benchmark method YOLOv7, an increase of 9.2% compared with the instant-teaching method, and an increase of 2.2% compared with the TOOD method, therefore verifying the effectiveness of the method of this paper.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_12
DP  - Springer Link
SP  - 146
EP  - 157
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - abalone detection
KW  - inter-class occlusion
KW  - intra-class occlusion
KW  - occlusion detection
KW  - YOLOv7
ER  - 

TY  - CONF
TI  - Camouflaged Object Segmentation Based on Fractional Edge Perception
AU  - Yuan, Xia
AU  - Cui, Junjie
AU  - Liu, Zhengyu
AU  - Yang, Shuting
AU  - Zhang, Xuejian
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Camouflaged object detection is a challenging task because of intrinsic similarity between background and foreground. In the existing models, many confusing edge features eventually lead to bad predictions. In this paper, we propose an Interactive Task Learning Network, in which an improved fractional-order differential operator is used to calculate the gradient intensity of the image. By calculating average gradient and spatial frequency of image, it can adaptively learn the fractional-order v and extract features from different directions. Experiments on three camouflaged datasets indicate that the proposed method is effective and progressiveness.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_2
DP  - Springer Link
SP  - 16
EP  - 28
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Camouflaged object detection
KW  - Fractional edge
KW  - Interactive task learning
ER  - 

TY  - CONF
TI  - Context-FPN and Memory Contrastive Learning for Partially Supervised Instance Segmentation
AU  - Yuan, Zheng
AU  - Cai, Weiling
AU  - Zhao, Chen
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Partially supervised instance segmentation aims to segment objects on both limited seen categories and novel unseen categories (without annotated masks), thereby eliminating expensive demands of mask annotation for new categories. Existing work mainly utilize the pipeline model of detection first and then segmentation, and explores how to provide more discriminative regions of interest for the class-agnostic mask head, but these methods do not perform well when faced with complex scenes. In this work, we propose a novel method, named CCMask, that combines Context Feature Pyramid Network (Context-FPN) and Memory Contrastive Learning Head (MCL Head) to achieve effective class-agnostic mask segmentation. Specifically, we introduce a Context-FPN to obtain context-rich feature map via context extraction module, which will benefit the subsequent task heads. In the MCL Head, we employ foreground/background query memory queue to store queries from recent training batches, this helps the MCL Head learns the general concepts of foreground and background. These strategies collectively contribute to improve the discrimination between foreground and background. Exhaustive experiments on COCO dataset demonstrate that our method achieves state-of-the-art results.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_14
DP  - Springer Link
SP  - 172
EP  - 184
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Contrastive learning
KW  - Feature Pyramid Network
KW  - Partially supervised instance segmentation
ER  - 

TY  - CONF
TI  - Modality Balancing Mechanism for RGB-Infrared Object Detection in Aerial Image
AU  - Cai, Weibo
AU  - Li, Zheng
AU  - Dong, Junhao
AU  - Lai, Jianhuang
AU  - Xie, Xiaohua
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - RGB-Infrared object detection in aerial images has gained significant attention due to its effectiveness in mitigating the challenges posed by illumination restrictions. Existing methods often focus heavily on enhancing the fusion of two modalities while ignoring the optimization imbalance caused by inherent differences between modalities. In this work, we observe that there is an inconsistency between two modalities during joint training, and this hampers the model’s performance. Inspired by these findings, we argue that the focus of RGB-Infrared detection should be shifted to the optimization of two modalities, and further propose a Modality Balancing Mechanism (MBM) method for training the detection model. To be specific, we initially introduce an auxiliary detection head to inspect the training process of both modalities. Subsequently, the learning rates of the two backbones are dynamically adjusted using the Scaled Gaussian Function (SGF). Furthermore, the Multi-modal Feature Hybrid Sampling Module (MHSM) is introduced to augment representation by combining complementary features extracted from both modalities. Benefiting from the design of the proposed mechanism, experimental results on DroneVehicle and LLVIP demonstrate that our approach achieves state-of-the-art performance. The code are available at (https://github.com/ccccwb/Multimodal-Detection-and-Tracking-UAV).
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_7
DP  - Springer Link
SP  - 81
EP  - 93
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Aerial image
KW  - Modality balancing mechanism
KW  - Multi-modal feature hybrid sampling
KW  - RGB-Infrared object detection
ER  - 

TY  - CONF
TI  - A Dynamic Tracking Framework Based on Scene Perception
AU  - Zhang, Jinpu
AU  - Li, Ziwen
AU  - Wang, Yuehuan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - While recent large models have greatly improved tracking performance, not all scenes require a large and complex network. Dynamic networks can adapt the architecture to different inputs, leading to notable accuracy and computational efficiency. However, existing dynamic architectures and decision mechanisms designed for classification are not applicable to the tracking task. This paper proposes a dynamic tracking framework based on scene perception, named DynamicTrack. We classify tracking scenes into easy and hard categories, and propose a dynamic architecture with an easy-hard dual-branch to handle different scenes respectively. Unlike previous works in classification that selectively prune a subset of the backbone, complete execution of the entire backbone is necessary for tracking. Hence, we maintain two complete transformer backbones for the dual branches and vary the number of input tokens to achieve modeling at different granularities. Then, we propose a scene router that automatically selects the optimal branch for each input frame. The router directly assesses the scene complexity of features extracted by the easy branch for decision-making, without relying on the tracking head output. This enhances decision efficiency during dynamic inference. Moreover, we introduce two techniques that benefit DynamicTrack optimization, namely, the Gumbel-Softmax trick and cross-branch transmission (CBT). The former increases the stochasticity of decisions and prevents mode collapse into trivial solutions. The latter establishes information transmission between the two branches, facilitating discriminative power and learning efficiency. Extensive experiments on four benchmarks demonstrate that the proposed DynamicTrack achieves SOTA performance and accuracy-speed trade-offs.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_15
DP  - Springer Link
SP  - 185
EP  - 197
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Dynamic network
KW  - Object tracking
KW  - Scene router
ER  - 

TY  - CONF
TI  - MVP-SEG: Multi-view Prompt Learning for Open-Vocabulary Semantic Segmentation
AU  - Guo, Jie
AU  - Wang, Qimeng
AU  - Gao, Yan
AU  - Jiang, Xiaolong
AU  - Lin, Shaohui
AU  - Zhang, Baochang
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - CLIP (Contrastive Language-Image Pretraining) is well developed for open-vocabulary zero-shot image-level recognition, while its applications in pixel-level tasks are less investigated, where most efforts directly adopt CLIP features without deliberative adaptations. In this work, we first demonstrate the necessity of image-pixel CLIP feature adaption, then provide Multi-View Prompt learning (MVP-SEG) as an effective solution to achieve image-pixel adaptation and to solve open-vocabulary semantic segmentation. Concretely, MVP-SEG deliberately learns multiple prompts trained by our Orthogonal Constraint Loss (OCLoss), by which each prompt is supervised to exploit CLIP feature on different object parts, and collaborative segmentation masks generated by all prompts promote better segmentation. Moreover, MVP-SEG introduces Global Prompt Refining (GPR) to further eliminate class-wise segmentation noise. Experiments show that the multi-view prompts learned from seen categories have strong generalization to unseen categories, and MVP-SEG+ which combines the knowledge transfer stage significantly outperforms previous methods on several benchmarks. Moreover, qualitative results justify that MVP-SEG does lead to better focus on different local parts.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_13
DP  - Springer Link
SP  - 158
EP  - 171
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - MVP-SEG
L4  - https://arxiv.org/pdf/2304.06957
KW  - CLIP
KW  - Open vocabulary
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - Feature Disentanglement and Adaptive Fusion for Improving Multi-modal Tracking
AU  - Li, Zheng
AU  - Cai, Weibo
AU  - Dong, Junhao
AU  - Lai, Jianhuang
AU  - Xie, Xiaohua
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Multi-modal tracking has increasingly gained attention due to its superior accuracy and robustness in complex scenarios. The primary challenges in this field lie in effectively extracting and fusing multi-modal data that inherently contain gaps. To address the above issues, we propose a novel regularized single-stream multi-modal tracking framework, drawing inspiration from the perspective of disentanglement. Specifically, taking into account the similarities and differences intrinsic in multi-modal data, we design a modality-specific weights sharing feature extraction module to extract well-disentangled multi-modal features. To emphasize feature-level specificity across different modal features, we propose a cross-modal deformable attention mechanism for the adaptive integration of multi-modal features with efficiency. Through extensive experiments on three multi-modal tracking benchmarks, including RGB+Thermal infrared and RGB+Depth, we demonstrate that our method significantly outperforms existing multi-modal tracking algorithms. Code is available at https://github.com/ccccwb/Multimodal-Detection-and-Tracking-UAV.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_6
DP  - Springer Link
SP  - 68
EP  - 80
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Cross-modal vision transformer
KW  - Multi-modal Fusion
KW  - Multi-modal tracking
KW  - Visual object tracking
ER  - 

TY  - CONF
TI  - Multi-task Self-supervised Few-Shot Detection
AU  - Zhang, Guangyong
AU  - Duan, Lijuan
AU  - Wang, Wenjian
AU  - Gong, Zhi
AU  - Ma, Bian
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Few-shot object detection involves detecting novel objects with only a few training samples. But very few samples are difficult to cover the bias of the new class in the deep model. To address the issue, we use self-supervision to expand the coverage of samples to provide more observation angles for new classes. In this paper, we propose a multi-task approach that combines self-supervision with few-shot learning to exploit the complementarity of these two domains. Specifically, our self-supervision as an auxiliary task to improve the detection performance of the main task of few-shot learning. Moreover, in order to make self-supervision more suitable for few-shot object detection, we introduce the denoising module to expand the positive and negative samples and the team module for precise positioning. The denoising module expands the positive and negative samples and accelerate model convergence using contrastive denoising training methods. The team module utilizes location constraints for precise localization to improve the accuracy of object detection. Our experimental results demonstrate the effectiveness of our method on the Few-shot object detection task on the PASCAL VOC and COCO datasets, achieving promising results. Our results highlight the potential of combining self-supervision with few-shot learning to improve the performance of object detection models in scenarios where annotated data is limited.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_9
DP  - Springer Link
SP  - 107
EP  - 119
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - End-to-End Detector
KW  - Few-shot object detection
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - DecTrans: Person Re-identification with Multifaceted Part Features via Decomposed Transformer
AU  - Zhang, Yan
AU  - Gao, Guangyu
AU  - Wang, Qianxiang
AU  - Ge, Jing
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Utilizing part-level features provides a more detailed representation, leading to improved results in person re-identification (ReID). Yet existing works either use external tasks like pose estimation or struggle to define part features, which limit the model’s learning capability. In this work, we propose the Decomposed Transformer (DecTrans), a transformer-based person ReID framework which exploits multifaceted part features. In particular, DecTrans extracts local features using the Vision Transformer (ViT) and then maps them into latent parts through a novel Token Decomposition (TD) layer. In the TD layer, soft clustering of ViT tokens forms clusters, and each token is decomposed into components based on its similarity to all cluster centroids. Token components referencing the same cluster are then regrouped to produce part features, thereby retaining more feature details. To ensure tokens from different pedestrians but referring to the same part are sufficiently clustered together, we propose to remove id information from tokens before clustering. Besides, we also propose a simple yet efficient data augmentation named Image Graying, which has been experimentally validated when used in conjunction with the TD layer. The DecTrans achieves remarkable performance, e.g., mAP and Rank1 of $$ 70.8\% \& 87.1\%$$70.8%&87.1%, and $$ 61.6\% \& 67.7\%$$61.6%&67.7%on MSMT17 and Occluded-Duke, significantly outperforming state-of-the-arts.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_3
DP  - Springer Link
SP  - 29
EP  - 42
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - DecTrans
KW  - Person ReID
KW  - Vision Transformer
ER  - 

TY  - CONF
TI  - DiffusionTracker: Targets Denoising Based on Diffusion Model for Visual Tracking
AU  - Zhang, Runqing
AU  - Cai, Dunbo
AU  - Qian, Ling
AU  - Du, Yujian
AU  - Lu, Huijun
AU  - Zhang, Yijun
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The problem of background clutter (BC) is caused by distractors in the background that resemble the target’s appearance, thereby reducing the precision of visual trackers. We consider these similar distractors as noise and formulate a denoising task to solve the visual tracking problem. We propose a target denoising method based on a diffusion model for visual tracking, referred to as DiffusionTracker, which introduces the diffusion model to distinguish between targets and noise (distractors). Specifically, we introduce a reverse diffusion model to eliminate noisy distractors from the proposal candidates generated by the Siamese tracking backbone. To handle the difficulty that distractors do not strictly conform to a Gaussian distribution, we incorporate Spatial-Temporal Weighting (STW) to integrate spatial correlation and noise decay time information, mitigating the impact of noise distribution on denoising effectiveness. Experimental results demonstrate the effectiveness of the proposed method, with DiffusionTracker achieving a precision of 64.0% on BC sequences and a success rate of 63.8% on BC sequences from the LaSOT test datasets, representing improvements of 11.7% and 10.2% respectively over state-of-the-art trackers. Furthermore, our proposed method can be seamlessly integrated as a plug-and-play module with cutting-edge tracking algorithms, significantly improving the success rate for tracking task in background clutter scenarios.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_18
DP  - Springer Link
SP  - 225
EP  - 237
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - DiffusionTracker
KW  - Deep Learning
KW  - Denoising
KW  - Diffusion Model
KW  - Siamese Network
KW  - Visual Tracking
ER  - 

TY  - CONF
TI  - AHT: A Novel Aggregation Hyper-transformer for Few-Shot Object Detection
AU  - Lai, Lanqing
AU  - Yu, Yale
AU  - Suo, Wei
AU  - Wang, Peng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Few-shot object detection aims to detect novel objects with few annotated examples and this task has been extensively investigated by meta-learning-based paradigm. However, most of the previous approaches suffer from: 1) Most of the previous methods only perform two-branch interaction in the detection head which lacks the interaction of low-level semantic features. 2) Traditional method is difficult to capture the fine-grained differences between categories due to fixed weights. To alleviate these issues, we proposed a simple yet effective method, named Aggregation Hyper-Transformer (AHT) framework, which can generate corresponding weights into the primary network by hypernetworks mechanism. In particular, we design a novel Dynamic Aggregation Module and a Conditional Adaptation Hypernetworks, which apply the aggregated category vectors as conditions to dynamically generates class-specific parameters. Benefiting from the above two modules, our method significantly exceeds the previous meta-learning methods and provides new insights for my community.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_4
DP  - Springer Link
SP  - 43
EP  - 55
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - AHT
KW  - Few-shot object detection
KW  - Hypernetwork
KW  - Meta-learning
ER  - 

TY  - CONF
TI  - HPAN: A Hybrid Pose Attention Network for Person Re-Identification
AU  - Huan, Ruohong
AU  - Chen, Tianya
AU  - Zhan, Ziwei
AU  - Chen, Peng
AU  - Liang, Ronghua
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - To address the difficulty in expressing the correlation between different local features extracted by the current person re-identification feature extraction methods, and the challenge of effectively integrating local features with global features, a Hybrid Pose Attention Network (HPAN) for person re-identification is proposed. In HPAN, the high-resolution network HRNet-W32 serves as the backbone for person re-identification and pose estimation, extracting global features and local key point heatmaps of the human images, and then generating local key point features. Self-attention is used to extract the correlation between each local key point feature, generating local pose features. Furthermore, a Hybrid Pose and Global Feature Fusion (HPGFF) module is adopted to fuse the global features and local pose features, creating integrated features. To evaluate, we conduct experiments on five publicly available datasets, and HPAN has all achieved competitive or state-of-the-art results.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_16
DP  - Springer Link
SP  - 198
EP  - 211
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - HPAN
KW  - Feature Correlation
KW  - Fusion
KW  - Local Feature
KW  - Pose Estimation
KW  - Re-identification
ER  - 

TY  - CONF
TI  - CSTrack: A Comprehensive and Concise Vision Transformer Tracker
AU  - Chen, Yao
AU  - Ding, Shuyan
AU  - Guo, Jianhui
AU  - Yang, Chen
AU  - Li, Lunbo
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The attention mechanism has been widely applied in visual tracking tasks due to its remarkable ability to capture global dependencies. However, there are two issues in previous attention-based methods: redundancy of template information and inappropriate utilization of information streams. In this work, we propose a spatial positioning attention mechanism that addresses these issues by selective template feature enhancement and elimination of redundant information streams, respectively, significantly improving tracking accuracy and speed. Furthermore, previous trackers fail to focus on channels containing crucial target information within the template features and search region features. To tackle this, we introduce a channel focus attention mechanism to perform channel weight rescaling, which allows the tracker to concentrate on those target-related channels, improving its localization capability. Extensive experiments on four well-known datasets, GOT-10k, LaSOT, TrackingNet, and TNL2K, show that CSTrack outperforms all previous state-of-the-art trackers, running at over 70 FPS.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_10
DP  - Springer Link
SP  - 120
EP  - 132
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - CSTrack
KW  - One-stream tracker
KW  - Vision Transformer
KW  - Visual tracking
ER  - 

TY  - CONF
TI  - Feature Implicit Enhancement via Super-Resolution for Small Object Detection
AU  - Xu, Zhehao
AU  - Liu, Mengyin
AU  - Zhu, Chao
AU  - Zhou, Fang
AU  - Yin, Xu-Cheng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In recent years, object detection has made significant strides due to advancements in deep convolutional neural networks. However, the detection performance for small objects remains challenging. The visual information of small objects is easily confused with the background and even more likely to get lost in a series of downsampling operations due to the limited number of pixels, resulting in poor representations. In this paper, we propose a novel approach namely Feature Implicit Enhancement via Super-Resolution (FIESR) to learn more robust feature representations for small object detection. Our FIESR consists of two detection branches and requires two steps of training. Firstly, the detector learns the relationship between low-resolution and corresponding original high-resolution images to enhance the representations of small objects by minimizing a super-resolution loss between the two branches. Secondly, the detector is fine-tuned on original resolution images to fit extremely large objects. Additionally, our FIESR could be applied to various popular detectors such as Faster-RCNN, RetinaNet, FCOS, and DyHead. Our FIESR achieves competitive results on COCO dataset and is proved effective and flexible by extensive experiments.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_11
DP  - Springer Link
SP  - 133
EP  - 145
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - COCO
KW  - Small Object Detection
KW  - Super Resolution
ER  - 

TY  - CONF
TI  - Feature Refinement from Multiple Perspectives for High Performance Salient Object Detection
AU  - Li, Xuan
AU  - Wang, Congao
AU  - Ma, Ding
AU  - Wu, Xiangqian
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Recently, deep-learning based salient object detection methods have gained great progress. However, there still exists some problems such as inefficient multi-level feature fusion, unstable multi-scale context-aware feature extraction, detail loss caused by upsampling and unbalanced distribution. To efficiently fuse multi-level features, we propose an attention-guided bi-directional feature refinement module (ABFRM) including top-down and bottom-up processes, which applies different attention-based feature fusion strategies for different directional processes. To obtain stable multi-scale contextual features, we design a serial atrous fusion module (SAFM), which uses serial atrous convolutional layers with small dilation rates. To reduce detail loss caused by upsampling with a large factor, we devise an upsampling feature refinement module (UFRM), which utilizes the combination of deconvolution and bilinear interpolation. To address unbalanced distribution from both foreground and background perspectives, we propose a novel hybrid loss, which contains Intersection-over-Union (IoU) and background boundary (BGB) losses. Comprehensive experiments on five benchmark datasets demonstrate that our proposed method outperforms 13 state-of-the-art approaches under four evaluation metrics. The code is available at https://github.com/xuanli01/PRCV210.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_5
DP  - Springer Link
SP  - 56
EP  - 67
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
KW  - Attention-guided bi-directional feature refinement
KW  - Background boundary loss
KW  - Salient object detection
KW  - Serial atrous fusion
KW  - Upsampling feature refinement
ER  - 

TY  - CONF
TI  - SpectralTracker: Jointly High and Low-Frequency Modeling for Tracking
AU  - Rong, Yimin
AU  - Liang, Qihua
AU  - Li, Ning
AU  - Mo, Zhiyi
AU  - Zhong, Bineng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Recently, a considerable number of top-performing Transformer based trackers have been proposed. However, most of them mainly focus on utilizing low-frequency information from a spatial-spectral analysis perspective, limiting their performance in complicated scenes. To address this problem, we propose a spectral tracker that explores how to capture high and low-frequency information for robust tracking jointly. Specifically, we design a novel dual-spectral information extraction and aggregation module (DSM) consisting of a high and low-frequency branch to capture and combine complementary frequency information of a Transformer effectively. Firstly, we divide the local window in the high-frequency branch to focus on more fine-grained high-frequency information. Then, in the low-frequency branch, we apply AvgPooling with a low-pass effect on a Transformer to amplify its low-frequency information. Furthermore, we design a shared MLP strategy to polarize the dual-frequency branching to high and low-frequency information attention. Finally, we utilize an MLP to complementarily fuse high and low-frequency information for frequency domain modeling. Comprehensive experiments on five tracking benchmarks (i.e., GOT-10k, TrackingNet, LaSOT, UAV123 and TNL2K) show that our spectral tracker achieves better performance than the state-of-the-art trackers.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8555-5_17
DP  - Springer Link
SP  - 212
EP  - 224
LA  - en
PB  - Springer Nature
SN  - 978-981-9985-55-5
ST  - SpectralTracker
KW  - Object Tracking
KW  - Single-stage Backbone
KW  - Spectral Domain
KW  - Vision Transformer
ER  - 

TY  - CONF
TI  - Self-supervised Social Relation Representation for Human Group Detection
AU  - Li, Jiacheng
AU  - Han, Ruize
AU  - Yan, Haomin
AU  - Qian, Zekun
AU  - Feng, Wei
AU  - Wang, Song
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Human group detection, which splits crowd of people into groups, is an important step for video-based human social activity analysis. The core of human group detection is the human social relation representation and division. In this paper, we propose a new two-stage multi-head framework for human group detection. In the first stage, we propose a human behavior simulator head to learn the social relation feature embedding, which is self-supervised trained by leveraging the socially grounded multi-person behavior relationship. In the second stage, based on the social relation embedding, we develop a self-attention inspired network for human group detection. Remarkable performance on two state-of-the-art large-scale benchmarks, i.e., PANDA and JRDB-Group, verifies the effectiveness of the proposed framework. Benefiting from the self-supervised social relation embedding, our method can provide promising results with very few (labeled) training data. We have released the source code to the public.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_9
DP  - Springer Link
SP  - 142
EP  - 159
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_9.pdf
KW  - Group detection
KW  - Self-supervised learning
KW  - Video analysis
ER  - 

TY  - CONF
TI  - Long Movie Clip Classification with State-Space Video Models
AU  - Islam, Md Mohaiminul
AU  - Bertasius, Gedas
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Most modern video recognition models are designed to operate on short video clips (e.g., 5–10 s in length). Thus, it is challenging to apply such models to long movie understanding tasks, which typically require sophisticated long-range temporal reasoning. The recently introduced video transformers partially address this issue by using long-range temporal self-attention. However, due to the quadratic cost of self-attention, such models are often costly and impractical to use. Instead, we propose ViS4mer, an efficient long-range video model that combines the strengths of self-attention and the recently introduced structured state-space sequence (S4) layer. Our model uses a standard Transformer encoder for short-range spatiotemporal feature extraction, and a multi-scale temporal S4 decoder for subsequent long-range temporal reasoning. By progressively reducing the spatiotemporal feature resolution and channel dimension at each decoder layer, ViS4mer learns complex long-range spatiotemporal dependencies in a video. Furthermore, ViS4mer is $$2.63{\times }$$2.63×faster and requires $$8{\times }$$8×less GPU memory than the corresponding pure self-attention-based model. Additionally, ViS4mer achieves state-of-the-art results in 6 out of 9 long-form movie video classification tasks on the Long Video Understanding (LVU) benchmark. Furthermore, we show that our approach successfully generalizes to other domains, achieving competitive results on the Breakfast and the COIN procedural activity datasets. The code is publicly available (https://github.com/md-mohaiminul/ViS4mer).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_6
DP  - Springer Link
SP  - 87
EP  - 104
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_6.pdf
ER  - 

TY  - CONF
TI  - Semi-supervised Learning of Optical Flow by Flow Supervisor
AU  - Im, Woobin
AU  - Lee, Sebin
AU  - Yoon, Sung-Eui
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - A training pipeline for optical flow CNNs consists of a pretraining stage on a synthetic dataset followed by a fine tuning stage on a target dataset. However, obtaining ground truth flows from a target video requires a tremendous effort. This paper proposes a practical fine tuning method to adapt a pretrained model to a target dataset without ground truth flows, which has not been explored extensively. Specifically, we propose a flow supervisor for self-supervision, which consists of parameter separation and a student output connection. This design is aimed at stable convergence and better accuracy over conventional self-supervision methods which are unstable on the fine tuning task. Experimental results show the effectiveness of our method compared to different self-supervision methods for semi-supervised learning. In addition, we achieve meaningful improvements over state-of-the-art optical flow models on Sintel and KITTI benchmarks by exploiting additional unlabeled datasets. Code is available at https://github.com/iwbn/flow-supervisor.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_18
DP  - Springer Link
SP  - 302
EP  - 318
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_18.pdf
ER  - 

TY  - CONF
TI  - Delta Distillation for Efficient Video Processing
AU  - Habibian, Amirhossein
AU  - Ben Yahia, Haitam
AU  - Abati, Davide
AU  - Gavves, Efstratios
AU  - Porikli, Fatih
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper aims to accelerate video stream processing, such as object detection and semantic segmentation, by leveraging the temporal redundancies that exist between video frames. Instead of propagating and warping features using motion alignment, such as optical flow, we propose a novel knowledge distillation schema coined as Delta Distillation. In our proposal, the student learns the variations in the teacher’s intermediate features over time. We demonstrate that these temporal variations can be effectively distilled due to the temporal redundancies within video frames. During inference, both teacher and student cooperate for providing predictions: the former by providing initial representations extracted only on the key-frame, and the latter by iteratively estimating and applying deltas for the successive frames. Moreover, we consider various design choices to learn optimal student architectures including an end-to-end learnable architecture search. By extensive experiments on a wide range of architectures, including the most efficient ones, we demonstrate that delta distillation sets a new state of the art in terms of accuracy vs. efficiency trade-off for semantic segmentation and object detection in videos. Finally, we show that, as a by-product, delta distillation improves the temporal consistency of the teacher model.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_13
DP  - Springer Link
SP  - 213
EP  - 229
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_13.pdf
ER  - 

TY  - CONF
TI  - K-centered Patch Sampling for Efficient Video Recognition
AU  - Park, Seong Hyeon
AU  - Tack, Jihoon
AU  - Heo, Byeongho
AU  - Ha, Jung-Woo
AU  - Shin, Jinwoo
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - For decades, it has beena common practice to choose a subset of video frames for reducing the computational burden of a video understanding model. In this paper, we argue that this popular heuristic might be sub-optimal under recent transformer-based models. Specifically, inspired by that transformers are built upon patches of video frames, we propose to sample patches rather than frames using the greedy K-center search, i.e., the farthest patch to what has been chosen so far is sampled iteratively. We then show that a transformer trained with the selected video patches can outperform its baseline trained with the video frames sampled in the traditional way. Furthermore, by adding a certain spatiotemporal structuredness condition, the proposed K-centered patch sampling can be even applied to the recent sophisticated video transformers, boosting their performance further. We demonstrate the superiority of our method on Something–Something and Kinetics datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_10
DP  - Springer Link
SP  - 160
EP  - 176
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_10.pdf
KW  - Efficient video recognition
KW  - Farthest point sampling
KW  - K-center search
KW  - Patch sampling
KW  - Video transformers
ER  - 

TY  - CONF
TI  - Prompting Visual-Language Models for Efficient Video Understanding
AU  - Ju, Chen
AU  - Han, Tengda
AU  - Zheng, Kunhao
AU  - Zhang, Ya
AU  - Xie, Weidi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Image-based visual-language (I-VL) pre-training has shown great success for learning joint visual-textual representations from large-scale web data, revealing remarkable ability for “zero-shot” generalisation. This paper presents a simple but strong baseline to efficiently adapt the pre-trained I-VL model for video understanding tasks, with minimal training. Specifically, we propose to optimise a few random vectors, termed as “continuous prompt vectors”, that convert video-related tasks into the same format as the pre-training objectives. In addition, to bridge the gap between static images and videos, temporal information is encoded with lightweight Transformers stacking on top of frame-wise visual features. Experimentally, we conduct extensive ablation studies to analyse the critical components. On ten public benchmarks of action recognition, action localisation, and text-video retrieval, across closed-set, few-shot, and zero-shot scenarios, we achieve competitive or state-of-the-art performance to existing methods, despite optimising significantly fewer parameters. Due to space limitation, we refer the readers to the arXiv version at https://arxiv.org/abs/2112.04478.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_7
DP  - Springer Link
SP  - 105
EP  - 124
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_7.pdf
ER  - 

TY  - CONF
TI  - Asymmetric Relation Consistency Reasoning for Video Relation Grounding
AU  - Li, Huan
AU  - Wei, Ping
AU  - Li, Jiapeng
AU  - Ma, Zeyu
AU  - Shang, Jiahui
AU  - Zheng, Nanning
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Video relation grounding has attracted growing attention in the fields of video understanding and multimodal learning. While the past years have witnessed remarkable progress in this issue, the difficulties of multi-instance and complex temporal reasoning make it still a challenging task. In this paper, we propose a novel Asymmetric Relation Consistency (ARC) reasoning model to solve the video relation grounding problem. To overcome the multi-instance confusion problem, an asymmetric relation reasoning method and a novel relation consistency loss are proposed to ensure the consistency of the relationships across multiple instances. In order to precisely localize the relation instance in temporal context, a transformer-based relation reasoning module is proposed. Our model is trained in a weakly-supervised manner. The proposed method was tested on the challenging video relation dataset. Experiments manifest that the performance of our method outperforms the state-of-the-art methods by a large margin. Extensive ablation studies also prove the effectiveness and strength of the proposed method.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_8
DP  - Springer Link
SP  - 125
EP  - 141
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_8.pdf
KW  - Asymmetric relation consistency
KW  - Video relation grounding
KW  - Weakly-supervised
ER  - 

TY  - CONF
TI  - Unified Fully and Timestamp Supervised Temporal Action Segmentation via Sequence to Sequence Translation
AU  - Behrmann, Nadine
AU  - Golestaneh, S. Alireza
AU  - Kolter, Zico
AU  - Gall, Jürgen
AU  - Noroozi, Mehdi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper introduces a unified framework for video action segmentation via sequence to sequence (seq2seq) translation in a fully and timestamp supervised setup. In contrast to current state-of-the-art frame-level prediction methods, we view action segmentation as a seq2seq translation task, i.e., mapping a sequence of video frames to a sequence of action segments. Our proposed method involves a series of modifications and auxiliary loss functions on the standard Transformer seq2seq translation model to cope with long input sequences opposed to short output sequences and relatively few videos. We incorporate an auxiliary supervision signal for the encoder via a frame-wise loss and propose a separate alignment decoder for an implicit duration prediction. Finally, we extend our framework to the timestamp supervised setting via our proposed constrained k-medoids algorithm to generate pseudo-segmentations. Our proposed framework performs consistently on both fully and timestamp supervised settings, outperforming or competing state-of-the-art on several datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_4
DP  - Springer Link
SP  - 52
EP  - 68
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_4.pdf
KW  - Action segmentation
KW  - Auto-regressive learning
KW  - Timestamp supervised learning
KW  - Transformers
KW  - Video understanding
ER  - 

TY  - CONF
TI  - GraphVid: It only Takes a Few Nodes to Understand a Video
AU  - Kosman, Eitan
AU  - Di Castro, Dotan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We propose a concise representation of videos that encode perceptually meaningful features into graphs. With this representation, we aim to leverage the large amount of redundancies in videos and save computations. First, we construct superpixel-based graph representations of videos by considering superpixels as graph nodes and create spatial and temporal connections between adjacent superpixels. Then, we leverage Graph Convolutional Networks to process this representation and predict the desired output. As a result, we are able to train models with much fewer parameters, which translates into short training periods and a reduction in computation resource requirements. A comprehensive experimental study on the publicly available datasets Kinetics-400 and Charades shows that the proposed method is highly cost-effective and uses limited commodity hardware during training and inference. It reduces the computational requirements 10-fold while achieving results that are comparable to state-of-the-art methods. We believe that the proposed approach is a promising direction that could open the door to solving video understanding more efficiently and enable more resource limited users to thrive in this research field.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_12
DP  - Springer Link
SP  - 195
EP  - 212
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
ST  - GraphVid
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_12.pdf
ER  - 

TY  - CONF
TI  - COMPOSER: Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality
AU  - Zhou, Honglu
AU  - Kadav, Asim
AU  - Shamsian, Aviv
AU  - Geng, Shijie
AU  - Lai, Farley
AU  - Zhao, Long
AU  - Liu, Ting
AU  - Kapadia, Mubbasir
AU  - Graf, Hans Peter
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Group Activity Recognition detects the activity collectively performed by a group of actors, which requires compositional reasoning of actors and objects. We approach the task by modeling the video as tokens that represent the multi-scale semantic concepts in the video. We propose COMPOSER, a Multiscale Transformer based architecture that performs attention-based reasoning over tokens at each scale and learns group activity compositionally. In addition, prior works suffer from scene biases with privacy and ethical concerns. We only use the keypoint modality which reduces scene biases and prevents acquiring detailed visual data that may contain private or biased information of users. We improve the multiscale representations in COMPOSER by clustering the intermediate scale representations, while maintaining consistent cluster assignments between scales. Finally, we use techniques such as auxiliary prediction and data augmentations tailored to the keypoint signals to aid model training. We demonstrate the model’s strength and interpretability on two widely-used datasets (Volleyball and Collective Activity). COMPOSER achieves up to $$+5.4\%$$+5.4%improvement with just the keypoint modality (Code is available at https://github.com/hongluzhou/composer.).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_15
DP  - Springer Link
SP  - 249
EP  - 266
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
ST  - COMPOSER
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_15.pdf
KW  - Compositionality
KW  - Keypoint-only group activity recognition
KW  - Multiscale representations
KW  - Transformer
KW  - Video understanding
ER  - 

TY  - CONF
TI  - Efficient Video Transformers with Spatial-Temporal Token Selection
AU  - Wang, Junke
AU  - Yang, Xitong
AU  - Li, Hengduo
AU  - Liu, Li
AU  - Wu, Zuxuan
AU  - Jiang, Yu-Gang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Video transformers have achieved impressive results on major video recognition benchmarks, which however suffer from high computational cost. In this paper, we present STTS, a token selection framework that dynamically selects a few informative tokens in both temporal and spatial dimensions conditioned on input video samples. Specifically, we formulate token selection as a ranking problem, which estimates the importance of each token through a lightweight scorer network and only those with top scores will be used for downstream evaluation. In the temporal dimension, we keep the frames that are most relevant to the action categories, while in the spatial dimension, we identify the most discriminative region in feature maps without affecting the spatial context used in a hierarchical way in most video transformers. Since the decision of token selection is non-differentiable, we employ a perturbed-maximum based differentiable Top-K operator for end-to-end training. We mainly conduct extensive experiments on Kinetics-400 with a recently introduced video transformer backbone, MViT. Our framework achieves similar results while requiring 20% less computation. We also demonstrate our approach is generic for different transformer architectures and video datasets. Code is available at https://github.com/wangjk666/STTS.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_5
DP  - Springer Link
SP  - 69
EP  - 86
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_5.pdf
KW  - Efficient action recognition
KW  - Transformer
ER  - 

TY  - CONF
TI  - Efficient One-Stage Video Object Detection by Exploiting Temporal Consistency
AU  - Sun, Guanxiong
AU  - Hua, Yang
AU  - Hu, Guosheng
AU  - Robertson, Neil
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recently, one-stage detectors have achieved competitive accuracy and faster speed compared with traditional two-stage detectors on image data. However, in the field of video object detection (VOD), most existing VOD methods are still based on two-stage detectors. Moreover, directly adapting existing VOD methods to one-stage detectors introduces unaffordable computational costs. In this paper, we first analyse the computational bottlenecks of using one-stage detectors for VOD. Based on the analysis, we present a simple yet efficient framework to address the computational bottlenecks and achieve efficient one-stage VOD by exploiting the temporal consistency in video frames. Specifically, our method consists of a location prior network to filter out background regions and a size prior network to skip unnecessary computations on low-level feature maps for specific frames. We test our method on various modern one-stage detectors and conduct extensive experiments on the ImageNet VID dataset. Excellent experimental results demonstrate the superior effectiveness, efficiency, and compatibility of our method. The code is available at https://github.com/guanxiongsun/EOVOD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_1
DP  - Springer Link
SP  - 1
EP  - 16
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_1.pdf
ER  - 

TY  - CONF
TI  - E-NeRV: Expedite Neural Video Representation with Disentangled Spatial-Temporal Context
AU  - Li, Zizhang
AU  - Wang, Mengmeng
AU  - Pi, Huaijin
AU  - Xu, Kechun
AU  - Mei, Jianbiao
AU  - Liu, Yong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recently, the image-wise implicit neural representation of videos, NeRV, has gained popularity for its promising results and swift speed compared to regular pixel-wise implicit representations. However, the redundant parameters within the network structure can cause a large model size when scaling up for desirable performance. The key reason of this phenomenon is the coupled formulation of NeRV, which outputs the spatial and temporal information of video frames directly from the frame index input. In this paper, we propose E-NeRV, which dramatically expedites NeRV by decomposing the image-wise implicit neural representation into separate spatial and temporal context. Under the guidance of this new formulation, our model greatly reduces the redundant model parameters, while retaining the representation ability. We experimentally find that our method can improve the performance to a large extent with fewer parameters, resulting in a more than $$8\times $$8×faster speed on convergence. Code is available at https://github.com/kyleleey/E-NeRV.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_16
DP  - Springer Link
SP  - 267
EP  - 284
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
ST  - E-NeRV
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_16.pdf
KW  - Implicit representation
KW  - Neural video representation
KW  - Spatial-temporal disentanglement
ER  - 

TY  - CONF
TI  - Leveraging Action Affinity and Continuity for Semi-supervised Temporal Action Segmentation
AU  - Ding, Guodong
AU  - Yao, Angela
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present a semi-supervised learning approach to the temporal action segmentation task. The goal of the task is to temporally detect and segment actions in long, untrimmed procedural videos, where only a small set of videos are densely labelled, and a large collection of videos are unlabelled. To this end, we propose two novel loss functions for the unlabelled data: an action affinity loss and an action continuity loss. The action affinity loss guides the unlabelled samples learning by imposing the action priors induced from the labelled set. Action continuity loss enforces the temporal continuity of actions, which also provides frame-wise classification supervision. In addition, we propose an Adaptive Boundary Smoothing (ABS) approach to build coarser action boundaries for more robust and reliable learning. The proposed loss functions and ABS were evaluated on three benchmarks. Results show that they significantly improved action segmentation performance with a low amount (5% and 10%) of labelled data and achieved comparable results to full supervision with 50% labelled data. Furthermore, ABS succeeded in boosting performance when integrated into fully-supervised learning.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_2
DP  - Springer Link
SP  - 17
EP  - 32
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_2.pdf
ER  - 

TY  - CONF
TI  - MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal Representation Learning
AU  - Zhang, David Junhao
AU  - Li, Kunchang
AU  - Wang, Yali
AU  - Chen, Yunpeng
AU  - Chandra, Shashwat
AU  - Qiao, Yu
AU  - Liu, Luoqi
AU  - Shou, Mike Zheng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recently, MLP-Like networks have been revived for image recognition. However, whether it is possible to build a generic MLP-Like architecture on video domain has not been explored, due to complex spatial-temporal modeling with large computation burden. To fill this gap, we present an efficient self-attention free backbone, namely MorphMLP, which flexibly leverages the concise Fully-Connected (FC) layer for video representation learning. Specifically, a MorphMLP block consists of two key layers in sequence, i.e., $$\mathtt {MorphFC_s}$$MorphFCsand $$\mathtt {MorphFC_t}$$MorphFCt, for spatial and temporal modeling respectively. $$\mathtt {MorphFC_s}$$MorphFCscan effectively capture core semantics in each frame, by progressive token interaction along both height and width dimensions. Alternatively, $$\texttt{MorphFC}_t$$MorphFCtcan adaptively learn long-term dependency over frames, by temporal token aggregation on each spatial location. With such multi-dimension and multi-scale factorization, our MorphMLP block can achieve a great accuracy-computation balance. Finally, we evaluate our MorphMLP on a number of popular video benchmarks. Compared with the recent state-of-the-art models, MorphMLP significantly reduces computation but with better accuracy, e.g., MorphMLP-S only uses 50% GFLOPs of VideoSwin-T but achieves 0.9% top-1 improvement on Kinetics400, under ImageNet1K pretraining. MorphMLP-B only uses 43% GFLOPs of MViT-B but achieves 2.4% top-1 improvement on SSV2, even though MorphMLP-B is pretrained on ImageNet1K while MViT-B is pretrained on Kinetics400. Moreover, our method adapted to the image domain outperforms previous SOTA MLP-Like architectures. Code is available at https://github.com/MTLab/MorphMLP.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_14
DP  - Springer Link
SP  - 230
EP  - 248
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
ST  - MorphMLP
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_14.pdf
KW  - MLP
KW  - Representation learning
KW  - Video classification
ER  - 

TY  - CONF
TI  - A Deep Moving-Camera Background Model
AU  - Erez, Guy
AU  - Weber, Ron Shapira
AU  - Freifeld, Oren
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In video analysis, background models have many applications such as background/foreground separation, change detection, anomaly detection, tracking, and more. However, while learning such a model in a video captured by a static camera is a fairly-solved task, in the case of a Moving-camera Background Model (MCBM), the success has been far more modest due to algorithmic and scalability challenges that arise due to the camera motion. Thus, existing MCBMs are limited in their scope and their supported camera-motion types. These hurdles also impeded the employment, in this unsupervised task, of end-to-end solutions based on deep learning (DL). Moreover, existing MCBMs usually model the background either on the domain of a typically-large panoramic image or in an online fashion. Unfortunately, the former creates several problems, including poor scalability, while the latter prevents the recognition and leveraging of cases where the camera revisits previously-seen parts of the scene. This paper proposes a new method, called DeepMCBM, that eliminates all the aforementioned issues and achieves state-of-the-art results. Concretely, first we identify the difficulties associated with joint alignment of video frames in general and in a DL setting in particular. Next, we propose a new strategy for joint alignment that lets us use a spatial transformer net with neither a regularization nor any form of specialized (and non-differentiable) initialization. Coupled with an autoencoder conditioned on unwarped robust central moments (obtained from the joint alignment), this yields an end-to-end regularization-free MCBM that supports a broad range of camera motions and scales gracefully. We demonstrate DeepMCBM’s utility on a variety of videos, including ones beyond the scope of other methods. Our code is available at https://github.com/BGU-CS-VIL/DeepMCBM.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_11
DP  - Springer Link
SP  - 177
EP  - 194
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_11.pdf
KW  - Background model
KW  - Background subtraction
KW  - Deep learning
KW  - Joint alignment
KW  - Moving camera
KW  - Regularization-free
KW  - Unsupervised
KW  - Video analysis
ER  - 

TY  - CONF
TI  - TDViT: Temporal Dilated Video Transformer for Dense Video Tasks
AU  - Sun, Guanxiong
AU  - Hua, Yang
AU  - Hu, Guosheng
AU  - Robertson, Neil
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Deep video models, for example, 3D CNNs or video transformers, have achieved promising performance on sparse video tasks, i.e., predicting one result per video. However, challenges arise when adapting existing deep video models to dense video tasks, i.e., predicting one result per frame. Specifically, these models are expensive for deployment, less effective when handling redundant frames and difficult to capture long-range temporal correlations. To overcome these issues, we propose a Temporal Dilated Video Transformer (TDViT) that consists of carefully-designed temporal dilated transformer blocks (TDTB). TDTB can efficiently extract spatiotemporal representations and effectively alleviate the negative effect of temporal redundancy. Furthermore, by using hierarchical TDTBs, our approach obtains an exponentially expanded temporal receptive field and therefore can model long-range dynamics. Extensive experiments are conducted on two different dense video benchmarks, i.e., ImageNet VID for video object detection and YouTube VIS for video instance segmentation. Excellent experimental results demonstrate the superior efficiency, effectiveness, and compatibility of our method. The code is available at https://github.com/guanxiongsun/TDViT.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_17
DP  - Springer Link
SP  - 285
EP  - 301
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
ST  - TDViT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_17.pdf
ER  - 

TY  - CONF
TI  - Flow Graph to Video Grounding for Weakly-Supervised Multi-step Localization
AU  - Dvornik, Nikita
AU  - Hadji, Isma
AU  - Pham, Hai
AU  - Bhatt, Dhaivat
AU  - Martinez, Brais
AU  - Fazly, Afsaneh
AU  - Jepson, Allan D.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this work, we consider the problem of weakly-supervised multi-step localization in instructional videos. An established approach to this problem is to rely on a given list of steps. However, in reality, there is often more than one way to execute a procedure successfully, by following the set of steps in slightly varying orders. Thus, for successful localization in a given video, recent works require the actual order of procedure steps in the video, to be provided by human annotators at both training and test times. Instead, here, we only rely on generic procedural text that is not tied to a specific video. We represent the various ways to complete the procedure by transforming the list of instructions into a procedure flow graph which captures the partial order of steps. Using the flow graphs reduces both training and test time annotation requirements. To this end, we introduce the new problem of flow graph to video grounding. In this setup, we seek the optimal step ordering consistent with the procedure flow graph and a given video. To solve this problem, we propose a new algorithm - Graph2Vid - that infers the actual ordering of steps in the video and simultaneously localizes them. To show the advantage of our proposed formulation, we extend the CrossTask dataset with procedure flow graph information. Our experiments show that Graph2Vid is both more efficient than the baselines and yields strong step localization results, without the need for step order annotation.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_19
DP  - Springer Link
SP  - 319
EP  - 335
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_19.pdf
KW  - Flow graphs
KW  - Instructional videos
KW  - Localization
KW  - Procedures
ER  - 

TY  - CONF
TI  - Spotting Temporally Precise, Fine-Grained Events in Video
AU  - Hong, James
AU  - Zhang, Haotian
AU  - Gharbi, Michaël
AU  - Fisher, Matthew
AU  - Fatahalian, Kayvon
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We introduce the task of spotting temporally precise, fine-grained events in video (detecting the precise moment in time events occur). Precise spotting requires models to reason globally about the full-time scale of actions and locally to identify subtle frame-to-frame appearance and motion differences that identify events during these actions. Surprisingly, we find that top performing solutions to prior video understanding tasks such as action detection and segmentation do not simultaneously meet both requirements. In response, we propose E2E-Spot, a compact, end-to-end model that performs well on the precise spotting task and can be trained quickly on a single GPU. We demonstrate that E2E-Spot significantly outperforms recent baselines adapted from the video action detection, segmentation, and spotting literature to the precise spotting task. Finally, we contribute new annotations and splits to several fine-grained sports action datasets to make these datasets suitable for future work on precise spotting.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19833-5_3
DP  - Springer Link
SP  - 33
EP  - 51
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19833-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19833-5_3.pdf
KW  - Temporally precise spotting
KW  - Video understanding
ER  - 

TY  - CONF
TI  - Soft-BAC: Soft Bidirectional Alignment Cost for End-to-End Automatic Speech Recognition
AU  - Wang, Yonghe
AU  - Zhang, Hui
AU  - Bao, Feilong
AU  - Gao, Guanglai
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Connectionist temporal classification (CTC) has gained success in both end-to-end ASR model and as an auxiliary task for attention-based sequence-to-sequence (S2S) system. However, the special topological structure of CTC and the modeling form that a redundant blank symbol to be optionally inserted between each modeling units makes the CTC inclined to model blank symbols, resulting in a worse than expected model alignment effect, and frames are usually aligned with redundant symbols. In this paper, we design a new simple topology and propose a novel smooth alignment optimization method named soft bidirectional alignment cost (soft-BAC), which is an alternative to the CTC. We propose a scheme that only inserts identifiers between consecutive repetitive labels and solve the alignment problem between two time series of speech-transcription pair by minimizing all costs of the left-to-right and right-to-left alignment process. Experiments on the LibriSpeech corpus show that the proposed soft-BAC method achieves significant improvement in word error rate and alignment effect over the CTC-based baseline model.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_18
DP  - Springer Link
SP  - 232
EP  - 243
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
ST  - Soft-BAC
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_18.pdf
KW  - CTC
KW  - End-to-end
KW  - Multitask learning
KW  - Soft bidirectional alignment cost
KW  - Speech recognition
ER  - 

TY  - CONF
TI  - An Attention-Based Approach to Accelerating Sequence Generative Adversarial Nets
AU  - Gao, Minglei
AU  - Zhang, Sai
AU  - Zhang, Xiaowang
AU  - Feng, Zhiyong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Automatic text generation is widely used in dialogue systems, machine translation and other fields. Sequence Generative Adversarial Network (SeqGAN) has achieved good performance in text generation tasks. Due to the discriminator can only evaluate the finished text, and cannot provide other valid information to the generator. When evaluating a single word, the Monte Carlo algorithm is mainly used to generate a complete text. This process requires a huge computational cost. As the length of the text increases, the time to obtain rewards will increase significantly. For text, different words have different effects on semantics, and keywords determine the final expression of semantics. Evaluation of the importance of each word is particularly critical. In this paper, we propose a new framework called AttGAN. We allow the discriminator to provide more features to the generator. Specifically, we add an attention layer to the new discriminator. The attention score is used as the basic reward so that the discriminator can calculate the reward value of each word through only one evaluation without multiple sampling by the generator. And to meet the requirements of valid reward, we further process the attention score. Our large number of experiments on synthetic data and tests on dialogue systems show that AttGAN can minimize computational costs and generate high-quality text. Furthermore, it also has a good performance in the generation of lengthy text.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_3
DP  - Springer Link
SP  - 31
EP  - 45
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_3.pdf
KW  - Attention
KW  - GAN
KW  - Text generation
ER  - 

TY  - CONF
TI  - Exploiting News Article Structure for Automatic Corpus Generation of Entailment Datasets
AU  - Cruz, Jan Christian Blaise
AU  - Resabal, Jose Kristian
AU  - Lin, James
AU  - Velasco, Dan John
AU  - Cheng, Charibeth
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Transformers represent the state-of-the-art in Natural Language Processing (NLP) in recent years, proving effective even in tasks done in low-resource languages. While pretrained transformers for these languages can be made, it is challenging to measure their true performance and capacity due to the lack of hard benchmark datasets, as well as the difficulty and cost of producing them. In this paper, we present three contributions: First, we propose a methodology for automatically producing Natural Language Inference (NLI) benchmark datasets for low-resource languages using published news articles. Through this, we create and release NewsPH-NLI, the first sentence entailment benchmark dataset in the low-resource Filipino language. Second, we produce new pretrained transformers based on the ELECTRA technique to further alleviate the resource scarcity in Filipino, benchmarking them on our dataset against other commonly-used transfer learning techniques. Lastly, we perform analyses on transfer learning techniques to shed light on their true performance when operating in low-data domains through the use of degradation tests.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_7
DP  - Springer Link
SP  - 86
EP  - 99
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_7.pdf
KW  - Automatic corpus creation
KW  - Low-resource languages
KW  - Transformer neural networks
ER  - 

TY  - CONF
TI  - Learning Vietnamese-English Code-Switching Speech Synthesis Model Under Limited Code-Switched Data Scenario
AU  - Nguyen, Cuong Manh
AU  - Phung, Lam Viet
AU  - Bui, Cuc Thi
AU  - Truong, Trang Van
AU  - Nguyen, Huy Tien
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Recent advances in deep learning facilitate the development of end-to-end Vietnamese text-to-speech (TTS) systems that produce Vietnamese voices with high intelligibility and naturalness. However, enabling these systems to speak Vietnamese and English words in the same utterance fluently remains a challenge known as the code-switching (CS) problem in speech synthesis. The main reason is that it is not easy to obtain a large amount of high-quality CS corpus from a Vietnamese speaker. In this paper, we explore the efficacy of three approaches, which are based on the Tacotron-2 end-to-end framework, to build such a Vietnamese TTS system under a limited code-switched data scenario: (1) CS synthesis based on grapheme-to-syllable (G2S), (2) CS synthesis based on speaker embedding, and (3) CS synthesis based on speaker embedding and language embedding. We handle English and Vietnamese words in the code-switched input text by converting them into Vietnamese syllables using our G2S model. For the speaker-embedding based approach, we combine Vietnamese monolingual data in our dataset with an English public dataset to train a multi-speaker Tacotron-2 system. The experimental results show that adding language embedding is effective, and training with character input representations outperforms phonemes. Thus, the speaker and language-embedding based approach achieves strong results in naturalness for CS speech. Besides, the G2S-based CS synthesis also has good results, with almost absolute English pronunciation accuracy.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_12
DP  - Springer Link
SP  - 153
EP  - 163
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_12.pdf
KW  - Code-switching
KW  - Multi-speaker
KW  - Speech synthesis
KW  - Tacotron-2
ER  - 

TY  - CONF
TI  - Fake News Detection Using Multiple-View Text Representation
AU  - Ha, Tuan
AU  - Gao, Xiaoying
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Fake news, or false information presented as news, is an increasing risk in today’s society. The practice of automatically detecting fake news is by no means an easy task, since the authors of fake news intend to confuse the readers and make them vulnerable to false information. Traditional methods only consider a limited number of characteristics of fake news, and hence, they face many difficulties in predicting the credibility of the news. This paper proposes WES, an integrated stacking model where the multiple-view text representation from (i) Word-level features, (ii) Emotional features, and (iii) Sentence-level features are used to classify the news article. The proposed system is applied on a real-world dataset, FakeNewsNet, and the experimental results show that the proposed approach achieves significantly better performance than the current state-of-the-art fake news detection method.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_8
DP  - Springer Link
SP  - 100
EP  - 112
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_8.pdf
KW  - Convolutional neural networks
KW  - Fake news detection
KW  - Multiple-view text representation
ER  - 

TY  - CONF
TI  - Short Text Clustering Using Joint Optimization of Feature Representations and Cluster Assignments
AU  - Sun, Liping
AU  - Du, Tingli
AU  - Duan, Xiaoyu
AU  - Luo, Yonglong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - The application of traditional text clustering methods to short text data is inefficient owing to the high dimensionality and semantic sparseness of such data. Contrastingly, convolutional neural networks can capture the local information between consecutive words in a sentence and extract the semantic features of the text. In this paper, we propose a short text clustering method based on convolutional autoencoders (CAE-STC) that jointly optimizes feature representations and cluster assignments. The proposed method employs a convolutional autoencoder to learn deep text feature representations and preserve the local structure of text generation distribution. By integrating the clustering loss and convolutional autoencoder’s reconstruction loss, a unified loss function is formulated to update the network parameters and cluster centers iteratively, improving the performance of the feature learning and clustering tasks. The results of extensive experiments conducted on three public short text datasets demonstrate that the proposed method outperforms several popular clustering methods in terms of the normalized mutual information and clustering accuracy.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_17
DP  - Springer Link
SP  - 217
EP  - 231
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_17.pdf
KW  - Convolutional autoencoder
KW  - Feature learning
KW  - Short text clustering
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Graph Convolutional Network Exploring Label Relations for Multi-label Text Classification
AU  - Pu, Ting
AU  - Yin, Shiqun
AU  - Li, Wenwen
AU  - Xu, Wenqiang
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Multi-label Text Classification (MLTC) aims to learn a classifier that is able to automatically annotate a data point with the most relevant subset of labels from an large number of labels. Label semantics and relationships are important information for multi-label text classification. Existing methods tend to ignore explore high-order dependencies among labels. In this paper, a model called HRGCN (Hop-Residual graph convolutional network) is proposed to capture label dependency and label structure. The hop-connected graph convolutional network can obtain the deep dependence between the labels through a label graph, where the label graph constructed by a correlation matrix and a feature matrix represents the co-occurrence of the labels. Meanwhile, the self-attention mechanism allows to assign different weights to the text features extracted by BiGRU. Fusion of text representation and label representation to form label-text awareness to achieve interaction and generate multi-label classifiers for end-to-end training. Experimental results demonstrate that the proposed model achieves better performance compared to baseline models on the dataset RCV1-V2 and AAPD.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_10
DP  - Springer Link
SP  - 127
EP  - 139
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_10.pdf
KW  - Graph convolutional network
KW  - Multi-label text classification
KW  - Self-attention
ER  - 

TY  - CONF
TI  - A Calibration Method for Sentiment Time Series by Deep Clustering
AU  - Wu, Jingyi
AU  - Qiu, Baopu
AU  - Shang, Lin
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Sentiment time series is an effective tool to describe the trend of users’ emotions towards specific topics over time. Most existing studies generate time series based on predicted results of the sentiment classifiers, which may not correspond to the actual values due to the lack of labeled data or the limited performance of the classifier. To alleviate this problem, we propose a calibrated-based method to generate time series composed of accurate sentiment scores. The texts are embedded into high dimensional representations with a feature extractor and then get fine-tuned and compressed into lower dimensional space with the unsupervised learning of an autoencoder. Then a deep clustering method is applied to partition the data into different clusters. A group of representative samples are selected according to their distance from the clustering centers. Finally combined the evaluation results on the sampled data and the predicted results, the calibrated sentiment score is obtained. We build a real-world dataset crawled from Sina Weibo and perform experiments on it. We compare the distance errors of predicted-based method with our calibrated-based method. The experimental results indicate that our method reduces the uncertainty raised by sampling as well as maintains excellent performance.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_1
DP  - Springer Link
SP  - 3
EP  - 16
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_1.pdf
KW  - Deep clustering
KW  - Representative sampling
KW  - Sentiment time series
ER  - 

TY  - CONF
TI  - Combining Improvements for Exploiting Dependency Trees in Neural Semantic Parsing
AU  - Xie, Defeng
AU  - Ji, Jianmin
AU  - Xu, Jiafei
AU  - Ji, Ran
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - The dependency tree of a natural language sentence can capture the interactions between semantics and words. However, it is unclear whether those methods which exploit such dependency information for semantic parsing can be combined to achieve further improvement and the relationship of those methods when they combine. In this paper, we examine three methods to incorporate such dependency information in a Transformer based semantic parser and empirically study their combinations. We first replace standard self-attention heads in the encoder with parent-scaled self-attention (PASCAL) heads, i.e., the ones that can attend to the dependency parent of each token. Then we concatenate syntax-aware word representations (SAWRs), i.e., the intermediate hidden representations of a neural dependency parser, with ordinary word embedding to enhance the encoder. Later, we insert the constituent attention (CA) module to the encoder, which adds an extra constraint to attention heads that can better capture the inherent dependency structure of input sentences. Transductive ensemble learning (TEL) is used for model aggregation, and an ablation study is conducted to show the contribution of each method. Our experiments show that CA is complementary to PASCAL or SAWRs, and PASCAL + CA provides state-of-the-art performance among neural approaches on ATIS, GEO, and JOBS.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_5
DP  - Springer Link
SP  - 58
EP  - 72
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_5.pdf
KW  - CA
KW  - PASCAL
KW  - SAWRs
KW  - Semantic parsing
ER  - 

TY  - CONF
TI  - Rumor Detection on Microblogs Using Dual-Grained Feature via Graph Neural Networks
AU  - Xu, Shouzhi
AU  - Liu, Xiaodi
AU  - Ma, Kai
AU  - Dong, Fangmin
AU  - Xiang, Shunzhi
AU  - Bing, Changsong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Online social media platforms have been developing rapidly in the era of the Internet and big data, which accelerate rumors being circulated. The spread of rumors might damage citizen rights and disturb social stability. Rumor detection on social media is a challenging task worldwide due to rumor’s feature of the high speed, fragmental information, and extensive range. In this paper, we propose a novel model for rumor detection based on Graph Neural Networks (GNN), named Dual-grained  Feature  Aggregation  Graph  Neural  Networks (Du-FAGNN). It applies a Graph Convolutional Network (GCN) with a graph of rumor propagation to learn the text-granularity representations with the spreading of events. We employ a GNN with a document graph to update aggregated features of both word and text granularity, it helps to form final representations of events to detect rumors. Experiments on the Sina Weibo dataset validate the performance of the proposed method for rumor detection.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_16
DP  - Springer Link
SP  - 205
EP  - 216
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_16.pdf
KW  - Dual-grained aggregation
KW  - Graph neural networks
KW  - Rumor detection
KW  - Rumor propagation
ER  - 

TY  - CONF
TI  - Punctuation Prediction in Vietnamese ASRs Using Transformer-Based Models
AU  - Bui, Viet The
AU  - Tran, Oanh Thi
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Punctuation prediction is the task of predicting and inserting punctuation like periods, commas, exclamation marks, etc. into the appropriate positions in transcribed texts in ASR systems. This helps to improve user readability and the performance of many downstream tasks. While most related studies have been performed for popular languages like English and Chinese, there is very little work done for low-resource languages. In order to stimulate the research on these languages, in this paper, we target to improve the quality of punctuation prediction for Vietnamese ASRs. Specifically, we propose a method based on recent advances on pre-trained language models (LMs) for general purposes such as BERT and ELECTRA. The benefit of using these models is that they can be effectively fine-tuned on this punctuation prediction task where only a small amount of training data is available. To further enhance the performance, a simple yet effective technique to provide more context information in predicting punctuation marks for the very left and right words in each segment is also proposed. The experimental results of the proposed model on public benchmark datasets are quite promising. Overall, the proposed architecture substantially enhanced the prediction performance by a large margin and yielded a new state-of-the-art result on these datasets. Specifically, we achieved the $$F_1$$F1scores of 71.49% and 80.38% on the Novel and Newspaper public datasets, respectively.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_15
DP  - Springer Link
SP  - 191
EP  - 204
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_15.pdf
KW  - Punctuation prediction
KW  - vELECTRA
KW  - viBERT
KW  - Vietnamese ASR
ER  - 

TY  - CONF
TI  - Deep Semantic Fusion Representation Based on Special Mechanism of Information Transmission for Joint Entity-Relation Extraction
AU  - Xu, Wenqiang
AU  - Yin, Shiqun
AU  - Zhao, Junfeng
AU  - Pu, Ting
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Joint entity and relation extraction is still a challenging problem in natural language processing, which goal is to extract all possible relational triplets from original texts. Nevertheless, previous work rarely considered the integration of relation information to capture fine-grained correlations over token and relation spaces before extracting the entity pair, resulting in the unreasonable matching of entities and relations. In this paper, we propose a deep semantics fusing representation method based on a special mechanism of information transmission for joint entity relation extraction (DSFR). Specially, we called this special information transmission mechanism with a gate structure as UMIT, and then fuse the fine-grained information of tokens and relations by stacking multiple layers of UMIT. Finally, we extract the head and tail entities of a sentence under a certain relation by sequence labeling. Experiments on two publicly available New York Times (NYT) and WebNLG corpus show that our proposed approaches can effectively extract overlapping triplets and achieve better performance.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_6
DP  - Springer Link
SP  - 73
EP  - 85
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_6.pdf
KW  - Gate architecture
KW  - Information transmission mechanism
KW  - Joint entity relation extraction
KW  - Overlapping triplet
ER  - 

TY  - CONF
TI  - Autoregressive Pre-training Model-Assisted Low-Resource Neural Machine Translation
AU  - Wu, Nier
AU  - Hou, Hongxu
AU  - Ji, Yatu
AU  - Zheng, Wei
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Pre-training methods have been proven to significantly improve language understanding ability of the model. However, when dealing with machine translation tasks involving two or more languages, the pre-training method can only handle a single language and prevent further improvement of machine translation performance. Therefore, there are two main methods to improve the quality of machine translation model by using the pre-training model. One is to use the word embedding generated by the pre-training model as the modeling unit. Second is to make the machine translation model learn the probability distribution of the pre-training model through the knowledge distillation method. In addition, the self-attention based pre-training model affects the effect of machine translation due to the “training-fine-tuning” difference and limited by the assumption of conditional independence. For this reason, we proposed a XLNet based pre-training method, that corrects the defects of the general self-encoding based pre-training model, and enhance NMT model for context feature extraction. We conducted experiments on the CCMT2019 Mongolian-Chinese (Mo-Zh), Uyghur-Chinese (Ug-Zh) and Tibetan-Chinese (Ti-Zh) tasks, our method significantly improves the quality compared to the baseline (Transformer), which fully verifies the effectiveness.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_4
DP  - Springer Link
SP  - 46
EP  - 57
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_4.pdf
KW  - Low-resource
KW  - Machine translation
KW  - Pre-training
KW  - XLNet
ER  - 

TY  - CONF
TI  - Performance-Driven Reinforcement Learning Approach for Abstractive Text Summarization
AU  - Nguyen, Trang-Phuong N.
AU  - Van, Nam-Chi
AU  - Tran, Nhi-Thao
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Recently, the use of Reinforcement Learning with Neural Networks in Abstractive Summarization is getting more popular, but still currently restricted. In this paper, we propose PEARL as a novel framework to expand the proficiency of Reinforcement Learning approach in Abstractive Text Summarization. PEARL consists of two out-of-the-box Reinforcement Learning algorithms: $$F_{Rouge}$$FRougeand $$D_{Threshold}$$DThreshold, where $$F_{Rouge}$$FRougereconstructs the training objective, and $$D_{Threshold}$$DThresholdhelps to improve the flexibility for the arbitrary data. We evaluate PEARL in the large-scale CNN/DailyMail and the medium-scale VNTC-Abs datasets. Results show that our PEARL produces significantly greater Rouge scores than baselines as well as achieves the new state-of-the-art model without either pre-trained models or extra training data. This research provides proof of validity based on data analysis.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_14
DP  - Springer Link
SP  - 177
EP  - 190
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_14.pdf
KW  - Abstractive Text Summarization
KW  - Cohesion threshold
KW  - PEARL
KW  - Performance-driven
KW  - REINFORCE
KW  - Reinforcement Learning
ER  - 

TY  - CONF
TI  - A Weak Supervision Approach with Adversarial Training for Named Entity Recognition
AU  - Shao, Jianxuan
AU  - Bu, Chenyang
AU  - Ji, Shengwei
AU  - Wu, Xindong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Named entity recognition (NER) is a basic task of natural language processing (NLP), whose purpose is to identify named entities such as the names of persons, places, and organizations in the corpus. Utilizing neural networks for feature extraction, followed by conditional random field (CRF) layer decoding, is effective for the NER task. However, achieving reliable results using neural networks generally requires a large amount of labeled data and the acquisition of high-quality labeled data is costly. To obtain a better NER effect without labeled data, we propose a weak supervision approach with adversarial training (WSAT). WSAT obtains supervised information and domain knowledge through labeling functions, including external knowledge bases, heuristic functions, and generic entity recognition tools. The labeled results are aggregated through the linked hidden Markov model (linked HMM), and adversarial training strategies are added when using the aggregated results for training. We evaluate WSAT on two real-world datasets. When compared to rival algorithms, the F1 values are improved by approximately 2% and 1% on the MSRA and Resume NER datasets, respectively.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_2
DP  - Springer Link
SP  - 17
EP  - 30
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_2.pdf
KW  - Adversarial training
KW  - Named entity recognition
KW  - Weak supervision
ER  - 

TY  - CONF
TI  - Multi-task Text Normalization Approach for Speech Synthesis
AU  - Bui, Cuc Thi
AU  - Truong, Trang Van
AU  - Nguyen, Cuong Manh
AU  - Phung, Lam Viet
AU  - Nguyen, Manh Tien
AU  - Nguyen, Huy Tien
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Text normalization for Text-To-Speech includes several challenging tasks in natural language processing such as verbalizing abbreviations, Out-Of-Vocabulary (OOV) words, and chunking phrases for long sentences without punctuation. Instead of dealing with these tasks independently, we propose a multi-task end-to-end model based on a denoising auto-encoder. As enriching information via multi-task learning and text denoising, the proposed approach shows improvement in the text normalization task, especially for complicated cases which require context and language understanding. In addition, we also design a novel process of data prepossessing to leverage annotated data for training. According to experiments on a handcrafted test set of 200,000 sentences in Vietnamese, our model achieves an overall accuracy of 95.5%.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_13
DP  - Springer Link
SP  - 164
EP  - 176
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_13.pdf
KW  - End-to-end model
KW  - Handle abbreviation
KW  - Handle OOV words
KW  - Machine translation
KW  - Prosodic phrasing
KW  - Speech synthesis
KW  - Text normalization
ER  - 

TY  - CONF
TI  - Improving Long Content Question Generation with Multi-level Passage Encoding
AU  - Zhu, Peide
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Generating questions that can be answered with word spans from passages is an important natural language task, which can be used for educational applications, question-answering systems, and conversational systems. Existing question generation models suffer from creating questions that are often unrelated to the context passage and answer span. In this paper, we first analyze questions generated by a common baseline model: we find over half of the generated questions that are rated as the lowest quality to be semantically unrelated to the context passage. We then investigate how humans ask factual questions and show that most often they are a reformulation of the target sentence and information from context passage. Based on these findings, we propose a multi-level encoding and gated attention fusion based neural network model for question generation (QG) which overcomes these shortcomings. Our experiments demonstrate that our model outperforms existing state-of-art seq2seq QG models.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_11
DP  - Springer Link
SP  - 140
EP  - 152
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_11.pdf
ER  - 

TY  - CONF
TI  - Generating Pseudo Connectives with MLMs for Implicit Discourse Relation Recognition
AU  - Jiang, Congcong
AU  - Qian, Tieyun
AU  - Chen, Zhuang
AU  - Tang, Kejian
AU  - Zhan, Shaohui
AU  - Zhan, Tao
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Due to the lack of connectives, the recognition of implicit discourse relations faces a big challenge. An early attempt overcomes this difficulty by predicting connectives with the use of the statistical language model. Recent years have witnessed the great success of masked language models (MLM). Then a new problem naturally arises, i.e., how can connectives benefit implicit discourse relation classification from such models? In this paper, we address this problem by developing a novel framework to generate the pseudo connectives using the pre-trained MLM. The key idea is to treat the absent connectives as missing words between two arguments and produce the pseudo connective from its contexts by fine-tuning MLM on the classification task. Moreover, we leverage the real connectives in explicit discourse relations to supervise the generation of pseudo connectives. Extensive experiments show that our model achieves the state-of-the-art performance on the PDTB benchmark.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89363-7_9
DP  - Springer Link
SP  - 113
EP  - 126
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89363-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89363-7_9.pdf
KW  - Connective
KW  - Implicit discourse relation
KW  - Masked language model
ER  - 

TY  - CONF
TI  - A Novel Transfer-Learning Network for Image Inpainting
AU  - Chen, Hui
AU  - Zhang, Zhichao
AU  - Deng, Jinsheng
AU  - Yin, Xiaoqing
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Image restoration techniques have developed rapidly in recent years. Some high-level vision tasks such as style transfer, automatic coloring, and large mask inpainting rely on deep learning methods to retrieve specific image attributes. However, due to the lack of a key remainder, the quality of image restoration remains at a low level. For instance, when the mask is large enough, traditional deep learning methods cannot imagine and fill a car on a bridge from a model. It is all dependent on the capacity of neural imagination. This is what an abstract neuron is good at. In this paper, we not only find specific neurons to guide semantic retrieval but also discover more neurons that serve as the indicator. In addition, we propose three principles to guarantee the leverage of reasonable visualization and coherent accuracy in terms of neuron guidance. A novel network called the Transfer-learning Network is designed to adopt the joint training strategy, multi-modal guided neurons, and multi-path attention edge algorithm for inpainting in a coarse-to-fine manner. This is the first time an extremely large mask is filled (35%–66%), guided by a high-level understanding of an image from abstract neuron reflection. Through ablation and combined experiments, the Transfer-learning Network validates that artificial neurons enhance the performance of joint training in multitasking vision problems. Therefore, this joint training framework meets the requirements of refining the background, i.e., removing meaningless noise more sharply and smartly between junior and advanced comprehensive vision tasks.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_3
DP  - Springer Link
SP  - 20
EP  - 27
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_3.pdf
KW  - Deep learning
KW  - High semantic guided training
KW  - Large mask inpainting
KW  - Multi-modal neuron
ER  - 

TY  - CONF
TI  - A Region Descriptive Pre-training Approach with Self-attention Towards Visual Question Answering
AU  - Kolawole, Bisi Bode
AU  - Lee, Minho
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Concatenation of text (question-answer) and image has been the bedrock of most visual language systems. Existing models concatenate the text (question-answer) and image inputs in a forced manner. In this paper, we introduce a region descriptive pre-training approach with self-attention towards VQA. The model is a new learning method that uses the image region descriptions combined with object labels to create a proper alignment between the text(question-answer) and the image inputs. We study the text associated with each image and discover that extracting the region descriptions from the image and using it during training greatly improves the model’s performance. In this research work, we use the region description extracted from the images as a bridge to map the text and image inputs. The addition of region description makes our model perform better against some recent state-of-the-art models. Experiments demonstrated in this paper show that our model significantly outperforms most of these models.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_9
DP  - Springer Link
SP  - 73
EP  - 80
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_9.pdf
KW  - Object label
KW  - Pre-training
KW  - Region descriptions
KW  - Visual question answering
ER  - 

TY  - CONF
TI  - Dynamical Characteristics of State Transition Defined by Neural Activity of Phase in Alzheimer’s Disease
AU  - Nobukawa, Sou
AU  - Ikeda, Takashi
AU  - Kikuchi, Mitsuru
AU  - Takahashi, Tetsuya
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - In recent findings of dynamical functional connectivity (dFC) as the degree of variability for functional connectivity, the dFC reflects the abilities and deficits in cognitive functions. Recently, we introduced the instantaneous phase difference between electroencephalography (EEG) signals (called the dynamical phase synchronization (DPS) approach) and succeeded in detecting moment-to-moment dFC dynamics. In this approach, neural interactions in whole-brain activity are decomposed into phase differences of pairwise brain regions. From the viewpoint of “emergence” in complex systems where interactions among several components produce additional functions, an integrated analysis of interactions in a whole-brain network without separating each interaction in pairwise brain regions might lead to new understanding of cognitive functions. Alzheimer’s disease (AD) involves cognitive impairments due to the loss of multiple neural interactions and affects dFC. We hypothesized that instantaneous phase dynamics without decomposing to pairwise instantaneous phase differences would bring another dimension of understanding of alternations of dFC regarding cognitive impairment in AD. To prove this hypothesis, we introduced dynamic states based on instantaneous frequency distribution across the whole brain. Upon applying this method to EEG signals of healthy controls (HC) and subjects with AD, the results showed that the state of the occipital leading phase in the AD group was more difficult to maintain. Moreover, the degree of maintenance of this state has a relatively high correlation with cognitive function in AD. In conclusion, dynamic states based on whole-brain instantaneous frequency distribution might be an additional approach to reveal different aspects of dFC among the other approaches.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_6
DP  - Springer Link
SP  - 46
EP  - 54
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_6.pdf
KW  - Alzheimer’s disease
KW  - Cognitive functions
KW  - Dynamical functional connectivity
KW  - Electroencephalography
ER  - 

TY  - CONF
TI  - Stress Recognition with EEG Signals Using Explainable Neural Networks and a Genetic Algorithm for Feature Selection
AU  - Pan, Eric
AU  - Rahman, Jessica Sharmin
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Stress is a natural human response to external conditions which have been studied for a long time. Since prolonged periods of stress can cause health deterioration, it is important for researchers to understand and improve its detection. This paper uses neural network techniques to classify whether an individual is stressed, based on signals from an electroencephalogram (EEG), a popular physiological sensor. We also overcome two prominent limitations of neural networks: low interpretability due to the complex nature of architectures, and hindrance to performance due to high data dimensionality. We resolve the first limitation with sensitivity analysis-based rule extraction, while the second limitation is addressed by feature selection via a genetic algorithm. Using summary statistics from the EEG, a simple Artificial Neural Network (ANN) is able to achieve 93.8% accuracy. The rules extracted are able to explain the ANN’s behaviour to a good degree and thus improve interpretability. Adding feature selection with a genetic algorithm improves average accuracy achieved by the ANN to 95.4%.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_16
DP  - Springer Link
SP  - 136
EP  - 143
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_16.pdf
KW  - Artificial Neural Network
KW  - EEG
KW  - Genetic algorithm
KW  - Neural network explainability
KW  - Rule extraction
KW  - Stress detection
ER  - 

TY  - CONF
TI  - Scale-Aware Multi-stage Fusion Network for Crowd Counting
AU  - Liu, Qi
AU  - Sang, Jun
AU  - Wang, Fusen
AU  - Yang, Li
AU  - Xia, Xiaofeng
AU  - Sang, Nong
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Crowd counting has been widely researched and many hopeful results have been obtained recently. Due to the large-scale variation and complex background noise, accurate crowd counting is still very difficult. In this paper, we raise a simple but efficient network named SMFNet, which focuses on dealing with the above two problems of highly congested noisy scenes. SMFNet consists of two main components: multi-scale dilated convolution block (MDCB) for multi-scale features extraction and U-shape fusion structure (UFS) for multi-stage features fusion. MDCB can address the challenge of scale variation via capturing multi-scale features. UFS provides an effective structure that continuously combines outputs of different stages to achieve the capability of optimizing multi-scale features and increasing resistance to background noise. Compared with the existing methods, SMFNet achieves better performance in capturing effective and richer multi-scale features through progressively multi-stage fusion. To evaluate our method, we have demonstrated it on three popular crowd counting datasets (ShanghaiTech, UCF_CC_50, UCF-QNRF). Experimental results indicate that SMFNet can achieve state-of-the-art results on highly congested scenes datasets.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_1
DP  - Springer Link
SP  - 3
EP  - 11
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_1.pdf
KW  - Crowd counting
KW  - Multi-scale features
KW  - Multi-stage fusion
ER  - 

TY  - CONF
TI  - A SSA-Based Attention-BiLSTM Model for COVID-19 Prediction
AU  - An, Shuqi
AU  - Chen, Shuyu
AU  - Yuan, Xiaohan
AU  - Yuwen, Lu
AU  - Mei, Sha
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - The Corona Virus Disease 2019 (COVID-19) has widely spread over the world and comes up with new challenges to the research community. Accurately predicting the number of new infections is essential for optimizing available resources and slowing the progression of such diseases. Long short-term memory network (LSTM) is a typical method for COVID-19 prediction in deep learning, but it is difficult to extract potentially important features in time series effectively. Thus, we proposed a Bidirectional LSTM (BiLSTM) model based on the attention mechanism (ATT) and used the Sparrow Search Algorithm (SSA) for parameter tuning, to predict the daily new cases of COVID-19. We capture the information in the past and future through the BiLSTM network and apply the attention mechanism to assign different weights to the hidden state of BiLSTM, enhance the ability of the model to learn vital information, and use the SSA to optimize the critical parameters of the model for matching the characteristics of COVID-19 data, enhance the interpretability of the model parameters. This study is based on daily confirmed cases collected from six countries: Egypt, Ireland, Iran, Japan, Russia, and the UK. The experimental results show that our proposed model has the best predictive performance among all the comparison models.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_14
DP  - Springer Link
SP  - 119
EP  - 126
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_14.pdf
KW  - Attention mechanism
KW  - BiLSTM
KW  - COVID-19
KW  - Sparrow search algorithm
ER  - 

TY  - CONF
TI  - Explaining Neural Network Results by Sensitivity Analysis for Deception Detection
AU  - Zhang, Xuecheng
AU  - Zhu, Xuanying
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Previous researches show that people are only able to recognise deception with an accuracy of 54%. In this paper, using physiological signals from observers, we train a three-layer neural network, a long short-term memory (LSTM) and a multi-tasking learning neural network (MTL-NN). We demonstrate that examined models are able to identify deception with an accuracy up to 62%, surpassing the average accuracy of human deception detection. The superior deception recognition ability shows that these tools are capable of helping people discriminate against deception. Further, to improve the interpret-ability of neural networks, we extract rules from the trained models using sensitivity analysis. We find that the rule extraction methods using sensitivity analysis along with genetic algorithm (GA) based data reduction successfully explain all three neural network models. We hope the rule extraction methods can help to improve the interpret-ability of neural networks.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_15
DP  - Springer Link
SP  - 127
EP  - 135
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_15.pdf
KW  - Genetic algorithm
KW  - LSTM
KW  - MTL
KW  - Neural network explanation
KW  - Rule extraction
KW  - Sensitivity analysis
ER  - 

TY  - CONF
TI  - UED: A Unified Encoder Decoder Network for Visual Dialog
AU  - Chen, Cheng
AU  - Gu, Xiaodong
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - This paper addresses the problem of visual dialog, which aims to answer multi-round questions based on the dialog history and image content. This is a challenging task because a question may be answered in relations to any previous dialog and visual clues in image. Existing methods mainly focus on discriminative setting, which design various attention mechanisms to model interaction between answer candidates and multi-modal context. Despite having impressive results with attention based model for visual dialog, a universal encoder-decoder for both answer understanding and generation remains challenging. In this paper, we propose UED, a unified framework that exploits answer candidates to jointly train discriminative and generative tasks. UED is unified in that (1) it fully exploiting the interaction between different modalities to support answer ranking and generation in a single transformer based model, and (2) it uses the answers as anchors to facilitate both two settings. We evaluate the proposed UED on the VisDial dataset, where our model outperforms the state-of-the-art.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_12
DP  - Springer Link
SP  - 101
EP  - 109
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
ST  - UED
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_12.pdf
KW  - Cross modal learning
KW  - Encoder decoder network
KW  - Visual dialog
ER  - 

TY  - CONF
TI  - Intermediate Sensitivity of Neural Activities Induces the Optimal Learning Speed in a Multiple-Timescale Neural Activity Model
AU  - Kurikawa, Tomoki
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Collective dynamics of the neural population are involved in a variety of cognitive functions. How such neural dynamics are shaped through learning and how the learning performance is related to the property of the individual neurons are fundamental questions in neuroscience. Previous model studies answered these questions by using developing machine-learning techniques for training a recurrent neural network. However, these techniques are not biologically plausible. Does another type of learning method, for instance, a more biologically plausible learning method, shape the similar neural dynamics and the similar relation between the learning performance and the property of the individual neurons to those observed in the previous studies? In this study, we have used the recently proposed learning model with multiple timescales in the neural activity, which is more biologically plausible, and analyzed the neural dynamics and the relation regarding the sensitivity of neurons. As result, we have found that our model shapes similar neural dynamics and the relation. Further, the intermediate sensitivity of neurons that is optimal for the learning speed generates a variety of neural activity patterns in line with the experimental observations in the neural system. This result suggests that the neural system might develop the sensitivity of neural activities to optimize the learning speed through evolution.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_8
DP  - Springer Link
SP  - 64
EP  - 72
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_8.pdf
KW  - Delayed match to sample
KW  - Learning
KW  - Multiple timescale
ER  - 

TY  - CONF
TI  - BCI Speller on Smartphone Device with Diminutive-Sized Visual Stimuli
AU  - Serkali, Nuray
AU  - Shomanov, Adai
AU  - Kudaibergenova, Madina
AU  - Lee, Min-Ho
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - In real-world BCI applications, small-sized and low-impact stimuli are more appropriate for smart devices. However, diminishing the stimuli intensity leads to a reduction of P300 amplitude, causing lower system performance. The purpose of this study is to propose a state-of-the-art BCI speller where diminutive (less than 1 mm) visual stimuli were implemented in a smartphone interface. To boost the task-relevant brain components, participants performed a certain mental task according to the given cue signs. Additionally, we applied a data-driven optimization approach to represent the user-specific spatial-temporal features. The results showed 96.8% of spelling accuracy with a maximum ITR of 31.6 [bits/min], which is comparable or even superior to conventional speller systems. Our study demonstrated the feasibility to create more reliable and practical BCI spelling systems in the future.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_17
DP  - Springer Link
SP  - 144
EP  - 151
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_17.pdf
KW  - BCI speller
KW  - Event related potential (ERP)
KW  - Late positive potential (LPP)
KW  - Mental task
KW  - Sound imagery
ER  - 

TY  - CONF
TI  - Analysis of Topological Variability in Mouse Neuronal Populations Based on Fluorescence Microscopy Images
AU  - Zaleshina, Margarita
AU  - Zaleshin, Alexander
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - In this work, we processed sets of images obtained by light-sheet fluorescence microscopy method. We selected different cell groups and determined areas occupied by ensembles of cell groups in mouse brain tissue. Recognition of mouse neuronal populations was performed on the basis of visual properties of fluorescence-activated cells. In our study 60 fluorescence microscopy datasets obtained from 23 mice ex vivo were analyzed. Based on data from light-sheet microscopy datasets, we identified visual characteristics of elements in multi-page TIFF files, such as the density of surface fill and its distribution over the study area, the boundaries of distinct objects and object groups, and the boundaries between homogeneous areas. To identify topological properties, we performed operations such as contouring and segmentation, and identification of areas of interest. Individual elements in fluorescence microscopy records were selected based on their brightness in grayscale mode. Frequently occurring patterns formed by individual elements were classified and found in other sets of images: this way we built a training sample and classified the optogenetics data. The presence of training samples was tested for different types of fluorescence microscopy. We selected and constructed six sets of typical samples, with certain topological properties, on the basis of the density at the boundaries, the density inside the boundaries, and the shape type.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_11
DP  - Springer Link
SP  - 90
EP  - 97
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_11.pdf
KW  - Brain mapping
KW  - Mouse brain
KW  - Optogenetics
KW  - Pattern recognition
ER  - 

TY  - CONF
TI  - Cortical Coding of Surface Textures and Contour Shapes in the Intermediate-Level Visual Area V4
AU  - Machida, Itsuki
AU  - Kodama, Atsushi
AU  - Kimura, Kouji
AU  - Shishikura, Motofumi
AU  - Tamura, Hiroshi
AU  - Sakai, Ko
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Integration of multiple properties of an object is a fundamental function for object recognition. Surface texture and contour shape are thought to be crucial characteristics that contribute to the recognition. We investigated the cortical coding of surface and shape in monkey V4, with the focus on the integration of the two. To examine how V4 neurons code surface and shape; whether single neurons jointly code the two, or distinct groups of neurons independently code the two, we examined the activities of V4 neurons in response to natural image patches and their silhouette, wherein the former included both contour shape and surface properties, such as texture and color, but the latter included only contour shape. We analyzed the correlation between the spike counts responding to the natural and silhouette patches. The correlation coefficient across neurons was 0.56, suggesting partial joint-coding of surface and shape in V4. The modulation latency was 78 and 57 ms for the natural and silhouette patches. The dimension of the neural responses for the natural patches was approximately 30% greater than that for the silhouette patches. These results indicate more complicated computation and representation for the natural images compared to the silhouette images. These results suggest two sub-populations of neurons, one with joint-coding of surface and shape, and the other without.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_5
DP  - Springer Link
SP  - 37
EP  - 45
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_5.pdf
KW  - Computational neuroscience
KW  - Cortex
KW  - Electrophysiology
KW  - V4
KW  - Vison
ER  - 

TY  - CONF
TI  - BPFNet: A Unified Framework for Bimodal Palmprint Alignment and Fusion
AU  - Li, Zhaoqun
AU  - Liang, Xu
AU  - Fan, Dandan
AU  - Li, Jinxing
AU  - Zhang, David
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Bimodal palmprint recognition use palm vein and palmprint images at the same time, which can achieve high accuracy and has intrinsic anti-falsification property. For bimodal palmprint recognition and verification, the ROI detection and ROI alignment of palmprint region-of-interest (ROI) are two crucial points for bimodal palmprint matching. Most existing plamprint ROI detection methods are based on keypoint detection algorithms, however the intrinsic difficulties lying in keypoint detection tasks make the results not accurate. Besides, in these methods the ROI alignment and feature fusion algorithms at image-level are not fully investigated. To improve the performance and bridge the gap, we propose our Bimodal Palmprint Fusion Network (BPFNet) which focuses on ROI localization, alignment and bimodal image fusion. BPFNet is an end-to-end deep learning framework which contains two parts: The detection network directly regresses the palmprint ROIs and conducts alignment by estimating translation. In the downstream, the fusion network conducts bimodal ROI image fusion leveraging a novel cross-modal selection scheme. To demonstrate the effectiveness of BPFNet, we implement experiments on two touchless palmprint datasets and the proposed framework achieves state-of-the-art performances.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_4
DP  - Springer Link
SP  - 28
EP  - 36
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
ST  - BPFNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_4.pdf
KW  - Bimodal fusion
KW  - Biometric
KW  - Touchless palmprint recognition
ER  - 

TY  - CONF
TI  - Robot Arm Control Using Reward-Modulated Hebbian Learning
AU  - Minato, Koutaro
AU  - Katori, Yuichi
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - In recent years, soft robots with “softness” have been attracting much attention. Since soft robots have “softness”, they are expected to be able to perform delicate tasks that only humans can do. On the other hand, it is challenging to control. Therefore, in this research, we focused on reservoir computing with a biologically inspired learning algorithm. Reward-modulated Hebbian learning, one of the reservoir computing frameworks, is based on Hebbian learning rules and rewards and allows us to train the network without explicit teacher signals. The rewards are provided depending on the predicted and actual state of the environment influenced by the exploratory noise. We demonstrate that our model successfully controls the robot arm so that the tip position of the arm draws a given target trajectory.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_7
DP  - Springer Link
SP  - 55
EP  - 63
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_7.pdf
KW  - Reservoir computing
KW  - Reward-modulated Hebbian learning
KW  - Soft robotics
ER  - 

TY  - CONF
TI  - Exploring Effective Speech Representation via ASR for High-Quality End-to-End Multispeaker TTS
AU  - Liu, Dawei
AU  - Wang, Longbiao
AU  - Li, Sheng
AU  - Li, Haoyu
AU  - Ding, Chenchen
AU  - Zhang, Ju
AU  - Dang, Jianwu
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - The quality of multispeaker text-to-speech (TTS) is composed of speech naturalness and speaker similarity. The current multispeaker TTS based on speaker embeddings extracted by speaker verification (SV) or speaker recognition (SR) models has made significant progress in speaker similarity of synthesized speech. SV/SR tasks build the speaker space based on the differences between speakers in the training set and thus extract speaker embeddings that can improve speaker similarity; however, they deteriorate the naturalness of synthetic speech since such embeddings lost speech dynamics to some extent. Unlike SV/SR-based systems, the automatic speech recognition (ASR) encoder outputs contain relatively complete speech information, such as speaker information, timbre, and prosody. Therefore, we propose an ASR-based synthesis framework to extract speech embeddings using an ASR encoder to improve multispeaker TTS quality, especially for speech naturalness. To enable the ASR system to learn the speaker characteristics better, we explicitly feed the speaker-id to the training label. The experimental results show that the speech embeddings extracted by the proposed method have good speaker characteristics and beneficial acoustic information for speech naturalness. The proposed method significantly improves the naturalness and similarity of multispeaker TTS.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_13
DP  - Springer Link
SP  - 110
EP  - 118
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_13.pdf
KW  - End-to-end model
KW  - Speech embedding
KW  - Speech recognition
KW  - Speech synthesis
ER  - 

TY  - CONF
TI  - Video Captioning with External Knowledge Assistance and Multi-feature Fusion
AU  - Miao, Jiao-Wei
AU  - Shao, Huan
AU  - Ji, Yi
AU  - Li, Ying
AU  - Liu, Chun-Ping
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - Video captioning aims to describe the main content of a given video in natural language, which has become a research hotspot because of its wide potential application prospect. Semantic information, as a priori knowledge, is often applied to improve the caption quality, but the scope of these semantic information is relatively small, resulting in insufficient coverage of video attributes. In this paper, we introduce external knowledge from ConceptNet to expand the semantic coverage, so that the model can refer to more semantic information. In addition, a multi-feature fusion is proposed to obtain more informative video features and higher quality semantic features. Experimental results on the MSVD and MSRVTT datasets show that the proposed method can greatly improve the caption diversity and model performance, surpass all previous models in all evaluation metrics, and achieve the new state-of-the-art results.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_2
DP  - Springer Link
SP  - 12
EP  - 19
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_2.pdf
KW  - Feature fusion
KW  - Semantic information
KW  - Video captioning
ER  - 

TY  - CONF
TI  - Prediction of Inefficient BCI Users Based on Cognitive Skills and Personality Traits
AU  - Hagedorn, Laura J.
AU  - Leeuwis, Nikki
AU  - Alimardani, Maryam
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Communications in Computer and Information Science
AB  - BCI inefficiency is one of the major challenges of Motor Imagery Brain-Computer Interfaces (MI-BCI). Past research suggests that certain cognitive skills and personality traits correlate with MI-BCI real-time performance. Other studies have examined sensorimotor rhythm changes (known as $$\mu $$μsuppression) as a valuable indicator of successful execution of the motor imagery task. This research aims to combine these insights by investigating whether cognitive factors and personality traits can predict a user’s ability to modulate $$\mu $$μrhythms during a MI-BCI task. Data containing 55 subjects who completed a MI task was employed, and a stepwise linear regression model was implemented to select the most relevant features for $$\mu $$μsuppression prediction. The most accurate model was based on: Spatial Ability, Visuospatial Memory, Autonomy, and Vividness of Visual Imagery. Further correlation analyses showed that a novice user’s $$\mu $$μsuppression during a MI-BCI task can be predicted based on their visuospatial memory, as measured by the Design Organization Test (DOT).
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92310-5_10
DP  - Springer Link
SP  - 81
EP  - 89
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92310-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92310-5_10.pdf
KW  - \(\mu \) suppression
KW  - BCI inefficiency
KW  - Brain-Computer Interface (BCI)
KW  - Cognitive factors
KW  - Design Organization Test (DOT)
KW  - Motor Imagery (MI)
KW  - Personality
KW  - Visuospatial memory
ER  - 

TY  - CONF
TI  - KinStyle: A Strong Baseline Photorealistic Kinship Face Synthesis with an Optimized StyleGAN Encoder
AU  - Cheng, Li-Chen
AU  - Hsu, Shu-Chuan
AU  - Lee, Pin-Hua
AU  - Lee, Hsiu-Chieh
AU  - Lin, Che-Hsien
AU  - Chen, Jun-Cheng
AU  - Wang, Chih-Yu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - High-fidelity kinship face synthesis is a challenging task due to the limited amount of kinship data available for training and low-quality images. In addition, it is also hard to trace the genetic traits between parents and children from those low-quality training images. To address these issues, we leverage the pre-trained state-of-the-art face synthesis model, StyleGAN2, for kinship face synthesis. To handle large age, gender and other attribute variations between the parents and their children, we conduct a thorough study of its rich latent spaces and different encoder architectures for an optimized encoder design to repurpose StyleGAN2 for kinship face synthesis. The obtained latent representation from our developed encoder pipeline with stage-wise training strikes a better balance of editability and synthesis fidelity for identity preserving and attribute manipulations than other compared approaches. With extensive subjective, quantitative, and qualitative evaluations, the proposed approach consistently achieves better performance in terms of facial attribute heredity and image generation fidelity than other compared state-of-the-art methods. This demonstrates the effectiveness of the proposed approach which can yield promising and satisfactory kinship face synthesis using only a single and straightforward encoder architecture.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_7
DP  - Springer Link
SP  - 105
EP  - 120
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
ST  - KinStyle
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_7.pdf
KW  - Kinship face synthesis
KW  - StyleGAN Encoder
ER  - 

TY  - CONF
TI  - Focal and Global Spatial-Temporal Transformer for Skeleton-Based Action Recognition
AU  - Gao, Zhimin
AU  - Wang, Peitao
AU  - Lv, Pei
AU  - Jiang, Xiaoheng
AU  - Liu, Qidong
AU  - Wang, Pichao
AU  - Xu, Mingliang
AU  - Li, Wanqing
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Despite great progress achieved by transformer in various vision tasks, it is still underexplored for skeleton-based action recognition with only a few attempts. Besides, these methods directly calculate the pair-wise global self-attention equally for all the joints in both the spatial and temporal dimensions, undervaluing the effect of discriminative local joints and the short-range temporal dynamics. In this work, we propose a novel Focal and Global Spatial-Temporal Transformer network (FG-STFormer), that is equipped with two key components: (1) FG-SFormer: focal joints and global parts coupling spatial transformer. It forces the network to focus on modelling correlations for both the learned discriminative spatial joints and human body parts respectively. The selective focal joints eliminate the negative effect of non-informative ones during accumulating the correlations. Meanwhile, the interactions between the focal joints and body parts are incorporated to enhance the spatial dependencies via mutual cross-attention. (2) FG-TFormer: focal and global temporal transformer. Dilated temporal convolution is integrated into the global self-attention mechanism to explicitly capture the local temporal motion patterns of joints or body parts, which is found to be vital important to make temporal transformer work. Extensive experimental results on three benchmarks, namely NTU-60, NTU-120 and NW-UCLA, show our FG-STFormer surpasses all existing transformer-based methods, and compares favourably with state-of-the-art GCN-based methods.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_10
DP  - Springer Link
SP  - 155
EP  - 171
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_10.pdf
KW  - Action recognition
KW  - Focal joints
KW  - Motion patterns
KW  - Skeleton
KW  - Spatial-temporal transformer
ER  - 

TY  - CONF
TI  - Generating Multiple Hypotheses for 3D Human Mesh and Pose Using Conditional Generative Adversarial Nets
AU  - Zheng, Xu
AU  - Zheng, Yali
AU  - Yang, Shubing
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Despite recent successes in 3D human mesh/pose recovery, the human mesh/pose reconstruction ambiguity is a challenging problem that can not be avoided as lighting, occlusion or self-occlusion in scenes happens. We argue that there could be multiple 3D human meshes corresponding a single image from a view point, because we really do not know what happens in extreme lighting or behind occlusion/self occlusion. In this paper, we address the problem using Conditional Generative Adversarial Nets (CGANs) to generate multiple hypotheses for 3D human mesh and pose from a single image under the condition of 2D joints and relative depth of adjacent joints. The initial estimation of 2D human skeletons, relative depth and features is taken as input of CGANs to train the generator and discriminator in the first stage. Then the generator of CGANs is used to generate multiple human meshes via different conditions which are consistent with human silhouette and 2D joint points in the second stage. Selecting and clustering are utilized to eliminate abnormal and redundant human meshes. The number of hypothesis is not unified for each single image, and it is dependent on 2D pose ambiguity. Unlike the existing end-to-end 3D human mesh recovery methods, our approach consists of three task-specific deep networks trained separately to mitigate the training burden in terms of time and datasets. Our approach has been evaluated not only on the datasets of laboratory and real scenes but also on Internet images qualitatively and quantitatively, and experimental results demonstrate the effectiveness of our approach.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_13
DP  - Springer Link
SP  - 206
EP  - 222
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_13.pdf
KW  - CGAN
KW  - Human mesh
KW  - Multiple hypotheses
ER  - 

TY  - CONF
TI  - SCOAD: Single-Frame Click Supervision for Online Action Detection
AU  - Ye, Na
AU  - Zhang, Xing
AU  - Yan, Dawei
AU  - Dong, Wei
AU  - Yan, Qingsen
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Online action detection based on supervised learning requires heavy manual annotation, which is difficult to obtain and may be impractical in real applications. Weakly supervised online action detection (WOAD) can effectively mitigate the problem of substantial labeling costs by using video-level labels. In this paper, we revisit WOAD and propose a weakly supervised online action detection using click-level labels for training, named Single-frame Click Supervision for Online Action Detection (SCOAD). Comparatively, click-level labels can effectively improve prediction accuracy by carrying a small amount of temporal information without massively increase the difficulty and cost of annotation. Specifically, SCOAD includes two joint training modules, i.e., Action Instance Miner (AIM) and Online Action Detector (OAD). To provide more guidance for training network as accuracy as possible, AIM mines pseudo-action instances under the supervision of click labels. Meanwhile, we generate video similarity instances offline by the similarity between video frames and use it to perform finer granularity filtering of error instances generated by AIM. OAD is trained jointly with AIM for online action detection by the pseudo frame-level labels converted from the filtered pseudo-action instances. We conduct extensive experiments on two benchmark datasets to demonstrate that SCOAD can effectively mine and utilize the small amount of temporal information in click-level labels. Code is available at https://github.com/zstarN70/SCOAD.git.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_14
DP  - Springer Link
SP  - 223
EP  - 238
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
ST  - SCOAD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_14.pdf
KW  - Online action detection
KW  - Weakly supervised learning
ER  - 

TY  - CONF
TI  - Social Aware Multi-modal Pedestrian Crossing Behavior Prediction
AU  - Zhai, Xiaolin
AU  - Hu, Zhengxi
AU  - Yang, Dingye
AU  - Zhou, Lei
AU  - Liu, Jingtai
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - With the development of self-driving vehicles, pedestrian behavior prediction plays a vital role in constructing a safe human-robot interactive environment. Previous methods ignored the inherent uncertainty of pedestrian future actions and the temporal correlations of spatial interactions. To solve the aforementioned problems, we propose a novel social aware multi-modal pedestrian crossing behavior prediction network. In this research field, our network innovatively explores the multimodality nature of pedestrian future action prediction and forecasts diverse and plausible futures. Also, to model the social aware context in both the spatial and temporal domain, we construct a spatial-temporal heterogeneous graph, bridging the spatial-temporal gap between the scene and the pedestrian. Experiments show that our model achieves state-of-the-art performance on pedestrian action detection and prediction task. The code is available at https://github.com/zxll0106/Pedestrian_Crossing_Behavior_Prediction.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_17
DP  - Springer Link
SP  - 275
EP  - 290
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_17.pdf
KW  - Pedestrian crossing behavior prediction
KW  - Video understanding
ER  - 

TY  - CONF
TI  - Spatial-Temporal Adaptive Graph Convolutional Network for Skeleton-Based Action Recognition
AU  - Hang, Rui
AU  - Li, MinXian
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Skeleton-based action recognition approaches usually construct the skeleton sequence as spatial-temporal graphs and perform graph convolution on these graphs to extract discriminative features. However, due to the fixed topology shared among different poses and the lack of direct long-range temporal dependencies, it is not trivial to learn the robust spatial-temporal feature. Therefore, we present a spatial-temporal adaptive graph convolutional network (STA-GCN) to learn adaptive spatial and temporal topologies and effectively aggregate features for skeleton-based action recognition. The proposed network is composed of spatial adaptive graph convolution (SA-GC) and temporal adaptive graph convolution (TA-GC) with an adaptive topology encoder. The SA-GC can extract the spatial feature for each pose with the spatial adaptive topology, while the TA-GC can learn the temporal feature by modeling the direct long-range temporal dependencies adaptively. On three large-scale skeleton action recognition datasets: NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton, the STA-GCN outperforms the existing state-of-the-art methods. The code is available at https://github.com/hang-rui/STA-GCN.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_11
DP  - Springer Link
SP  - 172
EP  - 188
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_11.pdf
KW  - Action recognition
KW  - Adaptive topology
KW  - Graph convolution
ER  - 

TY  - CONF
TI  - Exposing Face Forgery Clues via Retinex-Based Image Enhancement
AU  - Chen, Han
AU  - Lin, Yuzhen
AU  - Li, Bin
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Public concerns about deepfake face forgery are continually rising in recent years. Existing deepfake detection approaches typically use convolutional neural networks (CNNs) to mine subtle artifacts under high-quality forged faces. However, most CNN-based deepfake detectors tend to over-fit the content-specific color textures, and thus fail to generalize across different data sources, forgery methods, and/or post-processing operations. It motivates us to develop a method to expose the subtle forgery clues in RGB space. Herein, we propose to utilize multi-scale retinex-based enhancement of RGB space and compose a novel modality, named MSR, to complementary capture the forgery traces. To take full advantage of the MSR information, we propose a two-stream network combined with salience-guided attention and feature re-weighted interaction modules. The salience-guided attention module guides the RGB feature extractor to concentrate more on forgery traces from an MSR perspective. The feature re-weighted interaction module implicitly learns the correlation between the two complementary modalities to promote feature learning for each other. Comprehensive experiments on several benchmarks show that our method outperforms the state-of-the-art face forgery detection methods in detecting severely compressed deepfakes. Besides, our method also shows superior performances on cross-datasets evaluation.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_2
DP  - Springer Link
SP  - 20
EP  - 34
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_2.pdf
KW  - Deepfake detection
KW  - Generalization
KW  - Multi-scale retinex
ER  - 

TY  - CONF
TI  - Learning Video-Independent Eye Contact Segmentation from In-the-Wild Videos
AU  - Wu, Tianyi
AU  - Sugano, Yusuke
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Human eye contact is a form of non-verbal communication and can have a great influence on social behavior. Since the location and size of the eye contact targets vary across different videos, learning a generic video-independent eye contact detector is still a challenging task. In this work, we address the task of one-way eye contact detection for videos in the wild. Our goal is to build a unified model that can identify when a person is looking at his gaze targets in an arbitrary input video. Considering that this requires time-series relative eye movement information, we propose to formulate the task as a temporal segmentation. Due to the scarcity of labeled training data, we further propose a gaze target discovery method to generate pseudo-labels for unlabeled videos, which allows us to train a generic eye contact segmentation model in an unsupervised way using in-the-wild videos. To evaluate our proposed approach, we manually annotated a test dataset consisting of 52 videos of human conversations. Experimental results show that our eye contact segmentation model outperforms the previous video-dependent eye contact detector and can achieve $$71.88\%$$71.88%framewise accuracy on our annotated test set. Our code and evaluation dataset are available at https://github.com/ut-vision/Video-Independent-ECS.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_4
DP  - Springer Link
SP  - 52
EP  - 70
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_4.pdf
KW  - Eye contact
KW  - Human gaze
KW  - Video segmentation
ER  - 

TY  - CONF
TI  - Exemplar Free Class Agnostic Counting
AU  - Ranjan, Viresh
AU  - Nguyen, Minh Hoai
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - We tackle the task of Class Agnostic Counting, which aims to count objects in a novel object category at test time without any access to labeled training data for that category. All previous class agnostic counting methods cannot work in a fully automated setting, and require computationally expensive test time adaptation. To address these challenges, we propose a visual counter which operates in a fully automated setting and does not require any test time adaptation. Our proposed approach first identifies exemplars from repeating objects in an image, and then counts the repeating objects. We propose a novel region proposal network for identifying the exemplars. After identifying the exemplars, we obtain the corresponding count by using a density estimation based Visual Counter. We evaluate our proposed approach on FSC-147 dataset, and show that it achieves superior performance compared to the existing approaches. Our code and models are available at: https://github.com/Viresh-R/ExemplarFreeCounting.git.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_5
DP  - Springer Link
SP  - 71
EP  - 87
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_5.pdf
ER  - 

TY  - CONF
TI  - Heterogeneous Avatar Synthesis Based on Disentanglement of Topology and Rendering
AU  - Gao, Nan
AU  - Zeng, Zhi
AU  - Zhang, GuiXuan
AU  - Zhang, ShuWu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - There are obviously structural and color discrepancies among different heterogeneous domains. In this paper, we explore the challenging heterogeneous avatar synthesis (HAS) task considering topology and rendering transfer. HAS transfers the topology as well as rendering styles of the referenced face to the source face, to produce high-fidelity heterogeneous avatars. Specifically, first, we utilize a Rendering Transfer Network (RT-Net) to render the grayscale source face based on the color palette of the referenced face. The grayscale features and color style are injected into RT-Net based on adaptive feature modulation. Second, we apply a Topology Transfer Network (TT-Net) to conduct heterogeneous facial topology transfer, where the image content of RT-Net is transferred based on AdaIN controlled by heterogeneous identity embedding. Comprehensive experimental results show that the disentanglement of rendering and topology is beneficial to the HAS task, and our HASNet has comparable performance compared with other state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_9
DP  - Springer Link
SP  - 137
EP  - 152
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_9.pdf
KW  - Disentanglement representation learning
KW  - Image synthesis
KW  - Style transfer
ER  - 

TY  - CONF
TI  - Confidence-Calibrated Face Image Forgery Detection with Contrastive Representation Distillation
AU  - Yang, Puning
AU  - Huang, Huaibo
AU  - Wang, Zhiyong
AU  - Yu, Aijing
AU  - He, Ran
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Face forgery detection has been increasingly investigated due to the great success of various deepfake techniques. While most existing face forgery detection methods have achieved excellent results on the test split of the same dataset or the same type of manipulations, they often do not work well on unseen datasets or unseen manipulations due to the issue of model generalization. Therefore, in this paper, we propose a novel contrastive distillation calibration (CDC) framework, which distills the contrastive representations with confidence calibration to address this generalization issue. Different from previous methods that equally treat the two forgery types, Face Swapping and Face Reenactment, we devise a dual-teacher module where the knowledge is separately learned for each forgery type. A contrastive representation learning strategy is further presented to enhance the representations of diverse forgery artifacts. To prevent the proposed model from being overconfident, we propose a novel Kullback-Leibler divergence loss with dynamic weights to moderate the dual-teacher’s outputs. In addition, we introduce label smoothing to calibrate the model confidence with the target outputs. Extensive experiments on three popular datasets show that our proposed method achieves the state-of-the-art performance for cross-dataset face forgery detection.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_1
DP  - Springer Link
SP  - 3
EP  - 19
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_1.pdf
KW  - Confidence calibration
KW  - Deepfake detection
KW  - Knowledge distillation
ER  - 

TY  - CONF
TI  - Neural Puppeteer: Keypoint-Based Neural Rendering of Dynamic Shapes
AU  - Giebenhain, Simon
AU  - Waldmann, Urs
AU  - Johannsen, Ole
AU  - Goldluecke, Bastian
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - We introduce Neural Puppeteer, an efficient neural rendering pipeline for articulated shapes. By inverse rendering, we can predict 3D keypoints from multi-view 2D silhouettes alone, without requiring texture information. Furthermore, we can easily predict 3D keypoints of the same class of shapes with one and the same trained model and generalize more easily from training with synthetic data which we demonstrate by successfully applying zero-shot synthetic to real-world experiments. We demonstrate the flexibility of our method by fitting models to synthetic videos of different animals and a human, and achieve quantitative results which outperform our baselines. Our method uses 3D keypoints in conjunction with individual local feature vectors and a global latent code to allow for an efficient representation of time-varying and articulated shapes such as humans and animals. In contrast to previous work, we do not perform reconstruction in the 3D domain, but project the 3D features into 2D cameras and perform reconstruction of 2D RGB-D images from these projected features, which is significantly faster than volumetric rendering. Our synthetic dataset will be publicly available, to further develop the evolving field of animal pose and shape reconstruction.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_15
DP  - Springer Link
SP  - 239
EP  - 256
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
ST  - Neural Puppeteer
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_15.pdf
ER  - 

TY  - CONF
TI  - 3D Pose Based Feedback for Physical Exercises
AU  - Zhao, Ziyi
AU  - Kiciroglu, Sena
AU  - Vinzant, Hugues
AU  - Cheng, Yuan
AU  - Katircioglu, Isinsu
AU  - Salzmann, Mathieu
AU  - Fua, Pascal
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Unsupervised self-rehabilitation exercises and physical training can cause serious injuries if performed incorrectly. We introduce a learning-based framework that identifies the mistakes made by a user and proposes corrective measures for easier and safer individual training.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_12
DP  - Springer Link
SP  - 189
EP  - 205
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_12.pdf
ER  - 

TY  - CONF
TI  - Emphasizing Closeness and Diversity Simultaneously for Deep Face Representation
AU  - Zhao, Chaoyu
AU  - Qian, Jianjun
AU  - Zhu, Shumin
AU  - Xie, Jin
AU  - Yang, Jian
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Recent years have witnessed remarkable progress in deep face recognition due to the advancement of softmax-based methods. In this work, we first provide the analysis to reveal the working mechanism of softmax-based methods from the geometry view. Margin-based softmax methods enhance the feature discrimination by the extra margin. Mining-based softmax methods pay more attention to hard samples and try to enlarge their diversity during training. Both closeness and diversity are essential for discriminative features learning; however, we observe that most previous works dealing with hard samples fail to balance the relationship between closeness and diversity. Therefore, we propose a novel approach to tackle the above issue. Specifically, we design a two-branch cooperative network: the Elementary Representation Branch (ERB) and the Refined Representation Branch (RRB). ERB employs the margin-based softmax to guide the network to learn elementary features and measure the difficulty of training samples. RRB employs the proposed sampling strategy in conjunction with two loss terms to enhance closeness and diversity simultaneously. Extensive experimental results on popular benchmarks demonstrate the superiority of our proposed method over state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_6
DP  - Springer Link
SP  - 88
EP  - 104
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_6.pdf
KW  - Closeness and diversity
KW  - Deep face representation
KW  - Difficulty measure
KW  - Two-branch cooperative network
ER  - 

TY  - CONF
TI  - GB-CosFace: Rethinking Softmax-Based Face Recognition from the Perspective of Open Set Classification
AU  - Chen, Mingqiang
AU  - Liu, Lizhe
AU  - Chen, Xiaohao
AU  - Zhu, Siyu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - State-of-the-art face recognition methods typically take the multi-classification pipeline and adopt the softmax-based loss for optimization. Although these methods have achieved great success, the softmax-based loss has its limitation from the perspective of open set classification: the multi-classification objective in the training phase does not strictly match the objective of open set classification testing. In this paper, we derive a new loss named global boundary CosFace (GB-CosFace). Our GB-CosFace introduces an adaptive global boundary to determine whether two face samples belong to the same identity so that the optimization objective is aligned with the testing process from the perspective of open set classification. Meanwhile, since the loss formulation is derived from the softmax-based loss, our GB-CosFace retains the excellent properties of the softmax-based loss, and CosFace is proved to be a special case of the proposed loss. We analyze and explain the proposed GB-CosFace geometrically. Comprehensive experiments on multiple face recognition benchmarks indicate that the proposed GB-CosFace outperforms current state-of-the-art face recognition losses in mainstream face recognition tasks. Compared to CosFace, our GB-CosFace improves 5.30%, 0.70%, and 0.36% at TAR@FAR=1e-6, 1e-5, 1e-4 on IJB-C benchmark.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_3
DP  - Springer Link
SP  - 35
EP  - 51
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
ST  - GB-CosFace
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_3.pdf
ER  - 

TY  - CONF
TI  - Occluded Facial Expression Recognition Using Self-supervised Learning
AU  - Wang, Jiahe
AU  - Ding, Heyan
AU  - Wang, Shangfei
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Recent studies on occluded facial expression recognition typically required fully expression-annotated facial images for training. However, it is time consuming and expensive to collect a large number of facial images with various occlusions and expression annotations. To address this problem, we propose an occluded facial expression recognition method through self-supervised learning, which leverages the profusion of available unlabeled facial images to explore robust facial representations. Specifically, we generate a variety of occluded facial images by randomly adding occlusions to unlabeled facial images. Then we define occlusion prediction as the pretext task for representation learning. We also adopt contrastive learning to make facial representation of a facial image and those of its variations with synthesized occlusions close. Finally, we train an expression classifier as the downstream task. The experimental results on several databases containing both synthesized and realistic occluded facial images demonstrate the superiority of the proposed method over state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_8
DP  - Springer Link
SP  - 121
EP  - 136
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_8.pdf
KW  - Occluded facial expression recognition
KW  - Representation learning
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Decanus to Legatus: Synthetic Training for 2D-3D Human Pose Lifting
AU  - Zhu, Yue
AU  - Picard, David
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - 3D human pose estimation is a challenging task because of the difficulty to acquire ground-truth data outside of controlled environments. A number of further issues have been hindering progress in building a universal and robust model for this task, including domain gaps between different datasets, unseen actions between train and test datasets, various hardware settings and high cost of annotation, etc. In this paper, we propose an algorithm to generate infinite 3D synthetic human poses (Legatus) from a 3D pose distribution based on 10 initial handcrafted 3D poses (Decanus) during the training of a 2D to 3D human pose lifter neural network. Our results show that we can achieve 3D pose estimation performance comparable to methods using real data from specialized datasets but in a zero-shot setup, showing the generalization potential of our framework.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26316-3_16
DP  - Springer Link
SP  - 257
EP  - 274
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26316-3
ST  - Decanus to Legatus
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26316-3_16.pdf
KW  - 3D Human pose
KW  - Synthetic training
KW  - Zero-shot
ER  - 

TY  - CONF
TI  - Path Planning of Seeding Robot Based on Improved Ant Colony Algorithm
AU  - Wang, Ying
AU  - Xu, Jiaojiao
AU  - Liu, Qi
AU  - Zhang, Ye
AU  - Yang, Jiaxin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at solving the problems that using ant colony algorithm in the route planning results in slow convergence speed and too long search time of seeding robot, an improved ant colony algorithm based on grid model is proposed. In order to make the seeding robot travel the shortest path when it arrives at the work place from the starting point, the proposed algorithm is used. In this algorithm, the transfer operator and adjustment operator of butterfly optimization algorithm are introduced into ant colony algorithm to optimize the distribution of original pheromone, solve the blindness of original search path, expand the search space of solution and improve the global of solution; Cauchy mutation operator is used to optimize the probability transfer rule to increase various solutions and improve the convergence speed. In order to verify the superiority of the improved algorithm in the 20 m × 20 m grid map, the simulation experiments of the two algorithms are implemented. Through simulation, it is shown that convergence speed of the improved ant colony algorithm is greatly improved compared with the basic ant colony algorithm. It provides a certain research value for the future research of seeding robot route planning.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_4
DP  - Springer Link
SP  - 31
EP  - 37
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_4.pdf
KW  - Ant colony algorithm
KW  - Cauchy mutation operator
KW  - Path planning
KW  - Seeding robot
ER  - 

TY  - CONF
TI  - An Improved A* Algorithm Based on Localizability Estimation for Mobile Robots
AU  - Yang, Rui
AU  - Dai, Kun
AU  - Yan, Gaowei
AU  - Cheng, Lan
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - A* algorithm is widely adopted for path planning in the applications of mobile robots. However, the existence of extended nodes and redundant points after applying A* algorithm may cause a long planned path. To address this issue, an improved A* algorithm is proposed. Localizability of the robot's current node on a grid map is first estimated. Then, the parent node and the grandparent node of current node are referred to build the relation between the actual cost and the heuristic cost. The heuristic cost is weighted to analyze the effect of the actual cost and the heuristic cost on the planned path. Finally, a path planning strategy with adaptive step size is proposed to optimize the path. Simulations show that the proposed algorithm outperforms the A* algorithm and the ant colony algorithm in terms of localizability of the robot and the path cost.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_15
DP  - Springer Link
SP  - 124
EP  - 132
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_15.pdf
KW  - A* algorithm
KW  - Adaptive step size
KW  - Localizability estimation
KW  - Mobile robots
KW  - Path planning
ER  - 

TY  - CONF
TI  - A Patent Text Classification Method Based on Phrase-Context Fusion Feature
AU  - Wang, Yuhui
AU  - Du, Junping
AU  - Shao, Yingxia
AU  - Li, Ang
AU  - Xu, Xin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The traditional patent classification depends on manual classification, which needs the staff to have a strong professional background and has low efficiency. The accuracy of classification is also greatly affected by the high similarity between the subdivision categories. Therefore, automatic classification of patents is needed to speed up the patent classification and improve the accuracy. In this paper, we present a phrase-context fusion feature (PCFF) method for patent classification. The convolutional neural network (CNN) extracts the phrase feature of the patent text, and the bi-directional long short-term memory (BiLSTM) units produce the contextual features. Furthermore, an attention mechanism is developed to adaptively select the contextual features and combines the high separable parts of the features extracted. PCFF model combines the advantages of the two networks and complements each other through fusing the feature from two networks through fusion attention. Experimental results demonstrate that the PCFF model produces complementary fusion feature and obtains better performance against the state-of-the-art baselines on the patent dataset.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_19
DP  - Springer Link
SP  - 157
EP  - 164
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_19.pdf
KW  - Attention
KW  - CNN
KW  - Fusion feature
KW  - LSTM
KW  - Patent classification
ER  - 

TY  - CONF
TI  - Research on Control System of an Intelligent Cooking Robot
AU  - Tang, Wanpeng
AU  - Huang, Weiting
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This study can better help people to understand the professional chefs’ seasoning methods and enjoy a precise, hygienic and concise life. The system can enable the product be adjusted according to individual tastes. The seasoning conveying channel can be automatically cleaned, and the operation is simple and convenient. This system is mainly composed of gear pump control circuit, switching power supply circuit, PLC control circuit, push-button switch circuit and indicator lamp circuit, which respectively extract seven kinds of liquid seasonings. The switching power supply circuit provides 24 V power to PLC, intermediate relay and pumps. The push-button switch circuit performs signal control according to user’s needs, and the indicator lamp circuit indicates the current working state of seasoning circuit. The commonly used condiments are liquefied, and the condiments can be selected from the menu library of the touch screen, then with the command of the control pump be transferred to the frying pan to achieve the ideal taste. The design process and control method are novel and practical.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_2
DP  - Springer Link
SP  - 11
EP  - 19
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_2.pdf
KW  - Condiment
KW  - Intelligent control
KW  - Intelligent cooking machine
KW  - PLC control
ER  - 

TY  - CONF
TI  - Design of Manipulator System with Tactile Sensor Arrays Based on the Demand of Frail Older People
AU  - Wang, Lu
AU  - Liu, Shasha
AU  - Weng, Ling
AU  - Huang, Wenmei
AU  - Wang, Bowen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - With the growth of the aging population in China, the importance of home-based old age care in the construction of the model has increased, and issues such as the design of auxiliary intellectual tools and care for the older people are prominent. The manipulator with the tactile sensor is an essential form of intelligent perception of robot, and can help frail elders to finish the task of grasping objects. Here, the manipulator system with tactile sensor arrays has been designed according to the demand of older adults. The experimental results show that the manipulator system with a tactile sensor array can be applied to target object recognition effectively, and can provide meaningful reference and inspiration for the design and application of auxiliary products for the needs of seniors in the future.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_8
DP  - Springer Link
SP  - 65
EP  - 72
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_8.pdf
KW  - Frail older people
KW  - Grasping object
KW  - Manipulator system
KW  - Tactile sensor array
ER  - 

TY  - CONF
TI  - Pedestrian Detection Algorithm Based on Improved YOLOv3_tiny
AU  - Li, Guilan
AU  - Yang, Jie
AU  - Kang, Zhuang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - In view of the low detection accuracy of YOLOv3_tiny algorithm on small pedestrian target, a pedestrian detection method to improve YOLOv3_tiny is proposed. Firstly, the head and shoulder of the pedestrian are taken as the detection object. The K-means++ algorithm is used to improve the k-means algorithm and cluster the data set to get the anchor frame with higher accuracy. Secondly, add a target prediction layer with a resolution of 52 × 52 to the multi-scale prediction section, which improves the detection accuracy of the small target. In addition, the backbone structure of YOLOv3_tiny is light-weighted, which further compresses the model memory and reduces the deployment burden of the model while maintaining accuracy. A comparative experiment is conducted on the self-made pedestrian dataset which tags the head and shoulder. The results show that the recall of the improved algorithm is 0.8743, which is 11.78% higher than that of the original algorithm; The average accuracy is 77.69%, which is better than the classical algorithms, such as SSD, fast RCNN and Yolo v3; the model size is 26M, and the test time of single image is 0.0789s, which can achieve efficient and real-time detection.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_12
DP  - Springer Link
SP  - 98
EP  - 106
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_12.pdf
KW  - Deep learning
KW  - Object detection
KW  - Pedestrian detection
KW  - YOLOv3_tiny
ER  - 

TY  - CONF
TI  - Remaining Useful Life Prediction for Lithium-Ion Batteries Based on Empirical Model and Improved Least Squares Support Vector Machine
AU  - Chen, Wan
AU  - Cai, Yanping
AU  - Li, Aihua
AU  - Su, Yanzhao
AU  - Jiang, Ke
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Remaining useful life (RUL) prediction for lithium-ion batteries is important for the safety of the battery. To improve the accuracy of multi-step prediction, a novel method based on empirical model and improved least squares-support vector machine (LS-SVM) is proposed. Firstly, we constructed the deviation capacity based on the third-order polynomial empirical model to reduce the fluctuation of the data. Secondly, the differential evolution (DE) algorithm and multi-kernel (MK) functions were used to optimize the LS-SVM, and the improved LS-SVM was then built, which improved the prediction accuracy of the LS-SVM. On this basis, the framework for RUL prediction was constructed successfully. Finally, the experimental verification was carried out. The results show that the prediction accuracy of the proposed method is better than that of the existing methods.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_6
DP  - Springer Link
SP  - 47
EP  - 55
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_6.pdf
KW  - Differential evolution algorithm
KW  - Lithium-ion battery
KW  - Multi-kernel least squares support vector machine
KW  - Remaining useful life prediction
ER  - 

TY  - CONF
TI  - Design and Output Characteristics of Magnetostrictive Sensor Array for Tire Pattern Detection
AU  - Li, Runyu
AU  - Zhao, Zhizhong
AU  - Wang, Zhiqiang
AU  - Wang, Haifeng
AU  - Zhang, Wensheng
AU  - Wang, Bowen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - A new type of sensor unit is designed, based on the simulation of hair structure and the magnetic sensitive material Galfenol filament, which was integrated into an array. The output characteristic model of the sensor unit is established according to inverse magnetostrictive effect, linear piezomagnetic equation, and material mechanics. The experimental results show that the output voltage of the sensor unit varies linearly under the action of 0–2.4 N. The sensor array has a good stability and response speed. According to the characteristic of tire pattern, a tire pattern sample is selected to measure. A test system is built for data acquisition and storage, and the output characteristics of the sensor array are tested. The integrated sensor array can well identify the pattern characteristics of the selected tire sample, and the maximum absolute error is 0.7 mm.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_11
DP  - Springer Link
SP  - 90
EP  - 97
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_11.pdf
KW  - Detection
KW  - Magnetostrictive sensing unit
KW  - Sensor array
KW  - Tire pattern
ER  - 

TY  - CONF
TI  - Global Context Guided Multi-scale Feature Network for Salient Object Detection
AU  - Zhao, Zhenyu
AU  - Fang, Yachao
AU  - Zhang, Qing
AU  - Chen, Xiaowei
AU  - Dai, Meng
AU  - Lin, Jiajun
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Currently, fully convolutional network based salient object detection approaches have some challenging problems. This paper proposes a novel salient object detection approach using global context and multi-scale feature representation to estimate saliency maps in a pixel-wise manner. Firstly, we explore and design a multi-scale feature enhancement module to improve the capability of feature representation and learning of multi-level side-output features. Moreover, we use global features to guide side-output multi-scale features to focus on the useful information, which could help the network effectively locate salient objects and suppress background noises. Finally, the feature pyramid network structure is utilized to refine the estimated results in a coarse-to-fine manner, and then obtain the final predicted results. The comparisons of our approach and 15 state-of-the-art methods demonstrate the effictiveness and robustness of the proposed approach on various scenarios.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_10
DP  - Springer Link
SP  - 81
EP  - 89
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_10.pdf
KW  - Fully convolutional network
KW  - Multi-scale features
KW  - Saliency detection
KW  - Saliency map
KW  - Salient object detection
ER  - 

TY  - CONF
TI  - Research on Parking Space Allocation of Stereo Garage Based on Improved Genetic Algorithm
AU  - Liu, Qi
AU  - Zhang, Ye
AU  - Wang, Ying
AU  - Xu, Jiaojiao
AU  - Ye, Ze
AU  - Yin, Gang
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - In order to improve the traffic pressure of urban vehicles, improve the access efficiency of garages and reduce the waiting time for access, a queuing model is established based on the queuing theory. Considering the influence of parking layers and columns on the overall operation efficiency, an improved genetic algorithm is proposed to analyze the layout and energy consumption of parking space allocation in stereo garages. The traditional genetic algorithm and the improved genetic algorithm are used for parking space allocation. The results show that the improved genetic algorithm can improve the vehicle operation efficiency and reduce energy consumption, and solve the existing problems of three-dimensional garage, which has practical reference value.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_1
DP  - Springer Link
SP  - 1
EP  - 10
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_1.pdf
KW  - Improved genetic algorithm
KW  - Parking space allocation
KW  - Queuing theory
KW  - Stereo garage
ER  - 

TY  - CONF
TI  - A K-means Optimized Clustering Algorithm Based on Improved Genetic Algorithm
AU  - Pu, Qiu-Mei
AU  - Wu, Qiong
AU  - Li, Qian
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The K-means algorithm is highly sensitive to the initial clustering centers and easily get trapped in a local optimum. To avoid such problems, this paper proposes an improved crossover operator of chromosomes in the genetic algorithm, redefines the calculation method of genetic probability and the natural selection rules, introduces different individual selection mechanisms for the two adjacent generations of chromosomes, and integrates the K-means algorithm into the improved genetic algorithm. Experiment results demonstrate that the improved K-Means algorithm is better than the original genetic algorithm and K-Means algorithm in clustering performance, far better than the bisecting K-means algorithm.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_16
DP  - Springer Link
SP  - 133
EP  - 140
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_16.pdf
KW  - Clustering
KW  - Genetic algorithm
KW  - K-means algorithm
ER  - 

TY  - CONF
TI  - Model Optimization of ATO System for Rail Transit
AU  - Yang, Zhenyu
AU  - Jiang, Bo
AU  - Ren, Xiaocong
AU  - Wei, Ziyuan
AU  - Xu, Ran
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The control strategy of Automatic Train Operation (ATO) system based on multi-objective optimization technology is studied in this paper. On this basis, the performance in the process of train operation are analyzed. Based on the “penalty function” mechanism, the mathematical model of multi-objective optimal control strategy of ATO system is established, and the weight value between each performance of the objective function is determined by Analytic Hierarchy Process (AHP) model and cosine similarity. Then, the optimization model is solved by the genetic algorithm to generate the target curve of ideal railway speed-distance. Finally, the simulation results are tested and analyzed to verify the feasibility and effectiveness of the model and algorithm.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_18
DP  - Springer Link
SP  - 150
EP  - 156
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_18.pdf
KW  - ATO
KW  - Control strategy
KW  - Multi-objective optimization
ER  - 

TY  - CONF
TI  - Research on Active Safety Information Completion Method of Environmental Less-Information
AU  - He, Xiang
AU  - Li, Qing
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - The research on environmental perception system in the field of unmanned vehicle mainly focuses on obtaining environmental information by using visual, radar and multi-sensor information fusion in ideal environment, and lacks the research on the completion method of information loss in complex environment. A Locally Focused Neighbor-Value Completion method is proposed to restore the local less-information and traversal the global less-information global completion. Firstly, the distorted signal data are perceived by the Locally Focused location environment. Secondly, the adjacent values of the distorted data are extracted and the missing data are recovered by matrix completion. Finally, traversal global completion is not achieved. The simulation results show that this method can satisfy the real-time recovery of environmental less-information in complex environment.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_13
DP  - Springer Link
SP  - 107
EP  - 115
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_13.pdf
KW  - Less-information
KW  - Locally focused
KW  - Neighbor-value completion
KW  - Unmanned vehicle
ER  - 

TY  - CONF
TI  - UDE-Based Robust Walking Control of a Bipedal Robot
AU  - Cao, Guanqun
AU  - Zhang, Qizhi
AU  - Zhou, Yali
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Robust bipedal locomotion in robotics is a fundamental and challenging requirement. Firstly, we use the variable spring-loaded inverted pendulum (SLIP) model as the research system to derive the dynamics equation. Secondly, a robust control strategy based on the uncertainty and disturbance estimation (UDE) method is designed, which enables the bipedal robot to maintain stable periodic gaits even if there are uncertainties in the model. Considering the nonlinear and strongly coupling characteristics of the movement states of the system, we use the feedback linearization (FL) method to transform the model into a linear system. Finally, several simulations have illustrated the robustness of the proposed method. The salient feature of the UDE is that only the bandwidth of the model’s uncertainties is needed for the controller design, which makes it easy to implement. Simulation results have proved that the UDE-based controller can estimate and compensate for deviations and disturbances.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_5
DP  - Springer Link
SP  - 38
EP  - 46
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_5.pdf
KW  - Bipedal robot
KW  - Spring-loaded inverted pendulum
KW  - Uncertainty and disturbance estimation
KW  - Variable stiffness
ER  - 

TY  - CONF
TI  - Research on Active Disturbance Rejection Control of Multi-joint Robot Fish Path Tracking
AU  - Liu, Qi
AU  - Ye, Ze
AU  - Wang, Ying
AU  - Zhang, Ye
AU  - Yin, Gang
AU  - Yang, Jia Xin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problem that the multi-joint robotic fish is often interfered by the outside world during the path tracking process, a robotic fish based on the auto-disturbance rejection control algorithm is designed. First, analyze the force of the multi-joint robotic fish, build its motion model, design the guidance law of the robotic fish, import the guidance law into the ADRC controller, and use the Expanded State Observer (ESO) for real-time observation to predict the total disturbance. The direction and speed control of the robotic fish is transformed into a typical second-order cascade integral system, and the motion trajectory of the robotic fish is controlled in real time so that it can swim in the expected direction. Finally, simulations prove that the algorithm can enhance the real-time and robustness of the robotic fish path tracking system.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_17
DP  - Springer Link
SP  - 141
EP  - 149
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_17.pdf
KW  - ADRC
KW  - ESO
KW  - Multi-joint robotic fish
KW  - Path tracking
ER  - 

TY  - CONF
TI  - Path Following Control of Unmanned Surface Vessel with Unknown Ocean Currents Disturbances
AU  - Qin, Jinmeng
AU  - Guo, Chen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This paper studies the path following problem of underactuated unmanned surface vehicle (USV) under circumstance of ocean currents. Initially, in order to ensure the USV can converge to and follow the expected path, an improved adaptive integral line-of-sight (IAILOS) guidance law is proposed. IAILOS is suitable for any parametric paths and can deal with ocean currents. Furthermore, the path-following controller is designed by combining the sliding-mode method and backstepping technique. The Lyapunov stability theory verifies that the designed path-following guidance-control system of USV is uniformly ultimately bounded (UUB). Finally, numerical simulation results are carried out to illustrate the effectiveness the proposed controller.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_7
DP  - Springer Link
SP  - 56
EP  - 64
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_7.pdf
KW  - Line-of-sight
KW  - Path following
KW  - Sliding-mode control
KW  - Unmanned surface vehicles
ER  - 

TY  - CONF
TI  - A Barrier Function-Based Variable-Gain SOSM Power Control Scheme for DFIG Wind Turbine
AU  - Du, Cuiqi
AU  - Han, Yaozhen
AU  - Li, Shuzhen
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This paper proposes a variable-gain second order sliding mode (SOSM) controller applied to the vector control (stator voltage oriented) of doubly fed induction generator (DFIG) wind turbine (WT). DFIG power control is achieved via rotor current regulation. With the aid of barrier function, the controller parameters can be adjusted adaptively with the change of system perturbation. (Maximum power point tracking) MPPT algorithm is employed for WT control and pitch control is used to protect the WT when wind speed exceeds the nominal value. The proposed control scheme is compared with PI control and first-order sliding mode control (FOSMC) under different system conditions in MATLAB/ Simulink platform. It is proved that the proposed control scheme is effective, and has certain advantages in resisting the internal parameter and external disturbance of the system.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_14
DP  - Springer Link
SP  - 116
EP  - 123
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_14.pdf
KW  - Barrier function
KW  - DFIG
KW  - Rotor current control
KW  - Variable-gain second order sliding mode
ER  - 

TY  - CONF
TI  - Context-Awareness Based Battlefield Situation Information Recommendation
AU  - Zhou, Chunhua
AU  - Shen, Yue
AU  - Shen, Jianjing
AU  - Wang, Liusong
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - Based on the analysis of the key factors involved in the situation information recommendation, this paper integrates the situation information into the traditional “user-item” recommendation system, and constructs a multi-dimensional and multi-level battlefield situation information recommendation model. Furthermore, the two-dimensional recommendation model is extended to multi-dimensional recommendation model to improve the accuracy of the recommendation system. On the basis of the multi-dimensional recommendation model, the ontology modeling method is used to model the situation information, and the battlefield situation information recommendation method based on ontology similarity is designed.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_3
DP  - Springer Link
SP  - 20
EP  - 30
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_3.pdf
KW  - Battlefield situation information recommendation
KW  - Context-awareness
KW  - Ontology
KW  - Recommendation system
ER  - 

TY  - CONF
TI  - Disturbance-Observer-Based Attitude Tracking Control for Rigid Spacecraft with Unmeasurable Angular Velocity
AU  - Hu, Jintao
AU  - Jia, Yingmin
A2  - Deng, Zhidong
T3  - Lecture Notes in Electrical Engineering
AB  - This paper addresses the rigid spacecraft attitude tracking control problem in the presence of input saturation, unmeasurable angular velocity and external disturbance. First, an angular velocity observer is proposed to estimate the unavailable angular velocity. Further, another disturbance observer is provided to obtain the estimation of the external disturbance. Based on the second order sliding mode surface, the compensation of input saturation, and these two observers, a continuous attitude control strategy with only attitude measurement is constructed. By utilizing the Lyapunov theory, it is demonstrated that the proposed controller can realize attitude tracking control of spacecraft and keep all variables of the rigid spacecraft attitude system are uniformly bounded. Finally, numerous simulations illustrate the feasibility of the proposed control law.
C1  - Singapore
C3  - Proceedings of 2021 Chinese Intelligent Automation Conference
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6372-7_9
DP  - Springer Link
SP  - 73
EP  - 80
LA  - en
PB  - Springer
SN  - 9789811663727
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6372-7_9.pdf
KW  - Disturbance observer
KW  - Input saturation
KW  - Sliding mode control
KW  - Spacecraft attitude tracking
KW  - State observer
ER  - 

TY  - CONF
TI  - Loss Filtering Factor for Crowd Counting
AU  - Chen, Yufeng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In crowd counting datasets, each person is annotated by a point, typically representing the center of the head. However, due to the dense crowd, variety of scenarios, significant obscuration and low resolution, label noise in the dataset is inevitable and such label noise has a negative impact on the performance of the model. To alleviate the negative effects of label noise, in this paper we propose the Loss Filtering Factor, which can filter out the losses assumed to be caused by label noise during the training process. By doing so, the model can prioritize non-noise data and focus on it during training and predicting. Extensive experimental evaluations have demonstrated that the proposed Loss Filtering Factor consistently improves the performance of all models across all datasets used in the experiments. On average, it leads to a 5.48% improvement in MAE and 6.43% in MSE. Moreover, the proposed approach is universal and it can be easily implemented into any neural network model architecture to improve performance.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - crowd counting
KW  - loss function
KW  - noisy labels
ER  - 

TY  - CONF
TI  - Unsupervised Concept Drift Detection via Imbalanced Cluster Discriminator Learning
AU  - Zhao, Mingjie
AU  - Zhang, Yiqun
AU  - Ji, Yuzhu
AU  - Lu, Yang
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Streaming data processing has attracted much more attention and become a key research area in the fields of machine learning and data mining. Since the distribution of real data may evolve (called concept drift) with time due to many unforeseen factors and real data is usually with imbalanced cluster/class distributions during streaming data processing, drifts occurred in distributions with fewer data objects are easily masked by the larger distributions. This paper, therefore, proposes an unsupervised drift detection approach called Multi-Imbalanced Cluster Discriminator (MICD) to address the more challenging imbalance problem of unlabeled data. It first partitions data into compact clusters, and then learns a discriminator for each cluster to detect drift. It turns out that MICD can detect drift occurrence, locate where the drift occurs, and quantify the extent of the drift. MICD is efficient, interpretable, and has easy-to-set parameters. Extensive experiments on synthetic and real datasets illustrate the superiority of MICD.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_3
DP  - Springer Link
SP  - 31
EP  - 43
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - clustering
KW  - concept drift
KW  - imbalanced distribution
KW  - Streaming data
KW  - unsupervised drift detection
ER  - 

TY  - CONF
TI  - Boosting Out-of-Distribution Detection with Sample Weighting
AU  - Ke, Ao
AU  - Chen, Wenlong
AU  - Feng, Chuanwen
AU  - Xie, Xike
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - To enhance the reliability of machine learning models in the open world, there is considerable interest in detecting out-of-distribution (OOD) inputs that lie far away from the training distribution. Existing distance-based methods have shown promising performance in OOD detection. These methods generally follow a common approach of capturing the distances between training samples and each test sample in the feature space. This can be understood as encoding the distance information to assign sample weights, which are then used to calculate a weighted distance score to determine if the input is OOD. However, these methods often adopt a coarse-grained weighting approach, where only a small fraction of the training samples are considered and given weights. Consequently, they fail to fully leverage the complete distance information of the training data, leading to occasional difficulties in effectively distinguishing OOD samples. In this paper, we propose a novel approach to encode the complete distance information of the training data by assigning a weight to each sample based on its distance from the test sample, with the weights decaying as the distance increases. Furthermore, we introduce a weighted distance-based method for OOD detection. We demonstrate the superiority of our method over most existing supervised OOD detectors. Particularly, on a hard OOD detection task involving CIFAR-100 vs. CIFAR-10, our method achieves a reduction of $$1.82\%$$1.82%in the average FPR95 compared to the current best method KNN.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_17
DP  - Springer Link
SP  - 213
EP  - 223
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Contrastive training
KW  - Out-of-distribution detection
ER  - 

TY  - CONF
TI  - Continuous Exploration via Multiple Perspectives in Sparse Reward Environment
AU  - Chen, Zhongpeng
AU  - Guan, Qiang
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Exploration is a major challenge in deep reinforcement learning, especially in cases where reward is sparse. Simple random exploration strategies, such as $$\epsilon $$ϵ-greedy, struggle to solve the hard exploration problem in the sparse reward environment. A more effective approach to solve the hard exploration problem in the sparse reward environment is to use an exploration strategy based on intrinsic motivation, where the key point is to design reasonable and effective intrinsic reward to drive the agent to explore. This paper proposes a method called CEMP, which drives the agent to explore more effectively and continuously in the sparse reward environment. CEMP contributes a new framework for designing intrinsic reward from multiple perspectives, and can be easily integrated into various existing reinforcement learning algorithms. In addition, experimental results in a series of complex and sparse reward environments in MiniGrid demonstrate that our proposed CEMP method achieves better final performance and faster learning efficiency than ICM, RIDE, and TRPO-AE-Hash, which only calculate intrinsic reward from a single perspective.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_5
DP  - Springer Link
SP  - 57
EP  - 68
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Exploration Strategy
KW  - Intrinsic Motivation
KW  - Reinforcement Learning
KW  - Sparse Reward
ER  - 

TY  - CONF
TI  - DeepChrom: A Diffusion-Based Framework for Long-Tailed Chromatin State Prediction
AU  - Liu, Yuhang
AU  - Wang, Zixuan
AU  - Lv, Jiaheng
AU  - Zhang, Yongqing
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Chromatin state reflects distinct biological roles of the genome that can systematically characterize regulatory elements and their functional interaction. Despite extensive computational studies, accurate prediction of chromatin state remains a challenge because of the long-tailed class imbalance. Here, we propose a deep-learning framework, DeepChrom, to predict long-tailed chromatin state directly from DNA sequence. The framework includes a diffusion-based model that balances the samples of different classes by generating pseudo-samples and a novel dilated CNN-based model for chromatin state prediction. On top of that, we further develop a novel equalization loss to increase the penalty on generated samples, which alleviates the impact of the bias between ground truth and generated samples. DeepChrom achieves outstanding performance on nine human cell types with our designed paradigm. Specifically, our proposed long-tailed learning strategy surpasses the traditional training method by 0.056 in Acc. To our knowledge, DeepChrom is pioneering in predicting long-tailed chromatin states by the diffusion-based model to achieve sample balance.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_15
DP  - Springer Link
SP  - 188
EP  - 199
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
ST  - DeepChrom
KW  - Bioinformatics
KW  - Chromatin state
KW  - Diffusion model
KW  - Long-tailed learning
ER  - 

TY  - CONF
TI  - Unsupervised Domain Adaptation for Optical Flow Estimation
AU  - Ding, Jianpeng
AU  - Deng, Jinhong
AU  - Zhang, Yanru
AU  - Wan, Shaohua
AU  - Duan, Lixin
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In recent years, we have witnessed significant breakthroughs of optical flow estimation with the thriving of deep learning. The performance of the unsupervised method is unsatisfactory due to it is lack of effective supervision. The supervised approaches typically assume that the training and test data are drawn from the same distribution, which is not always held in practice. Such a domain shift problem are common exists in optical flow estimation and makes a significant performance drop. In this work, we address these challenge scenarios and aim to improve the model generalization ability of the cross-domain optical flow estimation model. Thus we propose a novel framework to tackle the domain shift problem in optical flow estimation. To be specific, we first design a domain adaptive autoencoder to transform the source domain and the target domain image into a common intermediate domain. We align the distribution between the source and target domain in the latent space by a discriminator. And the optical flow estimation module adopts the images in the intermediate domain to predict the optical flow. Our model can be trained in an end-to-end manner and can be a plug and play module to the existing optical flow estimation model. We conduct extensive experiments on the domain adaptation scenarios including Virtual KITTI to KITTI and FlyingThing3D to MPI-Sintel, the experimental results show the effectiveness of our proposed method.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_4
DP  - Springer Link
SP  - 44
EP  - 56
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Deep learning
KW  - Domain adaptation
KW  - Optical flow
ER  - 

TY  - CONF
TI  - QEA-Net: Quantum-Effects-based Attention Networks
AU  - Zhang, Juntao
AU  - Zhou, Jun
AU  - Wang, Hailong
AU  - Lei, Yang
AU  - Cheng, Peng
AU  - Li, Zehan
AU  - Wu, Hao
AU  - Yu, Kun
AU  - An, Wenbo
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In the past decade, the attention mechanism has played an increasingly important role in computer vision. Such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. In this paper, we propose Quantum-Effects-based Attention Networks (QEA-Net), the simple yet effective attention networks, they can be integrated into many network architectures seamlessly. QEA-Net uses quantum effects between two identical particles to enhance the global channel information representation of the attention module. Our method could consistently outperform the SENet, with a lower number of parameters and computational cost. We evaluate QEA-Net through experiments on ImageNet-1K and compare it with state-of-the-art counterparts. We also demonstrated the effect of QEA-Net in combination with pre-trained networks on small downstream transfer learning tasks.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_9
DP  - Springer Link
SP  - 109
EP  - 120
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
ST  - QEA-Net
KW  - Attention mechanism
KW  - Image classification
KW  - Quantum mechanics
ER  - 

TY  - CONF
TI  - Enhancing Rule Learning on Knowledge Graphs Through Joint Ontology and Instance Guidance
AU  - Bao, Xianglong
AU  - Wang, Zhe
AU  - Wang, Kewen
AU  - Zhang, Xiaowang
AU  - Wu, Hutong
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Rule learning is a machine learning method that extracts implicit rules and patterns from data, enabling symbol-based reasoning in artificial intelligence. Unlike data-driven approaches such as deep learning, using rules for inference allows for interpretability. Many studies have attempted to automatically learn first-order rules from knowledge graphs. However, existing methods lack attention to the hierarchical information between ontology and instance and require a separate rule evaluation stage for rule filtering. To address these issues, this paper proposes a Ontology and Instance Guided Rule Learning (OIRL) approach to enhance rule learning on knowledge graphs. Our method treats rules as sequences composed of relations and utilizes semantic information from both ontology and instances to guide path generation, ensuring that paths contain as much pattern information as possible. We also develop an end-to-end rule generator that directly infers rule heads and incorporates an attention mechanism to output confidence scores, eliminating the need for rule instance-based rule evaluation. We evaluate OIRL using the knowledge graph completion task, and experimental results demonstrate its superiority over existing rule learning methods, confirming the effectiveness of the mined rules.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_11
DP  - Springer Link
SP  - 138
EP  - 150
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - First-order Logic
KW  - Knowledge graph
KW  - Rule learning
ER  - 

TY  - CONF
TI  - Pairwise-Emotion Data Distribution Smoothing for Emotion Recognition
AU  - Jiang, Hexin
AU  - Liang, Xuefeng
AU  - Xu, Wenxin
AU  - Zhou, Ying
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - In speech emotion recognition tasks, models learn emotional representations from datasets. We find the data distribution in the IEMOCAP dataset is very imbalanced, which may harm models to learn a better representation. To address this issue, we propose a novel Pairwise-emotion Data Distribution Smoothing (PDDS) method. PDDS considers that the distribution of emotional data should be smooth in reality, then applies Gaussian smoothing to emotion-pairs for constructing a new training set with a smoother distribution. The required new data are complemented using the mixup augmentation. As PDDS is model and modality agnostic, it is evaluated with three state-of-the-art models on two benchmark datasets. The experimental results show that these models are improved by 0.2% $$\sim $$∼4.8% and 0.1% $$\sim $$∼5.9% in terms of weighted accuracy and unweighted accuracy. In addition, an ablation study demonstrates that the key advantage of PDDS is the reasonable data distribution rather than a simple data augmentation.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_13
DP  - Springer Link
SP  - 164
EP  - 175
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Gaussian Smoothing
KW  - Mixup Augmentation
KW  - Model-modality Agnostic
KW  - Pairwise-emotion Data Distribution Smoothing
ER  - 

TY  - CONF
TI  - SIEFusion: Infrared and Visible Image Fusion via Semantic Information Enhancement
AU  - Lv, Guohua
AU  - Song, Wenkuo
AU  - Wei, Zhonghe
AU  - Cheng, Jinyong
AU  - Dong, Aimei
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - At present, most of existing fusion methods focus on the metrics and visual effects of image fusion, but ignore the requirements of high-level tasks after image fusion, which leads to the unsatisfactory performance of some methods in subsequent high-level tasks such as semantic segmentation and object detection. In order to address this problem and obtain images with rich semantic information for subsequent semantic segmentation tasks, we propose a fusion network for infrared and visible images based on semantic information enhancement named SIEFusion. In our fusion network, we design a cross-modal information sharing module(CISM) and a fine-grained detail feature extraction module(FFEM) to obtain better fused images with more semantic information. Extensive experiments show that our method outperforms the state-of-the-art methods both in qualitative and quantitative comparison, as well as in the subsequent segmentation tasks.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_14
DP  - Springer Link
SP  - 176
EP  - 187
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
ST  - SIEFusion
KW  - Deep learning
KW  - Image fusion
KW  - Semantic information
KW  - Subsequent vision task
ER  - 

TY  - CONF
TI  - A Robust Detection and Correction Framework for GNN-Based Vertical Federated Learning
AU  - Yang, Zhicheng
AU  - Fan, Xiaoliang
AU  - Wang, Zheng
AU  - Wang, Zihui
AU  - Wang, Cheng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Graph Neural Network based Vertical Federated Learning (GVFL) facilitates data collaboration while preserving data privacy by learning GNN-based node representations from participants holding different dimensions of node features. Existing works have shown that GVFL is vulnerable to adversarial attacks from malicious participants. However, how to defend against various adversarial attacks has not been investigated under the non-i.i.d. nature of graph data and privacy constraints. In this paper, we propose RDC-GVFL, a novel two-phase robust GVFL framework. In the detection phase, we adapt a Shapley-based method to evaluate the contribution of all participants to identify malicious ones. In the correction phase, we leverage historical embeddings to rectify malicious embeddings, thereby obtaining accurate predictions. We conducted extensive experiments on three well-known graph datasets under four adversarial attack settings. Our experimental results demonstrate that RDC-GVFL can effectively detect malicious participants and ensure a robust GVFL model against diverse attacks. Our code and supplemental material is available at https://github.com/zcyang-cs/RDC-GVFL.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_8
DP  - Springer Link
SP  - 97
EP  - 108
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Adversarial attack
KW  - GNN-based Vertical Federated Learning
KW  - Robustness
ER  - 

TY  - CONF
TI  - Explore Across-Dimensional Feature Correlations for Few-Shot Learning
AU  - Li, Tianyuan
AU  - Cao, Wenming
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Few-shot learning (FSL) aims to learn new concepts with only few examples, which is a challenging problem in deep learning. Attention-oriented methods have shown great potential in addressing the FSL problem. However, many of these methods tend to separately focus on different dimensions of the samples, like channel dimension or spatial dimension only, which may lead to limitations in extracting discriminative features. To address this problem, we propose an across-dimensional attention network (ADANet) to explore the feature correlations across channel and spatial dimensions of input samples. The ADANet can capture across-dimensional feature dependencies and produce reliable representations for the similarity metric. In addition, we also design a three-dimensional offset position encoding (TOPE) method that embeds the 3D position information into the across-dimensional attention, enhancing the robustness and generalization ability of the model. Extensive experiments on standard FSL benchmarks have demonstrated that our method can achieve better performances compared to the state-of-the-art approaches.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_12
DP  - Springer Link
SP  - 151
EP  - 163
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Across-dimension
KW  - Attention mechanism
KW  - Few-shot learning
KW  - Position encoding
ER  - 

TY  - CONF
TI  - Causal Discovery via the Subsample Based Reward and Punishment Mechanism
AU  - Yang, Jing
AU  - Lu, Ting
AU  - Kuai, Fan
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The discovery of causal relationships between variables from a large number of nonlinear observations is an important research direction in the field of data mining. Extensive studies have highlighted the challenge of constructing accurate causal networks using existing algorithms using large-scale, nonlinear, and high-dimensional data. To address the challenge of this, we propose a general method for causal discovery algorithms applicable to handling large sample data, namely the subsample based reward and punishment mechanism (SRPM) method, which can handle nonlinear large sample data more effectively. We mainly made three contributions. First, we determine the size of the sample split based on experiments to obtain better learning results. Secondly, we developed a reward and punishment mechanism where each sub-sample dynamically changes its own weight in the process of learning the network skeleton, and proposed the SRPM, a subsample method based on the reward and punishment mechanism. Finally, we combine SRPM with three different additive noise model structure learning algorithms applicable to non-Gaussian nonlinear data respectively, and demonstrate the effectiveness of the method through experiments on data generated by a variety of nonlinear function dependencies. Compared with the existing algorithms, the causal network construction algorithm based on SRPM method has a great improvement in accuracy and time performance, and the effectiveness of the method is also verified in the real power plant data.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_18
DP  - Springer Link
SP  - 224
EP  - 238
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - causal discovery
KW  - high-dimensional
KW  - large sample
KW  - nonlinear
ER  - 

TY  - CONF
TI  - Network Transplanting for the Functionally Modular Architecture
AU  - Zhang, Quanshi
AU  - Cheng, Xu
AU  - Wang, Xin
AU  - Yang, Yu
AU  - Wu, Yingnian
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - This paper focuses on the problem of transplanting category-and-task-specific neural networks to a generic, modular network without strong supervision. Unlike traditional deep neural networks (DNNs) with black-box representations, we design a functionally modular network architecture, which divides the entire DNN into several functionally meaningful modules. Like building LEGO blocks, we can teach the proposed DNN a new object category by directly transplanting the module corresponding to the object category from another DNN, with a few or even without sample annotations. Our method incrementally adds new categories to the DNN, which do not affect representations of existing categories. Such a strategy of incremental network transplanting can avoid the typical catastrophic-forgetting problem in continual learning. We further develop a back distillation method to overcome challenges of model optimization in network transplanting. In experiments, our method with much fewer training samples outperformed baselines.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_6
DP  - Springer Link
SP  - 69
EP  - 83
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Deep Learning
KW  - Network transplant
ER  - 

TY  - CONF
TI  - Adaptable Conservative Q-Learning for Offline Reinforcement Learning
AU  - Qiu, Lyn
AU  - Li, Xu
AU  - Liang, Lenghan
AU  - Sun, Mingming
AU  - Yan, Junchi
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The Out-of-Distribution (OOD) issue presents a considerable obstacle in offline reinforcement learning. Although current approaches strive to conservatively estimate the Q-values of OOD actions, their excessive conservatism under constant constraints may adversely affect model learning throughout the policy learning procedure. Moreover, the diverse task distributions across various environments and behaviors call for tailored solutions. To tackle these challenges, we propose the Adaptable Conservative Q-Learning (ACQ) method, which capitalizes on the Q-value’s distribution for each fixed dataset to devise a highly generalizable metric that strikes a balance between the conservative constraint and the training objective. Experimental outcomes reveal that ACQ not only holds its own against a variety of offline RL algorithms but also significantly improves the performance of CQL on most D4RL MuJoCo locomotion tasks in terms of normalized return.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_16
DP  - Springer Link
SP  - 200
EP  - 212
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Conservative algorithm
KW  - Deep Reinforcement Learning
KW  - Offline Reinforcement Learning
KW  - Out-of distribution problem
ER  - 

TY  - CONF
TI  - TiAM-GAN: Titanium Alloy Microstructure Image Generation Network
AU  - Zhang, Zhixuan
AU  - Jin, Fusheng
AU  - Gong, Haichao
AU  - Fan, Qunbo
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The generation of titanium alloy microstructure images through mechanical properties is of great value to the research and production of titanium alloy materials. The appearance of GAN provides the possibility for image generation. However, there is currently no work related to handling multiple continuous labels for microstructure images. This paper presents a multi-label titanium alloy microstructure image generation network(TiAM-GAN). The TiAM-GAN proposed in this paper contains two sub-networks, a generation network for simple textures, which is based on the existing generation adversarial network, we reconstruct the loss function for multi-label continuous variables and deduce the error bound. Another microstructure image generation network for complex textures uses a mixture density network to learn the labels-to-noise mapping, and a deep convolution generation adversarial network is used to learn the noise-to-image mapping, then the noise output by the mixture density network will input to the deep convolution generation adversarial network to generate the image. Finally, we compared our method with existing methods qualitatively and quantitatively, which shows our method can achieve better results.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_7
DP  - Springer Link
SP  - 84
EP  - 96
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
ST  - TiAM-GAN
KW  - Generative Adversarial Network
KW  - Image Generation
KW  - Multi-Label
KW  - Titanium Alloy Microstructure
ER  - 

TY  - CONF
TI  - Learning Scene Graph for Better Cross-Domain Image Captioning
AU  - Jia, Junhua
AU  - Xin, Xiaowei
AU  - Gao, Xiaoyan
AU  - Ding, Xiangqian
AU  - Pang, Shunpeng
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - The current image captioning (IC) methods achieve good results within a single domain primarily due to training on a large amount of annotated data. However, the performance of single-domain image captioning methods suffers when extended to new domains. To address this, we propose a cross-domain image captioning framework, called SGCDIC, which achieves cross-domain generalization of image captioning models by simultaneously optimizing two coupled tasks, i.e., image captioning and text-to-image synthesis (TIS). Specifically, we propose a scene-graph-based approach SGAT for image captioning tasks. The image synthesis task employs a GAN variant (DFGAN) to synthesize plausible images based on the generated text descriptions by SGAT. We compare the generated images with the real images to enhance the image captioning performance in new domains. We conduct extensive experiments to evaluate the performance of SGCDIC by using the MSCOCO as the source domain data, and using Flickr30k and Oxford-102 as the new domain data. Sufficient comparative experiments and ablation studies demonstrate that SGCDIC achieves substantially better performance than the strong competitors for the cross-domain image captioning task.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_10
DP  - Springer Link
SP  - 121
EP  - 137
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Dual Learning
KW  - Image Captioning
KW  - Scene Graph
KW  - Text-to-Image Synthesis
ER  - 

TY  - CONF
TI  - Classifier Decoupled Training for Black-Box Unsupervised Domain Adaptation
AU  - Chen, Xiangchuang
AU  - Shen, Yunhang
AU  - Luo, Xuan
AU  - Zhang, Yan
AU  - Li, Ke
AU  - Lin, Shaohui
A2  - Liu, Qingshan
A2  - Wang, Hanzi
A2  - Ma, Zhanyu
A2  - Zheng, Weishi
A2  - Zha, Hongbin
A2  - Chen, Xilin
A2  - Wang, Liang
A2  - Ji, Rongrong
T3  - Lecture Notes in Computer Science
AB  - Black-box unsupervised domain adaptation ($$\textrm{B}^2 \textrm{UDA}$$B2UDA) is a challenging task in unsupervised domain adaptation, where the source model is treated as a black box and only its output is accessible. Previous works have treated the source models as a pseudo-labeling tool and formulated $$\textrm{B}^2 \textrm{UDA}$$B2UDAas a noisy labeled learning (LNL) problem. However, they have ignored the gap between the “shift noise” caused by the domain shift and the hypothesis noise in LNL. To alleviate the negative impact of shift noise on $$\textrm{B}^2 \textrm{UDA}$$B2UDA, we propose a novel framework called Classifier Decoupling Training (CDT), which introduces two additional classifiers to assist model training with a new label-confidence sampling. First, we introduce a self-training classifier to learn robust feature representation from the low-confidence samples, which is discarded during testing, and the final classifier is only trained with a few high-confidence samples. This step decouples the training of high-confidence and low-confidence samples to mitigate the impact of noise labels on the final classifier while avoiding overfitting to the few confident samples. Second, an adversarial classifier optimizes the feature distribution of low-confidence samples to be biased toward high-confidence samples through adversarial training, which greatly reduces intra-class variation. Third, we further propose a novel ETP-entropy Sampling (E$$^2$$2S) to collect class-balanced high-confidence samples, which leverages the early-time training phenomenon into LNL. Extensive experiments on several benchmarks show that the proposed CDT achieves $$88.2\%$$88.2%, $$71.6\%$$71.6%, and $$81.3\%$$81.3%accuracies on Office-31, Office-Home, and VisDA-17, respectively, which outperforms state-of-the-art methods.
C1  - Singapore
C3  - Pattern Recognition and Computer Vision
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8435-0_2
DP  - Springer Link
SP  - 16
EP  - 30
LA  - en
PB  - Springer Nature
SN  - 978-981-9984-35-0
KW  - Adversarial learning
KW  - Domain adaptation
KW  - Noisy label
ER  - 

TY  - CONF
TI  - Lightweight Image Matting via Efficient Non-local Guidance
AU  - Kang, Zhaoxiang
AU  - Li, Zonglin
AU  - Liu, Qinglin
AU  - Zhu, Yuhe
AU  - Zhou, Hongfei
AU  - Zhang, Shengping
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Natural image matting aims to estimate the opacity of foreground objects. Most existing approaches involve prohibitive parameters, daunting computational complexity, and redundant dependency. In this paper, we propose a lightweight matting method termed LiteMatting, which learns the local smoothness of color space and affinities between neighboring pixels to estimate the alpha mattes. Specifically, a modified mobile block is adopted to construct an encoder-decoder framework, which reduces parameters while retaining sufficient spatial and channel information. In addition, a Long-Short Range Pyramid Pooling Module (LSRPPM) is introduced to extend the reception field by capturing long-range dependency between regions distributed discretely. Finally, an Efficient Non-Local Block (ENB) is presented for guiding high-level semantics propagation from low-level detail features to refine the alpha mattes. Extensive experiments demonstrate that our method achieves a favorable trade-off between accuracy and efficiency. Compared with most state-of-the-art approaches, our method attains an immense descent in parameters and FLOPs with 30$$\%$$%and 13$$\%$$%, respectively, while achieving an improvement of over 15$$\%$$%in SAD metrics. Code and model are available at https://github.com/kzx2018/LiteMatting.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_15
DP  - Springer Link
SP  - 238
EP  - 255
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_15.pdf
KW  - Efficient non-local
KW  - Image matting
KW  - Lightweight
ER  - 

TY  - CONF
TI  - Unreliability-Aware Disentangling for Cross-Domain Semi-supervised Pedestrian Detection
AU  - Wu, Wenhao
AU  - Wu, Si
AU  - Wong, Hau-San
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - The rapid progress of pedestrian detection is supported by the ever-growing labeled training data and elaborate neural-network-based model. However, adequate labeled training data are not always accessible when it comes to a new scene. Semi-supervised learning is promising for the case where a small amount of manually annotated images and a large amount of unannotated images are handy. In the semi-supervised setting, data generation is a powerful technique as a type of data augmentation. Some methods conduct data generation by disentangling pedestrian instances into different codes in latent space and combining codes of different instances to reconstruct new instances. However, these methods either work in a single domain or cannot handle the case where some instances are partially represented in the images. In this work, we propose to solve code-level information transferring from reliable domains to unreliable domains by incorporating a domain classifier that competes with the disentangling module to generate domain-invariant codes. An external classifier is trained on appearance-enhanced instances and sends integrity signals to the generative module, which facilitates the generative module to recognize fully/partially represented pedestrian instances. The resulting classifier ultimately renders high-quality pseudo-annotations for the unannotated data. The pseudo-annotated data, combined with a small amount of manually annotated data, are used to achieve a detector with more generalization and accuracy. We perform extensive experiments on multiple challenging benchmarks to demonstrate the effectiveness of the proposed method.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_12
DP  - Springer Link
SP  - 187
EP  - 203
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_12.pdf
KW  - Domain adaptation
KW  - Pedestrian detection
KW  - Semi-supervised learning
ER  - 

TY  - CONF
TI  - Multispectral-Based Imaging and Machine Learning for Noninvasive Blood Loss Estimation
AU  - Ambita, Ara Abigail E.
AU  - Co, Catherine S.
AU  - David, Laura T.
AU  - Ferrera, Charissa M.
AU  - Naval, Prospero C.
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Blood loss estimation during surgical operations is crucial in determining the appropriate transfusion decisions. More practical emerging solutions, e.g. the Triton System, use image processing and artificial intelligence (AI) in quantifying blood loss from images of blood-soaked sponges. Triton utilizes an infrared or depth camera that’s used to identify the region of color (RGB) image corresponding to a surgical textile. However, calculating depth is computationally expensive and can provide only the shape information. In this research, we propose a multispectral-based imaging and machine learning approach to directly quantify blood loss from images of surgical sponges. Near-infrared (NIR) and Visible (Vis) light sources in conjunction with an RGB imaging sensor without a NIR filter are used. With this, in addition to the improved focus and reduced background interference on the gauze image due to blood’s IR absorption capacities, the color as well as the shape information may be utilized. Results show that the multispectral-based imaging approach rendered a +28.30%, +48%, +27.97%, and 25.72% improvement on the MAE, MSE, RMSE, and MAPE, compared to using a single Vis wavelength or RGB image.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_11
DP  - Springer Link
SP  - 171
EP  - 186
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_11.pdf
KW  - Blood loss
KW  - Machine learning
KW  - Multispectral imaging
ER  - 

TY  - CONF
TI  - Spatio-Channel Attention Blocks for Cross-modal Crowd Counting
AU  - Zhang, Youjia
AU  - Choi, Soyun
AU  - Hong, Sungeun
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Crowd counting research has made significant advancements in real-world applications, but it remains a formidable challenge in cross-modal settings. Most existing methods rely solely on the optical features of RGB images, ignoring the feasibility of other modalities such as thermal and depth images. The inherently significant differences between the different modalities and the diversity of design choices for model architectures make cross-modal crowd counting more challenging. In this paper, we propose Cross-modal Spatio-Channel Attention (CSCA) blocks, which can be easily integrated into any modality-specific architecture. The CSCA blocks first spatially capture global functional correlations among multi-modality with less overhead through spatial-wise cross-modal attention. Cross-modal features with spatial attention are subsequently refined through adaptive channel-wise feature aggregation. In our experiments, the proposed block consistently shows significant performance improvement across various backbone networks, resulting in state-of-the-art results in RGB-T and RGB-D crowd counting.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_2
DP  - Springer Link
SP  - 22
EP  - 40
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_2.pdf
KW  - Attention
KW  - Cross-modal
KW  - Crowd counting
ER  - 

TY  - CONF
TI  - Self-distilled Vision Transformer for Domain Generalization
AU  - Sultana, Maryam
AU  - Naseer, Muzammal
AU  - Khan, Muhammad Haris
AU  - Khan, Salman
AU  - Khan, Fahad Shahbaz
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - In the recent past, several domain generalization (DG) methods have been proposed, showing encouraging performance, however, almost all of them build on convolutional neural networks (CNNs). There is little to no progress on studying the DG performance of vision transformers (ViTs), which are challenging the supremacy of CNNs on standard benchmarks, often built on i.i.d assumption. This renders the real-world deployment of ViTs doubtful. In this paper, we attempt to explore ViTs towards addressing the DG problem. Similar to CNNs, ViTs also struggle in out-of-distribution scenarios and the main culprit is overfitting to source domains. Inspired by the modular architecture of ViTs, we propose a simple DG approach for ViTs, coined as self-distillation for ViTs. It reduces the overfitting of source domains by easing the learning of input-output mapping problem through curating non-zero entropy supervisory signals for intermediate transformer blocks. Further, it does not introduce any new parameters and can be seamlessly plugged into the modular composition of different ViTs. We empirically demonstrate notable performance gains with different DG baselines and various ViT backbones in five challenging datasets. Moreover, we report favorable performance against recent state-of-the-art DG methods. Our code along with pre-trained models are publicly available at: https://github.com/maryam089/SDViT.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_17
DP  - Springer Link
SP  - 273
EP  - 290
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_17.pdf
KW  - Domain generalization
KW  - Self distillation
KW  - Vision transformers
ER  - 

TY  - CONF
TI  - Fully Transformer Network for Change Detection of Remote Sensing Images
AU  - Yan, Tianyu
AU  - Wan, Zifu
AU  - Zhang, Pingping
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Recently, change detection (CD) of remote sensing images have achieved great progress with the advances of deep learning. However, current methods generally deliver incomplete CD regions and irregular CD boundaries due to the limited representation ability of the extracted visual features. To relieve these issues, in this work we propose a novel learning framework named Fully Transformer Network (FTN) for remote sensing image CD, which improves the feature extraction from a global view and combines multi-level visual features in a pyramid manner. More specifically, the proposed framework first utilizes the advantages of Transformers in long-range dependency modeling. It can help to learn more discriminative global-level features and obtain complete CD regions. Then, we introduce a pyramid structure to aggregate multi-level visual features from Transformers for feature enhancement. The pyramid structure grafted with a Progressive Attention Module (PAM) can improve the feature representation ability with additional interdependencies through channel attentions. Finally, to better train the framework, we utilize the deeply-supervised learning with multiple boundary-aware loss functions. Extensive experiments demonstrate that our proposed method achieves a new state-of-the-art performance on four public CD benchmarks. For model reproduction, the source code is released at https://github.com/AI-Zhpp/FTN.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_5
DP  - Springer Link
SP  - 75
EP  - 92
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_5.pdf
KW  - Change detection
KW  - Fully Transformer Network
KW  - Remote sensing image
ER  - 

TY  - CONF
TI  - CIRL: A Category-Instance Representation Learning Framework for Tropical Cyclone Intensity Estimation
AU  - Wang, Dengke
AU  - Xu, Yajing
AU  - Luo, Yicheng
AU  - Qian, Qifeng
AU  - Yuan, Lv
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Tropical Cyclone (TC) intensity estimation is a continuous label classification problem, which aims to build a mapping relationship from TC images to intensities. Due to the similar visual appearance of TCs in adjacent intensities, the discriminative image representation plays an important role in TC intensity estimation. Existing works mainly revolve around the continuity of intensity which may result in a crowded feature distribution and perform poorly at distinguishing the boundaries of categories. In this paper, we focus on jointly learning category-level and instance-level representations from tropical cyclone images. Specially, we propose a general framework containing a CI-extractor and a classifier, inside which the CI-extractor is used to extract an instance-separable and category-discriminative representation between images. Meanwhile, an inter-class distance consistency (IDC) loss is applied on top of the framework which can lead to a more uniform feature distribution. In addition, a non-parameter smoothing algorithm is proposed to aggregate temporal information from the image sequence. Extensive experiments demonstrate that our method, with the result of 7.35 knots at RMSE, outperforms the state-of-the-art TC intensity estimation method on the TCIR dataset.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_9
DP  - Springer Link
SP  - 141
EP  - 154
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - CIRL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_9.pdf
KW  - Intensity estimation
KW  - Representation learning
KW  - Tropical cyclone
ER  - 

TY  - CONF
TI  - Self-supervised Augmented Patches Segmentation for Anomaly Detection
AU  - Long, Jun
AU  - Yang, Yuxi
AU  - Hua, Liujie
AU  - Ou, Yiqi
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - In this paper, our goal is to detect unknown defects in high-resolution images in the absence of anomalous data. Anomaly detection is usually performed at image-level or pixel-level. Considering that pixel-level anomaly classification achieves better representation learning in a finer-grained manner, we regard data augmentation transforms as a self-supervised segmentation task from which to extract the critical and representative information from images. Due to the unpredictability of anomalies in real scenarios, we propose a novel abnormal sample simulation strategy which augmented patches are randomly pasted to original image to create a generalized anomalous pattern. Following the framework of self-supervised, segmenting augmented patches is used as a proxy task in the training phase to extract representation separating normal and abnormal patterns, thus constructing a one-class classifier with a robust decision boundary. During the inference phase, the classifier is used to perform anomaly detection on the test data, while directly determining regions of unknown defects in an end-to-end manner. Our experimental results on MVTec AD dataset and BTAD dataset demonstrate the proposed SSAPS outperforms any other self-supervised based methods in anomaly detection. Code is available at https://github.com/BadSeedX/SSAPS.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_6
DP  - Springer Link
SP  - 93
EP  - 107
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_6.pdf
KW  - Anomaly detection
KW  - Data augmentation
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Patch Embedding as Local Features: Unifying Deep Local and Global Features via Vision Transformer for Image Retrieval
AU  - Phan, Lam
AU  - Nguyen, Hiep Thi Hong
AU  - Warrier, Harikrishna
AU  - Gupta, Yogesh
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Image retrieval is the task of finding all images in the data-base that are similar to a query image. Two types of image representations have been studied to address this task: global and local image features. Those features can be extracted separately or jointly in a single model. State-of-the-art methods usually learn them with Convolutional Neural Networks (CNNs) and perform retrieval with multi-scale image representation. This paper’s main contribution is to unify global and local features with Vision Transformers (ViTs) and multi-atrous convolutions for high-performing retrieval. We refer to the new model as ViTGaL, standing for Vision Transformer based Global and Local features (ViTGaL). Specifically, we add a multi-atrous convolution to the output of the transformer encoder layer of ViTs to simulate the image pyramid used in standard image retrieval algorithms. We use class attention to aggregate the token embeddings output from the multi-atrous layer to get both global and local features. The entire network can be learned end-to-end, requiring only image-level labels. Extensive experiments show the proposed method outperforms the state-of-the-art methods on the Revisited Oxford and Paris datasets. Our code is available at here
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_13
DP  - Springer Link
SP  - 204
EP  - 221
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - Patch Embedding as Local Features
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_13.pdf
ER  - 

TY  - CONF
TI  - Explaining Deep Neural Networks for Point Clouds Using Gradient-Based Visualisations
AU  - Tayyub, Jawad
AU  - Sarmad, Muhammad
AU  - Schönborn, Nicolas
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Explaining decisions made by deep neural networks is a rapidly advancing research topic. In recent years, several approaches have attempted to provide visual explanations of decisions made by neural networks designed for structured 2D image input data. In this paper, we propose a novel approach to generate coarse visual explanations of networks designed to classify unstructured 3D data, namely point clouds. Our method uses gradients flowing back to the final feature map layers and maps these values as contributions of the corresponding points in the input point cloud. Due to dimensionality disagreement and lack of spatial consistency between input points and final feature maps, our approach combines gradients with points dropping to compute explanations of different parts of the point cloud iteratively. The generality of our approach is tested on various point cloud classification networks, including ‘single object’ networks PointNet, PointNet++, DGCNN, and a ‘scene’ network VoteNet. Our method generates symmetric explanation maps that highlight important regions and provide insight into the decision-making process of network architectures. We perform an exhaustive evaluation of trust and interpretability of our explanation method against comparative approaches using quantitative, quantitative and human studies. All our code is implemented in PyTorch and will be made publicly available.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_10
DP  - Springer Link
SP  - 155
EP  - 170
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_10.pdf
KW  - Deep neural networks
KW  - Explainability
KW  - Point cloud
ER  - 

TY  - CONF
TI  - Improving Surveillance Object Detection with Adaptive Omni-Attention over Both Inter-frame and Intra-frame Context
AU  - Yu, Tingting
AU  - Chen, Chen
AU  - Zhou, Yichao
AU  - Hu, Xiyuan
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Surveillance object detection is a challenging and practical sub-branch of object detection. Factors such as lighting variations, smaller objects, and motion blur in video frames affect detection results, but on the other hand, the temporal information and stable background of a surveillance video are major advantages that does not exist in generic object detection. In this paper, we propose an adaptive omni-attention model for surveillance object detection, which effectively and efficiently integrates inter-frame contextual information to improve the detection of low-quality frames and intra-frame attention to suppress false positive detections in the background regions. In addition, the training of the proposed network can converge quickly with less epochs because during multi-frame fusion stage, the pre-trained weights of the single-frame network can be used to update simultaneously in reverse in both single-frame and multi-frame feature maps. The experimental results on the UA-DETRAC and the UAVDT datasets have demonstrated the promising performance of our proposed detector in both accuracy and speed. (Code is available at https://github.com/Yubzsz/Omni-Attention-VOD.)
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_14
DP  - Springer Link
SP  - 222
EP  - 237
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_14.pdf
ER  - 

TY  - CONF
TI  - CV4Code: Sourcecode Understanding via Visual Code Representations
AU  - Shi, Ruibo
AU  - Tao, Lili
AU  - Saphal, Rohan
AU  - Silavong, Fran
AU  - Moran, Sean
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - We present CV4Code$$^1$$1, a compact and effective computer vision method for sourcecode understanding. Our method leverages the contextual and the structural information available from the code snippet by treating each snippet as a two-dimensional image, which naturally encodes the context and retains the underlying structural information through an explicit spatial representation. To codify snippets as images, we propose an ASCII codepoint-based image representation that facilitates fast generation of sourcecode images and eliminates redundancy in the encoding that would arise from an RGB pixel representation. Furthermore, as sourcecode is treated as images, neither lexical analysis (tokenisation) nor syntax tree parsing is required, which makes the proposed method agnostic to any particular programming language and lightweight from the application pipeline point of view. CV4Code can even featurise syntactically incorrect code which is not possible from methods that depend on the Abstract Syntax Tree (AST). We demonstrate the effectiveness of CV4Code by learning Convolutional and Transformer networks to predict the functional task, i.e.   the problem it solves, of the source code directly from its two-dimensional representation, and using an embedding from its latent space to derive a similarity score of two code snippets in a retrieval setup. Experimental results show that our approach achieves state-of-the-art performance in comparison to other methods with the same task and data configurations. For the first time we show the benefits of treating sourcecode understanding as a form of image processing task. ($$^1$$1https://github.com/jpmorganchase/cv4code)
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_18
DP  - Springer Link
SP  - 291
EP  - 306
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - CV4Code
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_18.pdf
KW  - ResNet
KW  - Sourcecode understanding
KW  - Transformer
KW  - ViT
ER  - 

TY  - CONF
TI  - DILane: Dynamic Instance-Aware Network for Lane Detection
AU  - Cheng, Zhengyun
AU  - Zhang, Guanwen
AU  - Wang, Changhao
AU  - Zhou, Wei
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Lane detection is a challenging task in computer vision and a critical technology in autonomous driving. The task requires the prediction of the topology of lane lines in complex scenarios; moreover, different types and instances of lane lines need to be distinguished. Most existing studies are based only on a single-level feature map extracted by deep neural networks. However, both high-level and low-level features are important for lane detection, because lanes are easily affected by illumination and occlusion, i.e., texture information is unavailable in non-visual evidence case; when the lanes are clearly visible, the curved and slender texture information plays a more important role in improving the detection accuracy. In this study, the proposed DILane utilizes both high-level and low-level features for accurate lane detection. First, in contrast to mainstream detection methods of predefined fixed-position anchors, we define learnable anchors to perform statistics of potential lane locations. Second, we propose a dynamic head aiming at leveraging low-level texture information to conditionally enhance high-level semantic features for each proposed instance. Finally, we present a self-attention module to gather global information in parallel, which remarkably improves detection accuracy. The experimental results on two mainstream public benchmarks demonstrate that our proposed method outperforms previous works with the F1 score of 79.43% for CULane and 97.80% for TuSimple dataset while achieving 148+ FPS.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_8
DP  - Springer Link
SP  - 124
EP  - 140
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - DILane
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_8.pdf
KW  - Dynamic head
KW  - Lane detection
KW  - Self-attention
ER  - 

TY  - CONF
TI  - Complex Handwriting Trajectory Recovery: Evaluation Metrics and Algorithm
AU  - Chen, Zhounan
AU  - Yang, Daihui
AU  - Liang, Jinglin
AU  - Liu, Xinwu
AU  - Wang, Yuyi
AU  - Peng, Zhenghua
AU  - Huang, Shuangping
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Many important tasks such as forensic signature verification, calligraphy synthesis, etc., rely on handwriting trajectory recovery of which, however, even an appropriate evaluation metric is still missing. Indeed, existing metrics only focus on the writing orders but overlook the fidelity of glyphs. Taking both facets into account, we come up with two new metrics, the adaptive intersection on union (AIoU) which eliminates the influence of various stroke widths, and the length-independent dynamic time warping (LDTW) which solves the trajectory-point alignment problem. After that, we then propose a novel handwriting trajectory recovery model named Parsing-and-tracing ENcoder-decoder Network (PEN-Net), in particular for characters with both complex glyph and long trajectory, which was believed very challenging. In the PEN-Net, a carefully designed double-stream parsing encoder parses the glyph structure, and a global tracing decoder overcomes the memory difficulty of long trajectory prediction. Our experiments demonstrate that the two new metrics AIoU and LDTW together can truly assess the quality of handwriting trajectory recovery and the proposed PEN-Net exhibits satisfactory performance in various complex-glyph languages including Chinese, Japanese and Indic. The source code is available at https://github.com/ChenZhounan/PEN-Net.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_4
DP  - Springer Link
SP  - 58
EP  - 74
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - Complex Handwriting Trajectory Recovery
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_4.pdf
KW  - Evaluation metrics
KW  - Handwriting
KW  - Trajectory recovery
ER  - 

TY  - CONF
TI  - Rethinking Low-Level Features for Interest Point Detection and Description
AU  - Wang, Changhao
AU  - Zhang, Guanwen
AU  - Cheng, Zhengyun
AU  - Zhou, Wei
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Although great efforts have been made for interest point detection and description, the current learning-based methods that use high-level features from the higher layers of Convolutional Neural Networks (CNN) do not completely outperform the conventional methods. On the one hand, interest points are semantically ill-defined and high-level features that emphasize semantic information are not adequate to describe interest points; On the other hand, the existing methods using low-level information usually perform detection on multi-level feature maps, which is time consuming for real time applications. To address these problems, we propose a Low-level descriptor-Aware Network (LANet) for interest point detection and description in self-supervised learning. Specifically, the proposed LANet exploits the low-level features for interest point description while using high-level features for interest point detection. Experimental results demonstrate that LANet achieves state-of-the-art performance on the homography estimation benchmark. Notably, the proposed LANet is a front-end feature learning framework that can be deployed in downstream tasks that require interest points with high-quality descriptors. (Code is available on https://github.com/wangch-g/lanet.).
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_7
DP  - Springer Link
SP  - 108
EP  - 123
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_7.pdf
ER  - 

TY  - CONF
TI  - Skin Tone Diagnosis in the Wild: Towards More Robust and Inclusive User Experience Using Oriented Aleatoric Uncertainty
AU  - Malherbe, Emmanuel
AU  - Remise, Michel
AU  - Zhang, Shuai
AU  - Perrot, Matthieu
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - The past decade has seen major advances in deep learning models that are trained to predict a supervised label. However, estimating the uncertainty for a predicted value might provide great information beyond the prediction itself. To address this goal, using a probabilistic loss was proven efficient for aleatoric uncertainty, which aims at capturing noise originating from the observations. For multidimensional predictions, this estimated noise is generally a multivariate normal variable, characterized by a mean value and covariance matrix. While most of literature have focused on isotropic uncertainty, with diagonal covariance matrix, estimating full covariance brings additional information, such as the noise orientation in the output space.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_1
DP  - Springer Link
SP  - 3
EP  - 21
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - Skin Tone Diagnosis in the Wild
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_1.pdf
ER  - 

TY  - CONF
TI  - RGB Road Scene Material Segmentation
AU  - Cai, Sudong
AU  - Wakaki, Ryosuke
AU  - Nobuhara, Shohei
AU  - Nishino, Ko
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - We address RGB road scene material segmentation, i.e., per-pixel segmentation of materials in real-world driving views with pure RGB images, by building a new tailored benchmark dataset and model for it. Our new dataset, KITTI-Materials, based on the well-established KITTI dataset, consists of 1000 frames covering 24 different road scenes of urban/suburban landscapes, annotated with one of 20 material categories for every pixel in high quality. It is the first dataset tailored to RGB material segmentation in realistic driving scenes which allows us to train and test any RGB material segmentation model. Based on an analysis on KITTI-Materials, we identify the extraction and fusion of texture and context as the key to robust road scene material appearance. We introduce Road scene Material Segmentation Network (RMSNet), a new Transformer-based framework which will serve as a baseline for this challenging task. RMSNet encodes multi-scale hierarchical features with self-attention. We construct the decoder of RMSNet based on a novel lightweight self-attention model, which we refer to as SAMixer. SAMixer achieves adaptive fusion of informative texture and context cues across multiple feature levels. It also significantly accelerates self-attention for feature fusion with a balanced query-key similarity measure. We also introduce a built-in bottleneck of local statistics to achieve further efficiency and accuracy. Extensive experiments on KITTI-Materials validate the effectiveness of our RMSNet. We believe our work lays a solid foundation for further studies on RGB road scene material segmentation.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_16
DP  - Springer Link
SP  - 256
EP  - 272
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_16.pdf
ER  - 

TY  - CONF
TI  - Domain Generalized RPPG Network: Disentangled Feature Learning with Domain Permutation and Domain Augmentation
AU  - Chung, Wei-Hao
AU  - Hsieh, Cheng-Ju
AU  - Liu, Sheng-Hung
AU  - Hsu, Chiou-Ting
A2  - Wang, Lei
A2  - Gall, Juergen
A2  - Chin, Tat-Jun
A2  - Sato, Imari
A2  - Chellappa, Rama
T3  - Lecture Notes in Computer Science
AB  - Remote photoplethysmography (rPPG) offers a contactless method for monitoring physiological signals from facial videos. Existing learning-based methods, although work effectively on intra-dataset scenarios, degrade severely on cross-dataset testing. In this paper, we address the cross-dataset testing as a domain generalization problem and propose a novel DG-rPPGNet to learn a domain generalized rPPG estimator. To this end, we develop a feature disentangled learning framework to disentangle rPPG, identity, and domain features from input facial videos. Next, we propose a domain permutation strategy to further constrain the disentangled rPPG features to be invariant to different domains. Finally, we design a novel adversarial domain augmentation strategy to enlarge the domain sphere of DG-rPPGNet. Our experimental results show that DG-rPPGNet outperforms other rPPG estimation methods in many cross-domain settings on UBFC-rPPG, PURE, COHFACE, and VIPL-HR datasets.
C1  - Cham
C3  - Computer Vision – ACCV 2022
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-26284-5_3
DP  - Springer Link
SP  - 41
EP  - 57
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-26284-5
ST  - Domain Generalized RPPG Network
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-26284-5_3.pdf
ER  - 

TY  - CONF
TI  - Design of Automatic Credit Card Approval System Using Machine Learning
AU  - Hemkiran, S.
AU  - Sudha Sadasivam, G.
AU  - Prasanna Rahavendra, A.
AU  - Anjhanna, A. K.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Commercial banks receive numerous applications for credit cards. Several applications are rejected for reasons such as high loan balances, low-income levels or too many inquiries on an individual’s credit report. Manual analysis of these applications is mundane, error-prone and time consuming. Hence, this task of analysis and approval can be automated with machine learning (ML) algorithms. In this study, an automatic credit card approval predictor is built using ML techniques. The credit card approval dataset from the UCI ML Repository is used to train the ML model to predict if an applicant can be issued with a credit card or not. The performance of the ML model built using logistic regression is evaluated with and without grid search technique. It was observed that implementing grid search improved the competency of the ML model by 4%. Subsequently, an ANN model was developed. The ANN substantially outperformed both the logistic regression models. This study indicates that ML models can be utilized to solve complex problems which are arduous to decipher with the aid of conventional programming techniques.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_1
DP  - Springer Link
SP  - 1
EP  - 9
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_1.pdf
KW  - Confusion matrix
KW  - Credit card approval system
KW  - Logistic regression
KW  - Machine learning
ER  - 

TY  - CONF
TI  - Machine Learning-Based Smart Surveillance and Intrusion Detection System for National Geographic Borders
AU  - Sharma, Mrinal
AU  - Kumar, C. R. S.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - The safety, security and unmanned surveillance of national geographic borders of the country is of supreme importance. Greater security measures and surveillance techniques are required at those border which are prone to cross-border terrorists movements. The use of video/image data sets, algorithms and computer vision can be aptly utilized to design an automated surveillance system which can learn and perform these supreme critical tasks. In this paper, we have proposed a new architecture of surveillance system for such volatile border areas prone to terrorist intrusion that detects infiltration of humans, weapons and UAVs. Its capabilities are enhanced to superior level by adding deep learning/machine learning algorithms and Bluetooth signature detection techniques, hence attaining the artificial intelligence (AI) embedded autonomous surveillance system at line of control. This will make border surveillance more effective and efficient, reducing physical domination by troops all along the fence, reducing the risk to life and saving the existing surveillance equipment for other important tasks.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_19
DP  - Springer Link
SP  - 165
EP  - 176
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_19.pdf
KW  - Bluetooth signature scanner
KW  - Deep learning
KW  - Human
KW  - Machine learning
KW  - Weapons and UAV detection
ER  - 

TY  - CONF
TI  - Depth Comparison of Objects in 2D Images Using Mask RCNN
AU  - Singh, Himanshu
AU  - Kirubanand, V. B.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Getting distance of an object from a single 2D image has always been a task. Due to various reasons, it was difficult to compare from images whether an object is closer or farther from camera. In this paper, we propose an idea to compare multiple images taken from same focal length cameras and specifying the distance of an object in those images with respect to each other.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_10
DP  - Springer Link
SP  - 81
EP  - 88
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_10.pdf
KW  - Depth analysis of object in image
KW  - Masked RCNN
KW  - Relative distance of object in images
ER  - 

TY  - CONF
TI  - A Fast Method for Retinal Disease Classification from OCT Images Using Depthwise Separable Convolution
AU  - Meenu Mohan, S.
AU  - Aji, S.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Retinal diseases are the commonest reason for losing eye sight at an early age. The retina is the most important part of forming visual images, which is a thin layer of tissue situated at the backside wall of the eye. These diseases can be identified accurately from SD-OCT scanned images. OCT is a non-contact imaging technology that is used to detect abnormalities among retinal layers. Currently, the classification performed by an ophthalmologist is relatively time consuming. Among the several retinal OCT classification techniques, a recent advancement is deep learning techniques for retinal image classification. Among the deep learning models used is the convolutional neural network (CNN), which can instinctively learn a series of hierarchical features. Therefore, the proposed method uses a variety of standard spatial convolution, which is depthwise separable convolution (DSC). DSC reduces the complexity of the network by reducing trainable parameters and by reducing time and space complexity. The method was tested on the public dataset OCT2017. Experimental results show the proposed method gives a promising result with better execution time compared to the standard CNN.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_18
DP  - Springer Link
SP  - 153
EP  - 163
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_18.pdf
KW  - Depthwise separable convolution
KW  - Retinal diseases classification
KW  - Spectral domain-optical coherence tomography
ER  - 

TY  - CONF
TI  - Recent Trends and Study on Perspective Crowd Counting in Smart Environments
AU  - Jaswanth, Vasupalli
AU  - Yeduguru, Arun Reddy
AU  - Manoj, Vura Seetha
AU  - Deepak, K.
AU  - Chandrakala, S.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Estimation of the people count in a highly congested scene is a challenging task. It has an extensive range of applications in smart environments such as traffic monitoring, video surveillance, and automatic crowd management. It includes various challenges such as insufficient resolution, dynamic backgrounds, severe congestion, excessive overlaps, occlusions, and perspective changes. With the advancements in deep learning, crowd counting has been achieving excellent results in terms of accuracy and robustness. In this paper, we perform a brief review of perspective crowd counting and a study on recent perspective crowd counting methods namely S-DC Net, PCC Net, and SCAR. We have also identified a variant, which use both S-DC Net and Down Up Left Right (DULR) module and studied its performance on benchmark datasets. Few directions for further research are also presented.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_7
DP  - Springer Link
SP  - 63
EP  - 72
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_7.pdf
KW  - Attention model
KW  - Deep learning
KW  - Density map
KW  - Perspective crowd counting
ER  - 

TY  - CONF
TI  - Short-Term Load Forecasting Using Random Forest with Entropy-Based Feature Selection
AU  - Subbiah, Siva Sankari
AU  - Chinnappan, Jayakumar
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - The forecasting of electricity load is an important task for the proper functioning of power system utilities. In the modern era, the dimension of the dataset becomes the barrier for achieving an accurate forecasting results. The dimension of the dataset can be reduced by eliminating the redundant and irrelevant features from the input data. In this paper, the entropy-based feature selection (EBFS) is utilized for identifying both the irrelevant and redundant features. The EBFS removes the irrelevant features using the information theoretic-based mutual information and removes the redundant features using the correlation-based symmetric uncertainty. The random forest (RF) is utilized to forecast the short-term load, and the performance of forecasting is compared against the back propagation neural network (BPNN). The experiment is conducted using R tool on the Australia electricity utility dataset. The result shows that the random forest with selected features achieves more accurate result than others.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_8
DP  - Springer Link
SP  - 73
EP  - 80
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_8.pdf
KW  - Backpropagation neural network
KW  - Feature selection
KW  - Load forecasting
KW  - Machine learning
KW  - Random forest
ER  - 

TY  - CONF
TI  - Comparative Investigation on Acoustic Attributes of Healthy Young Adults
AU  - Karunaimathi, V. Prarthana
AU  - Gladis, D.
AU  - Balakrishnan, D.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Human voice is so unique and used for a wide range of communication and entertainment. Any abnormality in voice quality, pitch, and loudness indicates voice disorder. The objective information of voice can be obtained through voice analysis applications using signal processing techniques. The results are visualized, so that the abnormal voice can be easily diagnosed and consecutively equips the clinicians to track the progression of the voice therapy and treatment. This paper aims at extraction of voice parameters from voice signals such as fundamental frequency (F0 mean, standard deviation, maximum and minimum), percentage of pitch perturbation (jitter%), amplitude perturbation (shimmer%) and harmonics-to-noise ratio (HNR) using a novel algorithm leading to an application named Ephphatha and the same were compared with the parameters of existing software applications Praat and Dr. Speech using t-test analysis and the correlation plot. The result shows that the attributes of the proposed system are strongly correlated to Praat than Dr. Speech.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_14
DP  - Springer Link
SP  - 123
EP  - 133
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_14.pdf
KW  - Fundamental frequency
KW  - Jitter
KW  - Shimmer
KW  - Signal processing
ER  - 

TY  - CONF
TI  - Hand Signs Recognition from Cellphone Camera Captured Images for Deaf-Mute Persons
AU  - Masum, Asif Irfanullah
AU  - Mollah, Ayatullah Faruk
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Vision-based hand gesture recognition is an important task in human–computer interaction research. Sign language recognition through hand gesture images or video frames may facilitate deaf-mute persons communicate with ordinary human beings through computers. In this paper, we report (i) development of a dataset of hand gesture images acquired with handheld digital camera built in a cellphone, (ii) a pipeline for effective segmentation of palm with fingers and orientation correction of segmented region, and (iii) initial benchmark performance with multiple classifiers and multiple folds of experiments. We have obtained highest performance of 99.47% accuracy with RBF kernel-based support vector machine. We would like to release this dataset and make it available for academic, scientific, and non-commercial purposes.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_5
DP  - Springer Link
SP  - 45
EP  - 52
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_5.pdf
KW  - Gesture recognition
KW  - Hand gesture dataset
KW  - Human–computer interaction
KW  - Image segmentation
KW  - Sign language
ER  - 

TY  - CONF
TI  - Automatic Road Surface Crack Detection Using Deep Learning Techniques
AU  - Aravindkumar, S.
AU  - Varalakshmi, P.
AU  - Alagappan, Chindhu
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Road serves an irreplaceable tool of transportation. Yet, it is the house of tremendous accidents. The common distresses that can affect the performance of road surface are crack and damage. We developed a new dataset which consists of 3,533 road images were collected from Inner Ring Road, Chennai, Tamil Nadu, India. The main contribution of this paper deals to detect crack and damage on road surface and also classify types of cracks based on its structure and then identify the location and send the notification to the nearest road maintenance government department officials. Our proposed work deals to design a pre-trained ResNet-152 model by incorporating with faster region-based convolutional neural network (Faster R-CNN). We apply our proposed model to other existing benchmark datasets. Experimental analysis and results of our model were measured using precision, recall and F-measure.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_4
DP  - Springer Link
SP  - 37
EP  - 44
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_4.pdf
KW  - First keyword
KW  - Second keyword
KW  - Third keyword
ER  - 

TY  - CONF
TI  - Robotic Process Automation
AU  - Choudhary, Raj
AU  - Karmel, A.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - In this era where celerity is expected in the software development process in terms of update release due to the immense competition in the market, automation of repetitive tasks can save a lot of time for the developers and engineers. Robotic process automation (RPA) handles this automation of repetitive tasks. Since the software robots handle these time-consuming tasks, the employees can invest their time in quality work that requires the expertise of the person and can lead to great returns for the organization. RPA leads to many benefits for the organization such as increased efficiency, better productivity, data integrity, data security, and improved accuracy. Implementing RPAs comes with its challenges like what are the tasks that should be automated, should a complete process be automated, or automating a sub-process can lead to better results. The automation for the software development industry was explored and implemented. This is the industry in which a lot of time of the developer is used in deploying and configuring the same services for testing, in case of failures, etc. By automating these tedious tasks, a lot of time of the developer could be saved and would lead to larger revenue generation for the organization.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_3
DP  - Springer Link
SP  - 29
EP  - 36
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_3.pdf
KW  - Process automation
KW  - Return on investment
KW  - Robotic process automation
KW  - Software automation
KW  - Software robots
ER  - 

TY  - CONF
TI  - Real-Time Big Data Analysis Using Web Scraping in Apache Spark Environment: Case Study—Mobile Data Analysis from Flipkart
AU  - Ganguly, Pushpita
AU  - Parihar, Giriraj
AU  - Sivagami, M.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - There are many data sources that produce sheer volumes of data, and this generated data named big data can be used for making decisions. There are lots of domains including finance, transportation, entertainment, energy, security, and emergency services rely on fast and efficient analytics based on available data to make quality decisions conveniently which is a key factor for businesses and many service industries. The big data nature requires new distributed processing approaches to extract the valuable information. Real-time sentiment analysis is one of the most demanding research areas that require powerful big data analytics tools such as Spark. This paper proposed a real-time data analysis. It first scraps data from the Web and will do real-time analysis using Spark with machine learning tools. As a case study for this real-time analysis, Flipkart mobile data is taken with the aim of doing classification of the dataset for further analysis as well as predicting the ratings of different kinds of mobile phones using machine learning modules. At last the accuracy of the implemented models is shown.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_20
DP  - Springer Link
SP  - 177
EP  - 185
LA  - en
PB  - Springer
SN  - 9789811664489
ST  - Real-Time Big Data Analysis Using Web Scraping in Apache Spark Environment
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_20.pdf
KW  - Data scraping
KW  - Data streaming
KW  - Exploratory data analysis
KW  - Machine learning models
KW  - Real-time data analysis
ER  - 

TY  - CONF
TI  - Future Frame Prediction Using Deep Learning
AU  - Itagi, Siddharth
AU  - Gowda, Sinchana
AU  - Udupa, Tanmaya
AU  - Shylaja, S. S.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - In today’s era, the usage of videos has led to major contributions in the technological world. Be it CCTV footage captured in apartments and at traffic intersections or real-time recordings in the medical industry, videos help in discerning various patterns and uncovering hidden details, accounting for its extensive usage. Future frame prediction involves using the analysis of videos to predict what could happen next in the video. This is an emerging field of deep learning and computer vision whose advancement would provide large potential to enable faster decision making processes in areas like autonomous driving cars, anomaly detection, and aggression in people and falls in the elderly. Due to the proven effectiveness of deep learning in image processing, our goal is to develop a generative model capable of producing a future frame given a set of sequential frames as input. Generative adversarial networks (GANs) and autoencoders are the models used in implementing and achieving the target results. This paper presents the analysis and results of different proposed architectures that take multiple frames as input and aim to produce accurate future frames with the use of multiple efficiency measures. A structural similarity index (SSIM) score of 0.875 was obtained for the predicted frame.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_21
DP  - Springer Link
SP  - 187
EP  - 199
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_21.pdf
KW  - Autoencoder
KW  - Computer vision
KW  - Deep learning
KW  - GAN
KW  - SSIM
ER  - 

TY  - CONF
TI  - Prediction of In-Cylinder Swirl in a Compression Ignition Engine with Vortex Tube Using Artificial and Recurrent Neural Networks
AU  - Renganathan, Manimaran
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Better combustion through induced swirl for stoichiometric air–fuel ratio is essential to achieve strictly lower pollution levels to mitigate climate crisis. This study proposes an innovative fuel–air mixing approach in which the swirl of air generated using vortex tube during induction in a four-stroke compression ignition engine is studied in a computational approach. The swirl ratio is observed from the solution of conservation equations of mass, momentum and energy out using computational fluid dynamics (CFD). The main focus of the work here is to predict the swirl ratio from training and testing methods in order to reduce the expensive computation from CFD. Artificial neural networks (ANN) and recurrent neural networks (RNN) are employed to predict the swirl ratio under different scenario. Predictions are verified with respect to percentage of data requirement for training/testing purposes, sampling frequency and moving window parameters. RNN and ANN predictions are within the scope of CFD results.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_6
DP  - Springer Link
SP  - 53
EP  - 62
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_6.pdf
KW  - Artificial neural network
KW  - Compression ignition engine
KW  - Recurrent neural network
KW  - Swirl ratio
KW  - Vortex tube
ER  - 

TY  - CONF
TI  - Constraint-Based Parallel Clustering with Optimized Feature Selection for SDN-Enabled Traffic Anomaly Detection and Mitigation
AU  - Vadivu, T.
AU  - Sumathi, B.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - The recent high-bandwidth applications have challenges in detecting the anomalies because of enormous amount of network traffics. It is resolved by designing software-defined networking (SDN) in such applications to avoid the network congestion. An optimized eliminated iterative symmetric uncertainty-based feature selection (OE-ISU-FS) with sampled-DP clustering scheme has been achieved better detection of anomalies via choosing the most relevant attributes and discarding the unwanted attributes/features in the dataset. But the clustering depends on the selection of regional density and distance of data which is influenced by the cutoff distance. Also, it focuses on previous information for choosing the appropriate cluster centroids and only apt for static dataset. In this article, a constraint-based parallel sampled-DP (CP sampled-DP) clustering scheme is designed which adopts a quick search. Cluster centroids algorithm is used to handle the dynamic large-scale dataset without any previous information. In this algorithm, many probable cluster centroids are generated automatically via computing the regional density and distance. After, the decision graph is evaluated from multiple perceptions to complete clustering without any faulty or miss-choice of variables. Moreover, the observational outcomes indicate that the CP sampled-DP clustering scheme attains enhanced efficiency compared to the existing schemes.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_15
DP  - Springer Link
SP  - 135
EP  - 144
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_15.pdf
KW  - Anomaly detection
KW  - Constraint-based parallel clustering
KW  - OE-ISU-FS
KW  - Sampled-DP
KW  - SDN
ER  - 

TY  - CONF
TI  - Face Recognition with Mask Using MTCNN and FaceNet
AU  - Tiwari, Abhishek Sunil
AU  - Gupta, Prajul
AU  - Jain, Aanya
AU  - Panjwani, Hari Vilas
AU  - Malathi, G.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - Face recognition is a method of identifying or verifying the identity of an individual using their face but what if this recognition method could be extended further to suit the needs of the current scenario. Given this COVID pandemic, this paper fits best by recognizing the people wearing masks. The research has been done by creating our own dataset using images from our friends and relatives followed by doing image augmentation by performing operations like rotating by some angle, changing brightness and contrast, zooming in and out, etc. Then, face with the mask is extracted from the given image with the help of MTCNN to get a bounding box, width, and the height of the face, and then, segmentation has been done by reducing the height by a factor of 2. FaceNet pretrained model has been used to represent the faces on a 128-dimensional unit hyper-sphere and get the embeddings for further classification. Many different algorithms like linear Discriminant analysis, SVM, ridge classifier, K-neighbors classifier, logistic regression, Naive Bayes, XGBoost, Ada Boost, random forest classifier, and decision tree classifier have been used for experimentation. After testing this, good accuracy was obtained as can be seen in the result section of this paper. The scope of this paper is quite vast as it covers many practical applications in real-scenario like detecting the presence of a particular person from an image or even from video by capturing faces frame by frame.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_12
DP  - Springer Link
SP  - 103
EP  - 109
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_12.pdf
KW  - Classification
KW  - Face recognition with mask
KW  - FaceNet
KW  - LDA
KW  - MTCNN
ER  - 

TY  - CONF
TI  - Predictive Policing—Are Ensemble Methods More Accurate Than Regression Methods?
AU  - Kathuria, Ronit
AU  - Kathuria, Vinish
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - The ability to predict crime before it takes place has acquired significant currency over the past decade. Predictive policing aims to achieve this ability using mathematical, predictive analytics in law enforcement to identify potential criminal activity. As machine learning models make inroads in predictive policing, this research aims to compare two widely used predictive policing methods with the concerted goal of predicting the time and locations where crime is most likely to occur—ensemble methods and individual regression. Leveraging historical datasets for two cities in the USA—San Francisco, CA, and Chicago, IL, we developed models for two distinct predictive policing techniques and compared their accuracy using a set of four metrics. Our analysis reveals the superiority of ensemble methods in their ability to accurately anticipate the occurrence or lack of crimes in each region, which is reflected by their significantly higher average true rate. Furthermore, the research also identifies crime distribution and spatiotemporal effects as potential reasons behind the disparity in accuracy levels.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_16
DP  - Springer Link
SP  - 145
EP  - 152
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_16.pdf
KW  - Ensemble methods
KW  - Machine learning
KW  - Predictive policing
KW  - Regression
ER  - 

TY  - CONF
TI  - A MIMO-Based Compatible Fuzzy Logic Controller for DFIG-Based Wind Turbine Generator
AU  - Sudarsana Reddy, K.
AU  - Mahalakshmi, R.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - The grid-connected doubly-fed induction generator (DFIG)-based wind energy conversion system is more popular nowadays. The DFIG has its own conventional controllers for the purpose of grid integration and for reactive power compensation. The conventional controllers are kept for machine side converter (MSC) and grid side converter (GSC) each. In total, there are eight controllers which have to be tuned for the control action, and this makes the control action difficult. This paper focuses on development of new single multi-input multi-output controller (MIMO) which controls both MSC-GSC together to extract the maximum power from varying wind velocity and for the grid synchronization. This control is developed based on compatible fuzzy logic control. The performance of the DFIG is validated with the help of proposed controller.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_2
DP  - Springer Link
SP  - 11
EP  - 27
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_2.pdf
KW  - Compatible fuzzy logic controller (CFLC)
KW  - Doubly-fed induction generator (DFIG)
KW  - Grid side converter (GSC)
KW  - Machine side converter (MSC)
KW  - MIMO systems
ER  - 

TY  - CONF
TI  - Ensemble Methods with Bidirectional Feature Elimination for Prediction and Analysis of Employee Attrition Rate During COVID-19 Pandemic
AU  - Mate, Yash
AU  - Potdar, Atharva
AU  - Priya, R. L.
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - In the wake of the COVID-19 pandemic, a myriad of organizations across the globe have decided to churn out some of their workforce owing to the economic recession. According to the International Monetary Fund (IMF), the world has experienced a financial shrinkage of 3% which is the steepest slowdown since the Great Depression in the 1930s. Aviation, tourism, travel, and hospitality are the industrial sectors that have been impacted the worst. Deloitte India’s 2020 Workforce and Increment Trends Survey has stated that the involuntary attrition rate for the current financial year is close to 15%. The research conducted aims at analyzing the attrition of employees based on factors like their educational qualifications, years of work experience, gender, department, and many others. The proposed system also predicts the attrition rate of employees using a machine learning pipeline that uses advanced ensembling, gradient boosting, feature selection through bidirectional elimination, and optimizing the hyperparameters through a randomized grid search approach. Owing to the optimizations carried out in the entire model building pipeline, the algorithm successfully achieves state-of-the-art performance. To ensure legitimacy in the results, the stratified K-fold cross-validation methodology is used for evaluation.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_11
DP  - Springer Link
SP  - 89
EP  - 101
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_11.pdf
KW  - Binary classification
KW  - Box plot representation
KW  - Cross-validation
KW  - Decision tree
KW  - Employee attrition
KW  - Ensemble learning
KW  - Exploratory data analysis
KW  - Feature selection
KW  - Gradient boosting
KW  - Hyperparameter tuning
KW  - Logistic regression
KW  - Machine learning
KW  - Naive Bayes
KW  - Random forest
KW  - Statistics
KW  - SVM
ER  - 

TY  - CONF
TI  - Speech Audio Cardinal Emotion Sentiment Detection and Prediction Using Deep Learning Approach
AU  - Bhardwaj, Sachit
AU  - Sharma, Akhilesh Kumar
A2  - Raje, Rajeev R.
A2  - Hussain, Farookh
A2  - Kannan, R. Jagadeesh
T3  - Lecture Notes in Electrical Engineering
AB  - This research work focuses on the sentiment-based analysis and prediction using deep neural networks. This study is mainly taken up from the data set available on Kaggle. In this research work, the three-layer back propagation NN performed for predicting with higher accuracy rates in comparison with the LSTM methods, Gaussian-based estimates and SVM. In final step, the highest accuracy rates with comparison to various other algorithms were obtained. The highest accuracy in this research work using the above mentioned approach is 97.35% followed by LSTM with 94.08%.
C1  - Singapore
C3  - Artificial Intelligence and Technologies
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-6448-9_13
DP  - Springer Link
SP  - 111
EP  - 121
LA  - en
PB  - Springer
SN  - 9789811664489
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-6448-9_13.pdf
KW  - DNN
KW  - Gaussian mixture
KW  - LSTM
KW  - Machine learning
KW  - Sentiment
KW  - SVM
ER  - 

TY  - CONF
TI  - Online Domain Adaptation for Semantic Segmentation in Ever-Changing Conditions
AU  - Panagiotakopoulos, Theodoros
AU  - Dovesi, Pier Luigi
AU  - Härenstam-Nielsen, Linus
AU  - Poggi, Matteo
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised Domain Adaptation (UDA) aims at reducing the domain gap between training and testing data and is, in most cases, carried out in offline manner. However, domain changes may occur continuously and unpredictably during deployment (e.g. sudden weather changes). In such conditions, deep neural networks witness dramatic drops in accuracy and offline adaptation may not be enough to contrast it. In this paper, we tackle Online Domain Adaptation (OnDA) for semantic segmentation. We design a pipeline that is robust to continuous domain shifts, either gradual or sudden, and we evaluate it in the case of rainy and foggy scenarios. Our experiments show that our framework can effectively adapt to new domains during deployment, while not being affected by catastrophic forgetting of the previous domains.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_8
DP  - Springer Link
SP  - 128
EP  - 146
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_8.pdf
ER  - 

TY  - CONF
TI  - Incomplete Multi-view Domain Adaptation via Channel Enhancement and Knowledge Transfer
AU  - Xia, Haifeng
AU  - Wang, Pu
AU  - Ding, Zhengming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised domain adaptation (UDA) borrows well-labeled source knowledge to solve the specific task on unlabeled target domain with the assumption that both domains are from a single sensor, e.g., RGB or depth images. To boost model performance, multiple sensors are deployemd on new-produced devices like autonomous vehicles to benefit from enriched information. However, the model trained with multi-view data difficultly becomes compatible with conventional devices only with a single sensor. This scenario is defined as incomplete multi-view domain adaptation (IMVDA), which considers that the source domain consists of multi-view data while the target domain only includes single-view instances. To overcome this practical demand, this paper proposes a novel Channel Enhancement and Knowledge Transfer (CEKT) framework with two modules. Concretely, the source channel enhancement module distinguishes view-common from view-specific channels and explores channel similarity to magnify the representation of important channels. Moreover, the adaptive knowledge transfer module attempts to enhance target representation towards multi-view semantic through implicit missing view recovery and adaptive cross-domain alignment. Extensive experimental results illustrate the effectiveness of our method in solving the IMVDA challenge.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_12
DP  - Springer Link
SP  - 200
EP  - 217
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_12.pdf
KW  - Domain adaptation
KW  - Multi-view fusion
ER  - 

TY  - CONF
TI  - Interpretable Open-Set Domain Adaptation via Angular Margin Separation
AU  - Li, Xinhao
AU  - Li, Jingjing
AU  - Du, Zhekai
AU  - Zhu, Lei
AU  - Li, Wen
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Open-set Domain Adaptation (OSDA) aims to recognize classes in the target domain that are seen in the source domain while rejecting other unseen target-exclusive classes into an unknown class, which ignores the diversity of the latter and is therefore incapable of their interpretation. The recently-proposed Semantic Recovery OSDA (SR-OSDA) brings in semantic attributes and attacks the challenge via partial alignment and visual-semantic projection, marking the first step towards interpretable OSDA. Following that line, in this work, we propose a representation learning framework termed Angular Margin Separation (AMS) that unveils the power of discriminative and robust representation for both open-set domain adaptation and cross-domain semantic recovery. Our core idea is to exploit an additive angular margin with regularization for both robust feature fine-tuning and discriminative joint feature alignment, which turns out advantageous to learning an accurate and less biased visual-semantic projection. Further, we propose a post-training re-projection that boosts the performance of seen classes interpretation without deterioration on unseen classes. Verified by extensive experiments, AMS achieves a notable improvement over the existing SR-OSDA baseline, with an average 7.6% increment in semantic recovery accuracy of unseen classes in multiple transfer tasks. Our code is available at AMS.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_1
DP  - Springer Link
SP  - 1
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_1.pdf
KW  - Open-set domain adaptation
KW  - Zero-shot learning
ER  - 

TY  - CONF
TI  - Factorizing Knowledge in Neural Networks
AU  - Yang, Xingyi
AU  - Ye, Jingwen
AU  - Wang, Xinchao
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this paper, we explore a novel and ambitious knowledge-transfer task, termed Knowledge Factorization (KF). The core idea of KF lies in the modularization and assemblability of knowledge: given a pretrained network model as input, KF aims to decompose it into several factor networks, each of which handles only a dedicated task and maintains task-specific knowledge factorized from the source network. Such factor networks are task-wise disentangled and can be directly assembled, without any fine-tuning, to produce the more competent combined-task networks. In other words, the factor networks serve as Lego-brick-like building blocks, allowing us to construct customized networks in a plug-and-play manner. Specifically, each factor network comprises two modules, a common-knowledge module that is task-agnostic and shared by all factor networks, alongside with a task-specific module dedicated to the factor network itself. We introduce an information-theoretic objective, InfoMax-Bottleneck (IMB), to carry out KF by optimizing the mutual information between the learned representations and input. Experiments across various benchmarks demonstrate that, the derived factor networks yield gratifying performances on not only the dedicated tasks but also disentanglement, while enjoying much better interpretability and modularity. Moreover, the learned common-knowledge representations give rise to impressive results on transfer learning. Our code is available at https://github.com/Adamdad/KnowledgeFactor.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_5
DP  - Springer Link
SP  - 73
EP  - 91
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_5.pdf
KW  - Knowledge factorization
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - Cross-Modal Knowledge Transfer Without Task-Relevant Source Data
AU  - Ahmed, Sk Miraj
AU  - Lohit, Suhas
AU  - Peng, Kuan-Chuan
AU  - Jones, Michael J.
AU  - Roy-Chowdhury, Amit K.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Cost-effective depth and infrared sensors as alternatives to usual RGB sensors are now a reality, and have some advantages over RGB in domains like autonomous navigation and remote sensing. As such, building computer vision and deep learning systems for depth and infrared data are crucial. However, large labeled datasets for these modalities are still lacking. In such cases, transferring knowledge from a neural network trained on a well-labeled large dataset in the source modality (RGB) to a neural network that works on a target modality (depth, infrared, etc.) is of great value. For reasons like memory and privacy, it may not be possible to access the source data, and knowledge transfer needs to work with only the source models. We describe an effective solution, SOCKET: SOurce-free Cross-modal KnowledgE Transfer for this challenging task of transferring knowledge from one source modality to a different target modality without access to task-relevant source data. The framework reduces the modality gap using paired task-irrelevant data, as well as by matching the mean and variance of the target features with the batch-norm statistics that are present in the source models. We show through extensive experiments that our method significantly outperforms existing source-free methods for classification tasks which do not account for the modality gap.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_7
DP  - Springer Link
SP  - 111
EP  - 127
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_7.pdf
KW  - Cross modal knowledge distillation
KW  - Source free adaptation
KW  - Unsupervised domain adaptation
ER  - 

TY  - CONF
TI  - BMD: A General Class-Balanced Multicentric Dynamic Prototype Strategy for Source-Free Domain Adaptation
AU  - Qu, Sanqing
AU  - Chen, Guang
AU  - Zhang, Jing
AU  - Li, Zhijun
AU  - He, Wei
AU  - Tao, Dacheng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Source-free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to the unlabeled target domain without accessing the well-labeled source data, which is a much more practical setting due to the data privacy, security, and transmission issues. To make up for the absence of source data, most existing methods introduced feature prototype based pseudo-labeling strategies to realize self-training model adaptation. However, feature prototypes are obtained by instance-level predictions based feature clustering, which is category-biased and tends to result in noisy labels since the visual domain gaps between source and target are usually different between categories. In addition, we found that a monocentric feature prototype may be ineffective to represent each category and introduce negative transfer, especially for those hard-transfer data. To address these issues, we propose a general class-Balanced Multicentric Dynamic prototype (BMD) strategy for the SFDA task. Specifically, for each target category, we first introduce a global inter-class balanced sampling strategy to aggregate potential representative target samples. Then, we design an intra-class multicentric clustering strategy to achieve more robust and representative prototypes generation. In contrast to existing strategies that update the pseudo label at a fixed training period, we further introduce a dynamic pseudo labeling strategy to incorporate network update information during model adaptation. Extensive experiments show that the proposed model-agnostic BMD strategy significantly improves representative SFDA methods to yield new state-of-the-art results. The code is available at https://github.com/ispc-lab/BMD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_10
DP  - Springer Link
SP  - 165
EP  - 182
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - BMD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_10.pdf
KW  - Class-balanced sampling
KW  - Domain adaptation
KW  - Multicentric prototype pseudo-labeling
KW  - Source-free
ER  - 

TY  - CONF
TI  - Contrastive Vicinal Space for Unsupervised Domain Adaptation
AU  - Na, Jaemin
AU  - Han, Dongyoon
AU  - Chang, Hyung Jin
AU  - Hwang, Wonjun
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recent unsupervised domain adaptation methods have utilized vicinal space between the source and target domains. However, the equilibrium collapse of labels, a problem where the source labels are dominant over the target labels in the predictions of vicinal instances, has never been addressed. In this paper, we propose an instance-wise minimax strategy that minimizes the entropy of high uncertainty instances in the vicinal space to tackle the stated problem. We divide the vicinal space into two subspaces through the solution of the minimax problem: contrastive space and consensus space. In the contrastive space, inter-domain discrepancy is mitigated by constraining instances to have contrastive views and labels, and the consensus space reduces the confusion between intra-domain categories. The effectiveness of our method is demonstrated on public benchmarks, including Office-31, Office-Home, and VisDA-C, achieving state-of-the-art performances. We further show that our method outperforms the current state-of-the-art methods on PACS, which indicates that our instance-wise approach works well for multi-source domain adaptation as well. Code is available at https://github.com/NaJaeMin92/CoVi.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_6
DP  - Springer Link
SP  - 92
EP  - 110
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_6.pdf
KW  - Contrastive Vicinal space
KW  - Equilibrium collapse
KW  - Unsupervised domain adaptation
ER  - 

TY  - CONF
TI  - Attention Diversification for Domain Generalization
AU  - Meng, Rang
AU  - Li, Xianfeng
AU  - Chen, Weijie
AU  - Yang, Shicai
AU  - Song, Jie
AU  - Wang, Xinchao
AU  - Zhang, Lei
AU  - Song, Mingli
AU  - Xie, Di
AU  - Pu, Shiliang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Convolutional neural networks (CNNs) have demonstrated gratifying results at learning discriminative features. However, when applied to unseen domains, state-of-the-art models are usually prone to errors due to domain shift. After investigating this issue from the perspective of shortcut learning, we find the devils lie in the fact that models trained on different domains merely bias to different domain-specific features yet overlook diverse task-related features. Under this guidance, a novel Attention Diversification framework is proposed, in which Intra-Model and Inter-Model Attention Diversification Regularization are collaborated to reassign appropriate attention to diverse task-related features. Briefly, Intra-Model Attention Diversification Regularization is equipped on the high-level feature maps to achieve in-channel discrimination and cross-channel diversification via forcing different channels to pay their most salient attention to different spatial locations. Besides, Inter-Model Attention Diversification Regularization is proposed to further provide task-related attention diversification and domain-related attention suppression, which is a paradigm of “simulate, divide and assemble”: simulate domain shift via exploiting multiple domain-specific models, divide attention maps into task-related and domain-related groups, and assemble them within each group respectively to execute regularization. Extensive experiments and analyses are conducted on various benchmarks to demonstrate that our method achieves state-of-the-art performance over other competing methods. Code is available at https://github.com/hikvision-research/DomainGeneralization.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_19
DP  - Springer Link
SP  - 322
EP  - 340
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_19.pdf
KW  - Attention diversification
KW  - Domain generalization
ER  - 

TY  - CONF
TI  - Personalized Education: Blind Knowledge Distillation
AU  - Deng, Xiang
AU  - Zheng, Jian
AU  - Zhang, Zhongfei
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Knowledge distillation compresses a large model (teacher) to a smaller one by letting the student imitate the outputs of the teacher. An interesting question is why the student still typically underperforms the teacher after the imitation. The existing literature usually attributes this to model capacity differences between them. However, capacity differences are unavoidable in model compression, and even large capacity differences are desired for achieving high compression rates. By designing exploratory experiments with theoretical analysis, we find that model capacity differences are not necessarily the root reason; instead the distillation data matter when the student capacity is greater than a threshold. In light of this, we propose personalized education (PE) to first help each student adaptively find its own blind knowledge region (BKR) where the student has not captured the knowledge from the teacher, and then teach the student on this region. Extensive experiments on several benchmark datasets demonstrate that PE substantially reduces the performance gap between students and teachers, even enables small students to outperform large teachers, and also beats the state-of-the-art approaches. Code link: https://github.com/Xiang-Deng-DL/PEBKD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_16
DP  - Springer Link
SP  - 269
EP  - 285
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - Personalized Education
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_16.pdf
KW  - Classification
KW  - Knowledge distillation
KW  - Model compression
ER  - 

TY  - CONF
TI  - How Stable Are Transferability Metrics Evaluations?
AU  - Agostinelli, Andrea
AU  - Pándy, Michal
AU  - Uijlings, Jasper
AU  - Mensink, Thomas
AU  - Ferrari, Vittorio
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Transferability metrics is a maturing field with increasing interest, which aims at providing heuristics for selecting the most suitable source models to transfer to a given target dataset, without fine-tuning them all. However, existing works rely on custom experimental setups which differ across papers, leading to inconsistent conclusions about which transferability metrics work best. In this paper we conduct a large-scale study by systematically constructing a broad range of 715k experimental setup variations. We discover that even small variations to an experimental setup lead to different conclusions about the superiority of a transferability metric over another. Then we propose better evaluations by aggregating across many experiments, enabling to reach more stable conclusions. As a result, we reveal the superiority of LogME at selecting good source datasets to transfer from in a semantic segmentation scenario, $$\mathcal {N}$$NLEEP at selecting good source architectures in an image classification scenario, and GBC at determining which target task benefits most from a given source model. Yet, no single transferability metric works best in all scenarios.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_18
DP  - Springer Link
SP  - 303
EP  - 321
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_18.pdf
ER  - 

TY  - CONF
TI  - Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space
AU  - Shao, Wenqi
AU  - Zhao, Xun
AU  - Ge, Yixiao
AU  - Zhang, Zhaoyang
AU  - Yang, Lei
AU  - Wang, Xiaogang
AU  - Shan, Ying
AU  - Luo, Ping
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper addresses an important problem of ranking the pre-trained deep neural networks and screening the most transferable ones for downstream tasks. It is challenging because the ground-truth model ranking for each task can only be generated by fine-tuning the pre-trained models on the target dataset, which is brute-force and computationally expensive. Recent advanced methods proposed several lightweight transferability metrics to predict the fine-tuning results. However, these approaches only capture static representations but neglect the fine-tuning dynamics. To this end, this paper proposes a new transferability metric, called Self-challenging Fisher Discriminant Analysis (SFDA), which has many appealing benefits that existing works do not have. First, SFDA can embed the static features into a Fisher space and refine them for better separability between classes. Second, SFDA uses a self-challenging mechanism to encourage different pre-trained models to differentiate on hard examples. Third, SFDA can easily select multiple pre-trained models for the model ensemble. Extensive experiments on 33 pre-trained models of 11 downstream tasks show that SFDA is efficient, effective, and robust when measuring the transferability of pre-trained models. For instance, compared with the state-of-the-art method NLEEP, SFDA demonstrates an average of 59.1% gain while bringing 22.5x speedup in wall-clock time. The code will be available at https://github.com/TencentARC/SFDA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_17
DP  - Springer Link
SP  - 286
EP  - 302
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - Not All Models Are Equal
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_17.pdf
KW  - Image classification
KW  - Model ranking
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - RBC: Rectifying the Biased Context in Continual Semantic Segmentation
AU  - Zhao, Hanbin
AU  - Yang, Fengyu
AU  - Fu, Xinghe
AU  - Li, Xi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recent years have witnessed a great development of Convolutional Neural Networks in semantic segmentation, where all classes of training images are simultaneously available. In practice, new images are usually made available in a consecutive manner, leading to a problem called Continual Semantic Segmentation (CSS). Typically, CSS faces the forgetting problem since previous training images are unavailable, and the semantic shift problem of the background class. Considering the semantic segmentation as a context-dependent pixel-level classification task, we explore CSS from a new perspective of context analysis in this paper. We observe that the context of old-class pixels in the new images is much more biased on new classes than that in the old images, which can sharply aggravate the old-class forgetting and new-class overfitting. To tackle the obstacle, we propose a biased-context-rectified CSS framework with a context-rectified image-duplet learning scheme and a biased-context-insensitive consistency loss. Furthermore, we propose an adaptive re-weighting class-balanced learning strategy for the biased class distribution. Our approach outperforms state-of-the-art methods by a large margin in existing CSS scenarios. Code is available in https://github.com/sntc129/RBC.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_4
DP  - Springer Link
SP  - 55
EP  - 72
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - RBC
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_4.pdf
KW  - Biased context
KW  - Class-incremental learning
KW  - Continual learning
KW  - Continual semantic segmentation
ER  - 

TY  - CONF
TI  - Prototypical Contrast Adaptation for Domain Adaptive Semantic Segmentation
AU  - Jiang, Zhengkai
AU  - Li, Yuxi
AU  - Yang, Ceyuan
AU  - Gao, Peng
AU  - Wang, Yabiao
AU  - Tai, Ying
AU  - Wang, Chengjie
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised Domain Adaptation (UDA) aims to adapt the model trained on the labeled source domain to an unlabeled target domain. In this paper, we present Prototypical Contrast Adaptation (ProCA), a simple and efficient contrastive learning method for unsupervised domain adaptive semantic segmentation. Previous domain adaptation methods merely consider the alignment of the intra-class representational distributions across various domains, while the inter-class structural relationship is insufficiently explored, resulting in the aligned representations on the target domain might not be as easily discriminated as done on the source domain anymore. Instead, ProCA incorporates inter-class information into class-wise prototypes, and adopts the class-centered distribution alignment for adaptation. By considering the same class prototypes as positives and other class prototypes as negatives to achieve class-centered distribution alignment, ProCA achieves state-of-the-art performance on classical domain adaptation tasks, i.e., GTA5 $$\rightarrow $$→Cityscapes and SYNTHIA $$\rightarrow $$→Cityscapes. Code is available at ProCA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_3
DP  - Springer Link
SP  - 36
EP  - 54
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_3.pdf
KW  - Domain adaptive semantic segmentation
KW  - Prototypical Contrast Adaptation
ER  - 

TY  - CONF
TI  - TACS: Taxonomy Adaptive Cross-Domain Semantic Segmentation
AU  - Gong, Rui
AU  - Danelljan, Martin
AU  - Dai, Dengxin
AU  - Paudel, Danda Pani
AU  - Chhatkuli, Ajad
AU  - Yu, Fisher
AU  - Van Gool, Luc
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Traditional domain adaptive semantic segmentation addresses the task of adapting a model to a novel target domain under limited or no additional supervision. While tackling the input domain gap, the standard domain adaptation settings assume no domain change in the output space. In semantic prediction tasks, different datasets are often labeled according to different semantic taxonomies. In many real-world settings, the target domain task requires a different taxonomy than the one imposed by the source domain. We therefore introduce the more general taxonomy adaptive cross-domain semantic segmentation (TACS) problem, allowing for inconsistent taxonomies between the two domains. We further propose an approach that jointly addresses the image-level and label-level domain adaptation. On the label-level, we employ a bilateral mixed sampling strategy to augment the target domain, and a relabelling method to unify and align the label spaces. We address the image-level domain gap by proposing an uncertainty-rectified contrastive learning method, leading to more domain-invariant and class-discriminative features. We extensively evaluate the effectiveness of our framework under different TACS settings: open taxonomy, coarse-to-fine taxonomy, and implicitly-overlapping taxonomy. Our approach outperforms the previous state-of-the-art by a large margin, while being capable of adapting to target taxonomies. Our implementation is publicly available at https://github.com/ETHRuiGong/TADA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_2
DP  - Springer Link
SP  - 19
EP  - 35
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - TACS
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_2.pdf
KW  - Domain adaptation
KW  - Inconsistent taxonomy
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - ML-BPM: Multi-teacher Learning with Bidirectional Photometric Mixing for Open Compound Domain Adaptation in Semantic Segmentation
AU  - Pan, Fei
AU  - Hur, Sungsu
AU  - Lee, Seokju
AU  - Kim, Junsik
AU  - Kweon, In So
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Open compound domain adaptation (OCDA) considers the target domain as the compound of multiple unknown homogeneous subdomains. The goal of OCDA is to minimize the domain gap between the labeled source domain and the unlabeled compound target domain, which benefits the model generalization to the unseen domains. Current OCDA for semantic segmentation methods adopt manual domain separation and employ a single model to simultaneously adapt to all the target subdomains. However, adapting to a target subdomain might hinder the model from adapting to other dissimilar target subdomains, which leads to limited performance. In this work, we introduce a multi-teacher framework with bidirectional photometric mixing to separately adapt to every target subdomain. First, we present an automatic domain separation to find the optimal number of subdomains. On this basis, we propose a multi-teacher framework in which each teacher model uses bidirectional photometric mixing to adapt to one target subdomain. Furthermore, we conduct an adaptive distillation to learn a student model and apply consistency regularization to improve the student generalization. Experimental results on benchmark datasets show the efficacy of the proposed approach for both the compound domain and the open domains against existing state-of-the-art approaches.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_14
DP  - Springer Link
SP  - 236
EP  - 251
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - ML-BPM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_14.pdf
KW  - Domain adaptation
KW  - Multi-teacher distillation
KW  - Open compound domain adaptation
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - Source-Free Video Domain Adaptation by Learning Temporal Consistency for Action Recognition
AU  - Xu, Yuecong
AU  - Yang, Jianfei
AU  - Cao, Haozhi
AU  - Wu, Keyu
AU  - Wu, Min
AU  - Chen, Zhenghua
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Video-based Unsupervised Domain Adaptation (VUDA) methods improve the robustness of video models, enabling them to be applied to action recognition tasks across different environments. However, these methods require constant access to source data during the adaptation process. Yet in many real-world applications, subjects and scenes in the source video domain should be irrelevant to those in the target video domain. With the increasing emphasis on data privacy, such methods that require source data access would raise serious privacy issues. Therefore, to cope with such concern, a more practical domain adaptation scenario is formulated as the Source-Free Video-based Domain Adaptation (SFVDA). Though there are a few methods for Source-Free Domain Adaptation (SFDA) on image data, these methods yield degenerating performance in SFVDA due to the multi-modality nature of videos, with the existence of additional temporal features. In this paper, we propose a novel Attentive Temporal Consistent Network (ATCoN) to address SFVDA by learning temporal consistency, guaranteed by two novel consistency objectives, namely feature consistency and source prediction consistency, performed across local temporal features. ATCoN further constructs effective overall temporal features by attending to local temporal features based on prediction confidence. Empirical results demonstrate the state-of-the-art performance of ATCoN across various cross-domain action recognition benchmarks. Code is provided at https://github.com/xuyu0010/ATCoN.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_9
DP  - Springer Link
SP  - 147
EP  - 164
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_9.pdf
KW  - Action recognition
KW  - Source-Free Domain Adaptation
KW  - Temporal consistency
KW  - Video domain adaptation
ER  - 

TY  - CONF
TI  - Generalized Brain Image Synthesis with Transferable Convolutional Sparse Coding Networks
AU  - Huang, Yawen
AU  - Zheng, Feng
AU  - Sun, Xu
AU  - Li, Yuexiang
AU  - Shao, Ling
AU  - Zheng, Yefeng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - High inter-equipment variability and expensive examination costs of brain imaging remain key challenges in leveraging the heterogeneous scans effectively. Despite rapid growth in image-to-image translation with deep learning models, the target brain data may not always be achievable due to the specific attributes of brain imaging. In this paper, we present a novel generalized brain image synthesis method, powered by our transferable convolutional sparse coding networks, to address the lack of interpretable cross-modal medical image representation learning. The proposed approach masters the ability to imitate the machine-like anatomically meaningful imaging by translating features directly under a series of mathematical processings, leading to the reduced domain discrepancy while enhancing model transferability. Specifically, we first embed the globally normalized features into a domain discrepancy metric to learn the domain-invariant representations, then optimally preserve domain-specific geometrical property to reflect the intrinsic graph structures, and further penalize their subspace mismatching to reduce the generalization error. The overall framework is cast in a minimax setting, and the extensive experiments show that the proposed method yields state-of-the-art results on multiple datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_11
DP  - Springer Link
SP  - 183
EP  - 199
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_11.pdf
KW  - Convolutional sparse coding networks
KW  - Image synthesis
ER  - 

TY  - CONF
TI  - DistPro: Searching a Fast Knowledge Distillation Process via Meta Optimization
AU  - Deng, Xueqing
AU  - Sun, Dawei
AU  - Newsam, Shawn
AU  - Wang, Peng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recent Knowledge distillation (KD) studies show that different manually designed schemes impact the learned results significantly. Yet, in KD, automatically searching an optimal distillation scheme has not yet been well explored. In this paper, we propose DistPro, a novel framework which searches for an optimal KD process via differentiable meta-learning. Specifically, given a pair of student and teacher networks, DistPro first sets up a rich set of KD connections from the transmitting layers of the teacher to the receiving layers of the student, and in the meanwhile, various transforms are also proposed for comparing feature maps along their pathways for distillation. Then, each combination of connection and transform (pathway) is associated with a stochastic weighting process which indicates its importance at every step during the distillation. At the searching stage, the process can be effectively learned through our proposed bi-level meta-optimization strategy. At the distillation stage, DistPro adopts the learned processes for knowledge distillation, which significantly improves the student accuracy especially when faster training is required. Lastly, we find the learned processes can be generalized between similar tasks and networks. In our experiments, DistPro produces state-of-the-art (SoTA) accuracy under varying number of learning epochs on popular datasets, i.e. CIFAR100 and ImageNet, which demonstrates the effectiveness of our framework. Codes are available at https://github.com/xdeng7/DistPro.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_13
DP  - Springer Link
SP  - 218
EP  - 235
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - DistPro
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_13.pdf
ER  - 

TY  - CONF
TI  - PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks
AU  - Ding, Nan
AU  - Chen, Xi
AU  - Levinboim, Tomer
AU  - Changpinyo, Soravit
AU  - Soricut, Radu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - With the increasing abundance of pretrained models in recent years, the problem of selecting the best pretrained checkpoint for a particular downstream classification task has been gaining increased attention. Although several methods have recently been proposed to tackle the selection problem (e.g. LEEP, H-score), these methods resort to applying heuristics that are not well motivated by learning theory. In this paper we present PACTran, a theoretically grounded family of metrics for pretrained model selection and transferability measurement. We first show how to derive PACTran metrics from the optimal PAC-Bayesian bound under the transfer learning setting. We then empirically evaluate three metric instantiations of PACTran on a number of vision tasks (VTAB) as well as a language-and-vision (OKVQA) task. An analysis of the results shows PACTran is a more consistent and effective transferability measure compared to existing selection methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19830-4_15
DP  - Springer Link
SP  - 252
EP  - 268
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19830-4
ST  - PACTran
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19830-4_15.pdf
ER  - 

TY  - CONF
TI  - On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond
AU  - Yang, Yuzhe
AU  - Wang, Hao
AU  - Katabi, Dina
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Real-world data often exhibit imbalanced label distributions. Existing studies on data imbalance focus on single-domain settings, i.e., samples are from the same data distribution. However, natural data can originate from distinct domains, where a minority class in one domain could have abundant instances from other domains. We formalize the task of Multi-Domain Long-Tailed Recognition (MDLT), which learns from multi-domain imbalanced data, addresses label imbalance, domain shift, and divergent label distributions across domains, and generalizes to all domain-class pairs. We first develop the domain-class transferability graph, and show that such transferability governs the success of learning in MDLT. We then propose BoDA, a theoretically grounded learning strategy that tracks the upper bound of transferability statistics, and ensures balanced alignment and calibration across imbalanced domain-class distributions. We curate five MDLT benchmarks based on widely-used multi-domain datasets, and compare BoDA to twenty algorithms that span different learning strategies. Extensive and rigorous experiments verify the superior performance of BoDA. Further, as a byproduct, BoDA establishes new state-of-the-art on Domain Generalization benchmarks, highlighting the importance of addressing data imbalance across domains, which can be crucial for improving generalization to unseen domains. Code and data are available at: https://github.com/YyzHarry/multi-domain-imbalance.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_4
DP  - Springer Link
SP  - 57
EP  - 75
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_4.pdf
ER  - 

TY  - CONF
TI  - tSF: Transformer-Based Semantic Filter for Few-Shot Learning
AU  - Lai, Jinxiang
AU  - Yang, Siqian
AU  - Liu, Wenlong
AU  - Zeng, Yi
AU  - Huang, Zhongyi
AU  - Wu, Wenlong
AU  - Liu, Jun
AU  - Gao, Bin-Bin
AU  - Wang, Chengjie
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-Shot Learning (FSL) alleviates the data shortage challenge via embedding discriminative target-aware features among plenty seen (base) and few unseen (novel) labeled samples. Most feature embedding modules in recent FSL methods are specially designed for corresponding learning tasks (e.g., classification, segmentation, and object detection), which limits the utility of embedding features. To this end, we propose a light and universal module named transformer-based Semantic Filter (tSF), which can be applied for different FSL tasks. The proposed tSF redesigns the inputs of a transformer-based structure by a semantic filter, which not only embeds the knowledge from whole base set to novel set but also filters semantic features for target category. Furthermore, the parameters of tSF is equal to half of a standard transformer block (less than 1M). In the experiments, our tSF is able to boost the performances in different classic few-shot learning tasks (about $$2\%$$2%improvement), especially outperforms the state-of-the-arts on multiple benchmark datasets in few-shot classification task.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_1
DP  - Springer Link
SP  - 1
EP  - 19
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
ST  - tSF
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_1.pdf
ER  - 

TY  - CONF
TI  - Doubly Deformable Aggregation of Covariance Matrices for Few-Shot Segmentation
AU  - Xiong, Zhitong
AU  - Li, Haopeng
AU  - Zhu, Xiao Xiang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Training semantic segmentation models with few annotated samples has great potential in various real-world applications. For the few-shot segmentation task, the main challenge is how to accurately measure the semantic correspondence between the support and query samples with limited training data. To address this problem, we propose to aggregate the learnable covariance matrices with a deformable 4D Transformer to effectively predict the segmentation map. Specifically, in this work, we first devise a novel hard example mining mechanism to learn covariance kernels for the Gaussian process. The learned covariance kernel functions have great advantages over existing cosine similarity-based methods in correspondence measurement. Based on the learned covariance kernels, an efficient doubly deformable 4D Transformer module is designed to adaptively aggregate feature similarity maps into segmentation results. By combining these two designs, the proposed method can not only set new state-of-the-art performance on public benchmarks, but also converge extremely faster than existing methods. Experiments on three public datasets have demonstrated the effectiveness of our method. (Code: https://github.com/ShadowXZT/DACM-Few-shot.pytorch)
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_8
DP  - Springer Link
SP  - 133
EP  - 150
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_8.pdf
KW  - Deep kernel learning
KW  - Few-shot segmentation
KW  - Gaussian process
KW  - Similarity measurement
KW  - Transformer
ER  - 

TY  - CONF
TI  - Open-World Semantic Segmentation via Contrasting and Clustering Vision-Language Embedding
AU  - Liu, Quande
AU  - Wen, Youpeng
AU  - Han, Jianhua
AU  - Xu, Chunjing
AU  - Xu, Hang
AU  - Liang, Xiaodan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - To bridge the gap between supervised semantic segmentation and real-world applications that acquires one model to recognize arbitrary new concepts, recent zero-shot segmentation attracts a lot of attention by exploring the relationships between unseen and seen object categories, yet requiring large amounts of densely-annotated data with diverse base classes. In this paper, we propose a new open-world semantic segmentation pipeline that makes the first attempt to learn to segment semantic objects of various open-world categories without any efforts on dense annotations, by purely exploiting the image-caption data that naturally exist on the Internet. Our method, Vision-language-driven Semantic Segmentation (ViL-Seg), employs an image and a text encoder to generate visual and text embeddings for the image-caption data, with two core components that endow its segmentation ability: First, the image encoder is jointly trained with a vision-based contrasting and a cross-modal contrasting, which encourage the visual embeddings to preserve both fine-grained semantics and high-level category information that are crucial for the segmentation task. Furthermore, an online clustering head is devised over the image encoder, which allows to dynamically segment the visual embeddings into distinct semantic groups such that they can be classified by comparing with various text embeddings to complete our segmentation pipeline. Experiments show that without using any data with dense annotations, our method can directly segment objects of arbitrary categories, outperforming zero-shot segmentation methods that require data labeling on three benchmark datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_16
DP  - Springer Link
SP  - 275
EP  - 292
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_16.pdf
ER  - 

TY  - CONF
TI  - Learning Instance and Task-Aware Dynamic Kernels for Few-Shot Learning
AU  - Ma, Rongkai
AU  - Fang, Pengfei
AU  - Avraham, Gil
AU  - Zuo, Yan
AU  - Zhu, Tianyu
AU  - Drummond, Tom
AU  - Harandi, Mehrtash
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Learning and generalizing to novel concepts with few samples (Few-Shot Learning) is still an essential challenge to real-world applications. A principle way of achieving few-shot learning is to realize a model that can rapidly adapt to the context of a given task. Dynamic networks have been shown capable of learning content-adaptive parameters efficiently, making them suitable for few-shot learning. In this paper, we propose to learn the dynamic kernels of a convolution network as a function of the task at hand, enabling faster generalization. To this end, we obtain our dynamic kernels based on the entire task and each sample, and develop a mechanism further conditioning on each individual channel and position independently. This results in dynamic kernels that simultaneously attend to the global information whilst also considering minuscule details available. We empirically show that our model improves performance on few-shot classification and detection tasks, achieving a tangible improvement over several baseline models. This includes state-of-the-art results on four few-shot classification benchmarks: mini-ImageNet, tiered-ImageNet, CUB and FC100 and competitive results on a few-shot detection dataset: MS COCO-PASCAL-VOC.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_15
DP  - Springer Link
SP  - 257
EP  - 274
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_15.pdf
ER  - 

TY  - CONF
TI  - CLASTER: Clustering with Reinforcement Learning for Zero-Shot Action Recognition
AU  - Gowda, Shreyank N.
AU  - Sevilla-Lara, Laura
AU  - Keller, Frank
AU  - Rohrbach, Marcus
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Zero-Shot action recognition is the task of recognizing action classes without visual examples. The problem can be seen as learning a representation on seen classes which generalizes well to instances of unseen classes, without losing discriminability between classes. Neural networks are able to model highly complex boundaries between visual classes, which explains their success as supervised models. However, in Zero-Shot learning, these highly specialized class boundaries may overfit to the seen classes and not transfer well from seen to unseen classes. We propose a novel cluster-based representation, which regularizes the learning process, yielding a representation that generalizes well to instances from unseen classes. We optimize the clustering using reinforcement learning, which we observe is critical. We call the proposed method CLASTER and observe that it consistently outperforms the state-of-the-art in all standard Zero-Shot video datasets, including UCF101, HMDB51 and Olympic Sports; both in the standard Zero-Shot evaluation and the generalized Zero-Shot learning. We see improvements of up to 11.9% over SOTA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_11
DP  - Springer Link
SP  - 187
EP  - 203
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
ST  - CLASTER
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_11.pdf
KW  - Action recognition
KW  - Clustering
KW  - Zero-shot
ER  - 

TY  - CONF
TI  - Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions
AU  - Wang, Zhenyi
AU  - Shen, Li
AU  - Fang, Le
AU  - Suo, Qiuling
AU  - Zhan, Donglin
AU  - Duan, Tiehang
AU  - Gao, Mingchen
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The paradigm of machine intelligence moves from purely supervised learning to a more practical scenario when many loosely related unlabeled data are available and labeled data is scarce. Most existing algorithms assume that the underlying task distribution is stationary. Here we consider a more realistic and challenging setting in that task distributions evolve over time. We name this problem as Semi-supervised meta-learning with Evolving Task diStributions, abbreviated as SETS. Two key challenges arise in this more realistic setting: (i) how to use unlabeled data in the presence of a large amount of unlabeled out-of-distribution (OOD) data; and (ii) how to prevent catastrophic forgetting on previously learned task distributions due to the task distribution shift. We propose an OOD Robust and knowleDge presErved semi-supeRvised meta-learning approach (ORDER) (we use ORDER to denote the task distributions sequentially arrive with some ORDER), to tackle these two major challenges. Specifically, our ORDER introduces a novel mutual information regularization to robustify the model with unlabeled OOD data and adopts an optimal transport regularization to remember previously learned knowledge in feature space. In addition, we test our method on a very challenging dataset: SETS on large-scale non-stationary semi-supervised task distributions consisting of (at least) 72K tasks. With extensive experiments, we demonstrate the proposed ORDER alleviates forgetting on evolving task distributions and is more robust to OOD data than related strong baselines.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_13
DP  - Springer Link
SP  - 221
EP  - 238
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_13.pdf
ER  - 

TY  - CONF
TI  - Rethinking Clustering-Based Pseudo-Labeling for Unsupervised Meta-Learning
AU  - Dong, Xingping
AU  - Shen, Jianbing
AU  - Shao, Ling
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The pioneering method for unsupervised meta-learning, CACTUs, is a clustering-based approach with pseudo-labeling. This approach is model-agnostic and can be combined with supervised algorithms to learn from unlabeled data. However, it often suffers from label inconsistency or limited diversity, which leads to poor performance. In this work, we prove that the core reason for this is lack of a clustering-friendly property in the embedding space. We address this by minimizing the inter- to intra-class similarity ratio to provide clustering-friendly embedding features, and validate our approach through comprehensive experiments. Note that, despite only utilizing a simple clustering algorithm (k-means) in our embedding space to obtain the pseudo-labels, we achieve significant improvement. Moreover, we adopt a progressive evaluation mechanism to obtain more diverse samples in order to further alleviate the limited diversity problem. Finally, our approach is also model-agnostic and can easily be integrated into existing supervised methods. To demonstrate its generalization ability, we integrate it into two representative algorithms: MAML and EP. The results on three main few-shot benchmarks clearly show that the proposed method achieves significant improvement compared to state-of-the-art models. Notably, our approach also outperforms the corresponding supervised method in two tasks. The code and models are available at https://github.com/xingpingdong/PL-CFE.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_10
DP  - Springer Link
SP  - 169
EP  - 186
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_10.pdf
KW  - Clustering-friendly
KW  - Meta-learning
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Time-rEversed DiffusioN tEnsor Transformer: A New TENET of Few-Shot Object Detection
AU  - Zhang, Shan
AU  - Murray, Naila
AU  - Wang, Lei
AU  - Koniusz, Piotr
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this paper, we tackle the challenging problem of Few-shot Object Detection. Existing FSOD pipelines (i) use average-pooled representations that result in information loss; and/or (ii) discard position information that can help detect object instances. Consequently, such pipelines are sensitive to large intra-class appearance and geometric variations between support and query images. To address these drawbacks, we propose a Time-rEversed diffusioN tEnsor Transformer (TENET), which i) forms high-order tensor representations that capture multi-way feature occurrences that are highly discriminative, and ii) uses a transformer that dynamically extracts correlations between the query image and the entire support set, instead of a single average-pooled support embedding. We also propose a Transformer Relation Head (TRH), equipped with higher-order representations, which encodes correlations between query regions and the entire support set, while being sensitive to the positional variability of object instances. Our model achieves state-of-the-art results on PASCAL VOC, FSOD, and COCO.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_18
DP  - Springer Link
SP  - 310
EP  - 328
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
ST  - Time-rEversed DiffusioN tEnsor Transformer
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_18.pdf
KW  - Few-shot object detection
KW  - Heat diffusion process
KW  - High order pooling
KW  - Multiple order pooling
KW  - Transformer
ER  - 

TY  - CONF
TI  - Few-Shot Class-Incremental Learning for 3D Point Cloud Objects
AU  - Chowdhury, Townim
AU  - Cheraghian, Ali
AU  - Ramasinghe, Sameera
AU  - Ahmadi, Sahar
AU  - Saberi, Morteza
AU  - Rahman, Shafin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot class-incremental learning (FSCIL) aims to incrementally fine-tune a model (trained on base classes) for a novel set of classes using a few examples without forgetting the previous training. Recent efforts address this problem primarily on 2D images. However, due to the advancement of camera technology, 3D point cloud data has become more available than ever, which warrants considering FSCIL on 3D data. This paper addresses FSCIL in the 3D domain. In addition to well-known issues of catastrophic forgetting of past knowledge and overfitting of few-shot data, 3D FSCIL can bring newer challenges. For example, base classes may contain many synthetic instances in a realistic scenario. In contrast, only a few real-scanned samples (from RGBD sensors) of novel classes are available in incremental steps. Due to the data variation from synthetic to real, FSCIL endures additional challenges, degrading performance in later incremental steps. We attempt to solve this problem using Microshapes (orthogonal basis vectors) by describing any 3D objects using a pre-defined set of rules. It supports incremental training with few-shot examples minimizing synthetic to real data variation. We propose new test protocols for 3D FSCIL using popular synthetic datasets (ModelNet and ShapeNet) and 3D real-scanned datasets (ScanObjectNN and CO3D). By comparing state-of-the-art methods, we establish the effectiveness of our approach in the 3D domain. Code is available at: https://github.com/townim-faisal/FSCIL-3D.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_12
DP  - Springer Link
SP  - 204
EP  - 220
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_12.pdf
KW  - 3D point cloud
KW  - Few-shot class-incremental learning
ER  - 

TY  - CONF
TI  - Adversarial Feature Augmentation for Cross-domain Few-Shot Classification
AU  - Hu, Yanxu
AU  - Ma, Andy J.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot classification is a promising approach to solving the problem of classifying novel classes with only limited annotated data for training. Existing methods based on meta-learning predict novel-class labels for (target domain) testing tasks via meta knowledge learned from (source domain) training tasks of base classes. However, most existing works may fail to generalize to novel classes due to the probably large domain discrepancy across domains. To address this issue, we propose a novel adversarial feature augmentation (AFA) method to bridge the domain gap in few-shot learning. The feature augmentation is designed to simulate distribution variations by maximizing the domain discrepancy. During adversarial training, the domain discriminator is learned by distinguishing the augmented features (unseen domain) from the original ones (seen domain), while the domain discrepancy is minimized to obtain the optimal feature encoder. The proposed method is a plug-and-play module that can be easily integrated into existing few-shot learning methods based on meta-learning. Extensive experiments on nine datasets demonstrate the superiority of our method for cross-domain few-shot classification compared with the state of the art. Code is available at https://github.com/youthhoo/AFA_For_Few_shot_learning.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_2
DP  - Springer Link
SP  - 20
EP  - 37
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_2.pdf
KW  - Adversarial learning
KW  - Domain adaptation
KW  - Few-shot classification
KW  - Meta-learning
ER  - 

TY  - CONF
TI  - Few-Shot Classification with Contrastive Learning
AU  - Yang, Zhanyuan
AU  - Wang, Jinghua
AU  - Zhu, Yingying
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - A two-stage training paradigm consisting of sequential pre-training and meta-training stages has been widely used in current few-shot learning (FSL) research. Many of these methods use self-supervised learning and contrastive learning to achieve new state-of-the-art results. However, the potential of contrastive learning in both stages of FSL training paradigm is still not fully exploited. In this paper, we propose a novel contrastive learning-based framework that seamlessly integrates contrastive learning into both stages to improve the performance of few-shot classification. In the pre-training stage, we propose a self-supervised contrastive loss in the forms of feature vector vs. feature map and feature map vs. feature map, which uses global and local information to learn good initial representations. In the meta-training stage, we propose a cross-view episodic training mechanism to perform the nearest centroid classification on two different views of the same episode and adopt a distance-scaled contrastive loss based on them. These two strategies force the model to overcome the bias between views and promote the transferability of representations. Extensive experiments on three benchmark datasets demonstrate that our method achieves competitive results.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_17
DP  - Springer Link
SP  - 293
EP  - 309
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_17.pdf
KW  - Contrastive learning
KW  - Cross-view episodic training
KW  - Few-shot learning
KW  - Meta learning
ER  - 

TY  - CONF
TI  - Worst Case Matters for Few-Shot Recognition
AU  - Fu, Minghao
AU  - Cao, Yun-Hao
AU  - Wu, Jianxin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot recognition learns a recognition model with very few (e.g., 1 or 5) images per category, and current few-shot learning methods focus on improving the average accuracy over many episodes. We argue that in real-world applications we may often only try one episode instead of many, and hence maximizing the worst-case accuracy is more important than maximizing the average accuracy. We empirically show that a high average accuracy not necessarily means a high worst-case accuracy. Since this objective is not accessible, we propose to reduce the standard deviation and increase the average accuracy simultaneously. In turn, we devise two strategies from the bias-variance tradeoff perspective to implicitly reach this goal: a simple yet effective stability regularization (SR) loss together with model ensemble to reduce variance during fine-tuning, and an adaptability calibration mechanism to reduce the bias. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed strategies, which outperforms current state-of-the-art methods with a significant margin in terms of not only average, but also worst-case accuracy.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_6
DP  - Springer Link
SP  - 99
EP  - 115
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_6.pdf
ER  - 

TY  - CONF
TI  - Few-Shot Video Object Detection
AU  - Fan, Qi
AU  - Tang, Chi-Keung
AU  - Tai, Yu-Wing
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We introduce Few-Shot Video Object Detection (FSVOD) with three contributions to real-world visual learning challenge in our highly diverse and dynamic world: 1) a large-scale video dataset FSVOD-500 comprising of 500 classes with class-balanced videos in each category for few-shot learning; 2) a novel Tube Proposal Network (TPN) to generate high-quality video tube proposals for aggregating feature representation for the target video object which can be highly dynamic; 3) a strategically improved Temporal Matching Network (TMN+) for matching representative query tube features with better discriminative ability thus achieving higher diversity. Our TPN and TMN+ are jointly and end-to-end trained. Extensive experiments demonstrate that our method produces significantly better detection results on two few-shot video object detection datasets compared to image-based methods and other naive video-based extensions. Codes and datasets are released at https://github.com/fanq15/FewX.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_5
DP  - Springer Link
SP  - 76
EP  - 98
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_5.pdf
KW  - Few-shot video object detection
KW  - Object indexing/retrieval
KW  - Temporal matching network
KW  - Tube proposal network
ER  - 

TY  - CONF
TI  - DnA: Improving Few-Shot Transfer Learning with Low-Rank Decomposition and Alignment
AU  - Jiang, Ziyu
AU  - Chen, Tianlong
AU  - Chen, Xuxi
AU  - Cheng, Yu
AU  - Zhou, Luowei
AU  - Yuan, Lu
AU  - Awadallah, Ahmed
AU  - Wang, Zhangyang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Self-supervised (SS) learning has achieved remarkable success in learning strong representation for in-domain few-shot and semi-supervised tasks. However, when transferring such representations to downstream tasks with domain shifts, the performance degrades compared to its supervised counterpart, especially at the few-shot regime. In this paper, we proposed to boost the transferability of the self-supervised pre-trained models on cross-domain tasks via a novel self-supervised alignment step on the target domain using only unlabeled data before conducting the downstream supervised fine-tuning. A new reparameterization of the pre-trained weights is also presented to mitigate the potential catastrophic forgetting during the alignment step. It involves low-rank and sparse decomposition, that can elegantly balance between preserving the source domain knowledge without forgetting (via fixing the low-rank subspace), and the extra flexibility to absorb the new out-of-the-domain knowledge (via freeing the sparse residual). Our resultant framework, termed Decomposition-and-Alignment (DnA), significantly improves the few-shot transfer performance of the SS pre-trained model to downstream tasks with domain gaps. (The code is released at https://github.com/VITA-Group/DnA).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_14
DP  - Springer Link
SP  - 239
EP  - 256
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
ST  - DnA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_14.pdf
KW  - Low-rank
KW  - Self-supervised learning
KW  - Transfer few-shot
ER  - 

TY  - CONF
TI  - Self-Promoted Supervision for Few-Shot Transformer
AU  - Dong, Bowen
AU  - Zhou, Pan
AU  - Yan, Shuicheng
AU  - Zuo, Wangmeng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The few-shot learning ability of vision transformers (ViTs) is rarely investigated though heavily desired. In this work, we empirically find that with the same few-shot learning frameworks, replacing the widely used CNN feature extractor with a ViT model often severely impairs few-shot classification performance. Moreover, our empirical study shows that in the absence of inductive bias, ViTs often learn the low-qualified token dependencies under few-shot learning regime where only a few labeled training data are available, which largely contributes to the above performance degradation. To alleviate this issue, we propose a simple yet effective few-shot training framework for ViTs, namely Self-promoted sUpervisioN (SUN). Specifically, besides the conventional global supervision for global semantic learning, SUN further pretrains the ViT on the few-shot learning dataset and then uses it to generate individual location-specific supervision for guiding each patch token. This location-specific supervision tells the ViT which patch tokens are similar or dissimilar and thus accelerates token dependency learning. Moreover, it models the local semantics in each patch token to improve the object grounding and recognition capability which helps learn generalizable patterns. To improve the quality of location-specific supervision, we further propose: 1) background patch filtration to filtrate background patches out and assign them into an extra background class; and 2) spatial-consistent augmentation to introduce sufficient diversity for data augmentation while keeping the accuracy of the generated local supervisions. Experimental results show that SUN using ViTs significantly surpasses other few-shot learning frameworks with ViTs and is the first one that achieves higher performance than those CNN state-of-the-arts. Our code is publicly available at https://github.com/DongSky/few-shot-vit.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_19
DP  - Springer Link
SP  - 329
EP  - 347
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_19.pdf
KW  - Few-shot learning
KW  - Location-specific supervision
ER  - 

TY  - CONF
TI  - Exploring Hierarchical Graph Representation for Large-Scale Zero-Shot Image Classification
AU  - Yi, Kai
AU  - Shen, Xiaoqian
AU  - Gou, Yunhao
AU  - Elhoseiny, Mohamed
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The main question we address in this paper is how to scale up visual recognition of unseen classes, also known as zero-shot learning, to tens of thousands of categories as in the ImageNet-21K benchmark. At this scale, especially with many fine-grained categories included in ImageNet-21K, it is critical to learn quality visual semantic representations that are discriminative enough to recognize unseen classes and distinguish them from seen ones. We propose a Hierarchical Graphical knowledge Representation framework for the confidence-based classification method, dubbed as HGR-Net. Our experimental results demonstrate that HGR-Net can grasp class inheritance relations by utilizing hierarchical conceptual knowledge. Our method significantly outperformed all existing techniques, boosting the performance by 7% compared to the runner-up approach on the ImageNet-21K benchmark. We show that HGR-Net is learning-efficient in few-shot scenarios. We also analyzed our method on smaller datasets like ImageNet-21K-P, 2-hops and 3-hops, demonstrating its generalization ability. Our benchmark and code are available at https://kaiyi.me/p/hgrnet.html.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_7
DP  - Springer Link
SP  - 116
EP  - 132
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_7.pdf
KW  - Large-scale knowledge transfer
KW  - Semantic hierarchical graph
KW  - Vision and language
KW  - Zero-shot learning
ER  - 

TY  - CONF
TI  - Dense Cross-Query-and-Support Attention Weighted Mask Aggregation for Few-Shot Segmentation
AU  - Shi, Xinyu
AU  - Wei, Dong
AU  - Zhang, Yu
AU  - Lu, Donghuan
AU  - Ning, Munan
AU  - Chen, Jiashun
AU  - Ma, Kai
AU  - Zheng, Yefeng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Research into Few-shot Semantic Segmentation (FSS) has attracted great attention, with the goal to segment target objects in a query image given only a few annotated support images of the target class. A key to this challenging task is to fully utilize the information in the support images by exploiting fine-grained correlations between the query and support images. However, most existing approaches either compressed the support information into a few class-wise prototypes, or used partial support information (e.g., only foreground) at the pixel level, causing non-negligible information loss. In this paper, we propose Dense pixel-wise Cross-query-and-support Attention weighted Mask Aggregation (DCAMA), where both foreground and background support information are fully exploited via multi-level pixel-wise correlations between paired query and support features. Implemented with the scaled dot-product attention in the Transformer architecture, DCAMA treats every query pixel as a token, computes its similarities with all support pixels, and predicts its segmentation label as an additive aggregation of all the support pixels’ labels—weighted by the similarities. Based on the unique formulation of DCAMA, we further propose efficient and effective one-pass inference for n-shot segmentation, where pixels of all support images are collected for the mask aggregation at once. Experiments show that our DCAMA significantly advances the state of the art on standard FSS benchmarks of PASCAL-5$$^i$$i, COCO-20$$^i$$i, and FSS-1000, e.g., with 3.1%, 9.7%, and 3.6% absolute improvements in 1-shot mIoU over previous best records. Ablative studies also verify the design DCAMA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_9
DP  - Springer Link
SP  - 151
EP  - 168
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_9.pdf
KW  - Attention weighted mask aggregation
KW  - Dense cross-query-and-support attention
KW  - Few-shot segmentation
ER  - 

TY  - CONF
TI  - Constructing Balance from Imbalance for Long-Tailed Image Recognition
AU  - Xu, Yue
AU  - Li, Yong-Lu
AU  - Li, Jiefeng
AU  - Lu, Cewu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Long-tailed image recognition presents massive challenges to deep learning systems since the imbalance between majority (head) classes and minority (tail) classes severely skews the data-driven deep neural networks. Previous methods tackle with data imbalance from the viewpoints of data distribution, feature space, and model design, etc. In this work, instead of directly learning a recognition model, we suggest confronting the bottleneck of head-to-tail bias before classifier learning, from the previously omitted perspective of balancing label space. To alleviate the head-to-tail bias, we propose a concise paradigm by progressively adjusting label space and dividing the head classes and tail classes, dynamically constructing balance from imbalance to facilitate the classification. With flexible data filtering and label space mapping, we can easily embed our approach to most classification models, especially the decoupled training methods. Besides, we find the separability of head-tail classes varies among different features with different inductive biases. Hence, our proposed model also provides a feature evaluation method and paves the way for long-tailed feature learning. Extensive experiments show that our method can boost the performance of state-of-the-arts of different types on widely-used benchmarks. Code is available at https://github.com/silicx/DLSA.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20044-1_3
DP  - Springer Link
SP  - 38
EP  - 56
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20044-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20044-1_3.pdf
KW  - Image classification
KW  - Long-tailed recognition
KW  - Normalizing flows
ER  - 

TY  - CONF
TI  - A Just-In-Time Compilation Approach for Neural Dynamics Simulation
AU  - Wang, Chaoming
AU  - Jiang, Yingqian
AU  - Liu, Xinyu
AU  - Lin, Xiaohan
AU  - Zou, Xiaolong
AU  - Ji, Zilong
AU  - Wu, Si
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - As the bridge between brain science and brain-inspired computation, computational neuroscience has been attracting more and more attention from researchers in different disciplines. However, the current neural simulators based on low-level language programming or pseudo-programming using high-level descriptive language can not full fill users’ basic requirements, including easy-to-learn-and-use, high flexibility, good transparency, and high-speed performance. Here, we introduce a Just-In-Time (JIT) compilation approach for neural dynamics simulation. The core idea behind the JIT approach is that any dynamical model coded with a high-level language can be just-in-time compiled into efficient machine codes running on a device of CPU or GPU. Based on the JIT approach, we develop a neural dynamics simulator in the Python framework called BrainPy, which is available publicly at https://github.com/PKU-NIP-Lab/BrainPy. BrainPy provides a friendly and highly flexible interface for users to define an arbitrary dynamical system, and the JIT compilation enables the defined model to run efficiently. We hope that BrainPy can serve as a general software for both research and education in computational neuroscience.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_2
DP  - Springer Link
SP  - 15
EP  - 26
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_2.pdf
KW  - Computational neuroscience
KW  - Just-In-Time compilation
KW  - Neural dynamics
KW  - Neural simulator
KW  - Spiking neural networks
ER  - 

TY  - CONF
TI  - STCN-GR: Spatial-Temporal Convolutional Networks for Surface-Electromyography-Based Gesture Recognition
AU  - Lai, Zhiping
AU  - Kang, Xiaoyang
AU  - Wang, Hongbo
AU  - Zhang, Weiqi
AU  - Zhang, Xueze
AU  - Gong, Peixian
AU  - Niu, Lan
AU  - Huang, Huijie
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Gesture recognition using surface electromyography (sEMG) is the technical core of muscle-computer interface (MCI) in human-computer interaction (HCI), which aims to classify gestures according to signals obtained from human hands. Since sEMG signals are characterized by spatial relevancy and temporal nonstationarity, sEMG-based gesture recognition is a challenging task. Previous works attempt to model this structured information and extract spatial and temporal features, but the results are not satisfactory. To tackle this problem, we proposed spatial-temporal convolutional networks for sEMG-based gesture recognition (STCN-GR). In this paper, the concept of the sEMG graph is first proposed by us to represent sEMG data instead of image and vector sequence adopted by previous works, which provides a new perspective for the research of sEMG-based tasks, not just gesture recognition. Graph convolutional networks (GCNs) and temporal convolutional networks (TCNs) are used in STCN-GR to capture spatial-temporal information. Additionally, the connectivity of the graph can be adjusted adaptively in different layers of networks, which increases the flexibility of networks compared with the fixed graph structure used by original GCNs. On two high-density sEMG (HD-sEMG) datasets and a sparse armband dataset, STCN-GR outperforms previous works and achieves the state-of-the-art, which shows superior performance and powerful generalization ability.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_3
DP  - Springer Link
SP  - 27
EP  - 39
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
ST  - STCN-GR
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_3.pdf
KW  - Gesture recognition
KW  - Human-computer interaction
KW  - sEMG graph
KW  - Spatial-temporal convolutional networks
KW  - Surface electromyography
ER  - 

TY  - CONF
TI  - DFFCN: Dual Flow Fusion Convolutional Network for Micro Expression Recognition
AU  - Chen, Jinjie
AU  - Fu, Yuzhuo
AU  - Jin, YiBo
AU  - Liu, Ting
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Recently, micro-expression recognition (MER) has attracted much attention due to its wide application in various fields such as crime trials and psychotherapy. However, the short duration and subtle movement of facial muscles make it difficult to extract micro-expression features. In this article, we propose a Dual Flow Fusion Convolutional Network (DFFCN) that combines the learning flow and optical flow to capture spatiotemporal features. Specifically, we adopt a trainable Learning Flow Module to extract the frame-level motion characteristics, fused with the mask generated from hand-crafted optical flow, and finally predict the micro-expression. Additionally, to overcome the shortcomings of limited and imbalanced training samples, we propose a data augmentation strategy based on Generative Adversarial Network (GAN). Comprehensive experiments are conducted on three public micro-expression datasets: CASME II, SAMM and SMIC with Leave-One-Subject-Out (LOSO) cross-validation. The results demonstrated that our method achieves competitive performance when compared with the existing approaches, with the best UF1 (0.8452) and UAR (0.8465).
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_7
DP  - Springer Link
SP  - 76
EP  - 87
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
ST  - DFFCN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_7.pdf
KW  - Convolutional neural network
KW  - Micro-expression recognition
KW  - Micro-expression synthesis
ER  - 

TY  - CONF
TI  - EvoBA: An Evolution Strategy as a Strong Baseline for Black-Box Adversarial Attacks
AU  - Ilie, Andrei
AU  - Popescu, Marius
AU  - Stefanescu, Alin
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Recent work has shown how easily white-box adversarial attacks can be applied to state-of-the-art image classifiers. However, real-life scenarios resemble more the black-box adversarial conditions, lacking transparency and usually imposing natural, hard constraints on the query budget.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_16
DP  - Springer Link
SP  - 188
EP  - 200
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
ST  - EvoBA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_16.pdf
ER  - 

TY  - CONF
TI  - A Novel Binary BCI Systems Based on Non-oddball Auditory and Visual Paradigms
AU  - Saparbayeva, Madina
AU  - Shomanov, Adai
AU  - Lee, Min-Ho
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Event-Related Potentials (ERPs) based binary BCI systems help enable users to control external devices through brain signals responding to stimulus. However, the external properties of the auditory or visual stimuli in the typical oddball-paradigm are loud and large for a user, which often brings psychological discomfort. In this study, we proposed novel non-oddball BCI paradigms where the intensity of external properties is greatly minimized while maintaining the system performance. To compensate for the loss of accuracy from the diminutive stimulus, users were instructed to generate discriminant ERP responses by performing a voluntary mental task. As the result, task-relevant endogenous components were investigated by the certain mental task and greatly enhanced system performance. The decoding accuracies of proposed CNN with data augmentation technique were 77.8% and 76.7% for the non-oddball visual and auditory paradigms, respectively, which significantly outperformed the linear classifier model. These results open up novel avenues for practical ERP systems, which could increase the usability of current brain-computer interfaces remarkably.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_1.pdf
KW  - Active mental task
KW  - Brain-computer interface (BCI)
KW  - Convolutional neural networks (CNN)
KW  - Event-related potential (ERP)
KW  - Non-oddball paradigm
ER  - 

TY  - CONF
TI  - Multi-branch Fusion Fully Convolutional Network for Person Re-Identification
AU  - Ji, Shanshan
AU  - Li, Te
AU  - Zhu, Shiqiang
AU  - Meng, Qiwei
AU  - Gu, Jianjun
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Building effective CNN architectures with light weight has become an increasing application demand for person re-identification (Re-ID) tasks. However, most of the existing methods adopt large CNN models as baseline, which is complicated and inefficient. In this paper, we propose an efficient and effective CNN architecture named Multi-branch Fusion Fully Convolutional Network (MBF-FCN). Firstly, multi-branch feature extractor module focusing on different receptive field sizes is designed to extract low-level features. Secondly, basic convolution block units (CBU) are used for constructing candidate network module to obtain deep-layer feature presentation. Finally, head structures consisted of multi-branches will be adopted, combining not only global and local features but also lower-level and higher-level features with fully convolutional layer. Experiments demonstrate our superior trade-off among model size, speed, computation, and accuracy. Specifically, our model trained from scratch, only has 2.1 million parameters, 0.84 GFLOPs and 384-dimensional features, reaching the state-of-the-art result on Market-1501 and DuckMTMCreID dataset of Rank-1/mAP = 94.5$$\%$$%/84.3$$\%$$%, Rank-1/mAP = 86.6$$\%$$%/73.5$$\%$$%without re-ranking, respectively.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_14
DP  - Springer Link
SP  - 164
EP  - 175
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_14.pdf
KW  - Fully convolutional network
KW  - Lightweight network
KW  - Multi-branch fusion
KW  - Person Re-Identification
ER  - 

TY  - CONF
TI  - A Reinforcement Learning Approach for Abductive Natural Language Generation
AU  - Huang, Hongru
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Teaching deep learning models commonsense knowledge is a crucial yet challenging step towards building human-level artificial intelligence. Abductive Commonsense Reasoning ($$\mathcal {ART}$$ART) is a benchmark that investigates model’s ability on inferencing the most plausible explanation within the given context, which requires model using commonsense knowledge about the world. $$\mathcal {ART}$$ARTconsists of two datasets, $$\alpha $$αNLG and $$\alpha $$αNLI, that challenge models from generative and discriminative settings respectively. Despite the fact that both of the datasets investigate the same ability, existing work solves them independently. In this work, we address $$\alpha $$αNLG in a teacher-student setting by getting help from another model with adequate commonsense knowledge fully-trained on $$\alpha $$αNLI. We fulfill this intuition by representing the desired optimal generation model as an Energy-Based Model and training it using a reinforcement learning algorithm. Experiment results showed that our model achieve state-of-the-art results on both automatic and human evaluation metrics, which have demonstrated the effectiveness and feasibility of our model (Code available in https://github.com/Huanghongru/commonsense-generation).
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_6
DP  - Springer Link
SP  - 64
EP  - 75
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_6.pdf
KW  - Commonsense knowledge
KW  - Natural language generation
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - PCMO: Partial Classification from CNN-Based Model Outputs
AU  - Xie, Jiarui
AU  - Antoine, Violaine
AU  - Chateau, Thierry
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - The partial classification can assign a sample to a class subset when this sample has similar probabilities for multiple classes. However, the extra information for making such predictions usually comes at the cost of retraining the model, changing the model architecture, or applying a new loss function. In an attempt to alleviate this computational burden, we fulfilled partial classification only based on pre-trained CNN-based model outputs (PCMO), by transforming the model outputs to beliefs for predicted sets under the Dempster-Shafer theory. The PCMO method has been executed on six prevalent datasets, four classical CNN-based models, and compared with three existing methods. For instance, experiments with MNIST and CIFAR10 datasets show the superiority of PCMO in terms of average discounted accuracy ($$0.23\%$$0.23%and $$7.71\%$$7.71%improvement, respectively) when compared to other methods. The performance demonstrated that the PCMO method makes it possible to improve classification accuracy and to make cautious decisions by assigning a sample to a class subset. Moreover, the PCMO method is simple to implement compared to the existing methods, as the PCMO method does not need to retrain the model or conduct any further modifications.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_13
DP  - Springer Link
SP  - 150
EP  - 163
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
ST  - PCMO
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_13.pdf
KW  - CNN-based model
KW  - Decision making
KW  - Dempster-Shafer theory
KW  - Partial classification
ER  - 

TY  - CONF
TI  - Gradient Descent Learning Algorithm Based on Spike Selection Mechanism for Multilayer Spiking Neural Networks
AU  - Lin, Xianghong
AU  - Hu, Tiandou
AU  - Wang, Xiangwen
AU  - Lu, Han
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Gradient descent is one of the significant research contents in supervised learning of spiking neural networks (SNNs). In order to improve the performance of gradient descent learning algorithms for multilayer SNNs, this paper proposes a spike selection mechanism to select optimal presynaptic spikes to participate in computing the change amount of synaptic weights during the process of weight adjustment. The proposed spike selection mechanism comprehensively considers the desired and actual output spikes of the network. The presynaptic spikes involved in the calculation are determined within a certain time interval, so that the network output spikes matches the desired output spikes perfectly as far as possible. The proposed spike selection mechanism is used for the gradient descent learning algorithm for multilayer SNNs. The experimental results show that our proposed mechanism can make the gradient descent learning algorithm for multilayer SNNs have higher learning accuracy, fewer learning epochs and shorten the running time. It indicates that the spike selection mechanism is very effective for improving gradient descent learning performance.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_4
DP  - Springer Link
SP  - 40
EP  - 51
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_4.pdf
KW  - Gradient descent
KW  - Spike selection mechanism
KW  - Spiking neural networks
KW  - Supervised learning
ER  - 

TY  - CONF
TI  - Learning to Coordinate via Multiple Graph Neural Networks
AU  - Xu, Zhiwei
AU  - Zhang, Bin
AU  - Bai, Yunpeng
AU  - Li, Dapeng
AU  - Fan, Guoliang
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - The collaboration between agents has gradually become an important topic in multi-agent systems. The key is how to efficiently solve the credit assignment problems. This paper introduces MGAN for collaborative multi-agent reinforcement learning, a new algorithm that combines graph convolutional networks and value-decomposition methods. MGAN learns the representation of agents from different perspectives through multiple graph networks, and realizes the proper allocation of attention between all agents. We show the amazing ability of the graph network in representation learning by visualizing the output of the graph network, and therefore improve interpretability for the actions of each agent in the multi-agent system.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_5
DP  - Springer Link
SP  - 52
EP  - 63
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_5.pdf
KW  - Decision making and control
KW  - Graph neural network
KW  - Multi-agent reinforcement learning
ER  - 

TY  - CONF
TI  - Open-Set Recognition with Dual Probability Learning
AU  - Liu, Shanshan
AU  - Yang, Fenglei
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - The open-set recognition task is proposed to handle unknown classes that do not belong to any of the classes in training set. The methods should reject unknown samples while maintaining high classification accuracy on the known classes. Previous methods are divided into two stages, including open-set identification and closed-set classification. These methods usually reject unknown samples according to the previous analysis of the known classes. However, this would inevitably cause risks if the discriminative representation from the unknown classes is insufficient. In contrast to the previous methods, we propose a new method which uses a dual probability distribution to represent the unknowns. From the dual distribution, the boundary of known space is naturally derived, thereby helping identify the unknowns without staging or thresholding. Following this formulation, this paper proposed a new method called Dual Probability Learning Model (DPLM). The model built a neural Gaussian Mixed Model for probability estimation. To learn this model, we also added the normalized joint probability of latent representations into the objective function in the training stage. The results showed that the proposed method is highly effective.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_11
DP  - Springer Link
SP  - 127
EP  - 137
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_11.pdf
KW  - Deep learning
KW  - Dual probability
KW  - Gaussian mixed model
KW  - Open-set recognition
ER  - 

TY  - CONF
TI  - Fast Organization of Objects’ Spatial Positions in Manipulator Space from Single RGB-D Camera
AU  - Sun, Yangchang
AU  - Yang, Minghao
AU  - Li, Jialing
AU  - Qiang, Baohua
AU  - Chen, Jinlong
AU  - Jia, Qingyu
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - For the grasp task in physical environment, it is important for the manipulator to know the objects’ spatial positions with as few sensors as possible in real time. This work proposed an effective framework to organize the objects’ spatial positions in the manipulator 3D workspace with a single RGB-D camera robustly and fast. It mainly contains two steps: (1) a 3D reconstruction strategy for objects’ contours obtained in environment; (2) a distance-restricted outlier point elimination strategy to reduce the reconstruction errors caused by sensor noise. The first step ensures fast object extraction and 3D reconstruction from scene image, and the second step contributes to more accurate reconstructions by eliminating outlier points from initial result obtained by the first step. We validated the proposed method in a physical system containing a Kinect 2.0 RGB-D camera and a Mico2 robot. Experiments show that the proposed method can run in quasi real time on a common PC and it outperforms the traditional 3D reconstruction methods.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_15
DP  - Springer Link
SP  - 176
EP  - 187
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_15.pdf
KW  - 3D reconstruction
KW  - Real-time system
KW  - Robot grasping
ER  - 

TY  - CONF
TI  - AUPro: Multi-label Facial Action Unit Proposal Generation for Sequence-Level Analysis
AU  - Chen, Yingjie
AU  - Zhang, Jiarui
AU  - Chen, Diqi
AU  - Wang, Tao
AU  - Wang, Yizhou
AU  - Liang, Yun
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Facial action unit (AU) plays an essential role in human facial behavior analysis. Despite the progress made in frame-level AU analysis, the discrete classification results provided by previous work are not explicit enough for the analysis required by many real-world applications, and as AU is a dynamic process, sequence-level analysis maintaining a global view has yet been gravely ignored in the literature. To fill in the blank, we propose a multi-label AU proposal generation task for sequence-level facial action analysis. To tackle the task, we design AUPro, which takes a video clip as input and directly generates proposals for each AU category. Extensive experiments conducted on two commonly used AU benchmark datasets, BP4D and DISFA, show the superiority of our proposed method.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_8
DP  - Springer Link
SP  - 88
EP  - 99
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
ST  - AUPro
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_8.pdf
KW  - Affective computing
KW  - Facial action unit
KW  - Sequence-level AU analysis
ER  - 

TY  - CONF
TI  - A Novel Oversampling Technique for Imbalanced Learning Based on SMOTE and Genetic Algorithm
AU  - Gong, Juan
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Learning from imbalanced datasets is a challenge in machine learning, oversampling is an effective method to solve the problem of class imbalance, owing to its easy-to-go capability of achieving the balance by synthesizing new samples. However several problems still exist such as noise samples, selection of boundary samples and the diversity of synthetic samples. To solve these problems, this paper proposes a new improved oversampling method based on SMOTE and genetic algorithm (GA-SMOTE). The main steps of GA-SMOTE are as follows. Firstly GA-SMOTE uses genetic algorithm to find an optimal noise processing scheme. Then GA-SMOTE assigns different sampling weight to each sample and the sample closer to the boundary is assigned greater weight. Finally, GA-SMOTE divides raw dataset into multiple sub-clusters by K-means clustering and intra-cluster neighborhood triangular sampling method is used in each sub-cluster to improve the diversity of synthetic samples. A large number of experiments have proved that GA-SMOTE is superior to the other five comparison methods in dealing with imbalanced data classification.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_17
DP  - Springer Link
SP  - 201
EP  - 212
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_17.pdf
KW  - Data mining
KW  - Genetic algorithm
KW  - Machine learning
KW  - Oversampling
ER  - 

TY  - CONF
TI  - How Much Do Synthetic Datasets Matter in Handwritten Text Recognition?
AU  - Wróblewska, Anna
AU  - Chechliński, Bartłomiej
AU  - Sysko-Romańczuk, Sylwia
AU  - Seweryn, Karolina
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - This paper explores synthetic image generators in dataset preparation to train models that allow human handwritten character recognition. We examined the most popular deep neural network architectures and presented a method based on autoencoder architecture and a schematic character generator. As a comparative model, we used a classifier trained on the whole NIST set of handwritten letters from the Latin alphabet. Our experiments showed that the 80% synthetic images in the training dataset achieved very high model accuracy, almost the same level as the 100% handwritten images in the training dataset. Our results prove that we can reduce the costs of creating, gathering, and describing human handwritten datasets five times over – with only a 5% loss in accuracy. Our method appears to be beneficial for a part of the training process and avoids unnecessary manual annotation work.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_12
DP  - Springer Link
SP  - 138
EP  - 149
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_12.pdf
KW  - Autoencoder
KW  - Data augmentation
KW  - Deep learning
KW  - Handwritten text
KW  - Image processing
KW  - Pattern recognition
KW  - Synthetic dataset
ER  - 

TY  - CONF
TI  - Deep Kernelized Network for Fine-Grained Recognition
AU  - Mahmoudi, M. Amine
AU  - Chetouani, Aladine
AU  - Boufera, Fatma
AU  - Tabia, Hedi
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Convolutional Neural Networks (CNNs) are based on linear kernel at different levels of the network. Linear kernels are not efficient, particularly, when the original data is not linearly separable. In this paper, we focus on this issue by investigating the impact of using higher order kernels. For this purpose, we replace convolution layers with Kervolution layers proposed in [28]. Similarly, we replace fully connected layers alternatively with Kernelized Dense Layers (KDL) proposed in [16] and Kernel Support vector Machines (SVM) [1]. These kernel-based methods are more discriminative in the way that they can learn more complex patterns compared to the linear one. Those methods first maps input data to a higher space. After that, they learn a linear classifier in that space which is similar to a powerful non-linear classifier in the first space. We have used Fine-Grained datasets namely FGVC-Aircraft, StanfordCars and CVPRIndoor as well as Facial Expression Recognition (FER) datasets namely, RAF-DB, ExpW and FER2013 to evaluate the performance of these methods. The experimental results demonstrate that these methods outperform the ordinary linear layers when used in a deep network fashion.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_9
DP  - Springer Link
SP  - 100
EP  - 111
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_9.pdf
KW  - Deep learning
KW  - Facial expression recognition
KW  - Fine-grained recognition
KW  - Kernel function
ER  - 

TY  - CONF
TI  - Semantic Perception Swarm Policy with Deep Reinforcement Learning
AU  - Zhang, Tianle
AU  - Liu, Zhen
AU  - Pu, Zhiqiang
AU  - Yi, Jianqiang
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Swarm systems with simple, homogeneous and autonomous individuals can efficiently accomplish specified complex tasks. Recent works have shown the power of deep reinforcement learning (DRL) methods to learn cooperative policies for swarm systems. However, most of them show poor adaptability when applied to new environments or tasks. In this paper, we propose a novel semantic perception swarm policy with DRL for distributed swarm systems. This policy implements innovative semantic perception, which enables agents to understand their observation information, yielding semantic information, to promote agents’ adaptability. In particular, semantic disentangled representation with posterior distribution and semantic mixture representation with network mapping are realized to represent semantic information of agents’ observations. Moreover, in the semantic representation, heterogeneous graph attention network is adopted to effectively model individual-level and group-level relational information. The distributed and transferable swarm policy can perceive the information of uncertain number of agents in swarm environments. Various simulations and real-world experiments on several challenging tasks, i.e., sheep food collection and wolves predation, demonstrate the superior effectiveness and adaptability performance of our method compared with existing methods.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92238-2_10
DP  - Springer Link
SP  - 112
EP  - 124
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92238-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92238-2_10.pdf
ER  - 

TY  - CONF
TI  - Towards Human-Level Performance in Solving Double Dummy Bridge Problem
AU  - Kowalik, Szymon
AU  - Mańdziuk, Jacek
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Double Dummy Bridge Problem (DDBP) is a hard classification problem that consists in estimating the number of tricks to be taken by N-S pair during a bridge game. In this paper we propose a new approach to DDBP which utilizes convolutional neural networks (CNNs) and a dedicated matrix representation of the problem, suitable for the CNN application. Following previous studies on the application of neural networks to DDBP, we take a knowledge-free approach, i.e. the CNN models are trained with no use of any expert knowledge or explicitly indicated bridge rules. As a result, two models are derived: a baseline CNN model and its ensemble refinement. The results are compared with two former neural network approaches, showing significant superiority of the CNN-based solution. Depending on the type DDBP deal, i.e. trump or notrump, our approach either outperforms or is slightly inferior to the outcomes of human bridge grandmasters solving DDBP. This state-of-the-art performance is complemented in the paper with an analysis of the internal structure (weight patterns) of the trained CNNs, which partly explains the underlying classification process.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_2
DP  - Springer Link
SP  - 15
EP  - 27
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_2.pdf
KW  - Classification
KW  - Convolutional neural network
KW  - Deep learning
KW  - Double dummy bridge problem
ER  - 

TY  - CONF
TI  - Efficient, Low-Cost, Real-Time Video Super-Resolution Network
AU  - Liu, Guanqun
AU  - Wang, Xin
AU  - Zha, Daren
AU  - Wang, Lei
AU  - Zhao, Lin
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Video Super-Resolution (VSR) task aims to reconstruct missing high-frequency information lost in degradation. Researchers have proposed many excellent models. However, these models require large memory and high computational cost. In this paper, we propose a novel VSR model called StudentVSR (StuVSR) which is a unidirectional recurrent network. To guarantee StuVSR can generate sufficient high-frequency information, we propose Inceptual Attention (IA) mechanism. Meanwhile, to compress the model size, we utilize the idea of knowledge distillation. We take an auto-encoder network as teacher and redesign the knowledge distillation mode. StuVSR employs extremely small parameters and accomplishes the VSR task in a rapid manner. StuVSR can generate 30-frame-per-second (FPS) 1080p-2k videos in real-time. We conduct comparison experiments to prove the superiority of StuVSR and StuVSR achieves the highest Peak Signal to Noise Ratio (PSNR) score among 16 state of the arts. We also explore the function of the inceptual attention and the knowledge distillation mode through ablation experiments. We will publish the codes at https://github.com/Dawn3474/StuVSR.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_17
DP  - Springer Link
SP  - 200
EP  - 211
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_17.pdf
KW  - Attention mechanism
KW  - Knowledge distillation
KW  - Video super-resolution
ER  - 

TY  - CONF
TI  - Low-Resource Neural Machine Translation Using Fast Meta-learning Method
AU  - Wu, Nier
AU  - Hou, Hongxu
AU  - Zheng, Wei
AU  - Sun, Shuo
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Data sparsity is fundamental reason that affects the quality of low-resource neural machine translation models (NMT), although transfer learning methods can alleviate data sparsity by introducing external knowledge. However, the pre-trained model parameters are only suitable for the current task set, which does not ensure better performance improvement in downstream tasks. Although meta-learning methods have better potential, while meta-parameters are determined by the second-order gradient term corresponding to a specific task, which directly leads to the consumption of computing resources. In addition, the integration and unified representation of external knowledge is also the main factor to improve performance. Therefore, we proposed a fast meta-learning method using multiple-aligned word embedding representation, which can map all languages to the word embedding space of the target language without seed dictionary. Meanwhile, we update the meta-parameters by calculating the cumulative gradient on different tasks to replace the second-order term in the ordinary meta-learning method, which not only pays attention to the potential but also improves the calculation efficiency. We conducted experiments on three low-resource translation tasks of the CCMT2019 data set and found that our method significantly improves the model quality compared with traditional methods, which fully reflects the effectiveness of the proposed method.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_16
DP  - Springer Link
SP  - 188
EP  - 199
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_16.pdf
KW  - Low-resource
KW  - Machine translation
KW  - Meta-learning
ER  - 

TY  - CONF
TI  - On the Unreasonable Effectiveness of Centroids in Image Retrieval
AU  - Wieczorek, Mikołaj
AU  - Rychalska, Barbara
AU  - Dąbrowski, Jacek
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Image retrieval task consists of finding similar images to a query image from a set of gallery (database) images. Such systems are used in various applications e.g. person re-identification (ReID) or visual product search. Despite active development of retrieval models it still remains a challenging task mainly due to large intra-class variance caused by changes in view angle, lighting, background clutter or occlusion, while inter-class variance may be relatively low. A large portion of current research focuses on creating more robust features and modifying objective functions, usually based on Triplet Loss. Some works experiment with using centroid/proxy representation of a class to alleviate problems with computing speed and hard samples mining used with Triplet Loss. However, these approaches are used for training alone and discarded during the retrieval stage. In this paper we propose to use the mean centroid representation both during training and retrieval. Such an aggregated representation is more robust to outliers and assures more stable features. As each class is represented by a single embedding - the class centroid - both retrieval time and storage requirements are reduced significantly. Aggregating multiple embeddings results in a significant reduction of the search space due to lowering the number of candidate target vectors, which makes the method especially suitable for production deployments. Comprehensive experiments conducted on two ReID and Fashion Retrieval datasets demonstrate effectiveness of our method, which outperforms the current state-of-the-art. We propose centroid training and retrieval as a viable method for both Fashion Retrieval and ReID applications. Our code is available at https://github.com/mikwieczorek/centroids-reid.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_18
DP  - Springer Link
SP  - 212
EP  - 223
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_18.pdf
KW  - Centroid triplet loss
KW  - Clothes retrieval
KW  - Deep learning in fashion
KW  - Fashion retrieval
KW  - Person re-identification
ER  - 

TY  - CONF
TI  - Identity-Based Data Augmentation via Progressive Sampling for One-Shot Person Re-identification
AU  - Si, Runxuan
AU  - Yang, Shaowu
AU  - Zhao, Jing
AU  - Chi, Haoang
AU  - Tang, Yuhua
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - One-shot person re-identification (Re-ID) is a hot spot nowadays, where there is only one labeled image along with many unlabeled images for each identity. Due to the short of labeled training images, it’s hard to catch up with performance under full supervision. In this paper, we propose a progressive method with identity-based data augmentation to improve lack of supervision information, which takes advantage of information of each identity to generate high-quality images. Specifically, with a certain image-to-image translation model, images are decoupled into content and style codes, where the images holding the features of identity well and injected in the style codes exclusive to the identity can be obtained by labeled images through the process of recombination. A progressive data augmentation method for one-shot labeled samples is also designed to optimize the sampling accuracy of pseudo labeled images, which contributes to our identity-based data augmentation process. The experimental results show that our method represents new state-of-the-art one-shot Re-ID work.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_10
DP  - Springer Link
SP  - 113
EP  - 124
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_10.pdf
KW  - GAN
KW  - Identity-based
KW  - One-shot
KW  - Progressive
KW  - Re-ID
ER  - 

TY  - CONF
TI  - WaveFuse: A Unified Unsupervised Framework for Image Fusion with Discrete Wavelet Transform
AU  - Liu, Shaolei
AU  - Wang, Manning
AU  - Song, Zhijian
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - We propose an unsupervised image fusion architecture for multiple application scenarios based on the combination of multi-scale discrete wavelet transform through regional energy and deep learning. To our best knowledge, this is the first time that a conventional frequency method has been combined with deep learning for feature maps fusion. The useful information of feature maps can be utilized adequately through multi-scale discrete wavelet transform in our proposed method. Compared with other state-of-the-art fusion methods, the proposed algorithm exhibits better fusion performance in both subjective and objective evaluation. Moreover, it’s worth mentioning that comparable fusion performance trained in COCO dataset can be obtained by training with a much smaller dataset with only hundreds of images chosen randomly from COCO. Hence, the training time is shortened substantially, leading to the improvement of the model’s performance both in practicality and training efficiency.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_14
DP  - Springer Link
SP  - 162
EP  - 174
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
ST  - WaveFuse
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_14.pdf
KW  - Discrete wavelet transform
KW  - Multi-scene image fusion
KW  - Regional energy
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Deep Supervised Hashing by Classification for Image Retrieval
AU  - Luo, Xiao
AU  - Guo, Yuhang
AU  - Ma, Zeyu
AU  - Zhong, Huasong
AU  - Li, Tao
AU  - Ju, Wei
AU  - Chen, Chong
AU  - Deng, Minghua
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Hashing has been widely used to approximate the nearest neighbor search for image retrieval due to its high computation efficiency and low storage requirement. With the development of deep learning, a series of deep supervised methods were proposed for end-to-end binary code learning. However, the similarity between each pair of images is simply defined by whether they belong to the same class or contain common objects, which ignores the heterogeneity within the class. Therefore, those existing methods have not fully addressed the problem and their results are far from satisfactory. Besides, it is difficult and impractical to apply those methods to large-scale datasets. In this paper, we propose a brand new perspective to look into the nature of deep supervised hashing and show that classification models can be directly utilized to generate hashing codes. We also provide a new deep hashing architecture called Deep Supervised Hashing by Classification (DSHC) which takes advantage of both inter-class and intra-class heterogeneity. Experiments on benchmark datasets show that our method outperforms the state-of-the-art supervised hashing methods on accuracy and efficiency.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_1.pdf
KW  - Deep hashing
KW  - Learning to hash
KW  - Supervised learning
ER  - 

TY  - CONF
TI  - BFConv: Improving Convolutional Neural Networks with Butterfly Convolution
AU  - Yang, Dengjie
AU  - Yu, Xuehui
AU  - Sun, Yi
AU  - Zhuang, Fuzhen
AU  - He, Qing
AU  - Ye, Shiwei
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Convolutional neural network (CNN) is a basic neural network widely used in vision tasks. Many CNNs alleviate the redundancy in feature maps to reduce model complexity. Inspired by digital signal processing theories, this paper reviews discrete fourier transform (DFT), finding its similarities with standard convolution. In particular, DFT has a fast algorithm called FFT, which sparks our thinking: can we learn from the idea of FFT to realize a more efficient convolution filter? Based on the butterfly operation of FFT, we propose a novel butterfly convolution (BFConv). In addition, we illustrate that group weight sharing convolution is a basic unit of BFConv. Compared with the traditional group convolution structure, BFConv constructs group residual-like connections and increases the range of receptive fields for each sub-feature layer. Without changing the network architecture, we integrate BFConv into ResNet-50, ShuffleNet and VGG-16. Experimental results on CIFAR-10 and ImageNet demonstrate the above BFConv-equipped networks reduce parameters and computation, achieving similar or higher accuracy. Remarkably, when ResNet-50 embedded BFConv reaches nearly half of the compression ratio of the model, it performs favorably against its state-of-the-art competitors.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_4
DP  - Springer Link
SP  - 40
EP  - 50
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
ST  - BFConv
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_4.pdf
KW  - Butterfly convolution
KW  - Convolutional neural network
KW  - FFT
KW  - Group Weight sharing convolution
ER  - 

TY  - CONF
TI  - Vehicle Image Generation Going Well with the Surroundings
AU  - Kim, Jeesoo
AU  - Kim, Jangho
AU  - Yoo, Jaeyoung
AU  - Kim, Daesik
AU  - Kwak, Nojun
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - In spite of the advancement of generative models, there have been few studies generating objects in uncontrolled real-world environments. In this paper, we propose an approach for vehicle image generation in real-world scenes. Using a subnetwork based on a precedent work of image completion, our model makes the shape of an object. Details of objects are trained by additional colorization and refinement subnetworks, resulting in a better quality of generated objects. Unlike many other works, our method does not require any segmentation layout but still makes a plausible vehicle in an image. We evaluate our method by using images from Berkeley Deep Drive (BDD) and Cityscape datasets, which are widely used for object detection and image segmentation problems. The adequacy of the generated images by the proposed method has also been evaluated using a widely utilized object detection algorithm and the FID score.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_6
DP  - Springer Link
SP  - 63
EP  - 74
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_6.pdf
KW  - Generative model
KW  - Image completion
KW  - Image generation
ER  - 

TY  - CONF
TI  - Feature Fusion Learning Based on LSTM and CNN Networks for Trend Analysis of Limit Order Books
AU  - Lv, Xuerui
AU  - Zhang, Li
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - In recent years, deep learning has been successfully applied to analyzing financial time series. In this paper, we propose a novel feature fusion learning (FFL) method to analyze the trend of high-frequency limit order books (LOBs). The proposed FFL method combines a convolutional neural network (CNN) and two long short-term memory (LSTM) models. The CNN module uses a kind of up-sampling techniques to enhance basic features and the two LSTM modules can extract time-related information from time-insensitive and time-sensitive features. In addition, two fusion rules (majority voting and weighted summation) are designed to fuse different feature models. Experiments are conducted on the benchmark dataset FI-2010. Experimental results show that FFL can go beyond the performance of every sub-model and outperform the state-of-the-art model on the prediction performance of LOBs.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_11
DP  - Springer Link
SP  - 125
EP  - 137
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_11.pdf
KW  - Convolutional neural network
KW  - Feature fusion learning
KW  - Limit order books
KW  - Long short-term memory
ER  - 

TY  - CONF
TI  - Tile2Vec with Predicting Noise for Land Cover Classification
AU  - Sinaga, Marshal Arijona
AU  - Ali, Fadel Muhammad
AU  - Arymurthy, Aniati Murni
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Tile2vec has proven to be a good representation learning model in the remote sensing field. The success of the model depends on l2-norm regularization. However, l2-norm regularization has the main drawback that affects the regularization. We propose to replace the l2-norm with regularization with predicting noise framework. We then develop an algorithm to integrate the framework. We evaluate the model by using it as a feature extractor on the land cover classification task. The result shows that our proposed model outperforms all the baseline models.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_8
DP  - Springer Link
SP  - 87
EP  - 99
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_8.pdf
KW  - Deep learning
KW  - Land cover classification
KW  - Predicting noise
KW  - Remote sensing
KW  - Representation learning
KW  - Tile2vec
ER  - 

TY  - CONF
TI  - Coarse-to-Fine Visual Place Recognition
AU  - Qi, Junkun
AU  - Wang, Rui
AU  - Wang, Chuan
AU  - Cao, Xiaochun
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Visual Place Recognition (VPR) aims to locate one or more images depicting the same place in the geotagged database with a given query and is typically conducted as an image retrieval task. Currently, global-based and local-based descriptors are two mainstream representations to solve VPR. However, they still struggle against viewpoint change, confusion from similar patterns in different places, or high computation complexity. In this paper, we propose a progressive Coarse-To-Fine (CTF-VPR) framework, which has a strong ability on handling irrelevant matches and controlling time consumption. It employs global descriptors to discover visually similar references and local descriptors to filter those with similar but irrelative patterns. Besides, a region-specific representing format called regional descriptor is introduced with region augmentation and increases the possibilities of positive references with partially relevant areas via region refinement. Furthermore, during the spatial verification, we provide the Spatial Deviation Index (SDI) considering coordinate deviation to evaluate the consistency of matches. It discards exhaustive and iterative search and reduces the time consumption hundreds of times. The proposed CTF-VPR outperforms existing approaches by 2%–3% recalls on Pitts250k and Tokyo24/7 benchmarks.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_3
DP  - Springer Link
SP  - 28
EP  - 39
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_3.pdf
KW  - Coarse-to-fine
KW  - Multi-scale descriptors
KW  - Visual place recognition
ER  - 

TY  - CONF
TI  - Scale Invariant Domain Generalization Image Recapture Detection
AU  - Luo, Jinian
AU  - Guo, Jie
AU  - Qiu, Weidong
AU  - Huang, Zheng
AU  - Hui, Hong
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Recapturing and rebroadcasting of images are common attack methods in insurance frauds and face identification spoofing, and an increasing number of detection techniques were introduced to handle this problem. However, most of them ignored the domain generalization scenario and scale variances, with an inferior performance on domain shift situations, and normally were exacerbated by intra-domain and inter-domain scale variances. In this paper, we propose a scale alignment domain generalization framework (SADG) to address these challenges. First, an adversarial domain discriminator is exploited to minimize the discrepancies of image representation distributions among different domains. Meanwhile, we exploit triplet loss as a local constraint to achieve a clearer decision boundary. Moreover, a scale alignment loss is introduced as a global relationship regularization to force the image representations of the same class across different scales to be undistinguishable. Experimental results on four databases and comparison with state-of-the-art approaches show that better performance can be achieved using our framework.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_7
DP  - Springer Link
SP  - 75
EP  - 86
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_7.pdf
KW  - Domain generalization
KW  - Image processing and computer vision
KW  - Recapture detection
KW  - Scale variance
ER  - 

TY  - CONF
TI  - WikiFlash: Generating Flashcards from Wikipedia Articles
AU  - Cheng, Yuang
AU  - Ding, Yue
AU  - Foucher, Sebastien
AU  - Pascual, Damián
AU  - Richter, Oliver
AU  - Volk, Martin
AU  - Wattenhofer, Roger
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Flashcards, or any sort of question-answer pairs, are a fundamental tool in education. However, the creation of question-answer pairs is a tedious job which often defers independent learners from properly studying a topic. We seek to provide a tool to automatically generate flashcards from Wikipedia articles to make independent education more attractive to a broader audience. We investigate different state-of-the-art natural language processing models and propose a pipeline to generate flashcards with different levels of detail from any given article. We evaluate the proposed pipeline based on its computing time and the number of generated and filtered questions, given the proposed filtering method. In a user study, we find that the generated flashcards are evaluated as helpful. Further, users evaluated the quality of human created flashcards that are available open source as comparable to or only slightly better than the automatically generated cards (Our application is available at: flashcard.ethz.ch).
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_12
DP  - Springer Link
SP  - 138
EP  - 149
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
ST  - WikiFlash
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_12.pdf
KW  - Natural language processing
KW  - Personalized education
KW  - Question-answer extraction
ER  - 

TY  - CONF
TI  - Video Face Recognition with Audio-Visual Aggregation Network
AU  - Li, Qinbo
AU  - Wan, Qing
AU  - Lee, Sang-Heon
AU  - Choe, Yoonsuck
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - With the continuing improvement in deep learning methods in recent years, face recognition performance is starting to surpass human performance. However, current state-of-the-art approaches are usually trained on high-quality still images and do not work well in unconstrained video face recognition. We propose to use audio information in the video to aid in the face recognition task with mixed quality inputs. We introduce an Audio-Visual Aggregation Network (AVAN) to aggregate multiple facial and voice information to improve face recognition performance. To effectively train and evaluate our approach, we constructed an Audio-Visual Face Recognition dataset. Empirical results show that our approach significantly improves the face recognition accuracy on unconstrained videos.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_13
DP  - Springer Link
SP  - 150
EP  - 161
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_13.pdf
KW  - Attention
KW  - Multimodal learning
KW  - Video face recognition
ER  - 

TY  - CONF
TI  - A Joint Representation Learning Approach for Social Media Tag Recommendation
AU  - Li, Xiangyu
AU  - Chen, Weizheng
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - In this paper, we analyze the mutual relationship between social media text and tags and explore how to integrate sematic information for tag recommendation. Our key motivation is to jointly map all words, tags and posts to vectors in a same hidden sematic space by modeling the syntagmatic and paradigmatic information simultaneously. We propose two novel distributed representation learning models for tagged documents: Tag Representation Learning (TRL) and Tag and Word Representation Learning (TWRL). The first models the immediate relationship between tags and words. The second one adds a skip-gram output layer to the first model, in order to enhance the semantic relationship among words. Extensive experiments are conducted on large scale datasets crawled from Twitter and Sina Weibo. By simulating two typical recommendation tasks, we discover that both models mentioned above outperform other competitive baselines remarkably.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_9
DP  - Springer Link
SP  - 100
EP  - 112
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_9.pdf
KW  - Representation learning
KW  - Social media
KW  - Tag recommendation
ER  - 

TY  - CONF
TI  - Manipulation-Invariant Fingerprints for Cross-Dataset Deepfake Detection
AU  - Li, Zuoyan
AU  - Yang, Wenyuan
AU  - Liu, Ruixin
AU  - Zhu, Yuesheng
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Most of the current deepfake detection methods make efforts to learn the classifiers on the manipulated face dataset forged by a single manipulation method. However, these classifiers lack the generalization capacity to other kinds of manipulated face images, limiting their applications in real-world scenarios. In this paper, we find common detectable fingerprints for face images manipulated by different forgery methods through mapping images into a fingerprint space. Such fingerprints are called manipulation-invariant fingerprints, which would allow a classifier to generalize to face datasets forged by other methods. Therefore, a mask drop regularized unsupervised domain adaptation (MDRUDA) method is proposed for cross-dataset deepfake detection through building up the manipulation-invariant fingerprints. Specifically, a feature generator and a discriminator are trained adversarially to align the fingerprint distributions from face images forged by different methods, building up the manipulation-fingerprints that could train a more generalized classifier. We impose a mask drop regularization on the discriminator and the classifier to enrich the fingerprint space and further boost generalization ability. Experiments on public deepfake datasets show that our approach can gain significantly better generalization capability in cross-datasets scenarios, compared with prior works.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_15
DP  - Springer Link
SP  - 175
EP  - 187
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_15.pdf
KW  - Deepfake detection
KW  - Digital forensics
KW  - Face manipulation
ER  - 

TY  - CONF
TI  - Integrating Rich Utterance Features for Emotion Recognition in Multi-party Conversations
AU  - Sun, Yang
AU  - Yu, Nan
AU  - Fu, Guohong
A2  - Mantoro, Teddy
A2  - Lee, Minho
A2  - Ayu, Media Anugerah
A2  - Wong, Kok Wai
A2  - Hidayanto, Achmad Nizar
T3  - Lecture Notes in Computer Science
AB  - Emotion recognition in multi-party conversations is a challenging task in natural language processing as it requires modeling the conversational context, the speaker-specific information, and the interaction within a conversation. To this end, we propose a graph-based multi-task learning network to integrate these utterance features for emotion recognition in multi-party conversations. First, we represent each utterance and each speaker as a node in a graph. In particular, we use three types of edges to connect these nodes to incorporate rich utterance features. Finally, we exploit link prediction as an auxiliary task to enhance the emotional consistency of extracted speaker-specific features. To verify the effectiveness of our strategy, we conduct experiments on two multi-party conversation corpora. Experimental results demonstrate an improvement of 1–2% in F1-score over multiple baselines.
C1  - Cham
C3  - Neural Information Processing
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-92273-3_5
DP  - Springer Link
SP  - 51
EP  - 62
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-92273-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-92273-3_5.pdf
KW  - Conversational emotion recognition
KW  - Graph neural network
KW  - Multi-task learning
ER  - 

TY  - CONF
TI  - Revisiting the Critical Factors of Augmentation-Invariant Representation Learning
AU  - Huang, Junqiang
AU  - Kong, Xiangwen
AU  - Zhang, Xiangyu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We focus on better understanding the critical factors of augmentation-invariant representation learning. We revisit MoCo v2 and BYOL and try to prove the authenticity of the following assumption: different frameworks bring about representations of different characteristics even with the same pretext task. We establish the first benchmark for fair comparisons between MoCo v2 and BYOL, and observe: (i) sophisticated model configurations enable better adaptation to pre-training dataset; (ii) mismatched optimization strategies of pre-training and fine-tuning hinder model from achieving competitive transfer performances. Given the fair benchmark, we make further investigation and find asymmetry of network structure endows contrastive frameworks to work well under the linear evaluation protocol, while may hurt the transfer performances on long-tailed classification tasks. Moreover, negative samples do not make models more sensible to the choice of data augmentations, nor does the asymmetric network structure. We believe our findings provide useful information for future work.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_3
DP  - Springer Link
SP  - 42
EP  - 58
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_3.pdf
ER  - 

TY  - CONF
TI  - GOCA: Guided Online Cluster Assignment for Self-supervised Video Representation Learning
AU  - Coskun, Huseyin
AU  - Zareian, Alireza
AU  - Moore, Joshua L.
AU  - Tombari, Federico
AU  - Wang, Chen
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Clustering is a ubiquitous tool in unsupervised learning. Most of the existing self-supervised representation learning methods typically cluster samples based on visually dominant features. While this works well for image-based self-supervision, it often fails for videos, which require understanding motion rather than focusing on background. Using optical flow as complementary information to RGB can alleviate this problem. However, we observe that a naïve combination of the two views does not provide meaningful gains. In this paper, we propose a principled way to combine two views. Specifically, we propose a novel clustering strategy where we use the initial cluster assignment of each view as prior to guide the final cluster assignment of the other view. This idea will enforce similar cluster structures for both views, and the formed clusters will be semantically abstract and robust to noisy inputs coming from each individual view. Additionally, we propose a novel regularization strategy to address the feature collapse problem, which is common in cluster-based self-supervised learning methods. Our extensive evaluation shows the effectiveness of our learned representations on downstream tasks, e.g., video retrieval and action recognition. Specifically, we outperform the state of the art by 7% on UCF and 4% on HMDB for video retrieval, and 5% on UCF and 6% on HMDB for video classification (Code available at https://github.com/Seleucia/goca).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_1
DP  - Springer Link
SP  - 1
EP  - 22
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - GOCA
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_1.pdf
KW  - Action recognition
KW  - Clustering
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Semi-supervised Object Detection via VC Learning
AU  - Chen, Changrui
AU  - Debattista, Kurt
AU  - Han, Jungong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Due to the costliness of labelled data in real-world applications, semi-supervised object detectors, underpinned by pseudo labelling, are appealing. However, handling confusing samples is nontrivial: discarding valuable confusing samples would compromise the model generalisation while using them for training would exacerbate the confirmation bias issue caused by inevitable mislabelling. To solve this problem, this paper proposes to use confusing samples proactively without label correction. Specifically, a virtual category (VC) is assigned to each confusing sample such that they can safely contribute to the model optimisation even without a concrete label. It is attributed to specifying the embedding distance between the training sample and the virtual category as the lower bound of the inter-class distance. Moreover, we also modify the localisation loss to allow high-quality boundaries for location regression. Extensive experiments demonstrate that the proposed VC learning significantly surpasses the state-of-the-art, especially with small amounts of available labels.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_10
DP  - Springer Link
SP  - 169
EP  - 185
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_10.pdf
KW  - Object detection
KW  - Semi-supervised learning
ER  - 

TY  - CONF
TI  - Improving Self-supervised Lightweight Model Learning via Hard-Aware Metric Distillation
AU  - Liu, Hao
AU  - Ye, Mang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The performance of self-supervised learning (SSL) models is hindered by the scale of the network. Existing SSL methods suffer a precipitous drop in lightweight models, which is important for many mobile devices. To address this problem, we propose a method to improve the lightweight network (as student) via distilling the metric knowledge in a larger SSL model (as teacher). We exploit the relation between teacher and student to mine the positive and negative supervision from the unlabeled data, which captures more accurate supervision signals. To adaptively handle the uncertainty in positive and negative sample pairs, we incorporate a dynamic weighting strategy to the metric relation between embeddings. Different from previous self-supervised distillers, our solution directly optimizes the network from a metric transfer perspective by utilizing the relationships between samples and networks, without additional SSL constraints. Our method significantly boosts the performance of lightweight networks and outperforms existing distillers with fewer training epochs on the large-scale ImageNet. Interestingly, the SSL performance even beats the teacher network in several settings.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_17
DP  - Springer Link
SP  - 295
EP  - 311
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_17.pdf
ER  - 

TY  - CONF
TI  - PSS: Progressive Sample Selection for Open-World Visual Representation Learning
AU  - Cao, Tianyue
AU  - Wang, Yongxin
AU  - Xing, Yifan
AU  - Xiao, Tianjun
AU  - He, Tong
AU  - Zhang, Zheng
AU  - Zhou, Hao
AU  - Tighe, Joseph
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We propose a practical open-world representation learning setting where the objective is to learn the representations for unseen categories without prior knowledge or access to images associated with these novel categories during training. Existing open-world representation learning methods make assumptions, which are often violated in practice and thus fail to generalize to the proposed setting. We propose a novel progressive approach which does not depend on such assumptions. At each iteration our approach selects unlabeled samples that attain a high homogeneity while belonging to classes that are distant to the current set of known classes in the feature space. Then we use the high-quality pseudo-labels generated via clustering over these selected samples to improve the feature generalization iteratively. Experiments demonstrate that the proposed method consistently outperforms state-of-the-art open-world semi-supervised learning methods and novel class discovery methods over nature species image retrieval and face verification benchmarks. Our training and inference code are released. (https://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander/PSS).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_16
DP  - Springer Link
SP  - 278
EP  - 294
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - PSS
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_16.pdf
KW  - Iterative methods
KW  - Open-world representation learning
KW  - Sample selection
KW  - Semi-supervised learning
ER  - 

TY  - CONF
TI  - Constrained Mean Shift Using Distant yet Related Neighbors for Representation Learning
AU  - Navaneet, K. L.
AU  - Abbasi Koohpayegani, Soroush
AU  - Tejankar, Ajinkya
AU  - Pourahmadi, Kossar
AU  - Subramanya, Akshayvarun
AU  - Pirsiavash, Hamed
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We are interested in representation learning in self-supervised, supervised, and semi-supervised settings. Some recent self-supervised learning methods like mean-shift (MSF) cluster images by pulling the embedding of a query image to be closer to its nearest neighbors (NNs). Since most NNs are close to the query by design, the averaging may not affect the embedding of the query much. On the other hand, far away NNs may not be semantically related to the query. We generalize the mean-shift idea by constraining the search space of NNs using another source of knowledge so that NNs are far from the query while still being semantically related. We show that our method (1) outperforms MSF in SSL setting when the constraint utilizes a different augmentation of an image from the previous epoch, and (2) outperforms PAWS in semi-supervised setting with less training resources when the constraint ensures that the NNs have the same pseudo-label as the query. Our code is available here: https://github.com/UCDvision/CMSF.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_2
DP  - Springer Link
SP  - 23
EP  - 41
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_2.pdf
ER  - 

TY  - CONF
TI  - Learn2Augment: Learning to Composite Videos for Data Augmentation in Action Recognition
AU  - Gowda, Shreyank N.
AU  - Rohrbach, Marcus
AU  - Keller, Frank
AU  - Sevilla-Lara, Laura
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We address the problem of data augmentation for video action recognition. Standard augmentation strategies in video are hand-designed and sample the space of possible augmented data points either at random, without knowing which augmented points will be better, or through heuristics. We propose to learn what makes a “good” video for action recognition and select only high-quality samples for augmentation. In particular, we choose video compositing of a foreground and a background video as the data augmentation process, which results in diverse and realistic new samples. We learn which pairs of videos to augment without having to actually composite them. This reduces the space of possible augmentations, which has two advantages: it saves computational cost and increases the accuracy of the final trained classifier, as the augmented pairs are of higher quality than average. We present experimental results on the entire spectrum of training settings: few-shot, semi-supervised and fully supervised. We observe consistent improvements across all of them over prior work and baselines on Kinetics, UCF101, HMDB51, and achieve a new state-of-the-art on settings with limited data. We see improvements of up to 8.6% in the semi-supervised setting. Project Page: https://sites.google.com/view/learn2augment/home.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_14
DP  - Springer Link
SP  - 242
EP  - 259
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - Learn2Augment
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_14.pdf
ER  - 

TY  - CONF
TI  - CYBORGS: Contrastively Bootstrapping Object Representations by Grounding in Segmentation
AU  - Wang, Renhao
AU  - Zhao, Hang
AU  - Gao, Yang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Many recent approaches in contrastive learning have worked to close the gap between pretraining on iconic images like ImageNet and pretraining on complex scenes like COCO. This gap exists largely because commonly used random crop augmentations obtain semantically inconsistent content in crowded scene images of diverse objects. In this work, we propose a framework which tackles this problem via joint learning of representations and segmentation. We leverage segmentation masks to train a model with a mask-dependent contrastive loss, and use the partially trained model to bootstrap better masks. By iterating between these two components, we ground the contrastive updates in segmentation information, and simultaneously improve segmentation throughout pretraining. Experiments show our representations transfer robustly to downstream tasks in classification, detection and segmentation. (Code and pretrained models available at https://github.com/renwang435/CYBORGS).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_15
DP  - Springer Link
SP  - 260
EP  - 277
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - CYBORGS
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_15.pdf
ER  - 

TY  - CONF
TI  - Domain Invariant Masked Autoencoders for Self-supervised Learning from Multi-domains
AU  - Yang, Haiyang
AU  - Tang, Shixiang
AU  - Chen, Meilin
AU  - Wang, Yizhou
AU  - Zhu, Feng
AU  - Bai, Lei
AU  - Zhao, Rui
AU  - Ouyang, Wanli
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Generalizing learned representations across significantly different visual domains is a fundamental yet crucial ability of the human visual system. While recent self-supervised learning methods have achieved good performances with evaluation set on the same domain as the training set, they will have an undesirable performance decrease when tested on a different domain. Therefore, the self-supervised learning from multiple domains task is proposed to learn domain-invariant features that are not only suitable for evaluation on the same domain as the training set, but also can be generalized to unseen domains. In this paper, we propose a Domain-invariant Masked AutoEncoder (DiMAE) for self-supervised learning from multi-domains, which designs a new pretext task, i.e., the cross-domain reconstruction task, to learn domain-invariant features. The core idea is to augment the input image with style noise from different domains and then reconstruct the image from the embedding of the augmented image, regularizing the encoder to learn domain-invariant features. To accomplish the idea, DiMAE contains two critical designs, 1) content-preserved style mix, which adds style information from other domains to input while persevering the content in a parameter-free manner, and 2) multiple domain-specific decoders, which recovers the corresponding domain style of input to the encoded domain-invariant features for reconstruction. Experiments on PACS and DomainNet illustrate that DiMAE achieves considerable gains compared with recent state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_9
DP  - Springer Link
SP  - 151
EP  - 168
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_9.pdf
ER  - 

TY  - CONF
TI  - Data Invariants to Understand Unsupervised Out-of-Distribution Detection
AU  - Doorenbos, Lars
AU  - Sznitman, Raphael
AU  - Márquez-Neila, Pablo
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised out-of-distribution (U-OOD) detection has recently attracted much attention due to its importance in mission-critical systems and broader applicability over its supervised counterpart. Despite this increased attention, U-OOD methods suffer from important shortcomings. By performing a large-scale evaluation on different benchmarks and image modalities, we show in this work that most popular state-of-the-art methods are unable to consistently outperform a simple anomaly detector based on pre-trained features and the Mahalanobis distance (MahaAD). A key reason for the inconsistencies of these methods is the lack of a formal description of U-OOD. Motivated by a simple thought experiment, we propose a characterization of U-OOD based on the invariants of the training dataset. We show how this characterization is unknowingly embodied in the top-scoring MahaAD method, thereby explaining its quality. Furthermore, our approach can be used to interpret predictions of U-OOD detectors and provides insights into good practices for evaluating future U-OOD methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_8
DP  - Springer Link
SP  - 133
EP  - 150
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_8.pdf
KW  - Out-of-distribution detection
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Completely Self-supervised Crowd Counting via Distribution Matching
AU  - Babu Sam, Deepak
AU  - Agarwalla, Abhinav
AU  - Joseph, Jimmy
AU  - Sindagi, Vishwanath A.
AU  - Babu, R. Venkatesh
AU  - Patel, Vishal M.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Dense crowd counting is a challenging task that demands millions of head annotations for training models. Though existing self-supervised approaches could learn good representations, they require some labeled data to map these features to the end task of density estimation. We mitigate this issue with the proposed paradigm of complete self-supervision, which does not need even a single labeled image. The only input required to train, apart from a large set of unlabeled crowd images, is the approximate upper limit of the crowd count for the given dataset. Our method dwells on the idea that natural crowds follow a power law distribution, which could be leveraged to yield error signals for backpropagation. A density regressor is first pretrained with self-supervision and then the distribution of predictions is matched to the prior. Experiments show that this results in effective learning of crowd features and delivers significant counting performance.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_11
DP  - Springer Link
SP  - 186
EP  - 204
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_11.pdf
KW  - Crowd counting
KW  - Self-supervision
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Self-Supervised Classification Network
AU  - Amrani, Elad
AU  - Karlinsky, Leonid
AU  - Bronstein, Alex
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present Self-Classifier – a novel self-supervised end-to-end classification learning approach. Self-Classifier learns labels and representations simultaneously in a single-stage end-to-end manner by optimizing for same-class prediction of two augmented views of the same sample. To guarantee non-degenerate solutions (i.e., solutions where all labels are assigned to the same class) we propose a mathematically motivated variant of the cross-entropy loss that has a uniform prior asserted on the predicted labels. In our theoretical analysis, we prove that degenerate solutions are not in the set of optimal solutions of our approach. Self-Classifier is simple to implement and scalable. Unlike other popular unsupervised classification and contrastive representation learning approaches, it does not require any form of pre-training, expectation-maximization, pseudo-labeling, external clustering, a second network, stop-gradient operation, or negative pairs. Despite its simplicity, our approach sets a new state of the art for unsupervised classification of ImageNet; and even achieves comparable to state-of-the-art results for unsupervised representation learning. Code is available at https://github.com/elad-amrani/self-classifier.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_7
DP  - Springer Link
SP  - 116
EP  - 132
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_7.pdf
KW  - Representation learning
KW  - Self-supervised classification
ER  - 

TY  - CONF
TI  - CA-SSL: Class-Agnostic Semi-Supervised Learning for Detection and Segmentation
AU  - Qi, Lu
AU  - Kuen, Jason
AU  - Lin, Zhe
AU  - Gu, Jiuxiang
AU  - Rao, Fengyun
AU  - Li, Dian
AU  - Guo, Weidong
AU  - Wen, Zhen
AU  - Yang, Ming-Hsuan
AU  - Jia, Jiaya
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - To improve instance-level detection/segmentation performance, existing self-supervised and semi-supervised methods extract either task-unrelated or task-specific training signals from unlabeled data. We show that these two approaches, at the two extreme ends of the task-specificity spectrum, are suboptimal for the task performance. Utilizing too little task-specific training signals causes underfitting to the ground-truth labels of downstream tasks, while the opposite causes overfitting to the ground-truth labels. To this end, we propose a novel Class-Agnostic Semi-Supervised Learning (CA-SSL) framework to achieve a more favorable task-specificity balance in extracting training signals from unlabeled data. CA-SSL has three training stages that act on either ground-truth labels (labeled data) or pseudo labels (unlabeled data). This decoupling strategy avoids the complicated scheme in traditional SSL methods that balances the contributions from both data types. Especially, we introduce a warmup training stage to achieve a more optimal balance in task specificity by ignoring class information in the pseudo labels, while preserving localization training signals. As a result, our warmup model can better avoid underfitting/overfitting when fine-tuned on the ground-truth labels in detection and segmentation tasks. Using 3.6M unlabeled data, we achieve a significant performance gain of $$4.7\%$$4.7%over ImageNet-pretrained baseline on FCOS object detection. In addition, our warmup model demonstrates excellent transferability to other detection and segmentation frameworks.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_4
DP  - Springer Link
SP  - 59
EP  - 77
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - CA-SSL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_4.pdf
KW  - Class-agnostic
KW  - Instance-level detection
KW  - Semi-supervised
ER  - 

TY  - CONF
TI  - Object Discovery via Contrastive Learning for Weakly Supervised Object Detection
AU  - Seo, Jinhwan
AU  - Bae, Wonho
AU  - Sutherland, Danica J.
AU  - Noh, Junhyug
AU  - Kim, Daijin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Weakly Supervised Object Detection (WSOD) is a task that detects objects in an image using a model trained only on image-level annotations. Current state-of-the-art models benefit from self-supervised instance-level supervision, but since weak supervision does not include count or location information, the most common “argmax” labeling method often ignores many instances of objects. To alleviate this issue, we propose a novel multiple instance labeling method called object discovery. We further introduce a new contrastive loss under weak supervision where no instance-level information is available for sampling, called weakly supervised contrastive loss (WSCL). WSCL aims to construct a credible similarity threshold for object discovery by leveraging consistent features for embedding vectors in the same class. As a result, we achieve new state-of-the-art results on MS-COCO 2014 and 2017 as well as PASCAL VOC 2012, and competitive results on PASCAL VOC 2007. The code is available at https://github.com/jinhseo/OD-WSCL.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_18
DP  - Springer Link
SP  - 312
EP  - 329
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_18.pdf
KW  - Weakly Supervised Object Detection (WSOD)
ER  - 

TY  - CONF
TI  - Stochastic Consensus: Enhancing Semi-Supervised Learning with Consistency of Stochastic Classifiers
AU  - Tang, Hui
AU  - Sun, Lin
AU  - Jia, Kui
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Semi-supervised learning (SSL) has achieved new progress recently with the emerging framework of self-training deep networks, where the criteria for selection of unlabeled samples with pseudo labels play a key role in the empirical success. In this work, we propose such a new criterion based on consistency among multiple, stochastic classifiers, termed Stochastic Consensus (STOCO). Specifically, we model parameters of the classifiers as a Gaussian distribution whose mean and standard deviation are jointly optimized during training. Due to the scarcity of labels in SSL, modeling classifiers as a distribution itself provides additional regularization that mitigates overfitting to the labeled samples. We technically generate pseudo labels using a simple but flexible framework of deep discriminative clustering, which benefits from the overall structure of data distribution. We also provide theoretical analysis of our criterion by connecting with the theory of learning from noisy data. Our proposed criterion can be readily applied to self-training based SSL frameworks. By choosing the representative FixMatch as the baseline, our method with multiple stochastic classifiers achieves the state of the art on popular SSL benchmarks, especially in label-scarce cases.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_19
DP  - Springer Link
SP  - 330
EP  - 346
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
ST  - Stochastic Consensus
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_19.pdf
KW  - Consistency criterion
KW  - Deep discriminative clustering
KW  - Semi-supervised learning
KW  - Stochastic classifiers
ER  - 

TY  - CONF
TI  - Dual Adaptive Transformations for Weakly Supervised Point Cloud Segmentation
AU  - Wu, Zhonghua
AU  - Wu, Yicheng
AU  - Lin, Guosheng
AU  - Cai, Jianfei
AU  - Qian, Chen
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Weakly supervised point cloud segmentation, i.e. semantically segmenting a point cloud with only a few labeled points in the whole 3D scene, is highly desirable due to the heavy burden of collecting abundant dense annotations for the model training. However, existing methods remain challenging to accurately segment 3D point clouds since limited annotated data may lead to insufficient guidance for label propagation to unlabeled data. Considering the smoothness-based methods have achieved promising progress, in this paper, we advocate applying the consistency constraint under various perturbations to effectively regularize unlabeled 3D points. Specifically, we propose a novel DAT (Dual Adaptive Transformations) model for weakly supervised point cloud segmentation, where the dual adaptive transformations are performed via an adversarial strategy at both point-level and region-level, aiming at enforcing the local and structural smoothness constraints on 3D point clouds. We evaluate our proposed DAT model with two popular backbones on the large-scale S3DIS and ScanNet-V2 datasets. Extensive experiments demonstrate that our model can effectively leverage the unlabeled 3D points and achieve significant performance gains on both datasets, setting new state-of-the-art performance for weakly supervised point cloud segmentation.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_5
DP  - Springer Link
SP  - 78
EP  - 96
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_5.pdf
KW  - Dual adaptive transformations
KW  - Point cloud segmentation
KW  - Weakly supervised segmentation
ER  - 

TY  - CONF
TI  - Coarse-To-Fine Incremental Few-Shot Learning
AU  - Xiang, Xiang
AU  - Tan, Yuwen
AU  - Wan, Qian
AU  - Ma, Jing
AU  - Yuille, Alan
AU  - Hager, Gregory D.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Different from fine-tuning models pre-trained on a large-scale dataset of preset classes, class-incremental learning (CIL) aims to recognize novel classes over time without forgetting pre-trained classes. However, a given model will be challenged by test images with finer-grained classes, e.g., a basenji is at most recognized as a dog. Such images form a new training set (i.e., support set) so that the incremental model is hoped to recognize a basenji (i.e., query) as a basenji next time. This paper formulates such a hybrid natural problem of coarse-to-fine few-shot (C2FS) recognition as a CIL problem named C2FSCIL, and proposes a simple, effective, and theoretically-sound strategy Knowe: to learn, freeze, and normalize a classifier’s weights from fine labels, once learning an embedding space contrastively from coarse labels. Besides, as CIL aims at a stability-plasticity balance, new overall performance metrics are proposed. In hat sense, on CIFAR-100, BREEDS, and tieredImageNet, Knowe outperforms all recent relevant CIL or FSCIL methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_12
DP  - Springer Link
SP  - 205
EP  - 222
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_12.pdf
KW  - Class-incremental learning
KW  - Coarse-to-fine
KW  - Few shots
ER  - 

TY  - CONF
TI  - Semantic-Aware Fine-Grained Correspondence
AU  - Hu, Yingdong
AU  - Wang, Renhao
AU  - Zhang, Kaifeng
AU  - Gao, Yang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Establishing visual correspondence across images is a challenging and essential task. Recently, an influx of self-supervised methods have been proposed to better learn representations for visual correspondence. However, we find that these methods often fail to leverage semantic information and over-rely on the matching of low-level features. In contrast, human vision is capable of distinguishing between distinct objects as a pretext to tracking. Inspired by this paradigm, we propose to learn semantic-aware fine-grained correspondence. Firstly, we demonstrate that semantic correspondence is implicitly available through a rich set of image-level self-supervised methods. We further design a pixel-level self-supervised learning objective which specifically targets fine-grained correspondence. For downstream tasks, we fuse these two kinds of complementary correspondence representations together, demonstrating that they boost performance synergistically. Our method surpasses previous state-of-the-art self-supervised methods using convolutional networks on a variety of visual correspondence tasks, including video object segmentation, human pose tracking, and human part tracking.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_6
DP  - Springer Link
SP  - 97
EP  - 115
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_6.pdf
KW  - Representation learning
KW  - Self-supervised learning
KW  - Tracking
KW  - Visual correspondence
ER  - 

TY  - CONF
TI  - Learning Unbiased Transferability for Domain Adaptation by Uncertainty Modeling
AU  - Hu, Jian
AU  - Zhong, Haowen
AU  - Yang, Fei
AU  - Gong, Shaogang
AU  - Wu, Guile
AU  - Yan, Junchi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Domain adaptation (DA) aims to transfer knowledge learned from a labeled source domain to an unlabeled or a less labeled but related target domain. Ideally, the source and target distributions should be aligned to each other equally to achieve unbiased knowledge transfer. However, due to the significant imbalance between the amount of annotated data in the source and target domains, usually only the target distribution is aligned to the source domain, leading to adapting unnecessary source specific knowledge to the target domain, i.e., biased domain adaptation. To resolve this problem, in this work, we delve into the transferability estimation problem in domain adaptation and propose a non-intrusive Unbiased Transferability Estimation Plug-in (UTEP) by modeling the uncertainty of a discriminator in adversarial-based DA methods to optimize unbiased transfer. We theoretically analyze the effectiveness of the proposed approach to unbiased transferability learning in DA. Furthermore, to alleviate the impact of imbalanced annotated data, we utilize the estimated uncertainty for pseudo label selection of unlabeled samples in the target domain, which helps achieve better marginal and conditional distribution alignments between domains. Extensive experimental results on a high variety of DA benchmark datasets show that the proposed approach can be readily incorporated into various adversarial-based DA methods, achieving state-of-the-art performance.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19821-2_13
DP  - Springer Link
SP  - 223
EP  - 241
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19821-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19821-2_13.pdf
KW  - Domain adaptation
KW  - Pseudo labeling
KW  - Unbiased transferability estimation
ER  - 

TY  - CONF
TI  - HQ-Trans: A High-Quality Screening Based Image Translation Framework for Unsupervised Cross-Domain Pedestrian Detection
AU  - Shen, Gelin
AU  - Tang, Zhi-Ri
AU  - Shen, Peng
AU  - Yu, Yang
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Pedestrian detection plays an important role in the research of computer vision, which has been used in many areas. Pedestrian detection is mainly to classify and locate pedestrians in a given input image, whose performance greatly depends on the number of annotations. When faced with unlabeled scenes in the target domain, the performance of a detector is severely degraded. Based on the above, an unsupervised image translation framework is adopted to generate an intermediate domain between the source and the target domains, which can effectively improve the cross-domain pedestrian detection performance. However, due to the instability of the translation network, some unsatisfactory images might be generated in the newly generated intermediate domain. Therefore, we propose a new method to process these unsatisfactory images. First, a blind image quality assessment framework is adopted on the original dataset, which aims to select relatively high-quality images as the training set for the translation framework and remove relatively low-quality images. Second, the image quality assessment framework is also adopted on the newly generated domain, which retain relatively high-quality generated images and replace the low-quality images with the corresponding images in the source domain. Finally, a new mixed domain, which is obtained from the above process, is applied to cross-domain pedestrian detection. The experimental results show that the proposed method can help to achieve good performance. Compared with some latest works, the proposed method can also achieve state-of-the-art performance under miss rate metrics.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_2
DP  - Springer Link
SP  - 16
EP  - 27
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
ST  - HQ-Trans
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_2.pdf
KW  - Image quality assessment
KW  - Image translation
KW  - Intermediate domain
KW  - Unsupervised pedestrian detection
ER  - 

TY  - CONF
TI  - FER-YOLO: Detection and Classification Based on Facial Expressions
AU  - Ma, Hui
AU  - Celik, Turgay
AU  - Li, Hengchao
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Due to the wide application prospect and market value of emotion recognition, it has become an important research topic in today’s society. Among them, facial expression recognition (FER) plays an important role in expressing human emotional information. Generally, the FER classification process includes face pre-processing (face detection, alignment, etc.), which adds extra workload. To this end, detection and classification are carried out simultaneously in this paper. We first manually annotated the RAF-DB dataset. We then designed an end-to-end FER network with better performance and applied it to facial expressions called FER-YOLO. FER-YOLO is built on the basis of YOLOv3. We combine the squeeze-and-excitation (SE) module with the backbone network and assign a certain weight to each feature channel so that FER-YOLO can focus on learning prominent facial features. We also discussed the performance changes caused by the lightweight enhanced feature extraction networks. Experimental results show that the proposed FER-YOLO network is 3.03% mAP higher than YOLOv3 on the RAF-DB dataset.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_3
DP  - Springer Link
SP  - 28
EP  - 39
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
ST  - FER-YOLO
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_3.pdf
KW  - Convolutional Neural Network (CNN)
KW  - Detection
KW  - Emotion recognition
KW  - Facial Expression Recognition (FER)
ER  - 

TY  - CONF
TI  - L2-CVAEGAN: Feature Aligned Generative Networks for Zero-Shot Learning
AU  - Liu, Jinhui
AU  - Zhao, Peng
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Many generative methods in zero-shot learning (ZSL) and generalized zero-shot learning (GZSL) perform data augmentation by random distribution. This naive strategy ignores the visual divergences of different classes, which will result in excessive differences between generated and real samples. In this work, random vectors sample from the real visual distribution encoded by the encoder. Therefore, the generated samples are more close to real-world samples. Additionally, the instances generated by GAN and VAE are not in the uniform numerical range, which causes the inconsistency of domain distributions. We perform domain alignment on visual features through L2 normalization. This strategy narrows variance between real and generated visual features. For fine-grained datasets, we set attribute, Word2Vec and Glove as the class-embedding vector of generative models. This natural way of semantic combination adds more potential information to each class. We name the proposed approach as L2-CVAEGAN, and conduct extensive experiments on several benchmark datasets. Compared with existing methods, these simple strategies lead to significant promotions. The comprehensive experiments of ZSL and GZSL prove the effectiveness of L2-CVAEGAN.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
ST  - L2-CVAEGAN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_1.pdf
KW  - Domain alignment
KW  - Generative adversarial networks
KW  - Zero-shot learning
ER  - 

TY  - CONF
TI  - Six-Channel Image Representation for Cross-Domain Object Detection
AU  - Zhang, Tianxiao
AU  - Ma, Wenchi
AU  - Wang, Guanghui
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Most deep learning models are data-driven and the excellent performance is highly dependent on the abundant and diverse datasets. However, it is very hard to obtain and label the datasets of some specific scenes or applications. If we train the detector using the data from one domain, it cannot perform well on the data from another domain due to domain shift, which is one of the big challenges of most object detection models. To address this issue, some image-to-image translation techniques have been employed to generate some fake data of some specific scenes to train the models. With the advent of Generative Adversarial Networks (GANs), we could realize unsupervised image-to-image translation in both directions from a source to a target domain and from the target to the source domain. In this study, we report a new approach to making use of the generated images. We propose to concatenate the original 3-channel images and their corresponding GAN-generated fake images to form 6-channel representations of the dataset, hoping to address the domain shift problem while exploiting the success of available detection models. The idea of augmented data representation may inspire further study on object detection and other applications.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_15
DP  - Springer Link
SP  - 171
EP  - 184
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_15.pdf
KW  - Domain shift
KW  - Object detection
KW  - Unsupervised image-to-image translation
ER  - 

TY  - CONF
TI  - Relation-Aware Reasoning with Graph Convolutional Network
AU  - Zhou, Lei
AU  - Liu, Yang
AU  - Bai, Xiao
AU  - Wang, Xiang
AU  - Wang, Chen
AU  - Zhang, Liang
AU  - Gu, Lin
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Semantic dependencies among objects are crucial for the recognition system to enhance performance. However, utilizing object-object relationships is a non-trivial task as objects are of various scales and locations, leading to irregular relationships. In this paper, we present a novel visual reasoning framework that incorporates both semantic and spatial relationships to improve the recognition system. We at first construct a knowledge graph to represent the co-occurrence frequency and relative position among categories. Based on this knowledge graph, we are able to enhance the original regional features by a Graph Convolutional Network (GCN) that encodes the high-level semantic contexts. Experiments show that our framework manages to outperform the baselines and state-of-the-art on different backbones in terms of both per-instance and per-class classification accuracy.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_5
DP  - Springer Link
SP  - 52
EP  - 64
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_5.pdf
KW  - Graph Convolutional Network
KW  - Knowledge graph
KW  - Object-object relationship
KW  - Visual reasoning
ER  - 

TY  - CONF
TI  - MSC-Fuse: An Unsupervised Multi-scale Convolutional Fusion Framework for Infrared and Visible Image
AU  - Chen, Guo-Yang
AU  - Wu, Xiao-Jun
AU  - Li, Hui
AU  - Xu, Tian-Yang
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Lacking the labeled data, how to establish an unsupervised learning method is essential for the infrared and visible image fusion task. As such, this article introduces a novel unsupervised learning fusion framework. Our proposed framework consists of three components: encoder, fusion layer, and decoder, respectively. Firstly, an encoder is designed to extract salient features from multiple source images. With the multi-scale convolution modules, the encoder can produce more useful features. Then these features are fused at the fusion layer. Finally, the decoder reconstructs the fused features to generate the fused image. To achieve the unsupervised training of the network, a no-reference quality metric and a pixel-level function are utilized to calculate the loss function. Experimental results show that compared with other fusion methods, our proposed method can achieve better performance in both objective and subjective assessments.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_4
DP  - Springer Link
SP  - 40
EP  - 51
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
ST  - MSC-Fuse
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_4.pdf
KW  - Image fusion
KW  - Infrared image
KW  - Multi-scale convolution
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Global Feature Polishing Network for Glass-Like Object Detection
AU  - Zhu, Minyu
AU  - Xu, Xiuqi
AU  - Yu, Jinhao
AU  - Chen, Shuhan
AU  - Wang, Jian
AU  - Hu, Xuelong
AU  - Zhu, Jinrong
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Glass object detection aims to detect and segment glass-like objects in an input image. Compared with other binary segmentation tasks, the transparent property of glass brings great challenges to glass object detection. This requires the model to capture more richer image global semantics and local detail information. In this work, we propose a novel global feature polishing network for glass object detection. We first design a global perception module for coarse localization by embedding a self-attention block on top of the backbone. Then we propose a global feature polishing module to establish long-distance semantic dependence between different pixels and a multi-scale refinement module to combine multi-level side-output features, which can well explore the missing object parts and also refine the false detection in previous layers. In addition, we build a challenging Window dataset for comprehensive evaluation and further research. Experimental results demonstrate that the proposed method performs favorably against state-of-the-art methods without any pre-processing and post-processing.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_7
DP  - Springer Link
SP  - 77
EP  - 88
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_7.pdf
KW  - Glass object detection
KW  - Global feature polishing
KW  - Multi-scale refinement
ER  - 

TY  - CONF
TI  - Moving Object Detection Based on Self-adaptive Contour Extraction
AU  - Shi, Xin
AU  - Xue, Tao
AU  - Zhao, Xueqing
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Object detection of moving targets requires both accuracy and real-time performance. In this paper, we propose a contour extraction prior to convolutional neural network to extract more salient features and use region proposal network to generate candidate regions. Afterwards, the feature maps and proposal regions are inputed to ROI pooling layer followed with some fully connected layers to classify objects and regress bounding box. Simulation experiments show that our method is effective in improving detection accuracy by testing on the dataset with 11 categories of moving targets.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_11
DP  - Springer Link
SP  - 126
EP  - 135
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_11.pdf
KW  - Contour extraction
KW  - Moving object detection
KW  - Region proposal network
ER  - 

TY  - CONF
TI  - Accurate Oriented Instance Segmentation in Aerial Images
AU  - Zhang, ZhenRong
AU  - Du, Jun
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - The dominant instance segmentation methods first detect the object with an axis-aligned box, then predict the foreground mask on each proposal. While in aerial images, methods detecting objects with axis-aligned boxes are unsuitable, since the orientation of objects is arbitrary. What’s more, the RoI pooling step existed in these systems results in the loss of spatial details due to the feature warping and resizing, which will degrade the segmentation quality, especially for large elongated objects. In this paper, we propose a novel accurate oriented instance segmentation method, named Rotated Blend Mask R-CNN. We perform mask prediction in oriented bounding boxes and predict the final mask by combining instance-level information with lower-level fine-granularity information. The proposed method is evaluated on the iSAID dataset, and competitive outcomes show that our model achieves state-of-the-art. Code will be made available at https://github.com/ZZR8066/RotatedBlendMaskRCNN
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_14
DP  - Springer Link
SP  - 160
EP  - 170
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_14.pdf
KW  - Aerial images
KW  - Oriented instance segmentation
ER  - 

TY  - CONF
TI  - Open-Set Product Authentication Based on Deep Texture Verification
AU  - Cai, Sudao
AU  - Zhao, Lin
AU  - Chen, Changsheng
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - The authenticity of consumer products has a significant impact on the economic and social issues of countries around the world. Due to the recent advancements in machine learning, there emerges some authentication techniques, in a close-set setting, based on texture features extracted from the product surfaces. However, the existing techniques have suffered from the problem of low accuracies or inability to deal with unknown classes in open-set authentication. In this work, we build an anti-counterfeiting system that works for consumer products in an open-set scenario. Different from other anti-counterfeiting methods, this work considers the problem of product authentication as a simple texture verification process. It allows the authentication being conducted under both close-set and open-set scenarios by a distance comparison operation with some customized metrics in the embedding space. We evaluate our system with two state-of-the-art texture databases. Experimental results show that the proposed system achieves 89.91% open-set authentication accuracy for a feature of 256 dimensions in the Outex texture database.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_10
DP  - Springer Link
SP  - 114
EP  - 125
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_10.pdf
KW  - Authentication
KW  - Deep metric learning
KW  - Texture
ER  - 

TY  - CONF
TI  - Skeleton-Aware Network for Aircraft Landmark Detection
AU  - Ye, Yuntong
AU  - Chang, Yi
AU  - Li, Yi
AU  - Yan, Luxin
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - The landmark detection has been widely investigated for the human pose with rapid progress in recent years. In this work, we aim at dealing with a new problem: aircraft landmark detection in the wild. We have a key observation: the aircraft is a rigid object with global structural relationships between local landmarks. This motivates us to progressively learn the global geometrical structure and local landmark localization in a coarse-to-fine guidance manner. In this paper, we propose a simple yet effective skeleton-aware landmark detection (SALD) network, including one stream for exploiting the coarse global skeleton structure and one stream for the precise local landmarks localization. The global skeleton structure models the aircraft “images” into skeleton “lines”, in which the multiple skeletons of the holistic aircraft and the parts are explicitly extracted to serve as the geometrical structure constraints for landmarks. Then, the local landmark localization precisely detects the key “points” with the guidance of skeleton “lines”. Consequently, the progressive strategy of “extracting lines from images, detecting points with lines” significantly eases the landmark detection task by decomposing the task into the simpler coarse-to-fine sub-tasks, thus further improving the detection performance. Extensive experimental results show the superiority of proposed method compared to state-of-the-arts.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_16
DP  - Springer Link
SP  - 185
EP  - 197
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_16.pdf
KW  - Aircraft
KW  - Convolutional neural network
KW  - Landmark detection
KW  - Skeleton
ER  - 

TY  - CONF
TI  - Fine-Grained Classification of Neutrophils with Hybrid Loss
AU  - Zhu, Qingtao
AU  - Lu, Danwei
AU  - Zhang, Tao
AU  - Yin, Junjun
AU  - Yang, Jian
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Acute leukemia is a malignant clonal disease of hematopoietic stem cells, which is usually diagnosed by morphological examination of bone marrow cells. However, the morphological examination usually relies on the subjective inference of cell morphology experts and is labor-intensive. With the development of computer vision, automatic classification and counting of blood cells is increasingly popular, which greatly improves work efficiency. Within this context, we here propose a novel method for neutrophil classification, which is based on deep neural network. In brief, it first crops the single cells from the large images, and then makes use of the loss functions designed for face recognition and weakly-supervised fine-grained visual classification. With the hybrid loss, the trained network can focus on nucleus areas, extract features with inter-class differences and intra-class compactness. Experiments show that the proposed method can obtain higher overall accuracy. Data is available at https://github.com/stevenxmy/subAML-dataset.git.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_9
DP  - Springer Link
SP  - 102
EP  - 113
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_9.pdf
KW  - Acute leukemia
KW  - Fine-grained classification
KW  - Neural network
ER  - 

TY  - CONF
TI  - Semi-supervised Cloud Edge Collaborative Power Transmission Line Insulator Anomaly Detection Framework
AU  - Yang, Yanqing
AU  - Mao, Jianxu
AU  - Zhang, Hui
AU  - Chen, Yurong
AU  - Zhong, Hang
AU  - Huang, Zhihong
AU  - Wang, Yaonan
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - The widely deployed power transmission line expedites developing the age of electricity. Thus, it is necessary to maintain a power system with a great quantity of manpower and material resources, especially for crucial equipment, such as insulator string. However, the current main inspection method relies on artificial with the problem of time-consuming and labor-intensive. There is a trend of utilizing deep learning techniques on unmanned aerial vehicles (UAVs) to accomplish the inspection task, but its development is restricted by the limitation of energy. In this paper, we propose a semi-supervised cloud edge collaborative insulator string anomaly detection framework. Specifically, an anchor-free object detector is deployed on the edge device for locating the insulator. On the cloud side, we propose a generative insulator defect detection model based on the autoencoder (AE) with a generator-discriminator pattern. Particularly, we introduce the variational memory encoder-decoder architecture to model defect-free insulator data distribution. Furthermore, the adversarial strategy is employed to regularize the generated data space with input data space. In the end, the anomaly can be detected if its data space is an outlier of training defect-free distribution. Comprehensive experiments demonstrate that our method can effectively reduce the computational load, meanwhile archiving superior performance, including accuracy (0.968) and recall (0.985), for defect recognition using a standard insulator data set.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_18
DP  - Springer Link
SP  - 210
EP  - 221
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_18.pdf
KW  - Autoencoder
KW  - Defect recognition
KW  - Insulator detection
ER  - 

TY  - CONF
TI  - Boundary Information Aggregation and Adaptive Keypoint Combination Enhanced Object Detection
AU  - Zhao, Ping
AU  - Yao, Dongsheng
AU  - Sun, Lijun
AU  - Fan, Jiaqi
AU  - Chen, Panyue
AU  - Wei, Zhihua
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Keypoint-based methods achieve increasing attention and competitive performance in the field of object detection. In this paper, we propose a new keypoint-based object detection method in order to better locate center keypoints of objects and adaptively combine keypoints to obtain more accurate bounding boxes. Specifically, to better locate center keypoints of objects, we aggregate boundary information by adding the center pooling operation to the original center keypoints prediction branch. The boundary information is the location of object boundary which is more easier to predict than object center. Furthermore, to obtain more accurate bounding boxes, we propose an adaptive keypoint combination algorithm to map all keypoints back to the original image so that the keypoints are combined with less localization errors. Experiments have demonstrated the effectiveness of the our proposed methods.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_13
DP  - Springer Link
SP  - 148
EP  - 159
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_13.pdf
KW  - Keypoint prediction
KW  - Object detection
ER  - 

TY  - CONF
TI  - Small Infrared Aerial Target Detection Using Spatial and Temporal Cues
AU  - Guo, Liangchao
AU  - Zhang, Wenlong
AU  - Sun, Xiaoliang
AU  - Wang, Zi
AU  - Shang, Yang
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Due to rapidly relative motion between target and infrared imaging platform, clutter background, etc., robust small infrared aerial target detection is still an open problem. A novel small infrared aerial target detection method using spatial and temporal cues is proposed in this paper. First, using spatial cues, we take target candidate detection as a binary classification problem. Target candidates in each single frame are detected via interesting pixel detection and a trained LightGBM model. Then, using temporal cues, we model the local smoothness and global continuous characteristic of the target trajectory as short-strict and long-loose constraints. The trajectory constraints within image sequence are used in detecting the true small infrared aerial targets from numerical target candidates. Experiment results on the public dataset SIATD show that the proposed method performs better than other existing methods in detecting small infrared aerial target and shows great robustness toward clutter backgrounds.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_12
DP  - Springer Link
SP  - 136
EP  - 147
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_12.pdf
KW  - Aerial
KW  - LightGBM
KW  - Small infrared target detection
KW  - Spatial and temporal cues
KW  - Trajectory constraint
ER  - 

TY  - CONF
TI  - Efficient Spectral Pyramid and Spectral-Spatial Feature Interactive Hyperspectral Image Classification
AU  - Wu, Jun
AU  - Wang, Huimin
AU  - Zhu, Xingliang
AU  - Wang, Meng
AU  - Yang, Jian
AU  - Luo, Wenting
AU  - Qu, Lei
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Deep-learning frameworks have been widely used in the hyperspectral image (HSI) classification and have demonstrated promising performance. In this paper, we propose a novel HSI classification method with a deeper network and fewer parameters. Two novel modules named the efficient spectral pyramid (ESP), and improved spectral-spatial feature interactive (SSI) are designed to improving the SS3FCN, which is proposed in our previous work. Specifically, the ESP module composed of the dilated convolution is utilised to increase the spectral receptive field and make up the lost spectral information. In addition, the improved SSI module is leveraged to reduce trainable parameters and strengthen spectral features. Finally, the advancement of the proposed method is experimentally proved on three representative HSI data sets, and the effectiveness of these two novel modules are verified with ablation experiments.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_17
DP  - Springer Link
SP  - 198
EP  - 209
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_17.pdf
KW  - Dilated convolution
KW  - Hyperspectral image classification
KW  - Residual connection
KW  - Spectral-spatial exploration
ER  - 

TY  - CONF
TI  - Feature Separation GAN for Cross View Gait Recognition
AU  - Huang, Chongdong
AU  - Song, Yonghong
AU  - Zhang, Yuanlin
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Gait information can be collected by a long-distance camera. But the relative angle between the subject and the camera changes, resulting in a cross-view gait recognition problem. This paper proposes a view transformation model method based on feature separation generate adversarial networks. Based on the GAN model, this method separates the features of the input data as an additional discriminant basis. On the premise of building a single model, it can convert image to any angle as needed. In order to make the images generated by GAN more realistic, the proposed method separates view and dress information from the identity data and encodes them. The discriminator is also optimized by adding the conditional codes as an additional basis, so that the generator can generate the corresponding image more realistically based on the encoded information image. In addition, the proposed method also adds a constraint to increase the inter-class variation of subjects and reduce their intra-class distance. Thus, the synthesized image retains more feature information of original subject. The proposed method achieves a great generating effect and improves the performance of cross-view gait recognition.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_6
DP  - Springer Link
SP  - 65
EP  - 76
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_6.pdf
KW  - Feature separation
KW  - Gait recognition
KW  - Generative adversarial network
KW  - View transform
ER  - 

TY  - CONF
TI  - Imitating What You Need: An Adaptive Framework for Detector Distillation
AU  - Sun, Ruoyu
AU  - Xiong, Hongkai
A2  - Peng, Yuxin
A2  - Hu, Shi-Min
A2  - Gabbouj, Moncef
A2  - Zhou, Kun
A2  - Elad, Michael
A2  - Xu, Kun
T3  - Lecture Notes in Computer Science
AB  - Object detection models with favorable performances usually suffer from high computational costs. Knowledge distillation, a simple model compression method, aims at training a light-weight student network by transferring knowledge from a cumbersome teacher model. In this paper, we investigate different components of typical two-stage and single-stage detector in details, and propose a detector distillation framework that adaptively transfers knowledge from teacher to student according to task specific priors. The knowledge is transferred adaptively at three levels, i.e., feature backbone, classification head, and bounding box regression head, according to which model performs more reasonably. Furthermore, considering that it would introduce optimization dilemma when minimizing distillation loss and detection loss simultaneously, we propose a distillation decay strategy to help improve model generalization via gradually reducing the distillation penalty. Experiments on widely used detection benchmarks demonstrate the effectiveness of our method. Particularly, taking Faster R-CNN as an example, we achieve an accuracy of $$39.4\%$$39.4%with Resnet-50 on MS COCO 2017 dataset, which surpasses its baseline $$37.5\%$$37.5%by $$1.9\%$$1.9%points, and even better than the teacher model with $$39.3\%$$39.3%mAP.
C1  - Cham
C3  - Image and Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-87355-4_8
DP  - Springer Link
SP  - 89
EP  - 101
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-87355-4
ST  - Imitating What You Need
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-87355-4_8.pdf
KW  - Adaptive regularization
KW  - Gaussian masking
KW  - Knowledge distillation
KW  - Object detection
ER  - 

TY  - CONF
TI  - Student Classroom Behavior Detection Based on YOLOv7+BRA and Multi-model Fusion
AU  - Yang, Fan
AU  - Wang, Tao
AU  - Wang, Xiaofei
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Accurately detecting student behavior in classroom videos can aid in analyzing their classroom performance and improving teaching effectiveness. However, the current accuracy rate in behavior detection is low. To address this challenge, we propose the Student Classroom Behavior Detection system based on YOLOv7+BRA (YOLOv7 with Bi-level Routing Attention). We identified eight different behavior patterns, including standing, sitting, talking, listening, walking, raising hands, reading, and writing. We constructed a dataset, which contained 11,248 labels and 4,001 images, with an emphasis on the common behavior of raising hands in a classroom setting (Student Classroom Behavior dataset, SCB-Dataset). To improve detection accuracy, we added the biformer attention module to the YOLOv7 network. Finally, we fused the results from YOLOv7 CrowdHuman, SlowFast, and DeepSort models to obtain student classroom behavior data. We conducted experiments on the SCB-Dataset, and YOLOv7+BRA achieved an mAP@0.5 of 87.1%, resulting in a 2.2% improvement over previous results. Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-dataset.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_4
DP  - Springer Link
SP  - 41
EP  - 52
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_4.pdf
KW  - Bi-level Routing Attention
KW  - SCB-dataset
KW  - Student Classroom Behavior
KW  - YOLOv7+BRA
ER  - 

TY  - CONF
TI  - End-to-End Multilingual Text Recognition Based on Byte Modeling
AU  - Wu, Jiajia
AU  - Zhao, Kun
AU  - Yang, Zhengyan
AU  - Yin, Bing
AU  - Liu, Cong
AU  - Dai, Lirong
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Nowadays, multilingual text recognition is more and more widely used in computer vision. However, in practical applications, the independent modeling of each language cannot make full use of the information between different languages and consumes hardware resources very much, which makes the unified modeling of multiple languages very necessary. A natural approach to unified multilingual modeling is to combine modeling units (characters, subwords, or words) from all languages into a large vocabulary, and then use a sequence-to-sequence approach to modeling. However, this vocabulary is often very large making modeling difficult. In this paper, we propose a byte-based multilingual text recognition method, which makes the vocabulary size only 256, which effectively solves the problem of unified modeling. The experiments show that our method effectively utilizes the information between different languages and outperforms the baseline of independent modeling by a large margin.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_11
DP  - Springer Link
SP  - 128
EP  - 137
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_11.pdf
KW  - byte modeling
KW  - end-to-end text recognition
KW  - multilingual
KW  - unified modeling
ER  - 

TY  - CONF
TI  - Dense Small Object Detection Based on Improved Deep Separable Convolution YOLOv5
AU  - Ben, Yiwei
AU  - Li, Xiaofei
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Aiming at the limited detection ability of YOLOv5 target detector when dealing with dense small targets, an improved YOLOv5 target detection method YOLOV5-G based on improved depth-wise separable convolution was proposed. The YOLOV5-G adds a prediction head based on the original YOLOv5 to improve the detection performance of small objects; The original loss function is changed to α-CIoU to obtain more accurate boundary box regression. The standard convolution module in the neck of the model is replaced by a hybrid convolution composed of standard convolution and depth-wise separable convolution. Compared with the original model using all the standard convolution modules, the calculation amount is reduced and the detection performance of the model is improved. Attention mechanism and lightweight module supplement each other, enables the attention mechanism to work better. Simulation experiments were conducted on CrowdHuman dataset, and the experimental results showed that YOLOv5-G increased by 3.1% compared with the original YOLOv5.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_9
DP  - Springer Link
SP  - 103
EP  - 115
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_9.pdf
KW  - attention mechanism
KW  - depth-wise separable convolution
KW  - intensive small target detection
KW  - loss function
KW  - YOLOv5
ER  - 

TY  - CONF
TI  - A Multimodal Text Block Segmentation Framework for Photo Translation
AU  - Wu, Jiajia
AU  - Li, Anni
AU  - Zhao, Kun
AU  - Yang, Zhengyan
AU  - Yin, Bing
AU  - Liu, Cong
AU  - Dai, Lirong
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Nowadays, with the vigorous development of OCR (Optical Character Recognition) and machine translation, photo translation technology brings great convenience to people’s life and study. However, when translating the content of an image line by line, the lack of contextual information in adjacent semantic-related text lines will seriously influence the actual effect of translation, making it difficult for people to understand. To tackle the above problem, we propose a novel multimodal text block segmentation encoder-decoder model. Specifically, we construct a convolutional encoder to extract the multimodal representation which combines visual, semantic, and positional features together for each text line. In the decoder stage, the LSTM (Long Short Term Memory) module is employed to output the predicted segmentation sequence inspired by the pointer network. Experimental results illustrate that our model outperforms the other baselines by a large margin.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_10
DP  - Springer Link
SP  - 116
EP  - 127
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_10.pdf
KW  - Multimodal fusion
KW  - Pointer network
KW  - Text block segmentation
ER  - 

TY  - CONF
TI  - Inscription-Image Inpainting with Edge Structure Reconstruction
AU  - Liu, Haonan
AU  - He, Xuelei
AU  - Zhu, Jiaxin
AU  - He, Xiaowei
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Textual relics are particularly crucial for understanding history because they provide written records of past societies and their development. However, inscriptions and calligraphy works are susceptible to varying degrees of pollution or damage, which can cause the characters to be blurry, unclear, or even partially missing, thereby affects the recorded information. Compared with natural images, handwritten ancient inscription images have higher similarity, obvious structural features, clear edges, and explicit semantics. Image restoration techniques have made significant progress, but in textual images areas, they often lack an understanding of the overall structure of the characters and the standardization of stroke details, which can result in unsatisfactory restoration results. An inscription-image inpainting method has been proposed for the automated restoration of damaged inscriptions based on edge detection module and generative adversarial networks, taking into account the characteristics of ancient Chinese inscriptions. The edge detection module used to collect the edge information of the characters’ strokes and lead the network to learn the structure and semantics of the characters. Moreover, a perceptual loss is adopted to enhance the detailed information of features which help to restore characters’ details. A dataset of ancient inscriptions was created from publication, and experiments on this dataset showed that our method has better restoration quality than common natural image restoration methods.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_2
DP  - Springer Link
SP  - 16
EP  - 27
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_2.pdf
KW  - Digitization of ancient inscription
KW  - Edge detection
KW  - Image inpainting
KW  - Text restoration
ER  - 

TY  - CONF
TI  - Structure-Aware Point Cloud Completion
AU  - Cheng, Zhihua
AU  - Chen, Xuejin
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Structure plays a crucial role in point cloud completion. While many efforts have been made to recover geometric details of the target shape, it is non-trivial to recover global structures, especially when large areas are missing in the input partial point cloud. In this paper, we propose a novel point cloud completion approach named SAPCNet to reconstruct complete 3D shapes in a global structure-aware manner. To establish long-range dependencies within the global scope and efficiently capture the object structure, we propose a structure-aware enhancement module by introducing global attention to the seed point generation process. To explicitly enforce the category-specific structure recovery, we design a classification-supervised training strategy to enable the network to generate structures more consistent with object category properties. Moreover, we design a category-guided adaptive seed selection module to generate seed points in the first stage. A redundant structure elimination loss is also introduced to reduce the ill-posed generation of heavily missing regions in the incomplete point cloud. Qualitative and quantitative evaluations on the PCN dataset demonstrate that our method outperforms state-of-the-art completion approaches.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_15
DP  - Springer Link
SP  - 174
EP  - 185
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_15.pdf
KW  - Classification-supervised
KW  - Point cloud completion
KW  - Structure-aware
ER  - 

TY  - CONF
TI  - Disentangled Shape and Pose Based on Attention and Mesh Autoencoder
AU  - Wu, Tao
AU  - Song, Xiaoning
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Deep 3D morphable models are widely applied in computer vision and graphics applications, including 3D reconstruction, pose estimation, and 3D pose transfer. The ability to decompose 3D data into shape and pose is essential in these applications. However, accurate and robust disentanglement of shape and pose remains a challenging task, as meshes with pose or shape labels are lacking. To alleviate this issue, we introduce A-MeshNet, an innovative approach that employs AFA module and Mesh Auto-encoder for unsupervised disentanglement of human mesh and high-precision human mesh reconstruction. Our approach builds a new mesh auto-encoder based on the AFA module for effective feature aggregation. We demonstrate that our proposed A-MeshNet achieves superior performance than state-of-the-art approaches on various benchmarking datasets.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_12
DP  - Springer Link
SP  - 138
EP  - 149
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_12.pdf
KW  - 3D Pose Transfer
KW  - Attention Mechanism
KW  - Mesh Auto-encoder
KW  - Unsupervised Learning
ER  - 

TY  - CONF
TI  - MGP-Net: Margin-Global Information Optimization-Prototype Network for Few-Shot Ancient Inscriptions Classification
AU  - Zhu, Jiaxin
AU  - He, Xuelei
AU  - Liu, Haonan
AU  - He, Xiaowei
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - This article focuses on the challenge of classifying bronze inscription rubbings, which have a limited number of samples and diverse characteristics. Traditional classification methods have failed to produce satisfactory results. With the emergence of meta-learning, few-shot image classification has become a popular research topic. This approach allows a classifier to recognize datasets outside the training set and complete classification with only a small number of samples. However, due to the existence of multiple categories in the ancient inscription dataset and the tendency for overfitting, existing prototype network structures have not achieved satisfactory prediction accuracy on ancient inscription datasets. To address this challenge, we propose two strategies. The first strategy is the Margin Prototype (MP), which expands the distribution of different class prototypes during the softmax operation. The second strategy is the global information optimization strategy (GioP), which reverses the prediction of support set samples to obtain more representative prototypes. Our proposed method achieves better accuracy without adding new parameters to the model. The end-to-end structural pattern remains unchanged.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_14
DP  - Springer Link
SP  - 162
EP  - 173
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
ST  - MGP-Net
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_14.pdf
KW  - ancient inscriptions
KW  - few-shot-learning
KW  - MGP-Net
KW  - prototype network
ER  - 

TY  - CONF
TI  - RatiO R-CNN: An Efficient and Accurate Detection Method for Oriented Object Detection
AU  - Pu, Chengdao
AU  - Ju, Liuxue
AU  - Gao, Fang
AU  - Yu, Jun
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - In recent years, oriented object detection has attracted much attention as an emerging branch of computer vision. Compared with objects in natural images, the oriented objects are distributed in any direction, and their ground truth bounding boxes have an extensive range of aspect ratios. In this paper, we propose a two-stage oriented object detection framework called RatiO R-CNN, which has good accuracy and efficiency on oriented object detection datasets. Specifically, we used a new anchor box generation method, RotateGA, to adapt to the characteristics of oriented detection datasets. We design a length ratio loss function to solve the deformation problem of the predicted boxes obtained by regression so that we can generate oriented proposals efficiently and accurately in the RPN phase. In the second stage, we propose a dynamic-oriented R-CNN head, which adjusts the IoU threshold and regression loss during the training process by adapting to the quality of the samples. Our model achieved the best results on the DOTA v1.0 dataset (77.82%mAP50, 49.44%mAP75), proving the validity of our model.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_3
DP  - Springer Link
SP  - 28
EP  - 40
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
ST  - RatiO R-CNN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_3.pdf
KW  - Aerial Images
KW  - Object Detection
KW  - Oriented Object
ER  - 

TY  - CONF
TI  - Adaptive Fine-Grained Region Matching for Image Harmonization
AU  - Ju, Liuxue
AU  - Pu, Chengdao
AU  - Gao, Fang
AU  - Yu, Jun
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Image harmonization aims to generate composite images that are visually consistent by adjusting the foreground to be compatible with the background. However, previous image harmonization methods overlook the fact that in a real image, the appearance (e.g., illumination, color temperature, saturation, hue, and texture) of different regions can vary significantly depending on content and position. For each foreground region, the background regions related to it should be taken as major references to adjust its appearance. To address this, a fine-grained appearance translation strategy is designed in this work. When adjusting the appearance of each foreground region, our method pays more attention to the background regions that are more relevant to it based on content similarity and position information. Furthermore, a multi-scale feature calibration strategy is introduced to adaptively calibrate the fine-grained features. Finally, an adaptive reconstruction strategy is proposed to further improve the harmonization result. Extensive experiments show our method significantly reduces parameters and achieves state-of-the-art performance compared with previous methods.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_1.pdf
KW  - Appearance translation
KW  - Content similarity
KW  - Image harmonization
KW  - Position information
ER  - 

TY  - CONF
TI  - Tiny-YOLOv7: Tiny Object Detection Model for Drone Imagery
AU  - Cheng, Pengchao
AU  - Tang, Xu
AU  - Liang, Wenqi
AU  - Li, Yu
AU  - Cong, Wei
AU  - Zang, Chuanzhi
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of drones, tiny object detection in drone-captured scenarios has become a challenge task. However, the altitude of the drone changes while flying lead to the scale of the object changes dramatically. In addition, drones flying quickly cause motion blur on the densely tiny objects. In order to address the two issues mention above, we propose Tiny-YOLOv7. In order to detect multi-scale objects, we replace the original prediction heads with transformer prediction heads. For the motion blur issue, we propose DBS module to extract more visual elements and maintain computational cost of model. The DBS module consists of Dynamic Region-Aware Convolution (DRConv), Batch Normalization and Silu modules. On scenarios with dense objects, we additionally incorporate the Convolutional Block Attention Model (CBAM) to find the attention region of dense objects. Tiny-YOLOv7 is an effective and elegant method for handing tiny object detection. We validate our model through extensive experiments on VisDrone2021 and DOTA-v1.0 datasets. The results show that our method obtains remarkable improvements over the other models. In VisDrone2021 dataset, the mAP result of our method is 39.22$$\%$$%, which is higher than SOTA method by 1.07$$\%$$%. Furthermore, experiments on dataset DOTA-v1.0 demonstrate generalization of the propose model.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_5
DP  - Springer Link
SP  - 53
EP  - 65
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
ST  - Tiny-YOLOv7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_5.pdf
KW  - Attention mechanism
KW  - Tiny object detection
KW  - Transformer
ER  - 

TY  - CONF
TI  - Wavelet Knowledge Distillation via Decoupled Target for Scene Text Detection
AU  - Qu, Kefan
AU  - Lin, Jianmin
AU  - Li, Jinrong
AU  - Yang, Ming
AU  - He, Wangpeng
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - In this paper, we investigate the knowledge distillation strategy for training a compact student model for scene text detection, using a cumbersome teacher model that is too computational to apply on resource-constrained devices. We observed that the frequency domain information of the response map is different between the teacher and student models obviously, which can effectively guide the student model to learn more effective knowledge. Furtherly, we propose a wavelet knowledge distillation method via decoupled target for training accurate compact scene text detection networks. Specifically, we first use discrete wavelet transformation to decompose the probability map into different frequency bands which contain different characteristic components, transferring knowledge in the high-frequency band and low-frequency band respectively. In addition, we decouple the target to enhance the distillation effect of the corresponding region, by separating text and background regions through the ground truth mask. Extensive experiments demonstrate that our method consistently improves the F-measure of the student model and outperforms the other mainstream distillation methods.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_13
DP  - Springer Link
SP  - 150
EP  - 161
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_13.pdf
KW  - knowledge distillation
KW  - scene text detection
KW  - wavelet decomposition
ER  - 

TY  - CONF
TI  - Geometric Encoding-Based Attention Mechanism for Point Cloud Registration Network
AU  - Liu, Xuheng
AU  - Bai, Zhengyao
AU  - Du, Jiajin
AU  - Zhang, Yihan
AU  - Li, Zekai
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - We propose a novel point cloud registration network called GEANet, which overcomes the issues of disregarding point cloud geometry information and inadequate utilization of geometric information by utilizing an attention mechanism-based approach and point cloud geometry encoding. Our approach starts by extracting point cloud features using Graph Neural Network (GNN) and feeding them into a point cloud geometry encoder to obtain geometric encoding. The encoding is then jointly input into the attention mechanism for feature interaction. Next, virtual point pairs and weight values are obtained by jointly calculating the point cloud features and point cloud spatial information features, such as Euclidean distance and direction vectors, and the required rigid transformation is solved through SVD. Our experimental results on the ModelNet40 dataset, including unseen point clouds, unseen point cloud categories, and Gaussian noise, demonstrate that the MSE for rotation matrices were reduced to 1.97, 1.68, and 3.70, and for translation to 0.015, 0.013, and 0.018. The findings suggest that our GEANet approach achieves higher accuracy and greater robustness than point cloud registration networks that solely rely on Transformer and do not utilize point cloud geometry encoding.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_17
DP  - Springer Link
SP  - 201
EP  - 212
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_17.pdf
KW  - Geometric Encoding
KW  - Point Cloud Registration
KW  - Transformer
ER  - 

TY  - CONF
TI  - Single Image Dehazing with Deep-Image-Prior Networks
AU  - Wang, Hongyan
AU  - Wang, Xin
AU  - Su, Zhixun
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Most conventional dehazing methods focus on separately estimating key parameters (e.g., the transmission map and the atmospheric light) based on the atmospheric scattering model to generate haze-free images, which may face the limitation of error accumulation. With the advance of deep learning technologies, employing deep neural networks (DNNs) to conduct haze removal becomes popular dehazing methods recently. Most DNNs-based methods automatically learn haze-free image or key parameters in the atmospheric scattering model in end-to-end manners, which heavily rely on training models on dataset. This work aims to recover haze-free images directly by DNNs without any time-consuming training process on dataset or cascading parameter estimation steps. In this paper, haze removal is achieved in Maximum-a-Posterior (MAP) framework based on an exist re-formulation of the atmospheric scattering model, which only involves one integrated variable. The proposed MAP framework is connected with DNN by two self-supervised generative networks—two deep-image-prior (DIP) networks, which are present for modeling the deep priors of the haze-free image and the integrated variable. We further investigate the statistical property of the integrated variable and propose handcrafted regularizers to better constrain the integrated variable. By iteratively updating two networks, solutions of the haze-free image and the integrated variable can be solved jointly. Experiments on both synthesized and real hazy images show that the proposed method performs competitively to state-of-the-art dehazing methods in terms of PSNR, SSIM and visual evaluations.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_7
DP  - Springer Link
SP  - 78
EP  - 90
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_7.pdf
KW  - All-in-one model
KW  - Deep image prior
KW  - Image dehazing
ER  - 

TY  - CONF
TI  - Learning Sparse Neural Networks with Identity Layers
AU  - Ni, Mingjian
AU  - Chen, Guangyao
AU  - Zheng, Xiawu
AU  - Peng, Peixi
AU  - Yuan, Li
AU  - Tian, Yonghong
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - The sparsity of Deep Neural Networks is well investigated to maximize the performance and reduce the size of overparameterized networks as possible. Existing methods focus on pruning parameters in the training process by using thresholds and metrics. Meanwhile, feature similarity between different layers has not been discussed sufficiently before, which could be rigorously proved to be highly correlated to the network sparsity in this paper. Inspired by interlayer feature similarity in overparameterized models, we investigate the intrinsic link between network sparsity and interlayer feature similarity. Specifically, we prove that reducing interlayer feature similarity based on Centered Kernel Alignment (CKA) improves the sparsity of the network by using information bottleneck theory. Applying such theory, we propose a plug-and-play CKA-based Sparsity Regularization for sparse network training, dubbed CKA-SR, which utilizes CKA to reduce feature similarity between layers and increase network sparsity. In other words, layers of our sparse network tend to have their own identity compared to each other. Experimentally, we plug the proposed CKA-SR into the training process of sparse network training methods and find that CKA-SR consistently improves the performance of several State-Of-The-Art sparse training methods, especially at extremely high sparsity. Code is included in the supplementary materials.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_8
DP  - Springer Link
SP  - 91
EP  - 102
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_8.pdf
KW  - Inter-layer feature similarity
KW  - Network compression
KW  - Network sparsity
ER  - 

TY  - CONF
TI  - Foreign Object Detection Based on Compositional Scene Modeling
AU  - Fu, Bingfei
AU  - Zhu, Lin
AU  - Xue, Xiangyang
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - We are dedicated to researching the problem of foreign object detection in industrial production. Due to dynamic interference such as occlusion, lighting, and color difference in scenes in industrial production, it is difficult for many anomaly detection methods to maintain high performance. We propose a foreign object detection method based on compositional scene modeling, which includes a background denoising module and a foreground reconstruction module. In the background denoising module, we model dynamic disturbances in the scene into the background representation via a deep generative model. In the foreground reconstruction module, we use an autoencoder to learn abnormal foreground representations to achieve foreign object detection. To verify the effectiveness of our method, we simulate an industrial production environment and construct a synthetic dataset in a circuit board assembly scenario. Experiments show that our proposed architecture has good performance on both synthetic dataset and real dataset. While maintaining a low false detection rate, all abnormal objects are detected, with a miss detection rate of 0% in real dataset.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_16
DP  - Springer Link
SP  - 186
EP  - 198
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_16.pdf
KW  - abnormal detection
KW  - compositional scene modeling
KW  - foreign object detection
ER  - 

TY  - CONF
TI  - Revisiting TENT for Test-Time Adaption Semantic Segmentation and Classification Head Adjustment
AU  - Zhao, Xuanpu
AU  - Chu, Qi
AU  - Miao, Changtao
AU  - Liu, Bin
AU  - Yu, Nenghai
A2  - Lu, Huchuan
A2  - Ouyang, Wanli
A2  - Huang, Hui
A2  - Lu, Jiwen
A2  - Liu, Risheng
A2  - Dong, Jing
A2  - Xu, Min
T3  - Lecture Notes in Computer Science
AB  - Test-time adaption is very effective at solving the domain shift problem where the training data and testing data are sampled from different domains. However, most test-time adaption methods made their success on classification tasks while object detection and segmentation tasks usually have more applications in the real world. Meanwhile, methods that update the model at test-time which is a main branch in test-time adaption (e.g., TENT [1], a typical method of this branch) only update the backbone, and the classification head remains unchanged. Though the classification head trained by the training data behaves well on the source domain, it is not guaranteed to be effective for a new domain and a new backbone. In our work, we re-weight the entropy of pixels in an image and adopt SAR [2] to overcome the instability in online adaption. Experiment results show that the segmentation method in TENT becomes more efficient and stable thanks to these improvements. For the classification task, we propose to use T3A [3] to update the backbone and finetune the classification head in the meantime based on TENT, which boosts the classification accuracy by a large margin.
C1  - Cham
C3  - Image and Graphics
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-46311-2_6
DP  - Springer Link
SP  - 66
EP  - 77
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-46311-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-46311-2_6.pdf
KW  - Classification head
KW  - Semantic segmentation
KW  - Test-time adaption
ER  - 

TY  - CONF
TI  - Two-Aspect Information Interaction Model for ABAW4 Multi-task Challenge
AU  - Sun, Haiyang
AU  - Lian, Zheng
AU  - Liu, Bin
AU  - Tao, Jianhua
AU  - Sun, Licai
AU  - Cai, Cong
AU  - He, Yu
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - The task of ABAW is to predict frame-level emotion descriptors from videos: discrete emotional state; valence and arousal; and action units. In this paper, we propose the solution to the Multi-Task Learning (MTL) Challenge of the 4th Affective Behavior Analysis in-the-wild (ABAW) competition. Although researchers have proposed several approaches and achieved promising results in ABAW, current works in this task rarely consider interactions between different emotion descriptors. To this end, we propose a novel end to end architecture to achieve full integration of different types of information. Experimental results demonstrate the effectiveness of our proposed solution. Code are available at https://github.com/Swiftsss/ECCV2022MTL.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_13
DP  - Springer Link
SP  - 173
EP  - 180
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_13.pdf
KW  - ABAW4 multi-task challenge
KW  - Action unit detection
KW  - Emotion recognition
KW  - Information fusion
ER  - 

TY  - CONF
TI  - Ensemble of Multi-task Learning Networks for Facial Expression Recognition In-the-Wild with Learning from Synthetic Data
AU  - Jeong, Jae-Yeop
AU  - Hong, Yeong-Gi
AU  - Hong, Sumin
AU  - Oh, JiYeon
AU  - Jung, Yuchul
AU  - Kim, Sang-Ho
AU  - Jeong, Jin-Woo
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Facial expression recognition in-the-wild is essential for various interactive computing applications. Especially, “Learning from Synthetic Data” is an important topic in the facial expression recognition task. In this paper, we propose a multi-task learning-based facial expression recognition approach where emotion and appearance perspectives of facial images are jointly learned. We also present our experimental results on validation and test set of the LSD challenge introduced in the 4th affective behavior analysis in-the-wild competition. Our method achieved the mean F1 score of 71.82 on the validation and 35.87 on the test set, ranking third place on the final leaderboard.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_5
DP  - Springer Link
SP  - 60
EP  - 75
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_5.pdf
KW  - Ensemble approach
KW  - Facial expression recognition
KW  - Leaning from synthetic data
KW  - Multi-task learning
ER  - 

TY  - CONF
TI  - Multi-Task Learning Framework for Emotion Recognition In-the-Wild
AU  - Zhang, Tenggan
AU  - Liu, Chuanhe
AU  - Liu, Xiaolong
AU  - Liu, Yuchen
AU  - Meng, Liyu
AU  - Sun, Lei
AU  - Jiang, Wenqiang
AU  - Zhang, Fengyuan
AU  - Zhao, Jinming
AU  - Jin, Qin
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - This paper presents our system for the Multi-Task Learning (MTL) Challenge in the 4th Affective Behavior Analysis in-the-wild (ABAW) competition. We explore the research problems of this challenge from three aspects: 1) For obtaining efficient and robust visual feature representations, we propose MAE-based unsupervised representation learning and IResNet/DenseNet-based supervised representation learning methods; 2) Considering the importance of temporal information in videos, we explore three types of sequential encoders to capture the temporal information, including the encoder based on transformer, the encoder based on LSTM, and the encoder based on GRU; 3) For modeling the correlation between these different tasks (i.e., valence, arousal, expression, and AU) for multi-task affective analysis, we first explore the dependency between these different tasks and propose three multi-task learning frameworks to model the correlations effectively. Our system achieves the performance of 1.7607 on the validation dataset and 1.4361 on the test dataset, ranking first in the MTL Challenge. The code is available at https://github.com/AIM3-RUC/ABAW4.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_11
DP  - Springer Link
SP  - 143
EP  - 156
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_11.pdf
ER  - 

TY  - CONF
TI  - MT-EmotiEffNet for Multi-task Human Affective Behavior Analysis and Learning from Synthetic Data
AU  - Savchenko, Andrey V.
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - In this paper, we present the novel multi-task EfficientNet model and its usage in the 4th competition on Affective Behavior Analysis in-the-wild (ABAW). This model is trained for simultaneous recognition of facial expressions and prediction of valence and arousal on static photos. The resulting MT-EmotiEffNet extracts visual features that are fed into simple feed-forward neural networks in the multi-task learning challenge. We obtain performance measure 1.3 on the validation set, which is significantly greater when compared to either performance of baseline (0.3) or existing models that are trained only on the s-Aff-Wild2 database. In the learning from synthetic data challenge, the quality of the original synthetic training set is increased by using the super-resolution techniques, such as Real-ESRGAN. Next, the MT-EmotiEffNet is fine-tuned on the new training set. The final prediction is a simple blending ensemble of pre-trained and fine-tuned MT-EmotiEffNets. Our average validation F1 score is 18% greater than the baseline model. As a result, our team took the first place in the learning from synthetic data task and the third place in the multi-task learning challenge.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_4
DP  - Springer Link
SP  - 45
EP  - 59
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_4.pdf
KW  - 4th Affective Behavior Analysis in-the-Wild (ABAW)
KW  - EfficientNet
KW  - Facial expression recognition
KW  - Learning from synthetic data
KW  - Multi-task learning
ER  - 

TY  - CONF
TI  - Geometric Pose Affordance: Monocular 3D Human Pose Estimation with Scene Constraints
AU  - Wang, Zhe
AU  - Chen, Liyan
AU  - Rathore, Shaurya
AU  - Shin, Daeyun
AU  - Fowlkes, Charless
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Accurate estimation of 3D human pose from a single image remains a challenging task despite many recent advances. In this paper, we explore the hypothesis that strong prior information about scene geometry can be used to improve pose estimation accuracy. To tackle this question empirically, we have assembled a novel Geometric Pose Affordance dataset, consisting of multi-view imagery of people interacting with a variety of rich 3D environments. We utilized a commercial motion capture system to collect gold-standard estimates of pose and construct accurate geometric 3D models of the scene geometry.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_1
DP  - Springer Link
SP  - 3
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
ST  - Geometric Pose Affordance
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_1.pdf
KW  - 3D human pose
KW  - Background pixels
KW  - Scene geometry
ER  - 

TY  - CONF
TI  - Affective Behavior Analysis Using Action Unit Relation Graph and Multi-task Cross Attention
AU  - Nguyen, Dang-Khanh
AU  - Pant, Sudarshan
AU  - Ho, Ngoc-Huynh
AU  - Lee, Guee-Sang
AU  - Kim, Soo-Hyung
AU  - Yang, Hyung-Jeong
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Facial behavior analysis is a broad topic with various categories such as facial emotion recognition, age, and gender recognition. Many studies focus on individual tasks while the multi-task learning approach is still an open research issue and requires more research. In this paper, we present our solution and experiment result for the Multi-Task Learning challenge of the Affective Behavior Analysis in-the-wild competition. The challenge is a combination of three tasks: action unit detection, facial expression recognition, and valance-arousal estimation. To address this challenge, we introduce a cross-attentive module to improve multi-task learning performance. Additionally, a facial graph is applied to capture the association among action units. As a result, we achieve the evaluation measure of 128.8 on the validation data provided by the organizers, which outperforms the baseline result of 30.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_10
DP  - Springer Link
SP  - 132
EP  - 142
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_10.pdf
KW  - Action unit detection
KW  - Cross attention
KW  - Facial expression recognition
KW  - Graph convolution network
KW  - Multi-task learning
KW  - Valence and arousal estimation
ER  - 

TY  - CONF
TI  - Facial Expression Recognition In-the-Wild with Deep Pre-trained Models
AU  - Li, Siyang
AU  - Xu, Yifan
AU  - Wu, Huanyu
AU  - Wu, Dongrui
AU  - Yin, Yingjie
AU  - Cao, Jiajiong
AU  - Ding, Jingting
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Facial expression recognition (FER) is challenging, when transiting from the laboratory to in-the-wild situations. In this paper, we present a general framework for the Learning from Synthetic Data Challenge in the 4th Affective Behavior Analysis In-The-Wild (ABAW4) competition, to learn as much knowledge as possible from synthetic faces with expressions. To cope with four problems in training robust deep FER models, including uncertain labels, class imbalance, mismatch between pretraining and downstream tasks, and incapability of a single model structure, our framework consists of four respective modules, which can be utilized for FER in-the-wild. Experimental results on the official validation set from the competition demonstrated that our proposed approach outperformed the baseline by a large margin.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_14
DP  - Springer Link
SP  - 181
EP  - 190
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_14.pdf
KW  - ABAW
KW  - Affective behavior analysis in-the-wild
KW  - Affective computing
KW  - Facial expression recognition
KW  - Learning from synthetic data
ER  - 

TY  - CONF
TI  - BYEL: Bootstrap Your Emotion Latent
AU  - Lee, Hyungjun
AU  - Lim, Hwangyu
AU  - Lim, Sejoon
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - With the improved performance of deep learning, the number of studies trying to apply deep learning to human emotion analysis is increasing rapidly. But even with this trend, it is still difficult to obtain high-quality images and annotations. For this reason, the Learning from Synthetic Data (LSD) Challenge, which learns from synthetic images and infers from real images, is one of the most interesting areas. Generally, domain adaptation methods are widely used to address LSD challenges, but the limitation is that the target domains (real images) are still needed. Focusing on these limitations, we propose a framework Bootstrap Your Emotion Latent (BYEL), which uses only synthetic images in training. BYEL is implemented by adding Emotion Classifiers and Emotion Vector Subtraction to the BYOL framework that performs well in self-supervised representation learning. We trained our framework using synthetic images generated from the Aff-wild2 dataset and evaluated it using real images from the Aff-wild2 dataset. The result shows that our framework (0.3084) performs 2.8% higher than the baseline (0.3) on the macro F1 score metric.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_9
DP  - Springer Link
SP  - 121
EP  - 131
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
ST  - BYEL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_9.pdf
KW  - 4th Affective Behavior Analysis in-the-Wild (ABAW)
KW  - Emotion-aware representation learning
KW  - Facial expression recognition
KW  - Learning from synthetic data
KW  - Representation learning
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - ABAW: Learning from Synthetic Data & Multi-task Learning Challenges
AU  - Kollias, Dimitrios
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - This paper describes the fourth Affective Behavior Analysis in-the-wild (ABAW) Competition, held in conjunction with European Conference on Computer Vision (ECCV), 2022. The 4th ABAW Competition is a continuation of the Competitions held at IEEE CVPR 2022, ICCV 2021, IEEE FG 2020 and IEEE CVPR 2017 Conferences, and aims at automatically analyzing affect. In the previous runs of this Competition, the Challenges targeted Valence-Arousal Estimation, Expression Classification and Action Unit Detection. This year the Competition encompasses two different Challenges: i) a Multi-Task-Learning one in which the goal is to learn at the same time (i.e., in a multi-task learning setting) all the three above mentioned tasks; and ii) a Learning from Synthetic Data one in which the goal is to learn to recognise the six basic expressions from artificially generated data and generalise to real data.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_12
DP  - Springer Link
SP  - 157
EP  - 172
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
ST  - ABAW
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_12.pdf
KW  - ABAW
KW  - Action unit detection
KW  - Aff-Wild2
KW  - Affective behavior analysis in-the-wild
KW  - Expression recognition and classification
KW  - Expression synthesis
KW  - Facial expression transfer
KW  - Learning from synthetic data
KW  - Multi-task learning
KW  - s-Aff-Wild2
KW  - Valence and arousal estimation
ER  - 

TY  - CONF
TI  - Affective Behaviour Analysis Using Pretrained Model with Facial Prior
AU  - Li, Yifan
AU  - Sun, Haomiao
AU  - Liu, Zhaori
AU  - Han, Hu
AU  - Shan, Shiguang
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Affective behavior analysis has aroused researchers’ attention due to its broad applications. However, it is labor exhaustive to obtain accurate annotations for massive face images. Thus, we propose to utilize the prior facial information via Masked Auto-Encoder (MAE) pretrained on unlabeled face images. Furthermore, we combine MAE pretrained Vision Transformer (ViT) and AffectNet pretrained CNN to perform multi-task emotion recognition. We notice that expression and action unit (AU) scores are pure and intact features for valence-arousal (VA) regression. As a result, we utilize AffectNet pretrained CNN to extract expression scores concatenating with expression and AU scores from ViT to obtain the final VA features. Moreover, we also propose a co-training framework with two parallel MAE pretrained ViTs for expression recognition tasks. In order to make the two views independent, we randomly mask most patches during the training process. Then, JS divergence is performed to make the predictions of the two views as consistent as possible. The results on ABAW4 show that our methods are effective, and our team reached 2nd place in the multi-task learning (MTL) challenge and 4th place in the learning from synthetic data (LSD) challenge. Code is available $$^{3}$$3https://github.com/JackYFL/EMMA_CoTEX_ABAW4.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_2
DP  - Springer Link
SP  - 19
EP  - 30
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_2.pdf
KW  - ABAW4
KW  - AU recognition
KW  - Expression recognition
KW  - Facial prior
KW  - MAE
KW  - Multi-task affective behaviour analysis
KW  - VA regression
ER  - 

TY  - CONF
TI  - PERI: Part Aware Emotion Recognition in the Wild
AU  - Mittel, Akshita
AU  - Tripathi, Shashank
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Emotion recognition aims to interpret the emotional states of a person based on various inputs including audio, visual, and textual cues. This paper focuses on emotion recognition using visual features. To leverage the correlation between facial expression and the emotional state of a person, pioneering methods rely primarily on facial features. However, facial features are often unreliable in natural unconstrained scenarios, such as in crowded scenes, as the face lacks pixel resolution and contains artifacts due to occlusion and blur. To address this, methods focusing on in the wild emotion recognition exploit full-body person crops as well as the surrounding scene context. While effective, in a bid to use body pose for emotion recognition, such methods fail to realize the potential that facial expressions, when available, offer. Thus, the aim of this paper is two-fold. First, we demonstrate a method, PERI, to leverage both body pose and facial landmarks. We create part aware spatial (PAS) images by extracting key regions from the input image using a mask generated from both body pose and facial landmarks. This allows us to exploit body pose in addition to facial context whenever available. Second, to reason from the PAS images, we introduce context infusion (Cont-In) blocks. These blocks attend to part-specific information, and pass them onto the intermediate features of an emotion recognition network. Our approach is conceptually simple and can be applied to any existing emotion recognition method. We provide our results on the publicly available in the wild EMOTIC dataset. Compared to existing methods, PERI achieves superior performance and leads to significant improvements in the mAP of emotion categories, while decreasing Valence, Arousal and Dominance errors. Importantly, we observe that our method improves performance in both images with fully visible faces as well as in images with occluded or blurred faces.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_6
DP  - Springer Link
SP  - 76
EP  - 92
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
ST  - PERI
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_6.pdf
ER  - 

TY  - CONF
TI  - Robustness of Embodied Point Navigation Agents
AU  - Rajič, Frano
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - We make a step towards robust embodied AI by analyzing the performance of two successful Habitat Challenge 2021 agents under different visual corruptions (low lighting, blur, noise, etc.) and robot dynamics corruptions (noisy egomotion). The agents had underperformed overall. However, one of the agents managed to handle multiple corruptions with ease, as the authors deliberately tackled robustness in their model. For specific corruptions, we concur with observations from literature that there is still a long way to go to recover the performance loss caused by corruptions, warranting more research on the robustness of embodied AI.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_15
DP  - Springer Link
SP  - 193
EP  - 204
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_15.pdf
KW  - Embodied AI
KW  - Habitat challenge
KW  - Point navigation
KW  - Robustness
ER  - 

TY  - CONF
TI  - Deep Semantic Manipulation of Facial Videos
AU  - Solanki, Girish Kumar
AU  - Roussos, Anastasios
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Editing and manipulating facial features in videos is an interesting and important field of research with a plethora of applications, ranging from movie post-production and visual effects to realistic avatars for video games and virtual assistants. Our method supports semantic video manipulation based on neural rendering and 3D-based facial expression modelling. We focus on interactive manipulation of the videos by altering and controlling the facial expressions, achieving promising photorealistic results. The proposed method is based on a disentangled representation and estimation of the 3D facial shape and activity, providing the user with intuitive and easy-to-use control of the facial expressions in the input video. We also introduce a user-friendly, interactive AI tool that processes human-readable semantic labels about the desired expression manipulations in specific parts of the input video and synthesizes photorealistic manipulated videos. We achieve that by mapping the emotion labels to points on the Valence-Arousal space (where Valence quantifies how positive or negative is an emotion and Arousal quantifies the power of the emotion activation), which in turn are mapped to disentangled 3D facial expressions through an especially-designed and trained expression decoder network. The paper presents detailed qualitative and quantitative experiments, which demonstrate the effectiveness of our system and the promising results it achieves.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_8
DP  - Springer Link
SP  - 104
EP  - 120
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_8.pdf
ER  - 

TY  - CONF
TI  - Facial Expression Recognition with Mid-level Representation Enhancement and Graph Embedded Uncertainty Suppressing
AU  - Lei, Jie
AU  - Liu, Zhao
AU  - Zou, Zeyu
AU  - Li, Tong
AU  - Xu, Juan
AU  - Wang, Shuaiwei
AU  - Yang, Guoyu
AU  - Feng, Zunlei
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Facial expression is an essential factor in conveying human emotional states and intentions. Although remarkable advancement has been made in facial expression recognition (FER) tasks, challenges due to large variations of expression patterns and unavoidable data uncertainties remain. In this paper, we propose mid-level representation enhancement (MRE) and graph embedded uncertainty suppressing (GUS) addressing these issues. On one hand, MRE is introduced to avoid expression representation learning being dominated by a limited number of highly discriminative patterns. On the other hand, GUS is introduced to suppress the feature ambiguity in the representation space. The proposed method not only has stronger generalization capability to handle different variations of expression patterns but also more robustness in capturing expression representations. Experimental evaluation on Aff-Wild2 have verified the effectiveness of the proposed method. We achieved 2nd place in the Learning from Synthetic Data (LSD) Challenge of the 4th Competition on Affective Behavior Analysis in-the-wild (ABAW). The code has been released at https://github.com/CruiseYuGH/GUS.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_7
DP  - Springer Link
SP  - 93
EP  - 103
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_7.pdf
ER  - 

TY  - CONF
TI  - CounTr: An End-to-End Transformer Approach for Crowd Counting and Density Estimation
AU  - Bai, Haoyue
AU  - He, Hao
AU  - Peng, Zhuoxuan
AU  - Dai, Tianyuan
AU  - Chan, S.-H. Gary
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Modeling context information is critical for crowd counting and desntiy estimation. Current prevailing fully-convolutional network (FCN) based crowd counting methods cannot effectively capture long-range dependencies with limited receptive fields. Although recent efforts on inserting dilated convolutions and attention modules have been taken to enlarge the receptive fields, the FCN architecture remains unchanged and retains the fundamental limitation on learning long-range relationships. To tackle the problem, we introduce CounTr, a novel end-to-end transformer approach for crowd counting and density estimation, which enables capture global context in every layer of the Transformer. To be specific, CounTr is composed of a powerful transformer-based hierarchical encoder-decoder architecture. The transformer-based encoder is directly applied to sequences of image patches and outputs multi-scale features. The proposed hierarchical self-attention decoder fuses the features from different layers and aggregates both local and global context features representations. Experimental results show that CounTr achieves state-of-the-art performance on both person and vehicle crowd counting datasets. Particularly, we achieve the first position (159.8 MAE) in the highly crowded UCF_CC_50 benchmark and achieve new SOTA performance (2.0 MAE) in the super large and diverse FDST open dataset. This demonstrates CounTr’s promising performance and practicality for real applications.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_16
DP  - Springer Link
SP  - 207
EP  - 222
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
ST  - CounTr
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_16.pdf
KW  - Hierarchical architecture
KW  - Single image crowd counting
KW  - Transformer-based approach
ER  - 

TY  - CONF
TI  - Facial Affect Recognition Using Semi-supervised Learning with Adaptive Threshold
AU  - Gera, Darshan
AU  - Raj Kumar, Bobbili Veerendra
AU  - Badveeti, Naveen Siva Kumar
AU  - Balasubramanian, S.
A2  - Karlinsky, Leonid
A2  - Michaeli, Tomer
A2  - Nishino, Ko
T3  - Lecture Notes in Computer Science
AB  - Automatic facial affect recognition has wide applications in areas like education, gaming, software development, automotives, medical care, etc. but it is non trivial task to achieve appreciable performance on in-the-wild data sets. Though these datasets represent real-world scenarios better than in-lab data sets, they suffer from the problem of incomplete labels due to difficulty in annotation. Inspired by semi-supervised learning, this paper presents our submission to the Multi-Task-Learning (MTL) Challenge and Learning from Synthetic Data (LSD) Challenge at the 4th Affective Behavior Analysis in-the-wild (ABAW) 2022 Competition. The three tasks that are considered in MTL challenge are valence-arousal estimation, classification of expressions into basic emotions and detection of action units. Our method Semi-supervised Learning based Multi-task Facial Affect Recognition titled SS-MFAR uses a deep residual network as backbone along with task specific classifiers for each of the tasks. It uses adaptive thresholds for each expression class to select confident samples using semi-supervised learning from samples with incomplete labels. The performance is validated on challenging s-Aff-Wild2 dataset. Source code is available at https://github.com/1980x/ABAW2022DMACS.
C1  - Cham
C3  - Computer Vision – ECCV 2022 Workshops
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-25075-0_3
DP  - Springer Link
SP  - 31
EP  - 44
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-25075-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-25075-0_3.pdf
KW  - Facial expression recognition
KW  - Multi task learning
KW  - s-AffWild2
KW  - Semi-supervised learning
ER  - 

TY  - CONF
TI  - Oyster Mushroom Growth Stage Identification: An Exploration of Computer Vision Technologies
AU  - Guo, Lipin
AU  - Zhang, Wei Emma
AU  - Chen, Weitong
AU  - Yang, Ni
AU  - Nguyen, Queen
AU  - Vo, Trung Duc
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Mushrooms play a pivotal role in bolstering Australia’s economy, impacting key sectors like agriculture, food production, and medicinal advancements. To meet the escalating need for sustainable food options and enhance mushroom harvesting efficiency, this research: i) introduces an innovative dataset featuring three growth stages of oyster mushrooms; ii) designs a monitoring system which consists of image acquisition, cloud storage, label map and applications to achieve effective monitoring; and iii) proposes a label map method to monitor different stages within panoramic images captured from the real mushroom cultivation environment. Our preliminary studies show that the label map with state-of-art VGG-16 model emerges as the optimal choice, achieving an impressive accuracy of 82.22%. Our dataset can be obtained upon request.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_6
DP  - Springer Link
SP  - 67
EP  - 78
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - Oyster Mushroom Growth Stage Identification
KW  - Computer Vision
KW  - Growth
KW  - Oyster Mushroom
ER  - 

TY  - CONF
TI  - SAR2EO: A High-Resolution Image Translation Framework with Denoising Enhancement
AU  - Du, Shenshen
AU  - Yu, Jun
AU  - Xie, Guochen
AU  - Lu, Renjie
AU  - Li, Pengwei
AU  - Cai, Zhongpeng
AU  - Lu, Keda
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Synthetic Aperture Radar (SAR) to electro-optical (EO) image translation is a fundamental task in remote sensing that can enrich the dataset by fusing information from different sources. Recently, many methods have been proposed to tackle this task, but they are still difficult to complete the conversion from low-resolution images to high-resolution images. Thus, we propose a framework, SAR2EO, aiming at addressing this challenge. Firstly, to generate high-quality EO images, we adopt the coarse-to-fine generator, multi-scale discriminators, and improved adversarial loss in the pix2pixHD model to increase the synthesis quality. Secondly, we introduce a denoising module to remove the noise in SAR images, which helps to suppress the noise while preserving the structural information of the images. To validate the effectiveness of the proposed framework, we conduct experiments on the dataset of the Multi-modal Aerial View Imagery Challenge (MAVIC), which consists of large-scale SAR and EO image pairs. The experimental results demonstrate the superiority of our proposed framework, and we win the first place in the MAVIC held in CVPR PBVS 2023.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_8
DP  - Springer Link
SP  - 91
EP  - 102
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - SAR2EO
L4  - https://arxiv.org/pdf/2304.04760
KW  - Denoising
KW  - High Resolution
KW  - Image Translation
ER  - 

TY  - CONF
TI  - Handling Heavy Occlusion in Dense Crowd Tracking by Focusing on the Heads
AU  - Zhang, Yu
AU  - Chen, Huaming
AU  - Lai, Zhongzheng
AU  - Zhang, Zao
AU  - Yuan, Dong
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of deep learning, object detection and tracking play a vital role in today’s society. Being able to identify and track all the pedestrians in the dense crowd scene with computer vision approaches is a typical challenge in this field, also known as the Multiple Object Tracking (MOT) challenge. Modern trackers are required to operate on more and more complicated scenes. According to the MOT20 challenge result, the pedestrian is 4 times denser than the MOT17 challenge. Hence, improving the ability to detect and track in extremely crowded scenes is the aim of this work. In light of the occlusion issue with the human body, the heads are usually easier to identify. In this work, we have designed a joint head and body detector in an anchor-free style to boost the detection recall and precision performance of pedestrians in both small and medium sizes. Innovatively, our model does not require information on the statistical head-body ratio for common pedestrians detection for training. Instead, the proposed model learns the ratio dynamically. To verify the effectiveness of the proposed model, we evaluate the model with extensive experiments on different datasets, including MOT20, Crowdhuman, and HT21 datasets. As a result, our proposed method significantly improves both the recall and precision rate on small and medium sized pedestrians, and achieves state-of-the-art results in these challenging datasets.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_7
DP  - Springer Link
SP  - 79
EP  - 90
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
L4  - https://arxiv.org/pdf/2304.07705
KW  - Crowd
KW  - Detection
KW  - Tracking
ER  - 

TY  - CONF
TI  - SimMining-3D: Altitude-Aware 3D Object Detection in Complex Mining Environments: A Novel Dataset and  ROS-Based Automatic Annotation Pipeline
AU  - Balamurali, Mehala
AU  - Mihankhah, Ehsan
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Accurate and efficient object detection is crucial for safe and efficient operation of earth-moving equipment in mining. Traditional 2D image-based methods face limitations in dynamic and complex mine environments. To overcome these challenges, 3D object detection using point cloud data has emerged as a comprehensive approach. However, training models for mining scenarios is challenging due to sensor height variations, viewpoint changes, and the need for diverse annotated datasets.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_5
DP  - Springer Link
SP  - 55
EP  - 66
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - SimMining-3D
KW  - Mining Automation
KW  - Simulation to Real
KW  - Viewpoint Diversity
ER  - 

TY  - CONF
TI  - CLIP-Based Composed Image Retrieval with Comprehensive Fusion and Data Augmentation
AU  - Lin, Haoqiang
AU  - Wen, Haokun
AU  - Chen, Xiaolin
AU  - Song, Xuemeng
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Composed image retrieval (CIR) is a challenging task where the input query consists of a reference image and its corresponding modification text. Recent methodologies harness the prowess of visual-language pre-training models, i.e., CLIP, yielding commendable performance in CIR. Despite their promise, several shortcomings linger. First, a salient domain discrepancy between the CLIP’s pre-training data and the CIR’s training data leads to suboptimal feature representation. Second, the existing multimodal fusion mechanisms solely rely on weighted summing and feature concatenation, neglecting the intricate higher-order interactions inherent in the multimodal query. This oversight poses challenges in modeling complex modification intents. Additionally, the paucity of data impedes model generalization. To address these issues, we propose a CLIP-based composed image retrieval model with comprehensive fusion and data augmentation (CLIP-CD), consisting of two training stages. In the first stage, we fine-tune both the image and text encoders of CLIP to alleviate the aforementioned domain discrepancy. In the second stage, we propose a comprehensive multimodal fusion module that enables the model to discern complex modification intentions. Furthermore, we propose a similarity-based data augmentation method for CIR, ameliorating data scarcity and enhancing the model’s generalization ability. Experimental results on the Fashion-IQ dataset demonstrate the effectiveness of our method.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_16
DP  - Springer Link
SP  - 190
EP  - 202
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Image retrieval
KW  - Multimodal fusion
KW  - Vision-Language pre-training model
ER  - 

TY  - CONF
TI  - Short-Term Solar Irradiance Forecasting from Future Sky Images Generation
AU  - Nguyen, Hoang Chuong
AU  - Liu, Miaomiao
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Solar irradiance prediction is critical for the integration of the solar power to the existing power system. A recent trend in the literature is to adopt deep learning-based methods to predict future solar irradiance from sky images. While these models have achieved significant improvements, they are only capable of making predictions for a fixed forecasting horizon due to their non-recurrent nature. To this end, we propose a deep learning network that is capable of predicting solar irradiance in an autoregressive manner, which allows predictions across a long time horizon. Particularly, we reduce the problem to first generating future sky images which are then used to predict future solar irradiance. We evaluate our models on TSI880 and ASI16 datasets, and show that our model achieves superior performance compared to previous works for 4-h ahead-of-time predictions. Furthermore, we also demonstrate that the solar irradiance forecast of our model is not limited to only 4 h, but can be extended for even longer horizon.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_2
DP  - Springer Link
SP  - 15
EP  - 27
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Computer Vision
KW  - Deep learning
KW  - Solar irradiance forecasting
ER  - 

TY  - CONF
TI  - Cross Domain Pulmonary Nodule Detection Without Source Data
AU  - Xu, Rui
AU  - Luo, Yong
AU  - Xu, Yan
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - The model performance on cross-domain pulmonary nodule detection usually degrades because of the significant shift in data distributions and the scarcity of annotated medical data in the test scenarios. Current approaches to cross-domain object detection assume that training data from the source domain are freely available; however, such an assumption is implausible in the medical field, as the data are confidential and cannot be shared due to privacy concerns. Thus, this paper introduces source data-free cross-domain pulmonary nodule detection. In this setting, only a pre-trained model from the source domain and a few annotated samples from the target domain are available. We introduce a novel method to tackle this issue, adapting the feature extraction module for the target domain through minimizing the proposed General Entropy (GE). Specifically, we optimize the batch normalization (BN) layers of the model by GE minimization. Thus, the dataset-level statistics of the target domain are utilized for optimization and inference. Furthermore, we tune the detection head of the model using annotated target samples to mitigate the rater difference and improve the accuracy. Extensive experiments on three different pulmonary nodule datasets show the efficacy of our method for source data-absent cross-domain pulmonary nodule detection.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_13
DP  - Springer Link
SP  - 153
EP  - 164
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Domain Adaptation
KW  - Entropy Minimization
KW  - Model Reuse
KW  - Pulmonary Nodule Detection
KW  - Source Free
ER  - 

TY  - CONF
TI  - A New Perspective of Weakly Supervised 3D Instance Segmentation via Bounding Boxes
AU  - Yu, Qingtao
AU  - Du, Heming
AU  - Yu, Xin
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Existing fully supervised method 3D point cloud segmentation methods heavily rely on carefully annotated point labels. In this work, we look at weakly-supervised 3D instance segmentation using bounding boxes supervision. Bounding boxes are much easier to annotate than dense point-wise labels. Moreover, they demonstrated high potential in addressing instance-level segmentation compared to other types of weak annotations. However, existing bounding-box supervised techniques have struggled to keep pace with the development of fully-supervised methods. To tackle this issue, we propose a simple-yet-effective approach to directly leverage the network architecture of fully-supervised methods for such weak supervision scenarios. We found that accurate instance labels for each point can be generated with the given bounding boxes by leveraging 3D geometric prior. Such a process is efficient and does not require any additional training or fine-tuning. The generated point-wise labels can be fed to any advanced fully-supervised model without re-designing specific networks for bounding-box supervision. In this fashion, our designed approach achieves on par performance of fully supervised methods in terms of AP, AP50 and AP25. Remarkably, we outperformed the state-of-the-art bounding-box supervised method by 21%. Compared with existing methods, our method is extremely simple and only involves two small heuristics in the data preprocessing step. In addition, our method is proven to be robust against noisy bounding box scenario through experiments.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_9
DP  - Springer Link
SP  - 103
EP  - 114
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - 3D point cloud
KW  - Weakly supervised learning
ER  - 

TY  - CONF
TI  - Story Sifting Using Object Detection Techniques
AU  - Leong, Wilkins
AU  - Porteous, Julie
AU  - Thangarajah, Jonathan
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Our focus is on the problem of story sifting (or story recognition), which is the automated sifting of interesting stories that emerge from the interactions between virtual characters in virtual storyworld environments. To date, approaches to story sifting have been either: manual, with the burden of authoring sifting patterns; or automated, but of limited efficiency and scalability. In this paper, we address these shortcomings via a novel approach that recasts the problem as one of object detection. We demonstrate how an object detection model can be trained to detect story arcs of prominent story types emerging from an interactive virtual storyworld which can occur anywhere in the storyworld’s timeline. We evaluate our approach using synthetic virtual story environments that show our approach is able to: detect story arcs anywhere in the storyworld’s timeline with a high degree of accuracy and more efficiently than the state-of-the-art Arc Sift, making it scalable in real-time.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_4
DP  - Springer Link
SP  - 42
EP  - 54
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Emergent Narratives
KW  - Interactive Narratives
KW  - Story Sifting
ER  - 

TY  - CONF
TI  - WeightRelay: Efficient Heterogeneous Federated Learning on Time Series
AU  - Tang, Wensi
AU  - Long, Guodong
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Federated learning for heterogeneous devices aims to obtain models of various structural configurations in order to fit multiple devices according to their hardware configurations and external environments. Existing solutions train those heterogeneous models simultaneously, which requires extra cost (e.g. computation, communication, or data) to transfer knowledge between models. In this paper, we proposed a method, namely, weight relay (WeightRelay), that could get heterogeneous models without any extra training cost. Specifically, we find that, compared with the classic random weight initialization, initializing the weight of a large neural network with the weight of a well-trained small network could reduce the training epoch and still maintain a similar performance. Therefore, we could order models from the smallest and train them one by one. Each model (except the first one) can be initialized with the prior model’s trained weight for training cost reduction. In the experiment, we evaluate the weight relay on 128-time series datasets from multiple domains, and the result confirms the effectiveness of WeightRelay. More theoretical analysis and code can be found in (https://github.com/Wensi-Tang/DPSN/blob/master/AJCAI23_wensi_fedTSC.pdf).
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_11
DP  - Springer Link
SP  - 129
EP  - 140
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - WeightRelay
KW  - Federated learning
KW  - Heterogeneous model
KW  - Time series classification
ER  - 

TY  - CONF
TI  - No Token Left Behind: Efficient Vision Transformer via Dynamic Token Idling
AU  - Xu, Xuwei
AU  - Li, Changlin
AU  - Chen, Yudong
AU  - Chang, Xiaojun
AU  - Liu, Jiajun
AU  - Wang, Sen
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Vision Transformers (ViTs) have demonstrated outstanding performance in computer vision tasks, yet their high computational complexity prevents their deployment in computing resource-constrained environments. Various token pruning techniques have been introduced to alleviate the high computational burden of ViTs by dynamically dropping image tokens. However, some undesirable pruning at early stages may result in permanent loss of image information in subsequent layers, consequently hindering model performance. To address this problem, we propose IdleViT, a dynamic token-idle-based method that achieves an excellent trade-off between performance and efficiency. Specifically, in each layer, IdleViT selects a subset of the image tokens to participate in computations while keeping the rest of the tokens idle and directly passing them to this layer’s output. By allowing the idle tokens to be re-selected in the following layers, IdleViT mitigates the negative impact of improper pruning in the early stages. Furthermore, inspired by the normalized graph cut, we devise a token cut loss on the attention map as regularization to improve IdleViT’s token selection ability. Our method is simple yet effective and can be extended to pyramid ViTs since no token is completely dropped. Extensive experimental results on various ViT architectures have shown that IdleViT can diminish the complexity of pretrained ViTs by up to 33% with no more than 0.2% accuracy decrease on ImageNet, after finetuning for only 30 epochs. Notably, when the keep ratio is 0.5, IdleViT outperforms the state-of-the-art EViT on DeiT-S by 0.5% higher accuracy and even faster inference speed. The source code is available in the supplementary material.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_3
DP  - Springer Link
SP  - 28
EP  - 41
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - No Token Left Behind
L4  - https://arxiv.org/pdf/2310.05654
KW  - Efficient Vision Transformer
KW  - Token Idle
ER  - 

TY  - CONF
TI  - LiDAR Inpainting of UAV Based 3D Point Cloud Using Supervised Learning
AU  - Talha, Muhammad
AU  - Hussein, Aya
AU  - Hossny, Mohammed
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Unmanned Aerial Vehicles (UAV) can quickly scan unknown environments to support a wide range of operations from intelligence gathering to search and rescue. LiDAR point clouds can give a detailed and accurate 3D representation of such unknown environments. However, LiDAR point clouds are often sparse and miss important information due to occlusions and limited sensor resolution. Several studies used inpainting techniques on LiDAR point clouds to complete the missing regions. However, these studies have three main limitations that hinder their use in UAV-based environment 3D reconstruction. First, existing studies focused only on synthetic data. Second, while the point clouds obtained from a UAV flying at moderate to high speeds can be severely distorted, none of the existing studies applied inpainting to UAV-based LiDAR point clouds. Third, all existing techniques considered inpainting isolated objects and did not generalise to inpainting complete environments. This paper aims to address these gaps by proposing an algorithm for inpainting point clouds of complete 3D environments obtained from a UAV. We use a supervised learning encoder-decoder model for point cloud inpainting and environment reconstruction. We tested the proposed approach for different LiDAR parameters and different environmental settings. The results demonstrate the ability of the system to inpaint the objects with a minimum average Chamfer Distance (CD) loss of 0.028 at a UAV speed of 5 ms$$^{-1}$$-1. We present the results of the 3D reconstruction for a few test environments.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_17
DP  - Springer Link
SP  - 203
EP  - 214
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - 3D Reconstruction
KW  - LiDAR inpainting
KW  - Point clouds
ER  - 

TY  - CONF
TI  - Superpixel Attack
AU  - Oe, Issa
AU  - Yamamura, Keiichiro
AU  - Ishikura, Hiroki
AU  - Hamahira, Ryo
AU  - Fujisawa, Katsuki
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is available at https://github.com/oe1307/SuperpixelAttack.git.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_12
DP  - Springer Link
SP  - 141
EP  - 152
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - adversarial attack
KW  - computer vision
KW  - deep learning
KW  - security for AI
ER  - 

TY  - CONF
TI  - Large-Kernel Attention Network with Distance Regression and Topological Self-correction for Airway Segmentation
AU  - Hu, Yan
AU  - Meijering, Erik
AU  - Song, Yang
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Airway segmentation is a prerequisite for diagnosing and screening pulmonary diseases. While computer aided algorithms have achieved great success in various medical image segmentation tasks, it remains a challenge in keeping the continuity of airway branches due to the special tubular shape. Some existing airway-specific segmentation models introduce topological representations such as neighbor connectivity and centerline overlapping into deep models and some other methods proposed customized network modules or training strategies based on the characteristics of airways. In this paper, we propose a large-kernel attention block to enlarge the receptive field as well as maintain the details of thin branches. We reformulate the segmentation problem into pixel-wise segmentation and connectivity prediction with a differentiable connectivity modeling technique, and also propose a self-correction loss to minimize the difference between these two tasks. In addition, the binary ground truth is transformed into distances from the boundary, and distance regression is used as additional supervision. Our proposed model has been evaluated on two public datasets, and the results show that our model outperforms other benchmark methods.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_10
DP  - Springer Link
SP  - 115
EP  - 126
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Airway segmentation
KW  - distance regression
KW  - large-kernel attention
KW  - self-correction loss
KW  - tubular structure
ER  - 

TY  - CONF
TI  - 3RE-Net: Joint Loss-REcovery and Super-REsolution Neural Network for REal-Time Video
AU  - Ge, Liming
AU  - Jiang, David Zhaochen
AU  - Bao, Wei
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Real-time video over the Internet suffers from packet loss and low network bandwidth. The receiving side may receive down-sampled video with damaged frames. In this work, we are motivated to enhance the quality of video by joint loss recovery and super-resolution. We propose Joint Loss-REcovery and Super-REsolution Neural Network for REal-time Video (3RE-Net), to recover the loss and super-resolve a damaged frame. 3RE-Net has two unprecedented advantages: (1) It only utilizes preceding frames and the current frame as input, as waiting for future frames causes additional delay, which is not suitable for real-time video streaming. (2) 3RE-Net induces small inference delay, which is applaudable for real-time videos. To mitigate computational workload, we jointly process the loss recover and super-resolve by reusing motions and features beneficial for both super-resolution and loss recovery. The design of 3RE-Net can be summarized as follows: It first extracts motions and features from the frames, and propagates the extracted motions and features through warping, synthesis, feature-level alignment, and deep detail refinement modules. Through this way, we can first obtain a set of warped candidate frames, which are later used to generate spatio-temporal consistent feature maps through synthesis and alignment. The output frame can be reconstructed by the feature maps in high resolution and loss free. We conduct experiments to compare 3RE-Net with state-of-the-art benchmark schemes. Results demonstrate that 3RE-Net outperforms all existing benchmarks in terms of both quality and delay.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_14
DP  - Springer Link
SP  - 165
EP  - 177
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
ST  - 3RE-Net
KW  - Motion estimation
KW  - Video enhancement
KW  - Video loss recovery
KW  - Video super-resolution
ER  - 

TY  - CONF
TI  - Neural Networks in Forecasting Financial Volatility
AU  - Ge, Wenbo
AU  - Lalbakhsh, Pooia
AU  - Isai, Leigh
AU  - Suominen, Hanna
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - In 2020s, the state of the art (SOTA) in financial volatility forecasting is underpinned by deep learning (DL). Despite this, forecasting methods in practice tend to be dominated by their more traditional counterparts (e.g., Generalised Auto-Regressive Conditional Heteroscedasticity (GARCH) models) or relatively simple neural networks (NN), leaving much of DL unexplored. Hence, this study experimented the power of DL in forecasting financial volatility and expedited further progress in such multidisciplinary DL applications to quantitative finance by releasing open-source software and proposing a shared task. We compared the financial forecasting ability of the SOTA methods used to more recent DL work, proceeding from simpler or shallower to deeper and more complex models. Specifically, the volatility of five assets (i.e., S&P500, NASDAQ100, gold, silver, and oil) was forecast with the GARCH models, multi-layer perceptrons, recurrent NNs, temporal convolutional networks, and Temporal Fusion Transformer. The results indicated that in almost all cases, DL models forecast volatility with less error than the SOTA models in financial volatility research. These experiments were repeated and the difference between competing models was shown to be statistically significant, therefore encouraging their use in practice.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_15
DP  - Springer Link
SP  - 178
EP  - 189
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Applications
KW  - Deep learning
KW  - Economics
KW  - Financial volatility
KW  - Multidisciplinary AI
KW  - Neural networks
KW  - Time series analysis
ER  - 

TY  - CONF
TI  - Multi-graph Laplacian Feature Mapping Incorporating Tag Information for Image Annotation
AU  - Liu, Yan
AU  - Shao, Qianqian
AU  - Cheng, Rui
AU  - Liu, Weifeng
AU  - Liu, Baodi
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Automatic image annotation has exerted a tremendous fascination of many researchers with the development of multimedia and computer vision. However, most methods employ graph learning omit to combine the label information with the manifold structure between samples or utilize the single graph when computing the sample graph. Furthermore, the visual content is ignored in the process of computing the manifold structure between labels. These drawbacks lead to incomplete and inaccurate manifold information. To this end, we propose a Multi-graph Laplacian Feature Mapping Incorporating Tag Information method for image annotation. Our method firstly combines the label information with the Laplacian eigenmaps, and multi-graphs are utilized to maintain the local geometric structure of samples. Then the visual content is taken into account to obtain tag correlations. Afterward, a sea of empirical evaluations is conducted on three benchmark datasets to prove the effectiveness of the proposed method.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8388-9_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-88-9
KW  - Automatic image annotation
KW  - label information
KW  - Laplacian feature mapping
KW  - multi-graphs
KW  - visual content
ER  - 

TY  - CONF
TI  - Underwater Image Enhancement and Restoration Techniques: A Comprehensive Review, Challenges, and Future Trends
AU  - Wang, Mingjie
AU  - Lan, Fengquan
AU  - Su, Zezhao
AU  - Chen, Weiling
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Underwater optical images serve as crucial carriers and representations of ocean information. They play a vital role in the field of marine exploration. However, the quality of images captured by underwater cameras often falls short of the expected standards due to the complex underwater environment. This limitation significantly hampers the application and advancement of intelligent underwater image processing systems. Consequently, underwater image enhancement and restoration have been attracting extensive research efforts. In this paper, we review the degradation mechanisms and imaging models of underwater images, and summarize the challenges associated with underwater image enhancement and restoration. Meanwhile, we provide a comprehensive overview of the research progress in underwater optical image enhancement and restoration, and introduces the publicly available underwater image datasets and commonly-used quality evaluation metrics. Through extensive and systematic experiments, the superiority and limitations of underwater image enhancement and restoration methods are further explored. Finally, this review discusses the existing issues in this field and prospects future research directions. It is hoped that this paper will provide valuable references for future studies and contribute to the advancement of research in this domain.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_1
DP  - Springer Link
SP  - 3
EP  - 18
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - Underwater Image Enhancement and Restoration Techniques
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_1.pdf
KW  - Image quality assessment
KW  - Object detection
KW  - Underwater image enhancement
KW  - Underwater image restoration
KW  - Underwater optical imaging
ER  - 

TY  - CONF
TI  - Visualization Research on Industry and Spatial Distribution of Industrial Heritage in New China
AU  - Senni, E.
AU  - Shen, Huaping
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Aiming at the spatial distribution and industrial distribution characteristics of industrial heritage built after 1949 in China, using visual analysis methods such as kernel density analysis diagram, point distribution diagram, pie chart, and chord diagram, a macroscopic analysis of the industrial heritage of New China is carried out from the perspectives of overall and regional research. The results show that the industrial heritage of New China is mainly distributed in central and south-western China as well as in the north-east. Spatially, it is characterised by macro-uniformity and micro-agglomeration; in terms of industrial characteristics, the industrial heritage industry types in the border areas are dominated by a single heavy industry, while those in the inland areas are more abundant. In addition, nearly half of the industrial heritage of science and technology is located in southwest China, and the industrial heritage of transportation is mainly located in east and central China. Finally, the future development of China’s industrial heritage conservation and reuse is reflected upon and foreseen.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_9
DP  - Springer Link
SP  - 110
EP  - 121
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_9.pdf
KW  - Industrial Heritage
KW  - New China
KW  - Visualization Research
ER  - 

TY  - CONF
TI  - Double-Stream Network for Clothes-Changing Person Re-identification Based on Clothes Related Feature Suppression and Attention Mechanism
AU  - Wang, Dingyi
AU  - Du, Haishun
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - The standard person re-identification task has a basic assumption that pedestrians will not change their clothes. However, in a more realistic and challenging scenario for clothes-changing person re-identification, this assumption does not hold, resulting in the failure of most mainstream methods in this scenario. To this end, a double-stream network for clothes-changing person re-identification based on clothes related feature suppression and attention mechanism is proposed. Firstly, the network is composed of a clothes feature stream and a pedestrian feature stream. By using attention modules on the two streams, salient clothes features and pedestrian features are extracted respectively. Then, the clothes related feature suppression module is used in the pedestrian feature stream to force it to learn clothes unrelated features. Finally, the triplet loss and cross entropy loss are used to supervise the training of the network. The ablation experiment shows that each module effectively improves the performance of the model. A large number of experiments on the PRCC and VC-Clothes datasets have been conducted in order to assess the proposed model. The experimental results show that the accuracy of mAP and Rank-1 is improved compared with other representative methods.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_16
DP  - Springer Link
SP  - 208
EP  - 219
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_16.pdf
KW  - Clothes Related Feature Suppression Module
KW  - Clothes-Changing Person re-identification
KW  - Computer Vision
KW  - Deep Learning
ER  - 

TY  - CONF
TI  - A Optical Flow-Based Fight Behavior Detection Method for Campus Scene
AU  - Yang, Shu
AU  - Li, Yali
AU  - Wang, Shengjin
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Campuses contain a large number of facilities that must all be monitored to ensure security. However, most of the existing video surveillance needs to be watched by people, and it is impossible to realize the automatic early warning of some dangerous situations. In this paper, a video-based action detection method is proposed for high-frequency student fight on campus, which uses an optical flow algorithm to perform coarse positioning of the area where fight actions may occur and uses the transformer network to identify the action category of the region of interest. In addition, this paper builds a dataset of fight recognition in middle school campuses for model training, validation and testing. The experimental results show that the method proposed in this paper can locate fight actions relatively accurately and provide real-time early warning.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_14
DP  - Springer Link
SP  - 181
EP  - 193
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_14.pdf
KW  - Action recognition
KW  - Fight detection
KW  - Optical flow
KW  - Video swin transformer
ER  - 

TY  - CONF
TI  - A Method for Enhancing the Quality of Compressed Videos Based on 2D Convolution and Aggregating Spatio-Temporal Information
AU  - Liu, Pengyu
AU  - Jin, Pengcheng
AU  - Chen, Shanji
AU  - Huang, Weiwei
AU  - Wang, Sirong
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Existing block-based video coding frameworks are often affected by the quantization step size and motion compensation accuracy, resulting in the loss of high-frequency information and compression artifacts. Especially in the case of limited coding resources, the blurring of content edges and obvious compression distortion will have a negative impact on the subjective quality of the video. Therefore, there is an urgent need to build a quality enhancement method to improve the compressed video quality at the receiving end under the same coding resources. This paper proposes a compression video quality enhancement method based on 2D convolution that aggregates spatial and temporal information. Based on the objective facts of analyzing the spatiotemporal correlation and video quality fluctuation, this method constructs a multi-frame input mechanism consisting of the current frame to be enhanced and its adjacent frames; furthermore, it efficiently extracts and integrates the temporal and spatial information features of the input video sequence by utilizing the excellent feature extraction and fusion capabilities of the encoder-decoder structure, achieving implicit alignment. On this basis, an attention mechanism is integrated to more accurately locate and extract key information in the video, thereby more accurately restoring the detail information in the video and improving the performance of the model. In public benchmark tests, our method achieved average ΔPSNR gains of 0.801 dB, 0.796 dB, 0.792 dB, and 0.714 dB on 18 video test sequences with QP = 22, 27, 32, and 37, respectively, outperforming other methods. Compared with the state-of-the-art algorithms, our method achieved speed improvements of 13.2%, 10.5%, and 6.2% for processing videos with resolutions of 832 × 480, 1080 × 720, and 1920 × 1080, respectively. The above results show that our method can improve the compressed video quality at the receiving end under the same coding resources and outperforms other methods in terms of performance.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_4
DP  - Springer Link
SP  - 42
EP  - 52
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_4.pdf
KW  - compressed video
KW  - deep learning
KW  - quality enhancement
ER  - 

TY  - CONF
TI  - MAIM-VO: A Robust Visual Odometry with Mixed MLP for Weak Textured Environment
AU  - Shen, Zhiwei
AU  - Kong, Bin
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Visual localization is a critical technology for visual SLAM systems, which determines the relative position and motion trajectory by tracking feature points. In recent years, deep learning has been widely applied to the field of visual localization. The method based on deep learning is capable of surpassing the limitations of traditional manual feature extraction methods and achieving high-precision visual localization in complex scenes, thus realizing the goal of lifelong SLAM. The MLP model has characteristics such as flexibility and adaptability. The Mixer-WMLP achieves token information exchange between spatial positions by evenly dividing the feature map into non-overlapping windows, which makes the Mixer-WMLP approach a global receptive field. Compared to CNNs and Transformers, Mixer MLPs have higher computational efficiency and robustness. In this paper, we utilize the Mixer MLP structure to design a deep learning-based visual odometry system called MAIM-VO. Even in complex scenes with low texture areas, high-quality matching can be achieved. After obtaining the matching point pairs, the camera pose is solved in an optimized way by minimizing the reprojection error of the feature points. Multiple datasets and experiments in real-world environments have demonstrated that MIAM-VO exhibits higher robustness and relative localization accuracy compared to currently popular visual SLAM systems.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_6
DP  - Springer Link
SP  - 67
EP  - 79
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - MAIM-VO
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_6.pdf
KW  - Life SLAM
KW  - Mixer MLP
KW  - Receptive field
KW  - Visual Odometry
ER  - 

TY  - CONF
TI  - 3D Shape Similarity Measurement Based on Scale Invariant Functional Maps
AU  - Wang, Ning
AU  - Zhang, Dan
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - In recent years, the research focus on shape analysis has centered around the similarity and consistency of 3D models. The matching results derived from this analysis have broad applications in various fields, including shape retrieval and symmetry detection. Shape similarity measurement primarily encompasses feature extraction and distance calculation, with the challenge of effectively handling the non-rigid transformation of shapes. However, most existing shape similarity measurement methods neglect the scale invariance of shapes during feature extraction, rendering them unsuitable for the current task. In this paper, we propose the construction of a 3D signature called AvgSI, which is based on scale-invariant functional maps. AvgSI is a shape descriptor that leverages Laplace-Beltrami operators to efficiently extract geometric and topological information from 3D models. It is capable of extracting high-level features from multiple characteristics. By combining AvgSI with the scale-invariant BCICP (bijective and continuous Iterative Closest Point), we establish an effective pipeline for measuring the similarity of 3D models. This is achieved by calculating the correlation coefficient distance between the AvgSI values of the 3D shapes. Through comprehensive comparisons with the initial BCICP, our proposed method demonstrates stronger scale invariance, topological robustness, and isometric invariance. Results from a series of experiments validate the suitability of our framework for measuring the similarity of 3D models.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_8
DP  - Springer Link
SP  - 95
EP  - 109
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_8.pdf
KW  - 3D shape similarity
KW  - BCICP
KW  - Laplace-Beltrami operator
KW  - scale invariance
KW  - shape feature
ER  - 

TY  - CONF
TI  - Infrared Small Target Detection Based on Prior Weighed Sparse Decomposition
AU  - Yang, Dongning
AU  - Zhang, Haopeng
AU  - Xie, Fengying
AU  - Jiang, Zhiguo
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Infrared small target detection is a critical topic and research focus in target detection. Compared to visible light and radar detection, infrared imaging-based detection can effectively avoid illumination limitations and potential exposure risks. However, detecting small infrared targets with complex backgrounds and significant noise is challenging, and existing algorithms often have low detection rates, high false alarm rates, long calculation times, and unsatisfactory performance. To address these issues, we proposes an infrared small target detection algorithm based on sparse representation. The algorithm enhances target sparsity through multi-scale contrast saliency mapping and global gray value fusion, leveraging the low rank of the background. We evaluate the proposed method on SIRST dataset and compare its performance with traditional and recent algorithms. The results demonstrate the superiority of our algorithm in terms of detection rate, false alarm rate, and calculation time.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_11
DP  - Springer Link
SP  - 141
EP  - 153
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_11.pdf
KW  - Infrared image
KW  - Small target detection
KW  - Sparse decomposition
ER  - 

TY  - CONF
TI  - CPML: Category Probability Mask Learning for Fine-Grained Visual Classification
AU  - Teng, Shangzhi
AU  - Mei, Changwang
AU  - You, Xindong
AU  - Lyu, Xueqiang
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Fine-Grained Visual classification (FGVC) is a fundamental problem in computer vision. FGVC is determined by subtle appearance difference of local parts, which thus inspires many part-based methods. Different from attention-based methods and other part-based methods, we propose a novel Category Probability Mask Learning (CPML) module to discover nuanced local differences and mitigate cluttered backgrounds. Meanwhile, the CPML is a simple and efficient module, which can be applied to both convolution neural networks and vision transformers to enhance the ability of feature representation. In addition, we utilize a Category Consistency Loss (CCL) to promote the robustness and discrimination of learned backbone deep features. It is worth mentioning that we only use global branch at test stage because the global feature is already regularized by the part features with CPML and CCL in training steps. Compared with current state-of-the-art methods, our methods achieve promising performance on three widely used FGVC datasets.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_12
DP  - Springer Link
SP  - 154
EP  - 166
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - CPML
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_12.pdf
KW  - computer vision
KW  - consistent learning
KW  - fine-grained visual classification
KW  - soft attention
ER  - 

TY  - CONF
TI  - Attention-Guided Neural Network for Face Mask Detection
AU  - Zhang, Bowen
AU  - Li, Shuyi
AU  - Wang, Zhuming
AU  - Wu, Lifang
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - With the outbreak of COVID-19 and various influenza diseases, it is necessary to wear masks properly in crowded public places to prevent the spread of the virus. Therefore, detecting mask-wearing efficiently and accurately is essential for people’s physical health and safety. In this paper, we present a novel one-stage mask detection method, named attention-guided neural network (AGNN) that can efficiently detect non-mask-wearing faces in public. Specifically, we started with YOLOv5 as a baseline and integrated the coordinate attention mechanism module into YOLOv5 to guide the holistic model for improving the ability of feature extraction. Furthermore, we explored utilizing the focal loss to solve the problem of class imbalance. The experiment is conducted on the face mask detection dataset of real-life scenes with twenty different categories. Experimental results demonstrate that the proposed AGNN method achieves higher precision and recall than the original YOLOv5 in multi-classification mask detection.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_15
DP  - Springer Link
SP  - 194
EP  - 207
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_15.pdf
KW  - Attention mechanism
KW  - Face mask detection
KW  - Focal Loss
KW  - One-stage detector
ER  - 

TY  - CONF
TI  - Multimedia-Based Informal Learning in Museum Using Augmented Reality
AU  - Zhao, Mengze
AU  - Ma, Shining
AU  - Liu, Yue
AU  - Song, Weitao
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Many studies have demonstrated that augmented reality (AR) learning environments could effectively enhance learning efficiency in formal education compared to real learning environments. Furthermore, multimedia learning in AR has been shown to significantly improve learning performance and reduce cognitive load. However, few studies have explored the impact of AR environments on cognitive load and learning performance in informal learning, such as museum education. This study aims to fill this gap and investigate the impact of the relationship between the visual and auditory channels on knowledge acquisition and cognitive load in AR, as quantified by various indicators including heart rate variability, knowledge questionnaire score, user preference, and NASA-TLX. The results of within-group experiments suggested that the combination of visual and auditory information can substantially improve learning performance and reduce the task load compared to single-channel information delivery.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_5
DP  - Springer Link
SP  - 53
EP  - 64
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_5.pdf
KW  - Augmented Reality
KW  - Cognitive Load
KW  - Informal learning
KW  - Museum Education
ER  - 

TY  - CONF
TI  - SCGTS: Semantic Content Guiding Teacher-Student Network for Group Activity Recognition
AU  - Xi, Zeyu
AU  - Shi, Ge
AU  - Wu, Lifang
AU  - Li, Xuefen
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Group activity recognition refers to the process of comprehending the activity performed by multi-person in a video. However, most methods need predefined individual labels during training or testing, which is impractical and lacks intelligence. Moreover, they only consider visual features and ignore corresponding semantic information. To address these issues, a Semantic Content Guiding Teacher-Student (SCGTS) network is developed. SCGTS depends neither on predefined individual labels nor on any detection methods. It utilizes a large-scale language model as the teacher network to extract content features from textual descriptions of labels. The semantic content features are then used to supervise the training of the baseline network which serves as the student network. In this way, the student network is enforced to mimic the teacher network to extract visual features with semantic information. Experiments on 2 challenging benchmarks, including Volleyball and NBA, demonstrate SCGTS outperforms the baseline network and achieves the leading performance.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_10
DP  - Springer Link
SP  - 125
EP  - 140
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - SCGTS
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_10.pdf
KW  - Group activity recognition
KW  - Semantic content guiding
KW  - Teacher-student network
ER  - 

TY  - CONF
TI  - TSR-Net: A Two-Step Reconstruction Approach for Cherenkov-Excited Luminescence Scanned Tomography
AU  - Zhang, Wenqian
AU  - Feng, Jinchao
AU  - Li, Zhe
AU  - Sun, Zhonghua
AU  - Jia, Kebin
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Cherenkov-excited luminescence scanned tomography (CELST) can recover a high-resolution 3D distribution of luminescent sources within tissue. However, reconstructing the distribution of the quantum field from boundary measurements is a typical ill-posed problem. In this work, we propose a novel two-step reconstruction network (TSR-Net) based on a fusion mechanism, that integrates two encoder-decoder networks (ED-Net) using a concatenation block. Firstly, an ED-Net is trained to learn the CT structural features of tissues with the measured data. Then, the trained ED-Net is fixed and cascaded by another ED-Net for a second-step training to predict the 3D distributions. Numerical simulations reveal that the proposed approach can not only accurately reconstruct the intensity values of the luminescent sources, but also achieve a reconstruction resolution of 1mm with low target-background contrast. Furthermore, the well-trained network is still effective in the reconstruction of tissues with different shapes, which indicates an excellent generalization ability of the algorithm.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_3
DP  - Springer Link
SP  - 30
EP  - 41
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - TSR-Net
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_3.pdf
KW  - Cherenkov-excited luminescence scanned imaging
KW  - feature fusion
KW  - generalization ability
KW  - tomography
ER  - 

TY  - CONF
TI  - A Self-supervised Learning Reconstruction Algorithm with an Encoder-Decoder Architecture for Diffuse Optical Tomography
AU  - Li, Yaxuan
AU  - Wei, Chengpu
AU  - Zhang, Wenqian
AU  - Li, Zhe
AU  - Sun, Zhonghua
AU  - Jia, Kebin
AU  - Feng, Jinchao
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Diffuse optical tomography (DOT) is an emerging non-invasive optical imaging technique, which has a promising application in breast cancer detection and diagnosis. However, the conventional image reconstruction algorithm in DOT is time-consuming and easy to error when recovering the distribution of optical parameters within the complete tissue. In this paper, we present an end-to-end reconstruction algorithm for DOT based on a deep convolutional encoder-decoder architecture, which consists of a data processing part and a convolutional encoder-decoder net. Its effectiveness was evaluated using simulation data. The results show that the overall quality of our method is significantly improved compared with the traditional algorithm based on the FEM method, the single inclusion deviation is reduced by 150% compared with the traditional algorithm, the standard deviation is reduced by 50%; multiple inclusions deviation is reduced by 100% and the standard deviation by 38.7%.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_2
DP  - Springer Link
SP  - 19
EP  - 29
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_2.pdf
KW  - Convolutional neural network
KW  - Deep learning
KW  - Diffusion optical tomography (DOT)
KW  - Image reconstruction
KW  - NIRFAST
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Visual SLAM Algorithm Based on Target Detection and Direct Geometric Constraints in Dynamic Environments
AU  - Lin, Jun
AU  - Feng, Zhengyong
AU  - Tang, Jialiang
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - To enhance the localization accuracy and robustness of the visual SLAM algorithm in dynamic environments, this paper proposes a methodology that relies on target detection and direct geometric constraints. The algorithm first obtains static feature points and possible dynamic feature points of the current frame using a YOLOV7 target detection network. It then judges the real dynamic target using the geometric change relationship between the edges connecting the feature points of two adjacent frames. Based on the motion information of the dynamic target in past frames, the potential dynamic targets of the current frame are again examined, all feature points in the dynamic target frame are removed. Comparative experiments on the TUM dataset show that the proposed algorithm reduces the absolute trajectory error by an average of 94.69% compared to ORB-SLAM2. It outperforms mainstream dynamic vision SLAM schemes such as Dyna-SLAM and DS_SLAM in terms of localization accuracy.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_7
DP  - Springer Link
SP  - 80
EP  - 94
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_7.pdf
KW  - Dynamic Environments
KW  - Geometric Constraints
KW  - SLAM
KW  - Target Detection
ER  - 

TY  - CONF
TI  - DPFMN: Dual-Path Feature Match Network for RGB-D and RGB-T Salient Object Detection
AU  - Wen, Xinyu
AU  - Feng, Zhengyong
AU  - Lin, Jun
AU  - Xiao, Xiaomei
A2  - Yongtian, Wang
A2  - Lifang, Wu
T3  - Communications in Computer and Information Science
AB  - Feature match is a hot research topic in salient object detection, because the information definition is complex and it is difficult to explore an effective match strategy. In this paper, we propose a Dual-Path Feature Match Network (DPFMN) to enhance the cross-modal and global-local match efficiency. Specifically, in the cross-modal match, we propose the Auxiliary-enhanced Module (AEM) to excavate the auxiliary information. In the global-local match, we propose the Capsule Correlation Module (CCM) to store information hierarchically in the sub-capsules, which can enhance the correlation from global to local features. Also, we design the Guided Fusion Module (GFM) to integrate global-local features in a distributed manner to ensure information integrity. Considering the quality and detail of the saliency map, we introduce the Saliency Reconstruct Module (SRM) for progressive image reconstruction to avoid the unstable reconstruction information caused by too large gradients. The method proves its effectiveness through a fair comparison with 12 RGB-D and 7 RGB-T networks on 8 public datasets.
C1  - Singapore
C3  - Image and Graphics Technologies and Applications
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-7549-5_13
DP  - Springer Link
SP  - 167
EP  - 180
LA  - en
PB  - Springer Nature
SN  - 978-981-9975-49-5
ST  - DPFMN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-7549-5_13.pdf
KW  - Capsule Network
KW  - Feature Integrity
KW  - Feature Matching
KW  - RGB-D Salient Object Detection
KW  - RGB-T Salient Object Detection
KW  - Saliency Map Reconstruction
ER  - 

TY  - CONF
TI  - An Optimized Convolutional Neural Network Model for Wild Animals Detection Using Filtering Techniques and Different Opacity Levels
AU  - Bodavarapu, Pavan Nageswar Reddy
AU  - Narayan, T. Ashish
AU  - Srinivas, P. V. V. S.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Despite the fact that there are numerous ways for object identification, these techniques under-perform in real-world conditions. For example, heavy rains and fog at night. As a result, this research work has devised a new convolutional neural network for identifying animals in low-light environments. In the proposed system, images of different animals (containing both domestic and wild animals) are collected from various resources in the form of images and videos. The overall number of samples in the dataset is 2300; however, because convolutional neural networks require more samples for training, a few data augmentation techniques are employed to raise the number of samples in the dataset to 6700. Horizontal flip, rotation, and padding are the data augmentation techniques. The proposed model has achieved an accuracy of 0.72 on the testing set and 0.88 on training set, respectively, without applying the edge detection techniques. The proposed model has achieved 0.81 accuracy after using Canny edge detection technique on animal dataset for outperforming the state-of-the-art models with ResNet-50 and EfficientNet-B7.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_1
DP  - Springer Link
SP  - 1
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_1.pdf
KW  - Animal detection
KW  - Convolutional neural network
KW  - Deep learning
KW  - Edge detection
KW  - Object detection
ER  - 

TY  - CONF
TI  - Audio Denoising Using Deep Neural Networks
AU  - Mohammed, S. Jassem
AU  - Radhika, N.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Improving speech quality is becoming a basic requirement with increasing interest in speech processing applications. A lot of speech enhancement techniques are developed to reduce or completely remove listeners fatigue from various devices like smartphones and also from online communication applications. Background noise often interrupts communication, and this was solved using a hardware physical device that normally emits a negative frequency of the incoming audio noise signal to cancel out the noise. Deep learning has recently made a break-through in the speech enhancement process. This paper proposes an audio denoising model which is built on a deep neural network architecture based on spectrograms (which is a hybrid between frequency domain and time domain). The proposed deep neural network model effectively predicts the negative noise frequency for given input incoming audio file with noise. After prediction, the predicted values are then removed from the original noise audio file to create the denoised audio output.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_3
DP  - Springer Link
SP  - 33
EP  - 47
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_3.pdf
KW  - Activation function
KW  - Audio synthesizing
KW  - Deep neural network
KW  - Preprocessing
KW  - Sampling rate
KW  - Spectrogram
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - Novel Intelligent System for Medical Diagnostic Applications Using Artificial Neural Network
AU  - Anithaashri, T. P.
AU  - Rajendran, P. Selvi
AU  - Ravichandran, G.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In recent years, the recognition of images with feature extraction in medical applications is a big challenge. It is a tough task for the Doctors to diagnose the diseases through image recognition with the scanned images or x-ray images. To enhance the image recognition with feature extraction for the medical applications, a novel intelligent system has been developed using artificial neural network. It gives high efficiency in recognizing the image with feature extraction compared over fuzzy logic system. The artificial neural network algorithm was used for the feature extraction from the scanned images of patients. The implementation has been carried out with the help of Tensor flow and Pytorch. The algorithms was tested over 200 sets of scanned images has been utilized for the classification and prediction of trained dataset images. The analysis on the data set and test cases has been performed successfully and acquired 81% of accuracy for the image recognition using artificial neural network algorithm. With the level of significance (p < 0.005), the resultant data depicts the reliability in independent sample t tests. The process of prediction of accuracy for the image recognition, through the ANN gives significantly better performance than the fuzzy logic system.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_7
DP  - Springer Link
SP  - 93
EP  - 101
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_7.pdf
KW  - Artificial neural network
KW  - Feature extraction
KW  - Fuzzy logic system
KW  - Image recognition
KW  - Novel diagnostic system
ER  - 

TY  - CONF
TI  - Extracting Purposes from an Application to Enable Purpose Based Processing
AU  - Jain, Amruta
AU  - Mane, Sunil
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In general, applications are built to serve certain business purposes. For example, a bank invests into an application development to offer its customers online services such as online shopping, FD services, utility bill payments, etc. Within the application, every screen has its own purpose. For example, the login page is used to authenticate a customer. Dashboard screen gives a high-level view of activities done by a customer. Similarly, every field appearing on the screen has purpose too. The username field of login screen enables customer to supply a username given to the customer by the bank. Every screen of a given enterprise application is not developed keeping the exact purposes in mind. Many a times, a screen may serve multiple purposes. While an application screen may serve different purposes and an application with less number of screens suits an enterprise in terms of reduced expenditure for the development and subsequent maintenance activities, it is at loggerhead with privacy laws which are demanding purpose-based processing. Therefore, it is necessary to first build a repository of purposes that a given application can serve. And, then subsequent refactoring of application can be done (if required) to comply with privacy laws. To find out purposes, we use keyword extraction method, K-means clustering on text data of application, to get keywords and respective purposes.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_8
DP  - Springer Link
SP  - 103
EP  - 113
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_8.pdf
KW  - Crawljax
KW  - html parser jsoup
KW  - K-means
KW  - Keyword extraction
KW  - Purpose repository
KW  - Similarity
KW  - tf-idf
KW  - Web data
ER  - 

TY  - CONF
TI  - Partially Supervised Image Captioning Model for Urban Road Views
AU  - Srihari, K.
AU  - Sikha, O. K.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Automatically generating a characteristic language portrayal of an image has pulled in interests in light of its significance in practical applications and on the grounds that it associates two significant artificial intelligence fields: natural language processing and computer vision. This paper proposes a partially supervised model for generating image descriptions based on instance segmentation labels. Instance segmentation, a combined approach of object detection and semantic segmentation is used for generating instance level labels which is then used for generating natural language descriptions for the image. The instance segmentation model uses MRCNN framework with feature pyramid networks and region proposal networks for object detection, and fully convolution layer for semantic segmentation. Information obtained from different local region proposals are used to generate region wise captions. Important aspects of the caption include distance, color and region calculations based on the results obtained from the instance segmentation layers. This paper uses instance segmentation layer information such as ROIs, class labels, probability scores and segmentation values for generating effective captions for the image. The proposed model is evaluated on Cityscape dataset where the primary objective is to provide semantic scene understanding based on the instances available in urban areas.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_5
DP  - Springer Link
SP  - 59
EP  - 73
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_5.pdf
KW  - Instance segmentation
KW  - MRCNN (Mask region based convolution neural networks) framework
KW  - Partially supervised model
ER  - 

TY  - CONF
TI  - Ease and Handy Household Water Management System
AU  - Priyadharsini, K.
AU  - Dhanushmathi, S. K.
AU  - Dharaniga, M.
AU  - Dharsheeni, R.
AU  - Dinesh Kumar, J. R.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Managing waste water is one of the important things that is directly connected to the entire water chain and so it is essential to manage water utility. This is the right time to start saving water as population increases drastically along with which the necessity of water increases. For an instance, about 85 L/day of water is wasted on an average by a family. The water we save today will serve tomorrow, by this way though there are lots of technologies in saving water wastage, this project is all about narrowing down all the technologies and making an IOT application which not only makes water management at home easy but also make it handy which indeed helps to monitor and access the household water even at the absence of physical presence.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_6
DP  - Springer Link
SP  - 75
EP  - 91
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_6.pdf
KW  - Handy device
KW  - IOT
KW  - Portable
KW  - Water management
ER  - 

TY  - CONF
TI  - Cotton Price Prediction and Cotton Disease Detection Using Machine Learning
AU  - Tanwar, Priya
AU  - Shah, Rashi
AU  - Shah, Jaini
AU  - Lokhande, Unik
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Agricultural productivity is something on which the economy extensively depends. This is one reason why price prediction and plant disease detection play an important role in agriculture. The proposed system is an effort to predict the price of cotton and classify it as fresh or sick as accurately as possible for the benefit of all those who depend on it as a source of income, be they farmers or traders. The main goal of the created system is the prevention of losses and the boost of the economy. For this purpose, we have proposed a website in which both the price prediction using LSTM algorithm and disease detection by CNN algorithm are implemented.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_9
DP  - Springer Link
SP  - 115
EP  - 128
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_9.pdf
KW  - Agriculture
KW  - Classification
KW  - CNN
KW  - Disease detection
KW  - LSTM
KW  - Machine learning
KW  - Price prediction
ER  - 

TY  - CONF
TI  - Concept and Development of Triple Encryption Lock System
AU  - Ahamed, A. Fayaz
AU  - Prathiksha, R.
AU  - Keerthana, M.
AU  - Priya, D. Mohana
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The main aim of the triple encryption lock system is to surge the concept of security and to illuminate threats, and it allows higher authorities to authorise the concerned person to access the restricted areas. The issue of accessing highly authorised areas is paramount in all places. This system is suitable for server rooms, examination cells, home security and highly secured places. It is designed in such a way that the door has three encryptions—DTMF, password security and fingerprint sensing. We have designed it in such a way that the circuit will be in an OFF condition. The user sends a signal to audio jack frequency, then the relay is triggered, and it moves to the other two encryptions—keypad and fingerprint sensing. The attempt of our encryption system is that the microcontroller gets turned on only when the signal is sent from the user so that 24 h of heating issues are resolved. The real benefit is that it provides significant changes in accessing highly authorised areas and can bring a great change in the security system.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_4
DP  - Springer Link
SP  - 49
EP  - 57
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_4.pdf
KW  - Door lock
KW  - DTMF—dual-tone multiple frequency
KW  - Fingerprint sensor
KW  - Keypad
KW  - Microcontroller
KW  - Triple encryption lock
ER  - 

TY  - CONF
TI  - Hand Gesture Recognition for Disabled Person with Speech Using CNN
AU  - Shadiya Febin, E. P.
AU  - Nair, Arun T.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Because handicapped people account for a large percentage of our community, we should make an effort to interact with them in order to exchange knowledge, perspectives, and ideas. To that aim, we wish to establish a means of contact. Individuals who are deaf or hard of hearing can communicate with one another using sign language. A handicapped person can communicate without using acoustic noises when they use sign language. The objective of this article is to explain the design and development of a hand gesture-based sign language recognition system. To aid handicapped individuals, particularly those who are unable to communicate verbally, sign language is translated into text and subsequently into speech. The solution is based on a web camera as the major component, which is used to record a live stream video using a proprietary MATLAB algorithm. Recognition of hand movements is possible with the technology. Recognizing hand gestures is a straightforward technique of providing a meaningful, highly flexible interaction between robots and their users. There is no physical communication between the user and the devices. A deep learning system that is efficient at picture recognition is used to locate the dynamically recorded hand movements. Convolutional neural networks are used to optimize performance. A static image of a hand gesture is used to train the model. Without relying on a pre-trained model, the CNN is constructed.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_17
DP  - Springer Link
SP  - 239
EP  - 249
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_17.pdf
KW  - CNN
KW  - Gesture recognition
KW  - Human–computer interaction
KW  - MATLAB
KW  - Web camera
ER  - 

TY  - CONF
TI  - A Study on Current Research and Challenges in Attribute-based Access Control Model
AU  - Vijayalakshmi, K.
AU  - Jayalakshmi, V.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Access control models are used to identify and detect anonymous users or attacks when sharing big data or other resources in the distributed environment such as cloud, edge, and fog computing. The attribute-based access control model (ABAC) is a promising model used in intrusion detection systems. Comparing with the primary access control models: discretionary access control model (DAC), mandatory access control model (MAC), and role-based access control model, ABAC gets attention in the current research due to its flexibility, efficiency, and granularity. Despite ABAC is performing well in addressing the security requirements of today’s computing technologies, there are open challenges such as policy errors, scalability, delegations, and policy representation with heterogeneous datasets. This paper presents the fundamental concepts of ABAC and a review of current research works toward framing efficient ABAC models. This paper identifies and discusses the current challenges in ABAC based on the study and analysis of the surveyed works.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_2
DP  - Springer Link
SP  - 17
EP  - 31
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_2.pdf
KW  - Access control models
KW  - Attribute-based access control model
KW  - Big data
KW  - Cloud computing
KW  - DAC
KW  - Intrusion detection system
KW  - MAC
KW  - RBAC
ER  - 

TY  - CONF
TI  - Optimization of Patch Antenna with Koch Fractal DGS Using PSO
AU  - Viswasom, Sanoj
AU  - Santhosh Kumar, S.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - An edge fed patch antenna is designed to operate in the Wi-Fi band of 5.2 GHz. For improving the band width and for achieving multiband operation, a Koch fractal DGS structure was incorporated into the ground plane. On introduction of fractal DGS, the antenna exhibits dual-band operation at 3.9 and 6.8 GHz. In order to obtain the originally designed frequency of 5.2 GHz, the antenna structure was optimized using Particle Swarm Optimization (PSO). The optimized antenna resonates at 5.2 GHz and also at 3.5 GHz, which is the proposed frequency for 5G operations. So our optimized antenna exhibits dual-band operation and is suitable for Wi-Fi and 5G applications. Also, it provides good gain in the operating frequency bands. This novel antenna design approach provides dual-band operation with enhanced bandwidth in compact size. The antenna structure was simulated and its performance parameters evaluated using OpenEMS.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_12
DP  - Springer Link
SP  - 159
EP  - 171
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_12.pdf
KW  - Defected Ground Structure (DGS)
KW  - Koch Snowflake fractal
KW  - Microstrip antenna
KW  - Particle Swarm Optimization (PSO)
ER  - 

TY  - CONF
TI  - Intrusion Detection System Intensive on Securing IoT Networking Environment Based on Machine Learning Strategy
AU  - Jeyanthi, D. V.
AU  - Indrani, B.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The Internet of Things is the technology that is exploding in the day-to-day life of the home to the large industrial environment. An IoT connects various applications and services via the internet to make the environment contented. The way of communication among the devices leads to network vulnerability with various attacks. To protect from the security vulnerability of the IoT, the Intrusion Detection Systems (IDS) is employed in the network layer. The network packets from the interconnected IoT applications and services are stored in the Linux server on the end nodes. The packets are got from the server using the crawler into the network layer for attack prediction. Thus, the work contains the main objective is to identify and detect the intrusion among the IoT environment based on machine learning (ML) using the benchmark dataset NSL-KDD. The NSL-KDD dataset is pre-processed to sanitize the null values, eliminating the duplicate and unwanted columns. The cleaned dataset is then assessed to construct the novel custom features and basic features for the attack detection, which represent the feature vector. Novel features are constructed to reduce the learning confusion of machine learning algorithm. The feature vector with the novel and basic features is then processed by employing the feature selection strategy LASSO to get the significant features to increase the prediction accuracy. Due to the outperform of ensembled machine learning algorithms, HSDTKNN (Hybrid Stacking Decision Tree with KNN), HSDTSVM (Hybrid Stacking Decision Tree with SVM) and TCB (Tuned CatBoost) are used for classification. Tuned CatBoost (TCB) technique remarkably predicts the attack that occurs among the packets and generates the alarm. The experimental outcomes established the sufficiency of the proposed model to suits the IoT IDS environment with an accuracy rate of 97.8313%, 0.021687 of error rate, 97.1001% of sensitivity, and specificity of 98.7052%, while prediction.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_11
DP  - Springer Link
SP  - 139
EP  - 157
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_11.pdf
KW  - Custom novel features
KW  - HSDTKNN
KW  - HSDTSVM
KW  - IDS
KW  - IoT network environment
KW  - LASSO
KW  - Machine learning
KW  - NSL-KDD
KW  - PSO
KW  - TCB
ER  - 

TY  - CONF
TI  - Coronavirus Pandemic: A Review of Different Machine Learning Approaches
AU  - Singh, Bhupinder
AU  - Agarwal, Ritu
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Millions of individuals have been affected by coronavirus illness. The coronavirus epidemic offers a significant medical danger to the wider range of population. The COVID-19 disease outbreak and subsequent control strategies have created a global syndrome that has impacted all aspects of human life. The initial stage detection of COVID-19 has become a difficult task for all researchers and scientists. There exist various ML and Deep Learning techniques to detect COVID-19 disease. There are various stages of COVID-19, initially, it was spread by people who travelled from countries which were severely affected by Corona Virus. After some time, it entered the  community transmission phase. The virus has different impact on different individuals and there is no known cure found for this disease. The virus shows immediate affect on certain individuals whereas on others it takes few days to weeks for the symptoms to show but on some people it does not show any symptoms. The  most common  symptoms are dry cough, fever, lung infection, etc. This paper provides information about the several tests available for the detection of COVID-19. This paper provides a detailed comparison among the deep learning (DL) and AI (artificial intelligence) based techniques  which are used to detect COVID-19 diesease.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_18
DP  - Springer Link
SP  - 251
EP  - 263
LA  - en
PB  - Springer Nature
SN  - 9789811676109
ST  - Coronavirus Pandemic
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_18.pdf
KW  - AI
KW  - COVID-19 disease
KW  - CXR images
KW  - Stages and symptoms
ER  - 

TY  - CONF
TI  - Study on Class Imbalance Problem with Modified KNN for Classification
AU  - Sasirekha, R.
AU  - Kanisha, B.
AU  - Kaliraj, S.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Identification of data imbalance is a very challenging one in the modern era. When we go for a data warehouse, there would be a vast data available in it but managing data and sustaining the balanced state of data is very difficult to handle in any type of sector. Occurrence of data imbalance comes when specimens are classified based on their behaviour. In this paper, the imbalance state of data is analysed and the machine learning techniques are studied carefully to choose the best technique to handle data imbalance problems. Wide analysis of the k-nearest neighbour (KNN) algorithm can be carried out to keep the classification of specimens grouped equally.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_15
DP  - Springer Link
SP  - 207
EP  - 217
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_15.pdf
KW  - Classification specimens
KW  - Imbalance
KW  - KNN algorithm
ER  - 

TY  - CONF
TI  - Acute Leukemia Subtype Prediction Using EODClassifier
AU  - Abdullah, S. K.
AU  - Hasan, S. K. Rohit
AU  - Mollah, Ayatullah Faruk
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Leukemia is a type of blood cancer having two major subtypes—acute lymphoblastic leukemia and acute myeloid leukemia. A possible cause of leukemia is the genetic factors of a person. Machine learning techniques are being increasingly applied in analyzing the relation between gene expression and genetic diseases such as leukemia. In this paper, we report prediction of leukemia subtypes from microarray gene expression samples using a recently reported ensemble classifier called EODClassifier. Across multiple cross-validation experiments, classification accuracy of over 96% is obtained which reveals consistent performance and robustness. It is also demonstrated that like other popular classifiers, the EODClassifier is also performing well in leukemia prediction.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_10
DP  - Springer Link
SP  - 129
EP  - 137
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_10.pdf
KW  - Data classification
KW  - Ensemble approach
KW  - EODClassifier
KW  - Feature selection
KW  - Leukemia gene expression
ER  - 

TY  - CONF
TI  - High Spectrum and Efficiency Improved Structured Compressive Sensing-Based Channel Estimation Scheme for Massive MIMO Systems
AU  - Baranidharan, V.
AU  - Raju, C.
AU  - Naveen Kumar, S.
AU  - Keerthivasan, S. N.
AU  - Isaac Samson, S.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Due to its high spectrum and energy proficiency, massive MIMO will become the most promising technique for 5G communications in future. For accurate channel estimation, potential performance gain is essential. The pilot overhead in conventional channel approximation schemes is due to the enormous number of antennas used at the base station (BS), and also this will be too expensive; for frequency division duplex (FDD) massive MIMO, it is very much unaffordable. We introduced a structured compressive sensing (SCS)-based temporal joint channel estimation scheme which reduces pilot overhead where it requires, delay-domain MIMO channels are leveraged whereby the spatiotemporal common sparsity. The accurate channel estimation is required to fully exploit the mass array gain, which states the information at the transmitter side. However, FDD downlink channel estimation always requires more training and computation than TDD mode, even though the uplink and downlink channel is always not straightforwardly reciprocal, due to the massive number of antennas in base station. At the base station, we first introduce the non-orthogonal pilots which come under the structure of compressive sensing theory to reduce the pilot overhead where they are required. Then, a structured compressive sensing (SCS) algorithm is introduced to approximate the channels associated with all the other OFDM symbols in multiple forms, then the inadequate number of pilots is estimated, and the spatiotemporal common sparsity of massive MIMO channels is also exploited to recover the channel estimation with precision. Furthermore, we recommend a space–time adaptive pilot scheme to decrease the pilot overhead, by making use of the spatiotemporal channel correlation. Additionally, in the multi-cell scenario, we discussed the proposed channel estimation scheme. The spatial correlation in the wireless channels is exploited for outdoor communication scenarios, where mostly in wireless channels. Meanwhile, compared with the long signal transmission distance, the scale of the transmit antenna is negligible. By utilizing the greater number of spatial freedoms in massive MIMO can rise the system capacity and energy proficiency of magnitude. Simulation results will show that the proposed system outperforms than all the other existing systems.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_19
DP  - Springer Link
SP  - 265
EP  - 279
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_19.pdf
KW  - Frequency division duplexing
KW  - Massive MIMO
KW  - Pilot overhead
KW  - Structured compressive sensing
ER  - 

TY  - CONF
TI  - Severity Classification of Diabetic Retinopathy Using Customized CNN
AU  - Firke, Shital N.
AU  - Jain, Ranjan Bala
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Diabetic retinopathy is an issue that impacts the eyes due to diabetes. The problem is caused by arteries in the light-sensitive tissue in the eyeball. It is becoming extremely crucial to diagnose early important things to save many lives. This work will be classified by identifying patients with diabetic retinopathy. A convoluted neural network has been developed using K-Fold cross-validation technology to make the above diagnosis and to give highly accurate results. The image is put through convolution and max-pooling layers that are triggered with the ReLU function before being categorized. The softmax function was then utilized to complete the process by triggering the neurons in the dense layers. While learning the system, the accuracy improves, and at the same period, the loss is reduced. Image enhancement is used before installing the algorithm to reduce overfitting. The network-based convolution neural network gave a total validation accuracy of 89.14%, recall of 82%, precision of 83%, and F1-Score of 81%.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_14
DP  - Springer Link
SP  - 193
EP  - 206
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_14.pdf
KW  - Convolutional neural network
KW  - Cross validation
KW  - Deep learning
KW  - Diabetic retinopathy
KW  - K-Fold
ER  - 

TY  - CONF
TI  - Analysis of (IoT)-Based Healthcare Framework System Using Machine Learning
AU  - Lalithadevi, B.
AU  - Krishnaveni, S.
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In recent years, Internet of things (IoT) are being applied in several fields like smart healthcare, smart cities and smart agriculture. IoT-based applications are growing day by day. In healthcare industry, wearable sensor devices are widely used to track patient’s health status and their mobility. In this paper, IoT-based framework for healthcare us ing a suitable machine learning algorithm have been analysed intensely. Transmission of data using various standards are reviewed. Secure storage and retrieval of medical data using various ways are discussed. Machine learning techniques and storage mechanisms are analysed to ensure the quality of service to the patient care.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_16
DP  - Springer Link
SP  - 219
EP  - 237
LA  - en
PB  - Springer Nature
SN  - 9789811676109
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_16.pdf
KW  - Cloud computing
KW  - Fog computing
KW  - Internet of Things (IoT)
KW  - Machine learning
KW  - Security
KW  - Wearable sensors
ER  - 

TY  - CONF
TI  - Artificial Intelligence-Based Phonocardiogram: Classification Using Cepstral Features
AU  - Saritha Haridas, A.
AU  - Nair, Arun T.
AU  - Haritha, K. S.
AU  - Namboothiri, Kesavan
A2  - Hemanth, D. Jude
A2  - Pelusi, Danilo
A2  - Vuppalapati, Chandrasekar
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - When cardiovascular issues arise in a cardiac patient, it is essential to diagnose them as soon as possible for monitoring and treatment would be less difficult than in the old. Paediatric cardiologists have a difficult time keeping track of their patients’ cardiovascular condition. To accomplish this, a phonocardiogram (PCG) device was created in combination with a MATLAB software based on artificial intelligence (AI) for automatic diagnosis of heart state classification as normal or pathological. Due to the safety concerns associated with COVID-19, testing on school-aged children is currently being explored. Using PCG analyses and machine learning methods, the goal of this work is to detect a cardiac condition, whilst operating on a limited amount of computing resources. This makes it possible for anybody, including non-medical professionals, to diagnose cardiac issues. To put it simply, the current system consists of a distinct portable electronic stethoscope, headphones linked to the stethoscope, a sound-processing computer, and specifically developed software for capturing and analysing heart sounds. However, this is more difficult and time-consuming, and the accuracy is lowered as a result. According to statistical studies, even expert cardiologists only achieve an accuracy of approximately 80%. Nevertheless, primary care doctors and medical students usually attain a level of accuracy of between 20 and 40%. Due to the nonstationary nature of heart sounds and PCG's superior ability to model and analyse even in the face of noise, PCG sounds provide valuable information regarding heart diseases. Spectral characteristics PCG is used to characterise heart sounds in order to diagnose cardiac conditions. We categorise normal and abnormal sounds using cepstral coefficients, or PCG waves, for fast and effective identification, prompted by cepstral features’ effectiveness in speech signal classification. On the basis of their statistical properties, we suggest a new feature set for cepstral coefficients. The PhysioNet PCG training dataset is used in the experiments. This section compares KNN with SVM classifiers, indicating that KNN is more accurate. Furthermore, the results indicate that statistical features derived from PCG Mel-frequency cepstral coefficients outperform both frequently used wavelet-based features and conventional cepstral coefficients, including MFCCs.
C1  - Singapore
C3  - Intelligent Data Communication Technologies and Internet of Things
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-16-7610-9_13
DP  - Springer Link
SP  - 173
EP  - 191
LA  - en
PB  - Springer Nature
SN  - 9789811676109
ST  - Artificial Intelligence-Based Phonocardiogram
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-16-7610-9_13.pdf
KW  - AI
KW  - Cardiovascular disorders
KW  - Health care
KW  - Phonocardiogram
ER  - 

TY  - CONF
TI  - Box-Supervised Instance Segmentation with Level Set Evolution
AU  - Li, Wentong
AU  - Liu, Wenyu
AU  - Zhu, Jianke
AU  - Cui, Miaomiao
AU  - Hua, Xian-Sheng
AU  - Zhang, Lei
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In contrast to the fully supervised methods using pixel-wise mask labels, box-supervised instance segmentation takes advantage of the simple box annotations, which has recently attracted a lot of research attentions. In this paper, we propose a novel single-shot box-supervised instance segmentation approach, which integrates the classical level set model with deep neural network delicately. Specifically, our proposed method iteratively learns a series of level sets through a continuous Chan-Vese energy-based function in an end-to-end fashion. A simple mask supervised SOLOv2 model is adapted to predict the instance-aware mask map as the level set for each instance. Both the input image and its deep features are employed as the input data to evolve the level set curves, where a box projection function is employed to obtain the initial boundary. By minimizing the fully differentiable energy function, the level set for each instance is iteratively optimized within its corresponding bounding box annotation. The experimental results on four challenging benchmarks demonstrate the leading performance of our proposed approach to robust instance segmentation in various scenarios. The code is available at: https://github.com/LiWentomng/boxlevelset.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_1
DP  - Springer Link
SP  - 1
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_1.pdf
KW  - Box supervision
KW  - Instance segmentation
KW  - Level set
ER  - 

TY  - CONF
TI  - Point Primitive Transformer for Long-Term 4D Point Cloud Video Understanding
AU  - Wen, Hao
AU  - Liu, Yunze
AU  - Huang, Jingwei
AU  - Duan, Bo
AU  - Yi, Li
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper proposes a 4D backbone for long-term point cloud video understanding. A typical way to capture spatial-temporal context is using 4Dconv or transformer without hierarchy. However, those methods are neither effective nor efficient enough due to camera motion, scene changes, sampling patterns, and complexity of 4D data. To address those issues, we leverage the primitive plane as mid-level representation to capture the long-term spatial-temporal context in 4D point cloud videos, and propose a novel hierarchical backbone named Point Primitive Transformer (PPTr), which is mainly composed of intra-primitive point transformers and primitive transformers. Extensive experiments show that PPTr outperforms the previous state of the arts on different tasks.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_2
DP  - Springer Link
SP  - 19
EP  - 35
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_2.pdf
KW  - Long-term point cloud video
KW  - Primitive
KW  - Transformer
ER  - 

TY  - CONF
TI  - SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and Boosting Segmentation Robustness
AU  - Gu, Jindong
AU  - Zhao, Hengshuang
AU  - Tresp, Volker
AU  - Torr, Philip H. S.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Deep neural network-based image classifications are vulnerable to adversarial perturbations. The image classifications can be easily fooled by adding artificial small and imperceptible perturbations to input images. As one of the most effective defense strategies, adversarial training was proposed to address the vulnerability of classification models, where the adversarial examples are created and injected into training data during training. The attack and defense of classification models have been intensively studied in past years. Semantic segmentation, as an extension of classifications, has also received great attention recently. Recent work shows a large number of attack iterations are required to create effective adversarial examples to fool segmentation models. The observation makes both robustness evaluation and adversarial training on segmentation models challenging. In this work, we propose an effective and efficient segmentation attack method, dubbed SegPGD. Besides, we provide a convergence analysis to show the proposed SegPGD can create more effective adversarial examples than PGD under the same number of attack iterations. Furthermore, we propose to apply our SegPGD as the underlying attack method for segmentation adversarial training. Since SegPGD can create more effective adversarial examples, the adversarial training with our SegPGD can boost the robustness of segmentation models. Our proposals are also verified with experiments on popular Segmentation model architectures and standard segmentation datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_18
DP  - Springer Link
SP  - 308
EP  - 325
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - SegPGD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_18.pdf
KW  - Adversarial robustness
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - Fine-Grained Egocentric Hand-Object Segmentation: Dataset, Model, and Applications
AU  - Zhang, Lingzhi
AU  - Zhou, Shenghao
AU  - Stent, Simon
AU  - Shi, Jianbo
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Egocentric videos offer fine-grained information for high-fidelity modeling of human behaviors. Hands and interacting objects are one crucial aspect of understanding a viewer’s behaviors and intentions. We provide a labeled dataset consisting of 11,243 egocentric images with per-pixel segmentation labels of hands and objects being interacted with during a diverse array of daily activities. Our dataset is the first to label detailed hand-object contact boundaries. We introduce a context-aware compositional data augmentation technique to adapt to out-of-distribution YouTube egocentric video. We show that our robust hand-object segmentation model and dataset can serve as a foundational tool to boost or enable several downstream vision applications, including hand state classification, video activity recognition, 3D mesh reconstruction of hand-object interactions, and video inpainting of hand-object foregrounds in egocentric videos. Dataset and code are available at: https://github.com/owenzlz/EgoHOS.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_8
DP  - Springer Link
SP  - 127
EP  - 145
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - Fine-Grained Egocentric Hand-Object Segmentation
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_8.pdf
KW  - Datasets
KW  - Egocentric activity recognition
KW  - Egocentric hand-object segmentation
KW  - Hand-object mesh reconstruction
ER  - 

TY  - CONF
TI  - Adaptive Agent Transformer for Few-Shot Segmentation
AU  - Wang, Yuan
AU  - Sun, Rui
AU  - Zhang, Zhe
AU  - Zhang, Tianzhu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot segmentation (FSS) aims to segment objects in a given query image with only a few labelled support images. The limited support information makes it an extremely challenging task. Most previous best-performing methods adopt prototypical learning or affinity learning. Nevertheless, they either neglect to further utilize support pixels for facilitating segmentation and lose spatial information, or are not robust to noisy pixels and computationally expensive. In this work, we propose a novel end-to-end adaptive agent transformer (AAFormer) to integrate prototypical and affinity learning to exploit the complementarity between them via a transformer encoder-decoder architecture, including a representation encoder, an agent learning decoder and an agent matching decoder. The proposed AAFormer enjoys several merits. First, to learn agent tokens well without any explicit supervision, and to make agent tokens capable of dividing different objects into diverse parts in an adaptive manner, we customize the agent learning decoder according to the three characteristics of context awareness, spatial awareness and diversity. Second, the proposed agent matching decoder is responsible for decomposing the direct pixel-level matching matrix into two more computationally-friendly matrices to suppress the noisy pixels. Extensive experimental results on two standard benchmarks demonstrate that our AAFormer performs favorably against state-of-the-art FSS methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_3
DP  - Springer Link
SP  - 36
EP  - 52
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_3.pdf
KW  - Few-shot segmentation
KW  - Semantic segmentation
KW  - Transformer
ER  - 

TY  - CONF
TI  - TransFGU: A Top-Down Approach to Fine-Grained Unsupervised Semantic Segmentation
AU  - Yin, Zhaoyuan
AU  - Wang, Pichao
AU  - Wang, Fan
AU  - Xu, Xianzhe
AU  - Zhang, Hanling
AU  - Li, Hao
AU  - Jin, Rong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised semantic segmentation aims to obtain high-level semantic representation on low-level visual features without manual annotations. Most existing methods are bottom-up approaches that try to group pixels into regions based on their visual cues or certain predefined rules. As a result, it is difficult for these bottom-up approaches to generate fine-grained semantic segmentation when coming to complicated scenes with multiple objects and some objects sharing similar visual appearance. In contrast, we propose the first top-down unsupervised semantic segmentation framework for fine-grained segmentation in extremely complicated scenarios. Specifically, we first obtain rich high-level structured semantic concept information from large-scale vision data in a self-supervised learning manner, and use such information as a prior to discover potential semantic categories presented in target datasets. Secondly, the discovered high-level semantic categories are mapped to low-level pixel features by calculating the class activate map (CAM) with respect to certain discovered semantic representation. Lastly, the obtained CAMs serve as pseudo labels to train the segmentation module and produce the final semantic segmentation. Experimental results on multiple semantic segmentation benchmarks show that our top-down unsupervised segmentation is robust to both object-centric and scene-centric datasets under different semantic granularity levels, and outperforms all the current state-of-the-art bottom-up methods. Our code is available at https://github.com/damo-cv/TransFGU.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_5
DP  - Springer Link
SP  - 73
EP  - 89
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - TransFGU
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_5.pdf
ER  - 

TY  - CONF
TI  - Perceptual Artifacts Localization for Inpainting
AU  - Zhang, Lingzhi
AU  - Zhou, Yuqian
AU  - Barnes, Connelly
AU  - Amirghodsi, Sohrab
AU  - Lin, Zhe
AU  - Shechtman, Eli
AU  - Shi, Jianbo
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Image inpainting is an essential task for multiple practical applications like object removal and image editing. Deep GAN-based models greatly improve the inpainting performance in structures and textures within the hole, but might also generate unexpected artifacts like broken structures or color blobs. Users perceive these artifacts to judge the effectiveness of inpainting models, and retouch these imperfect areas to inpaint again in a typical retouching workflow. Inspired by this workflow, we propose a new learning task of automatic segmentation of inpainting perceptual artifacts, and apply the model for inpainting model evaluation and iterative refinement. Specifically, we first construct a new inpainting artifacts dataset by manually annotating perceptual artifacts in the results of state-of-the-art inpainting models. Then we train advanced segmentation networks on this dataset to reliably localize inpainting artifacts within inpainted images. Second, we propose a new interpretable evaluation metric called Perceptual Artifact Ratio (PAR), which is the ratio of objectionable inpainted regions to the entire inpainted area. PAR demonstrates a strong correlation with real user preference. Finally, we further apply the generated masks for iterative image inpainting by combining our approach with multiple recent inpainting methods. Extensive experiments demonstrate the consistent decrease of artifact regions and inpainting quality improvement across the different methods. Dataset and code are available at: https://github.com/owenzlz/PAL4Inpaint
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_9
DP  - Springer Link
SP  - 146
EP  - 164
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_9.pdf
ER  - 

TY  - CONF
TI  - MVSalNet: Multi-view Augmentation for RGB-D Salient Object Detection
AU  - Zhou, Jiayuan
AU  - Wang, Lijun
AU  - Lu, Huchuan
AU  - Huang, Kaining
AU  - Shi, Xinchu
AU  - Liu, Bocong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - RGB-D salient object detection (SOD) enjoys significant advantages in understanding 3D geometry of the scene. However, the geometry information conveyed by depth maps are mostly under-explored in existing RGB-D SOD methods. In this paper, we propose a new framework to address this issue. We augment the input image with multiple different views rendered using the depth maps, and cast the conventional single-view RGB-D SOD into a multi-view setting. Since different views captures complementary context of the 3D scene, the accuracy can be significantly improved through multi-view aggregation. We further design a multi-view saliency detection network (MVSalNet), which firstly performs saliency prediction for each view separately and incorporates multi-view outputs through a fusion model to produce final saliency prediction. A dynamic filtering module is also designed to facilitate more effective and flexible feature extraction. Extensive experiments on 6 widely used datasets demonstrate that our approach compares favorably against state-of-the-art approaches.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_16
DP  - Springer Link
SP  - 270
EP  - 287
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - MVSalNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_16.pdf
KW  - Multi-view augmentation
KW  - Multi-view fusion
KW  - RGB-D salient object detection
ER  - 

TY  - CONF
TI  - Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot Segmentation
AU  - Hong, Sunghwan
AU  - Cho, Seokju
AU  - Nam, Jisu
AU  - Lin, Stephen
AU  - Kim, Seungryong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper presents a novel cost aggregation network, called Volumetric Aggregation with Transformers (VAT), for few-shot segmentation. The use of transformers can benefit correlation map aggregation through self-attention over a global receptive field. However, the tokenization of a correlation map for transformer processing can be detrimental, because the discontinuity at token boundaries reduces the local context available near the token edges and decreases inductive bias. To address this problem, we propose a 4D Convolutional Swin Transformer, where a high-dimensional Swin Transformer is preceded by a series of small-kernel convolutions that impart local context to all pixels and introduce convolutional inductive bias. We additionally boost aggregation performance by applying transformers within a pyramidal structure, where aggregation at a coarser level guides aggregation at a finer level. Noise in the transformer output is then filtered in the subsequent decoder with the help of the query’s appearance embedding. With this model, a new state-of-the-art is set for all the standard benchmarks in few-shot segmentation. It is shown that VAT attains state-of-the-art performance for semantic correspondence as well, where cost aggregation also plays a central role. Code and trained models are available at https://seokju-cho.github.io/VAT/.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_7
DP  - Springer Link
SP  - 108
EP  - 126
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_7.pdf
ER  - 

TY  - CONF
TI  - 2D Amodal Instance Segmentation Guided by 3D Shape Prior
AU  - Li, Zhixuan
AU  - Ye, Weining
AU  - Jiang, Tingting
AU  - Huang, Tiejun
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Amodal instance segmentation aims to predict the complete mask of the occluded instance, including both visible and invisible regions. Existing 2D AIS methods learn and predict the complete silhouettes of target instances in 2D space. However, masks in 2D space are only some observations and samples from the 3D model in different viewpoints and thus can not represent the real complete physical shape of the instances. With the 2D masks learned, 2D amodal methods are hard to generalize to new viewpoints not included in the training dataset. To tackle these problems, we are motivated by observations that (1) a 2D amodal mask is the projection of a 3D complete model, and (2) the 3D complete model can be recovered and reconstructed from the occluded 2D object instances. This paper builds a bridge to link the 2D occluded instances with the 3D complete models by 3D reconstruction and utilizes 3D shape prior for 2D AIS. To deal with the diversity of 3D shapes, our method is pretrained on large 3D reconstruction datasets for high-quality results. And we adopt the unsupervised 3D reconstruction method to avoid relying on 3D annotations. In this approach, our method can reconstruct 3D models from occluded 2D object instances and generalize to new unseen 2D viewpoints of the 3D object. Experiments demonstrate that our method outperforms all existing 2D AIS methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_10
DP  - Springer Link
SP  - 165
EP  - 181
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_10.pdf
KW  - Amodal
KW  - Instance segmentation
KW  - Occlusion
ER  - 

TY  - CONF
TI  - TransMatting: Enhancing Transparent Objects Matting with Transformers
AU  - Cai, Huanqia
AU  - Xue, Fanglei
AU  - Xu, Lele
AU  - Guo, Lili
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Image matting refers to predicting the alpha values of unknown foreground areas from natural images. Prior methods have focused on propagating alpha values from known to unknown regions. However, not all natural images have a specifically known foreground. Images of transparent objects, like glass, smoke, web, etc., have less or no known foreground. In this paper, we propose a Transformer-based network, TransMatting, to model transparent objects with a big receptive field. Specifically, we redesign the trimap as three learnable tri-tokens for introducing advanced semantic features into the self-attention mechanism. A small convolutional network is proposed to utilize the global feature and non-background mask to guide the multi-scale feature propagation from encoder to decoder for maintaining the contexture of transparent objects. In addition, we create a high-resolution matting dataset of transparent objects with small known foreground areas. Experiments on several matting benchmarks demonstrate the superiority of our proposed method over the current state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_15
DP  - Springer Link
SP  - 253
EP  - 269
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - TransMatting
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_15.pdf
KW  - Deep learning
KW  - Image matting
KW  - Vision Transformer
ER  - 

TY  - CONF
TI  - AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-Shot Interactions
AU  - Wang, Yian
AU  - Wu, Ruihai
AU  - Mo, Kaichun
AU  - Ke, Jiaqi
AU  - Fan, Qingnan
AU  - Guibas, Leonidas J.
AU  - Dong, Hao
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Perceiving and interacting with 3D articulated objects, such as cabinets, doors, and faucets, pose particular challenges for future home-assistant robots performing daily tasks in human environments.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_6
DP  - Springer Link
SP  - 90
EP  - 107
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - AdaAfford
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_6.pdf
ER  - 

TY  - CONF
TI  - Waymo Open Dataset: Panoramic Video Panoptic Segmentation
AU  - Mei, Jieru
AU  - Zhu, Alex Zihao
AU  - Yan, Xinchen
AU  - Yan, Hang
AU  - Qiao, Siyuan
AU  - Chen, Liang-Chieh
AU  - Kretzschmar, Henrik
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Panoptic image segmentation is the computer vision task of finding groups of pixels in an image and assigning semantic classes and object instance identifiers to them. Research in image segmentation has become increasingly popular due to its critical applications in robotics and autonomous driving. The research community thereby relies on publicly available benchmark dataset to advance the state-of-the-art in computer vision. Due to the high costs of densely labeling the images, however, there is a shortage of publicly available ground truth labels that are suitable for panoptic segmentation. The high labeling costs also make it challenging to extend existing datasets to the video domain and to multi-camera setups. We therefore present the Waymo Open Dataset: Panoramic Video Panoptic Segmentation, a large-scale dataset that offers high-quality panoptic segmentation labels for autonomous driving. We generate our dataset using the publicly available Waymo Open Dataset (WOD), leveraging the diverse set of camera images. Our labels are consistent over time for video processing and consistent across multiple cameras mounted on the vehicles for full panoramic scene understanding. Specifically, we offer labels for 28 semantic categories and 2,860 temporal sequences that were captured by five cameras mounted on autonomous vehicles driving in three different geographical locations, leading to a total of 100k labeled camera images. To the best of our knowledge, this makes our dataset an order of magnitude larger than existing datasets that offer video panoptic segmentation labels. We further propose a new benchmark for Panoramic Video Panoptic Segmentation and establish a number of strong baselines based on the DeepLab family of models. We have made the benchmark and the code publicly available, which we hope will facilitate future research on holistic scene understanding. Our dataset can be found at: waymo.com/open.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_4
DP  - Springer Link
SP  - 53
EP  - 72
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
ST  - Waymo Open Dataset
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_4.pdf
KW  - Panoramic video panoptic segmentation
ER  - 

TY  - CONF
TI  - k-means Mask Transformer
AU  - Yu, Qihang
AU  - Wang, Huiyu
AU  - Qiao, Siyuan
AU  - Collins, Maxwell
AU  - Zhu, Yukun
AU  - Adam, Hartwig
AU  - Yuille, Alan
AU  - Chen, Liang-Chieh
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The rise of transformers in vision tasks not only advances network backbone designs, but also starts a brand-new page to achieve end-to-end image recognition (e.g., object detection and panoptic segmentation). Originated from Natural Language Processing (NLP), transformer architectures, consisting of self-attention and cross-attention, effectively learn long-range interactions between elements in a sequence. However, we observe that most existing transformer-based vision models simply borrow the idea from NLP, neglecting the crucial difference between languages and images, particularly the extremely large sequence length of spatially flattened pixel features. This subsequently impedes the learning in cross-attention between pixel features and object queries. In this paper, we rethink the relationship between pixels and object queries, and propose to reformulate the cross-attention learning as a clustering process. Inspired by the traditional k-means clustering algorithm, we develop a $$\textbf{k}$$k-means Mask Xformer (kMaX-DeepLab) for segmentation tasks, which not only improves the state-of-the-art, but also enjoys a simple and elegant design. As a result, our kMaX-DeepLab achieves a new state-of-the-art performance on COCO val set with 58.0% PQ, and Cityscapes val set with 68.4% PQ, 44.0% AP, and 83.5% mIoU without test-time augmentation or external dataset. We hope our work can shed some light on designing transformers tailored for vision tasks. Code and models are available at https://github.com/google-research/deeplab2.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_17
DP  - Springer Link
SP  - 288
EP  - 307
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_17.pdf
KW  - k-means Clustering
KW  - Segmentation
KW  - Transformer
ER  - 

TY  - CONF
TI  - Adaptive Spatial-BCE Loss for Weakly Supervised Semantic Segmentation
AU  - Wu, Tong
AU  - Gao, Guangyu
AU  - Huang, Junshi
AU  - Wei, Xiaolin
AU  - Wei, Xiaoming
AU  - Liu, Chi Harold
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - For Weakly-Supervised Semantic Segmentation (WSSS) with image-level annotation, mostly relies on the classification network to generate initial segmentation pseudo-labels. However, the optimization target of classification networks usually neglects the discrimination between different pixels, like insignificant foreground and background regions. In this paper, we propose an adaptive Spatial Binary Cross-Entropy (Spatial-BCE) Loss for WSSS, which aims to enhance the discrimination between pixels. In Spatial-BCE Loss, we calculate the loss independently for each pixel, and heuristically assign the optimization directions for foreground and background pixels separately. An auxiliary self-supervised task is also proposed to guarantee the Spatial-BCE Loss working as envisaged. Meanwhile, to enhance the network’s generalization for different data distributions, we design an alternate training strategy to adaptively generate thresholds to divide the foreground and background. Benefiting from high-quality initial pseudo-labels by Spatial-BCE Loss, our method also reduce the reliance on post-processing, thereby simplifying the pipeline of WSSS. Our method is validated on the PASCAL VOC 2012 and COCO 2014 datasets, and achieves the new state-of-the-arts. Code is available at https://github.com/allenwu97/Spatial-BCE.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_12
DP  - Springer Link
SP  - 199
EP  - 216
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_12.pdf
KW  - Adaptive threshold
KW  - Pseudo-labels
KW  - Spatial-BCE
KW  - WSSS
ER  - 

TY  - CONF
TI  - Data Efficient 3D Learner via Knowledge Transferred from 2D Model
AU  - Yu, Ping-Chung
AU  - Sun, Cheng
AU  - Sun, Min
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Collecting and labeling the registered 3D point cloud is costly. As a result, 3D resources for training are typically limited in quantity compared to the 2D images counterpart. In this work, we deal with the data scarcity challenge of 3D tasks by transferring knowledge from strong 2D models via RGB-D images. Specifically, we utilize a strong and well-trained semantic segmentation model for 2D images to augment RGB-D images with pseudo-label. The augmented dataset can then be used to pre-train 3D models. Finally, by simply fine-tuning on a few labeled 3D instances, our method already outperforms existing state-of-the-art that is tailored for 3D label efficiency. We also show that the results of mean-teacher and entropy minimization can be improved by our pre-training, suggesting that the transferred knowledge is helpful in semi-supervised setting. We verify the effectiveness of our approach on two popular 3D models and three different tasks. On ScanNet official evaluation, we establish new state-of-the-art semantic segmentation results on the data-efficient track.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_11
DP  - Springer Link
SP  - 182
EP  - 198
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_11.pdf
KW  - 3D pre-training
KW  - 3D semantic segmentation
KW  - Knowledge transfer
KW  - Label efficiency
KW  - Point cloud recognition
ER  - 

TY  - CONF
TI  - Adversarial Erasing Framework via Triplet with Gated Pyramid Pooling Layer for Weakly Supervised Semantic Segmentation
AU  - Yoon, Sung-Hoon
AU  - Kweon, Hyeokjun
AU  - Cho, Jegyeong
AU  - Kim, Shinjeong
AU  - Yoon, Kuk-Jin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Weakly supervised semantic segmentation (WSSS) has employed Class Activation Maps (CAMs) to localize the objects. However, the CAMs typically do not fit along the object boundaries and highlight only the most-discriminative regions. To resolve the problems, we propose a Gated Pyramid Pooling (GPP) layer which is a substitute for a Global Average Pooling (GAP) layer, and an Adversarial Erasing Framework via Triplet (AEFT). In the GPP layer, a feature pyramid is obtained by pooling the CAMs at multiple spatial resolutions, and then be aggregated into an attention for class prediction by gated convolution. With the process, CAMs are trained not only to capture the global context but also to preserve fine-details from the image. Meanwhile, the AEFT targets an over-expansion, a chronic problem of Adversarial Erasing (AE). Although AE methods expand CAMs by erasing the discriminative regions, they usually suffer from the over-expansion due to an absence of guidelines on when to stop erasing. We experimentally verify that the over-expansion is due to rigid classification, and metric learning can be a flexible remedy for it. AEFT is devised to learn the concept of erasing with the triplet loss between the input image, erased image, and negatively sampled image. With the GPP and AEFT, we achieve new state-of-the-art both on the PASCAL VOC 2012 val/test and MS-COCO 2014 val set by 70.9%/71.7% and 44.8% in mIoU, respectively.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_19
DP  - Springer Link
SP  - 326
EP  - 344
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_19.pdf
KW  - Weakly supervised semantic segmentation
ER  - 

TY  - CONF
TI  - Dense Gaussian Processes for Few-Shot Segmentation
AU  - Johnander, Joakim
AU  - Edstedt, Johan
AU  - Felsberg, Michael
AU  - Khan, Fahad Shahbaz
AU  - Danelljan, Martin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot segmentation is a challenging dense prediction task, which entails segmenting a novel query image given only a small annotated support set. The key problem is thus to design a method that aggregates detailed information from the support set, while being robust to large variations in appearance and context. To this end, we propose a few-shot segmentation method based on dense Gaussian process (GP) regression. Given the support set, our dense GP learns the mapping from local deep image features to mask values, capable of capturing complex appearance distributions. Furthermore, it provides a principled means of capturing uncertainty, which serves as another powerful cue for the final segmentation, obtained by a CNN decoder. Instead of a one-dimensional mask output, we further exploit the end-to-end learning capabilities of our approach to learn a high-dimensional output space for the GP. Our approach sets a new state-of-the-art on the PASCAL-5$$^i$$iand COCO-20$$^i$$ibenchmarks, achieving an absolute gain of $$+8.4$$+8.4mIoU in the COCO-20$$^i$$i5-shot setting. Furthermore, the segmentation quality of our approach scales gracefully when increasing the support set size, while achieving robust cross-dataset transfer. Code and trained models are available at https://github.com/joakimjohnander/dgpnet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_13
DP  - Springer Link
SP  - 217
EP  - 234
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_13.pdf
ER  - 

TY  - CONF
TI  - 3D Instances as 1D Kernels
AU  - Wu, Yizheng
AU  - Shi, Min
AU  - Du, Shuaiyuan
AU  - Lu, Hao
AU  - Cao, Zhiguo
AU  - Zhong, Weicai
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We introduce a 3D instance representation, termed instance kernels, where instances are represented by one-dimensional vectors that encode the semantic, positional, and shape information of 3D instances. We show that instance kernels enable easy mask inference by simply scanning kernels over the entire scenes, avoiding the heavy reliance on proposals or heuristic clustering algorithms in standard 3D instance segmentation pipelines. The idea of instance kernel is inspired by recent success of dynamic convolutions in 2D/3D instance segmentation. However, we find it non-trivial to represent 3D instances due to the disordered and unstructured nature of point cloud data, e.g., poor instance localization can significantly degrade instance representation. To remedy this, we construct a novel 3D instance encoding paradigm. First, potential instance centroids are localized as candidates. Then, a candidate merging scheme is devised to simultaneously aggregate duplicated candidates and collect context around the merged centroids to form the instance kernels. Once instance kernels are available, instance masks can be reconstructed via dynamic convolutions whose weights are conditioned on instance kernels. The whole pipeline is instantiated with a dynamic kernel network (DKNet). Results show that DKNet outperforms the state of the arts on both ScanNetV2 and S3DIS datasets with better instance localization. Code is available: https://github.com/W1zheng/DKNet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19818-2_14
DP  - Springer Link
SP  - 235
EP  - 252
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19818-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19818-2_14.pdf
KW  - Instance kernel
KW  - Instance segmentation
KW  - Point cloud
ER  - 

TY  - CONF
TI  - Out-of-Distribution Detection Using Outlier Detection Methods
AU  - Diers, Jan
AU  - Pigorsch, Christian
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Out-of-distribution detection (OOD) deals with anomalous input to neural networks. In the past, specialized methods have been proposed to identify anomalous input. Similarly, it was shown that feature extraction models in combination with outlier detection algorithms are well suited to detect anomalous input. We use outlier detection algorithms to detect anomalous input as reliable as specialized methods from the field of OOD. No neural network adaptation is required; detection is based on the model’s softmax score. Our approach works unsupervised using an Isolation Forest and can be further improved by using a supervised learning method such as Gradient Boosting.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_2
DP  - Springer Link
SP  - 15
EP  - 26
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_2.pdf
KW  - Isolation Forest
KW  - Out-of-distribution detection
KW  - Outlier detection
ER  - 

TY  - CONF
TI  - Recurrent Vision Transformer for Solving Visual Reasoning Problems
AU  - Messina, Nicola
AU  - Amato, Giuseppe
AU  - Carrara, Fabio
AU  - Gennaro, Claudio
AU  - Falchi, Fabrizio
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Although convolutional neural networks (CNNs) showed remarkable results in many vision tasks, they are still strained by simple yet challenging visual reasoning problems. Inspired by the recent success of the Transformer network in computer vision, in this paper, we introduce the Recurrent Vision Transformer (RViT) model. Thanks to the impact of recurrent connections and spatial attention in reasoning tasks, this network achieves competitive results on the same-different visual reasoning problems from the SVRT dataset. The weight-sharing both in spatial and depth dimensions regularizes the model, allowing it to learn using far fewer free parameters, using only 28k training samples. A comprehensive ablation study confirms the importance of a hybrid CNN + Transformer architecture and the role of the feedback connections, which iteratively refine the internal representation until a stable prediction is obtained. In the end, this study can lay the basis for a deeper understanding of the role of attention and recurrent connections for solving visual abstract reasoning tasks. The code for reproducing our results is publicly available here: https://tinyurl.com/recvit.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_5
DP  - Springer Link
SP  - 50
EP  - 61
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_5.pdf
KW  - Deep learning
KW  - Transformer networks
KW  - Visual reasoning
ER  - 

TY  - CONF
TI  - User-Biased Food Recognition for Health Monitoring
AU  - Hussain, Mazhar
AU  - Ortis, Alessandro
AU  - Polosa, Riccardo
AU  - Battiato, Sebastiano
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - This paper presents a user-biased food recognition system. The presented approach has been developed in the context of the FoodRec project, which aims to define an automatic framework for the monitoring of people’s health and habits, during their smoke quitting program. The goal of food recognition is to extract and infer semantic information from the food images to classify diverse foods present in the image. We propose a novel Deep Convolutional Neural Network able to recognize food items of specific users and monitor their habits. It consists of a food branch to learn visual representation for the input food items and a user branch to take into account the specific user’s eating habits. Furthermore, we introduce a new FoodRec-50 dataset with 2000 images and 50 food categories collected by the iOS and Android smartphone applications, taken by 164 users during their smoking cessation therapy. The information inferred from the users’ eating habits is then exploited to track and monitor the dietary habits of people involved in a smoke quitting protocol. Experimental results show that the proposed food recognition method outperforms the baseline model results on the FoodRec-50 dataset. We also performed an ablation study which demonstrated that the proposed architecture is able to tune the prediction based on the users’ eating habits.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_9
DP  - Springer Link
SP  - 98
EP  - 108
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_9.pdf
KW  - Artificial intelligence for health
KW  - Dietary monitoring
KW  - Food dataset
KW  - Food recognition
ER  - 

TY  - CONF
TI  - Hangul Fonts Dataset: A Hierarchical and Compositional Dataset for Investigating Learned Representations
AU  - Livezey, Jesse A.
AU  - Hwang, Ahyeon
AU  - Yeung, Jacob
AU  - Bouchard, Kristofer E.
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Hierarchy and compositionality are common latent properties in many natural and scientific image datasets. Determining when a deep network’s hidden activations represent hierarchy and compositionality is important both for understanding deep representation learning and for applying deep networks in domains where interpretability is crucial. However, current benchmark machine learning datasets either have little hierarchical or compositional structure, or the structure is not known. This gap impedes precise analysis of a network’s representations and thus hinders development of new methods that can learn such properties. To address this gap, we developed a new benchmark dataset with known hierarchical and compositional structure. The Hangul Fonts Dataset (HFD) is comprised of 35 fonts from the Korean writing system (Hangul), each with 11,172 blocks (syllables) composed from the product of initial, medial, and final glyphs. All blocks can be grouped into a few geometric types which induces a hierarchy across blocks. In addition, each block is composed of individual glyphs with rotations, translations, scalings, and naturalistic style variation across fonts. We find that both shallow and deep unsupervised methods show only modest evidence of hierarchy and compositionality in their representations of the HFD compared to supervised deep networks. Thus, HFD enables the identification of shortcomings in existing methods, a critical first step toward developing new machine learning algorithms to extract hierarchical and compositional structure in the context of naturalistic variability.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
ST  - Hangul Fonts Dataset
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_1.pdf
KW  - Compositionality
KW  - Hierarchy
KW  - Representation learning
ER  - 

TY  - CONF
TI  - FirstPiano: A New Egocentric Hand Action Dataset Oriented Towards Augmented Reality Applications
AU  - Voillemin, Théo
AU  - Wannous, Hazem
AU  - Vandeborre, Jean-Philippe
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Research on hand action recognition has achieved very interesting performance in recent years, notably thanks to deep learning methods. With those improvements, we can see new visions towards real applications of new Human-Machine interfaces (HMI) using this recognition. Such new interactions and interfaces need data to develop the best user experience iteratively. However, current datasets for hand action recognition in an egocentric view, even if perfectly useful for these problems of recognition, they generally lack of a limited but coherent context for the proposed actions. Indeed, these datasets tend to provide a wide range of actions, more or less in relation to each other, which does not help to create an interesting context for HMI application purposes. Thereby, we present in this paper a new dataset, FirstPiano, for hand action recognition in an egocentric view, in the context of piano training. FirstPiano provides a total of 672 video sequences directly extracted from the sensors of the Microsoft HoloLens Augmented Reality device. Each sequence is provided in depth, infrared and grayscale data, with 4 different points of view for the last one, for a total of 6 streams for each video. We also present the first benchmark of experiments using a Capsule Network over different classification problems and different stream combinations. Our dataset and experiments can therefore be interesting for research communities of action recognition and human-machine interface.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_15
DP  - Springer Link
SP  - 170
EP  - 181
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
ST  - FirstPiano
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_15.pdf
KW  - Action recognition
KW  - Hand action dataset
KW  - Human machine interaction
ER  - 

TY  - CONF
TI  - Keyframe Insights into Real-Time Video Tagging of Compressed UHD Content
AU  - Rüfenacht, Dominic
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - We present a method that can analyze coded ultra-high resolution (UHD) video content an order of magnitude faster than real-time. We observe that the larger the resolution of a video, the larger the fraction of the overall processing time is spent on decoding frames from the video. In this paper, we exploit the way video is coded to significantly speed up the frame decoding process. More precisely, we only decode keyframes, which can be decoded significantly faster than ‘random’ frames in the video. A key insight is that in modern video codecs, keyframes are often placed around scene changes (shot boundaries), and hence form a very representative subset of frames of the video. We show on the example of video genre tagging that keyframes nicely lend themselves to video analysis tasks. Unlike previous genre prediction methods which include a multitude of signals, we train a per-frame genre classification system using a CNN that solely takes (key-)frames as input. We show that the aggregated genre predictions are very competitive to much more involved methods at predicting the video genre(s), and even outperform state-of-the-art genre tagging that solely rely on video frames as input. The proposed system can reliably tag video genres of a compressed video between 12$$\times $$×(8K content) and 96$$\times $$×(1080p content) faster than real-time.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_13
DP  - Springer Link
SP  - 147
EP  - 157
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_13.pdf
KW  - Movie genre tagging
KW  - Real-time
ER  - 

TY  - CONF
TI  - Multi-view Spectral Clustering via Integrating Label and Data Graph Learning
AU  - El Hajjar, Sally
AU  - Dornaika, Fadi
AU  - Abdallah, Fahed
AU  - Omrani, Hichem
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Nowadays, one-step multi-view clustering algorithms attract many interests. The main issue of multi-view clustering approaches is how to combine the information extracted from the available views. A popular approach is to use view-based graphs and/or a consensus graph to describe the different views. We introduce a novel one-step graph-based multi-view clustering approach in this study. Our suggested method, in contrast to existing graph-based one-step clustering methods, provides two major novelties to the method called Nonnegative Embedding and Spectral Embedding (NESE) proposed in the recent paper [1]. To begin, we use the cluster label correlation to create an additional graph in addition to the graphs associated with the data space. Second, the cluster-label matrix is constrained by adopting some restrictions to make it more consistent. The effectiveness of the proposed method is demonstrated by experimental results on many public datasets.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_10
DP  - Springer Link
SP  - 109
EP  - 120
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_10.pdf
KW  - Cluster label space
KW  - Graph construction
KW  - Multi-view clustering
KW  - Similarity graph
KW  - Spectral projection matrix
ER  - 

TY  - CONF
TI  - Case Study on the Use of the SafeML Approach in Training Autonomous Driving Vehicles
AU  - Bergler, Matthias
AU  - Kolagari, Ramin Tavakoli
AU  - Lundqvist, Kristina
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - The development quality for the control software for autonomous vehicles is rapidly progressing, so that the control units in the field generally perform very reliably. Nevertheless, fatal misjudgments occasionally occur putting people at risk: such as the recent accident in which a Tesla vehicle in Autopilot mode rammed a police vehicle. Since the object recognition software which is a part of the control software is based on machine learning (ML) algorithms at its core, one can distinguish a training phase from a deployment phase of the software. In this paper we investigate to what extent the deployment phase has an impact on the robustness and reliability of the software; because just as traditional, software based on ML degrades with time. A widely known effect is the so-called concept drift: in this case, one finds that the deployment conditions in the field have changed and the software, based on the outdated training data, no longer responds adequately to the current field situation. In a previous research paper, we developed the SafeML approach with colleagues from the University of Hull, where datasets are compared for their statistical distance measures. In doing so, we detected that for simple, benchmark data, the statistical distance correlates with the classification accuracy in the field. The contribution of this paper is to analyze the applicability of the SafeML approach to complex, multidimensional data used in autonomous driving. In our analysis, we found that the SafeML approach can be used for this data as well. In practice, this would mean that a vehicle could constantly check itself and detect concept drift situation early.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_8
DP  - Springer Link
SP  - 87
EP  - 97
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_8.pdf
KW  - Automotive
KW  - Autonomous driving
KW  - Machine learning
KW  - SafeML
KW  - Safety
ER  - 

TY  - CONF
TI  - Distance-Based Random Forest Clustering with Missing Data
AU  - Raniero, Matteo
AU  - Bicego, Manuele
AU  - Cicalese, Ferdinando
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - In recent years there has been an increased interest in clustering methods based on Random Forests, due to their flexibility and their capability in describing data. One problem of current RF-clustering approaches is that they are not able to directly deal with missing data, a common scenario in many application fields (e.g. Bioinformatics): the usual solution in this case is to pre-impute incomplete data before running standard clustering methods. In this paper we present the first Random Forest clustering approach able to directly deal with missing data. We start from the very recent RatioRF distance for clustering [3], which has shown to outperform all other distance-based RF clustering schemes, extending the framework in two directions, which allow the integration of missing data mechanisms directly inside the clustering pipeline. Experimental results, based on 6 standard UCI ML datasets, are promising, also in comparison with some literature alternatives.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_11
DP  - Springer Link
SP  - 121
EP  - 132
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_11.pdf
KW  - Missing data
KW  - Random Forest clustering
KW  - Ratio RF distance
ER  - 

TY  - CONF
TI  - Relaxation Labeling Meets GANs: Solving Jigsaw Puzzles with Missing Borders
AU  - Khoroshiltseva, Marina
AU  - Traviglia, Arianna
AU  - Pelillo, Marcello
AU  - Vascon, Sebastiano
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - This paper proposes JiGAN, a GAN-based method for solving Jigsaw puzzles with eroded or missing borders. Missing borders is a common real-world situation, for example, when dealing with the reconstruction of broken artifacts or ruined frescoes. In this particular condition, the puzzle’s pieces do not align perfectly due to the borders’ gaps; in this situation, the patches’ direct match is unfeasible due to the lack of color and line continuations. JiGAN, is a two-steps procedure that tackles this issue: first, we repair the eroded borders with a GAN-based image extension model and measure the alignment affinity between pieces; then, we solve the puzzle with the relaxation labeling algorithm to enforce consistency in pieces positioning, hence, reconstructing the puzzle. We test the method on a large dataset of small puzzles and on three commonly used benchmark datasets to demonstrate the feasibility of the proposed approach.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_3
DP  - Springer Link
SP  - 27
EP  - 38
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
ST  - Relaxation Labeling Meets GANs
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_3.pdf
KW  - Image extension
KW  - Jigsaw puzzles
KW  - Relaxation labeling
ER  - 

TY  - CONF
TI  - Foreground Detection Using an Attention Module and a Video Encoding
AU  - Benavides-Arce, Anthony A.
AU  - Flores-Benites, Victor
AU  - Mora-Colque, Rensso
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Foreground detection is the task of labelling the foreground or background pixels in the video sequence and it depends on the context of the scene. For many years, methods based on background model have been the most used approaches for detecting foreground; however, their methods are sensitive to error propagation from the first background model estimations. To address this problem, we proposed a U-net based architecture with an attention module, where the encoding of the entire video sequence is used as attention context to get features related to the background model. We tested our network on sixteen scenes from the CDnet2014 dataset, with an average F-measure of 88.42. The results also show that our model outperforms traditional and neural networks methods. Thus, we demonstrated that an attention module on a U-net based architecture can deal with the foreground detection challenges.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_17
DP  - Springer Link
SP  - 195
EP  - 205
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_17.pdf
KW  - Attention
KW  - Foreground Detection
KW  - U-Net
KW  - Video encoding
ER  - 

TY  - CONF
TI  - Unsupervised Person Re-identification Based on Skeleton Joints Using Graph Convolutional Networks
AU  - Khaldi, Khadija
AU  - Mantini, Pranav
AU  - Shah, Shishir K.
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - With the remarkable progress of deep learning methods, person re-identification has received a lot of attention from researchers. However, the majority of previous work mainly focus on supervised learning setting, which requires expensive data annotations. In this paper, we address this problem by proposing a purely unsupervised learning model. Inspired by the effectiveness of modeling the spatio-temporal information of pedestrian video, we mine the relationships between human body joints. Specifically, we propose a novel framework by learning inter-frame and intra-frame relationships for discriminative feature learning via two Graph Convolutional Networks (GCN) modules: spatial and temporal. The spatial module captures the structural information of the human body and the temporal module propagates information across adjacent frames. At the end, we perform hierarchical clustering by selecting P identities and K instances (PK sampling) to generate pseudo-labels for the unlabeled data. By iteratively optimizing these modules, our model extracts robust spatial-temporal information that can alleviate the occlusion problem. We conduct experiments on two benchmarks: MARS and DukeMTMC-VideoReID datasets, where we demonstrate the effectiveness of our proposed method.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_12
DP  - Springer Link
SP  - 135
EP  - 146
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_12.pdf
KW  - Graph neural network
KW  - Person re-identification
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Using Random Forest Distances for Outlier Detection
AU  - Mensi, Antonella
AU  - Cicalese, Ferdinando
AU  - Bicego, Manuele
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - In recent years, a great variety of outlier detectors have been proposed in the literature, many of which are based on pairwise distances or derived concepts. However, in such methods, most of the efforts have been devoted to the outlier detection mechanisms, not paying attention to the distance measure – in most cases the basic Euclidean distance is used. Instead, in the clustering field, data-dependent measures have shown to be very useful, especially those based on Random Forests: actually, Random Forests are partitioners of the space able to naturally encode the relation between two objects. In the outlier detection field, these informative distances have received scarce attention. This manuscript is aimed at filling this gap, studying the suitability of these measures in the identification of outliers. In our scheme, we build an unsupervised Random Forest model, from which we extract pairwise distances; these distances are then input to an outlier detector. In particular, we study the impact of several Random Forest-based distances, including advanced and recent ones, on different outlier detectors. We evaluate thoroughly our methodology on nine benchmark datasets for outlier detection, focusing on different aspects of the pipeline, such as the parametrization of the forest, the type of distance-based outlier detector, and most importantly, the impact of the adopted distance.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_7
DP  - Springer Link
SP  - 75
EP  - 86
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_7.pdf
KW  - Data-dependent distances
KW  - Outlier detection
KW  - Random forest distances
ER  - 

TY  - CONF
TI  - Metric Learning-Based Unsupervised Domain Adaptation for 3D Skeleton Hand Activities Categorization
AU  - Boutaleb, Yasser
AU  - Soladié, Catherine
AU  - Duong, Nam-duong
AU  - Kacete, Amine
AU  - Royan, Jérôme
AU  - Seguier, Renaud
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - First-person hand activity recognition plays a significant role in the computer vision field with various applications. Thanks to recent advances in depth sensors, several 3D skeleton-based hand activity recognition methods using supervised Deep Learning (DL) have been proposed, proven effective when a large amount of labeled data is available. However, the annotation of such data remains difficult and costly, which motivates the use of unsupervised methods. We propose in this paper a new approach based on unsupervised domain adaptation (UDA) for 3D skeleton hand activity clustering. It aims at exploiting the knowledge-driven from labeled samples of the source domain to categorize the unlabeled ones of the target domain. To this end, we introduce a novel metric learning-based loss function to learn a highly discriminative representation while preserving a good activity recognition accuracy on the source domain. The learned representation is used as a low-level manifold to cluster unlabeled samples. In addition, to ensure the best clustering results, we proposed a statistical and consensus-clustering-based strategy. The proposed approach is experimented on the real-world FPHA data set.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_6
DP  - Springer Link
SP  - 62
EP  - 74
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_6.pdf
KW  - Hand activities clustering
KW  - Metric learning
KW  - Unsupervised domain adaptation
ER  - 

TY  - CONF
TI  - Exploring the Use of Efficient Projection Kernels for Motion Saliency Estimation
AU  - Nicora, Elena
AU  - Noceti, Nicoletta
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - In this paper we investigate the potential of a family of efficient filters – the Gray-Code Kernels – for addressing visual saliency estimation guided by motion. Our implementation relies on the use of 3D kernels applied to overlapping blocks of frames and is able to gather meaningful spatio-temporal information with a very light computation. We introduce an attention module that reasons on the use of pooling strategies, combined in an unsupervised way to derive a saliency map highlighting the presence of motion in the scene. In the experiments we show that our method is able to effectively and efficiently identify the portion of the image where the motion is occurring, providing tolerance to a variety of scene conditions.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_14
DP  - Springer Link
SP  - 158
EP  - 169
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_14.pdf
KW  - Gray-Code Kernels
KW  - Motion detection
KW  - Motion saliency estimation
ER  - 

TY  - CONF
TI  - Learning Video Retrieval Models with Relevance-Aware Online Mining
AU  - Falcon, Alex
AU  - Serra, Giuseppe
AU  - Lanz, Oswald
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Due to the amount of videos and related captions uploaded every hour, deep learning-based solutions for cross-modal video retrieval are attracting more and more attention. A typical approach consists in learning a joint text-video embedding space, where the similarity of a video and its associated caption is maximized, whereas a lower similarity is enforced with all the other captions, called negatives. This approach assumes that only the video and caption pairs in the dataset are valid, but different captions - positives - may also describe its visual contents, hence some of them may be wrongly penalized. To address this shortcoming, we propose the Relevance-Aware Negatives and Positives mining (RANP) which, based on the semantics of the negatives, improves their selection while also increasing the similarity of other valid positives. We explore the influence of these techniques on two video-text datasets: EPIC-Kitchens-100 and MSR-VTT. By using the proposed techniques, we achieve considerable improvements in terms of nDCG and mAP, leading to state-of-the-art results, e.g. +5.3% nDCG and +3.0% mAP on EPIC-Kitchens-100. We share code and pretrained models at https://github.com/aranciokov/ranp.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_16
DP  - Springer Link
SP  - 182
EP  - 194
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_16.pdf
KW  - Contrastive loss
KW  - Cross-modal retrieval
KW  - Hard negative mining
KW  - Video retrieval
ER  - 

TY  - CONF
TI  - Computationally Efficient Rehearsal for Online Continual Learning
AU  - Davalas, Charalampos
AU  - Michail, Dimitrios
AU  - Diou, Christos
AU  - Varlamis, Iraklis
AU  - Tserpes, Konstantinos
A2  - Sclaroff, Stan
A2  - Distante, Cosimo
A2  - Leo, Marco
A2  - Farinella, Giovanni M.
A2  - Tombari, Federico
T3  - Lecture Notes in Computer Science
AB  - Continual learning is a crucial ability for learning systems that have to adapt to changing data distributions, without reducing their performance in what they have already learned. Rehearsal methods offer a simple countermeasure to help avoid this catastrophic forgetting which frequently occurs in dynamic situations and is a major limitation of machine learning models. These methods continuously train neural networks using a mix of data both from the stream and from a rehearsal buffer, which maintains past training samples. Although the rehearsal approach is reasonable and simple to implement, its effectiveness and efficiency is significantly affected by several hyperparameters such as the number of training iterations performed at each step, the choice of learning rate, and the choice on whether to retrain the agent at each step. These options are especially important in resource-constrained environments commonly found in online continual learning for image analysis. This work evaluates several rehearsal training strategies for continual online learning and proposes the combined use of a drift detector that decides on (a) when to train using data from the buffer and the online stream, and (b) how to train, based on a combination of heuristics. Experiments on the MNIST and CIFAR-10 image classification datasets demonstrate the effectiveness of the proposed approach over baseline training strategies at a fraction of the computational cost.
C1  - Cham
C3  - Image Analysis and Processing – ICIAP 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06433-3_4
DP  - Springer Link
SP  - 39
EP  - 49
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06433-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06433-3_4.pdf
KW  - Catastrophic forgetting
KW  - Continual learning
KW  - Online learning
ER  - 

TY  - CONF
TI  - Learning Depth from Focus in the Wild
AU  - Won, Changyeon
AU  - Jeon, Hae-Gon
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - For better photography, most recent commercial cameras including smartphones have either adopted large-aperture lens to collect more light or used a burst mode to take multiple images within short times. These interesting features lead us to examine depth from focus/defocus. In this work, we present a convolutional neural network-based depth estimation from single focal stacks. Our method differs from relevant state-of-the-art works with three unique features. First, our method allows depth maps to be inferred in an end-to-end manner even with image alignment. Second, we propose a sharp region detection module to reduce blur ambiguities in subtle focus changes and weakly texture-less regions. Third, we design an effective downsampling module to ease flows of focal information in feature extractions. In addition, for the generalization of the proposed network, we develop a simulator to realistically reproduce the features of commercial cameras, such as changes in field of view, focal length and principal points. By effectively incorporating these three unique features, our network achieves the top rank in the DDFF 12-Scene benchmark on most metrics. We also demonstrate the effectiveness of the proposed method on various quantitative evaluations and real-world images taken from various off-the-shelf cameras compared with state-of-the-art methods. Our source code is publicly available at https://github.com/wcy199705/DfFintheWild.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_1
DP  - Springer Link
SP  - 1
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_1.pdf
KW  - Depth from focus
KW  - Image alignment
KW  - Sharp region detection and simulated focal stack dataset
ER  - 

TY  - CONF
TI  - PanoFormer: Panorama Transformer for Indoor 360$$^{\circ }$$Depth Estimation
AU  - Shen, Zhijie
AU  - Lin, Chunyu
AU  - Liao, Kang
AU  - Nie, Lang
AU  - Zheng, Zishuo
AU  - Zhao, Yao
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Existing panoramic depth estimation methods based on convolutional neural networks (CNNs) focus on removing panoramic distortions, failing to perceive panoramic structures efficiently due to the fixed receptive field in CNNs. This paper proposes the panorama transformer (named PanoFormer) to estimate the depth in panorama images, with tangent patches from spherical domain, learnable token flows, and pano-rama specific metrics. In particular, we divide patches on the spherical tangent domain into tokens to reduce the negative effect of panoramic distortions. Since the geometric structures are essential for depth estimation, a self-attention module is redesigned with an additional learnable token flow. In addition, considering the characteristic of the spherical domain, we present two panorama-specific metrics to comprehensively evaluate the panoramic depth estimation models’ performance. Extensive experiments demonstrate that our approach significantly outperforms the state-of-the-art (SOTA) methods. Furthermore, the proposed method can be effectively extended to solve semantic panorama segmentation, a similar pixel2pixel task.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_12
DP  - Springer Link
SP  - 195
EP  - 211
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - PanoFormer
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_12.pdf
ER  - 

TY  - CONF
TI  - Adaptive Co-teaching for Unsupervised Monocular Depth Estimation
AU  - Ren, Weisong
AU  - Wang, Lijun
AU  - Piao, Yongri
AU  - Zhang, Miao
AU  - Lu, Huchuan
AU  - Liu, Ting
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Unsupervised depth estimation using photometric losses suffers from local minimum and training instability. We address this issue by proposing an adaptive co-teaching framework to distill the learned knowledge from unsupervised teacher networks to a student network. We design an ensemble architecture for our teacher networks, integrating a depth basis decoder with multiple depth coefficient decoders. Depth prediction can then be formulated as a combination of the predicted depth bases weighted by coefficients. By further constraining their correlations, multiple coefficient decoders can yield a diversity of depth predictions, serving as the ensemble teachers. During the co-teaching step, our method allows different supervision sources from not only ensemble teachers but also photometric losses to constantly compete with each other, and adaptively select the optimal ones to teach the student, which effectively improves the ability of the student to jump out of the local minimum. Our method is shown to significantly benefit unsupervised depth estimation and sets new state of the art on both KITTI and Nuscenes datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_6
DP  - Springer Link
SP  - 89
EP  - 105
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_6.pdf
KW  - Ensemble learning
KW  - Knowledge distillation
KW  - Monocular depth estimation
KW  - Unsupervised
ER  - 

TY  - CONF
TI  - Fusing Local Similarities for Retrieval-Based 3D Orientation Estimation of Unseen Objects
AU  - Zhao, Chen
AU  - Hu, Yinlin
AU  - Salzmann, Mathieu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this paper, we tackle the task of estimating the 3D orientation of previously-unseen objects from monocular images. This task contrasts with the one considered by most existing deep learning methods which typically assume that the testing objects have been observed during training. To handle the unseen objects, we follow a retrieval-based strategy and prevent the network from learning object-specific features by computing multi-scale local similarities between the query image and synthetically-generated reference images. We then introduce an adaptive fusion module that robustly aggregates the local similarities into a global similarity score of pairwise images. Furthermore, we speed up the retrieval process by developing a fast retrieval strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets show that our method yields a significantly better generalization to unseen objects than previous works. Our code and pre-trained models are available at https://sailor-z.github.io/projects/Unseen_Object_Pose.html.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_7
DP  - Springer Link
SP  - 106
EP  - 122
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_7.pdf
KW  - Object 3D orientation estimation
KW  - Unseen objects
ER  - 

TY  - CONF
TI  - DID-M3D: Decoupling Instance Depth for Monocular 3D Object Detection
AU  - Peng, Liang
AU  - Wu, Xiaopei
AU  - Yang, Zheng
AU  - Liu, Haifeng
AU  - Cai, Deng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Monocular 3D detection has drawn much attention from the community due to its low cost and setup simplicity. It takes an RGB image as input and predicts 3D boxes in the 3D space. The most challenging sub-task lies in the instance depth estimation. Previous works usually use a direct estimation method. However, in this paper we point out that the instance depth on the RGB image is non-intuitive. It is coupled by visual depth clues and instance attribute clues, making it hard to be directly learned in the network. Therefore, we propose to reformulate the instance depth to the combination of the instance visual surface depth (visual depth) and the instance attribute depth (attribute depth). The visual depth is related to objects’ appearances and positions on the image. By contrast, the attribute depth relies on objects’ inherent attributes, which are invariant to the object affine transformation on the image. Correspondingly, we decouple the 3D location uncertainty into visual depth uncertainty and attribute depth uncertainty. By combining different types of depths and associated uncertainties, we can obtain the final instance depth. Furthermore, data augmentation in monocular 3D detection is usually limited due to the physical nature, hindering the boost of performance. Based on the proposed instance depth disentanglement strategy, we can alleviate this problem. Evaluated on KITTI, our method achieves new state-of-the-art results, and extensive ablation studies validate the effectiveness of each component in our method. The codes are released at https://github.com/SPengLiang/DID-M3D.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_5
DP  - Springer Link
SP  - 71
EP  - 88
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - DID-M3D
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_5.pdf
KW  - Instance depth estimation
KW  - Monocular 3D detection
ER  - 

TY  - CONF
TI  - A Reliable Online Method for Joint Estimation of Focal Length and Camera Rotation
AU  - Qian, Yiming
AU  - Elder, James H.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Linear perspective cues deriving from regularities of the built environment can be used to recalibrate both intrinsic and extrinsic camera parameters online, but these estimates can be unreliable due to irregularities in the scene, uncertainties in line segment estimation and background clutter. Here we address this challenge through four initiatives. First, we use the PanoContext panoramic image dataset [27] to curate a novel and realistic dataset of planar projections over a broad range of scenes, focal lengths and camera poses. Second, we use this novel dataset and the YorkUrbanDB [4] to systematically evaluate the linear perspective deviation measures frequently found in the literature and show that the choice of deviation measure and likelihood model has a huge impact on reliability. Third, we use these findings to create a novel system for online camera calibration we call $$f\textbf{R}$$fR, and show that it outperforms the prior state of the art, substantially reducing error in estimated camera rotation and focal length. Our fourth contribution is a novel and efficient approach to estimating uncertainty that can dramatically improve online reliability for performance-critical applications by strategically selecting which frames to use for recalibration.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_15
DP  - Springer Link
SP  - 249
EP  - 265
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_15.pdf
ER  - 

TY  - CONF
TI  - Learning-Based Point Cloud Registration for 6D Object Pose Estimation in the Real World
AU  - Dang, Zheng
AU  - Wang, Lizhou
AU  - Guo, Yu
AU  - Salzmann, Mathieu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this work, we tackle the task of estimating the 6D pose of an object from point cloud data. While recent learning-based approaches to addressing this task have shown great success on synthetic datasets, we have observed them to fail in the presence of real-world data. We thus analyze the causes of these failures, which we trace back to the difference between the feature distributions of the source and target point clouds, and the sensitivity of the widely-used SVD-based loss function to the range of rotation between the two point clouds. We address the first challenge by introducing a new normalization strategy, Match Normalization, and the second via the use of a loss function based on the negative log likelihood of point correspondences. Our two contributions are general and can be applied to many existing learning-based 3D object registration frameworks, which we illustrate by implementing them in two of them, DCP and IDAM. Our experiments on the real-scene TUD-L [26], LINEMOD [23] and Occluded-LINEMOD [7] datasets evidence the benefits of our strategies. They allow for the first time learning-based 3D object registration methods to achieve meaningful results on real-world data. We therefore expect them to be key to the future development of point cloud registration methods. Our source code can be found at https://github.com/Dangzheng/MatchNorm.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_2
DP  - Springer Link
SP  - 19
EP  - 37
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_2.pdf
KW  - 6D object pose estimation
KW  - Point cloud registration
ER  - 

TY  - CONF
TI  - Lidar Point Cloud Guided Monocular 3D Object Detection
AU  - Peng, Liang
AU  - Liu, Fei
AU  - Yu, Zhengxu
AU  - Yan, Senbo
AU  - Deng, Dan
AU  - Yang, Zheng
AU  - Liu, Haifeng
AU  - Cai, Deng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Monocular 3D object detection is a challenging task in the self-driving and computer vision community. As a common practice, most previous works use manually annotated 3D box labels, where the annotating process is expensive. In this paper, we find that the precisely and carefully annotated labels may be unnecessary in monocular 3D detection, which is an interesting and counterintuitive finding. Using rough labels that are randomly disturbed, the detector can achieve very close accuracy compared to the one using the ground-truth labels. We delve into this underlying mechanism and then empirically find that: concerning the label accuracy, the 3D location part in the label is preferred compared to other parts of labels. Motivated by the conclusions above and considering the precise LiDAR 3D measurement, we propose a simple and effective framework, dubbed LiDAR point cloud guided monocular 3D object detection (LPCG). This framework is capable of either reducing the annotation costs or considerably boosting the detection accuracy without introducing extra annotation costs. Specifically, It generates pseudo labels from unlabeled LiDAR point clouds. Thanks to accurate LiDAR 3D measurements in 3D space, such pseudo labels can replace manually annotated labels in the training of monocular 3D detectors, since their 3D location information is precise. LPCG can be applied into any monocular 3D detector to fully use massive unlabeled data in a self-driving system. As a result, in KITTI benchmark, we take the first place on both monocular 3D and BEV (bird’s-eye-view) detection with a significant margin. In Waymo benchmark, our method using 10% labeled data achieves comparable accuracy to the baseline detector using 100% labeled data. The codes are released at https://github.com/SPengLiang/LPCG.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_8
DP  - Springer Link
SP  - 123
EP  - 139
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_8.pdf
KW  - LiDAR point cloud
KW  - Monocular 3D detection
KW  - Self-driving
ER  - 

TY  - CONF
TI  - Few-Shot Single-View 3D Reconstruction with Memory Prior Contrastive Network
AU  - Xing, Zhen
AU  - Chen, Yijiang
AU  - Ling, Zhixin
AU  - Zhou, Xiangdong
AU  - Xiang, Yu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - 3D reconstruction of novel categories based on few-shot learning is appealing in real-world applications and attracts increasing research interests. Previous approaches mainly focus on how to design shape prior models for different categories. Their performance on unseen categories is not very competitive. In this paper, we present a Memory Prior Contrastive Network (MPCN) that can store shape prior knowledge in a few-shot learning based 3D reconstruction framework. With the shape memory, a multi-head attention module is proposed to capture different parts of a candidate shape prior and fuse these parts together to guide 3D reconstruction of novel categories. Besides, we introduce a 3D-aware contrastive learning method, which can not only complement the retrieval accuracy of memory network, but also better organize image features for downstream tasks. Compared with previous few-shot 3D reconstruction methods, MPCN can handle the inter-class variability without category annotations. Experimental results on a benchmark synthetic dataset and the Pascal3D+ real-world dataset show that our model outperforms the current state-of-the-art methods significantly.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_4
DP  - Springer Link
SP  - 55
EP  - 70
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_4.pdf
KW  - 3D reconstruction
KW  - Few-shot learning
KW  - Memory network
ER  - 

TY  - CONF
TI  - An End-to-End Transformer Model for Crowd Localization
AU  - Liang, Dingkang
AU  - Xu, Wei
AU  - Bai, Xiang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Crowd localization, predicting head positions, is a more practical and high-level task than simply counting. Existing methods employ pseudo-bounding boxes or pre-designed localization maps, relying on complex post-processing to obtain the head positions. In this paper, we propose an elegant, end-to-end Crowd Localization TRansformer named CLTR that solves the task in the regression-based paradigm. The proposed method views the crowd localization as a direct set prediction problem, taking extracted features and trainable embeddings as input of the transformer-decoder. To reduce the ambiguous points and generate more reasonable matching results, we introduce a KMO-based Hungarian matcher, which adopts the nearby context as the auxiliary matching cost. Extensive experiments conducted on five datasets in various data settings show the effectiveness of our method. In particular, the proposed method achieves the best localization performance on the NWPU-Crowd, UCF-QNRF, and ShanghaiTech Part A datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_3
DP  - Springer Link
SP  - 38
EP  - 54
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_3.pdf
KW  - Crowd counting
KW  - Crowd localization
KW  - Transformer
ER  - 

TY  - CONF
TI  - AvatarCap: Animatable Avatar Conditioned Monocular Human Volumetric Capture
AU  - Li, Zhe
AU  - Zheng, Zerong
AU  - Zhang, Hongwen
AU  - Ji, Chaonan
AU  - Liu, Yebin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - To address the ill-posed problem caused by partial observations in monocular human volumetric capture, we present AvatarCap, a novel framework that introduces animatable avatars into the capture pipeline for high-fidelity reconstruction in both visible and invisible regions. Our method firstly creates an animatable avatar for the subject from a small number ($$\sim $$∼20) of 3D scans as a prior. Then given a monocular RGB video of this subject, our method integrates information from both the image observation and the avatar prior, and accordingly reconstructs high-fidelity 3D textured models with dynamic details regardless of the visibility. To learn an effective avatar for volumetric capture from only few samples, we propose GeoTexAvatar, which leverages both geometry and texture supervisions to constrain the pose-dependent dynamics in a decomposed implicit manner. An avatar-conditioned volumetric capture method that involves a canonical normal fusion and a reconstruction network is further proposed to integrate both image observations and avatar dynamics for high-fidelity reconstruction in both observed and invisible regions. Overall, our method enables monocular human volumetric capture with detailed and pose-dependent dynamics, and the experiments show that our method outperforms state of the art.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_19
DP  - Springer Link
SP  - 322
EP  - 341
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - AvatarCap
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_19.pdf
ER  - 

TY  - CONF
TI  - Towards Comprehensive Representation Enhancement in Semantics-Guided Self-supervised Monocular Depth Estimation
AU  - Ma, Jingyuan
AU  - Lei, Xiangyu
AU  - Liu, Nan
AU  - Zhao, Xian
AU  - Pu, Shiliang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Semantics-guided self-supervised monocular depth estimation has been widely researched, owing to the strong cross-task correlation of depth and semantics. However, since depth estimation and semantic segmentation are fundamentally two types of tasks: one is regression while the other is classification, the distribution of depth feature and semantic feature are naturally different. Previous works that leverage semantic information in depth estimation mostly neglect such representational discrimination, which leads to insufficient representation enhancement of depth feature. In this work, we propose an attention-based module to enhance task-specific feature by addressing their feature uniqueness within instances. Additionally, we propose a metric learning based approach to accomplish comprehensive enhancement on depth feature by creating a separation between instances in feature space. Extensive experiments and analysis demonstrate the effectiveness of our proposed method. In the end, our method achieves the state-of-the-art performance on KITTI dataset.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_18
DP  - Springer Link
SP  - 304
EP  - 321
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_18.pdf
KW  - Feature metric learning
KW  - Monocular depth estimation
KW  - Representation enhancement
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Learning to Train a Point Cloud Reconstruction Network Without Matching
AU  - Huang, Tianxin
AU  - Yang, Xuemeng
AU  - Zhang, Jiangning
AU  - Cui, Jinhao
AU  - Zou, Hao
AU  - Chen, Jun
AU  - Zhao, Xiangrui
AU  - Liu, Yong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Reconstruction networks for well-ordered data such as 2D images and 1D continuous signals are easy to optimize through element-wised squared errors, while permutation-arbitrary point clouds cannot be constrained directly because their points permutations are not fixed. Though existing works design algorithms to match two point clouds and evaluate shape errors based on matched results, they are limited by pre-defined matching processes. In this work, we propose a novel framework named PCLossNet which learns to train a point cloud reconstruction network without any matching. By training through an adversarial process together with the reconstruction network, PCLossNet can better explore the differences between point clouds and create more precise reconstruction results. Experiments on multiple datasets prove the superiority of our method, where PCLossNet can help networks achieve much lower reconstruction errors and extract more representative features, with about 4 times faster training efficiency than the commonly-used EMD loss. Our codes can be found in https://github.com/Tianxinhuang/PCLossNet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_11
DP  - Springer Link
SP  - 179
EP  - 194
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_11.pdf
KW  - Learning to train
KW  - No matching
KW  - Point cloud reconstruction
ER  - 

TY  - CONF
TI  - 3D Human Pose Estimation Using Möbius Graph Convolutional Networks
AU  - Azizi, Niloofar
AU  - Possegger, Horst
AU  - Rodolà, Emanuele
AU  - Bischof, Horst
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - 3D human pose estimation is fundamental to understanding human behavior. Recently, promising results have been achieved by graph convolutional networks (GCNs), which achieve state-of-the-art performance and provide rather light-weight architectures. However, a major limitation of GCNs is their inability to encode all the transformations between joints explicitly. To address this issue, we propose a novel spectral GCN using the Möbius transformation (MöbiusGCN). In particular, this allows us to directly and explicitly encode the transformation between joints, resulting in a significantly more compact representation. Compared to even the lightest architectures so far, our novel approach requires 90–$$98\%$$98%fewer parameters, i.e. our lightest MöbiusGCN uses only $$0.042\text {M}$$0.042Mtrainable parameters. Besides the drastic parameter reduction, explicitly encoding the transformation of joints also enables us to achieve state-of-the-art results. We evaluate our approach on the two challenging pose estimation benchmarks, Human3.6M and MPI-INF-3DHP, demonstrating both state-of-the-art results and the generalization capabilities of MöbiusGCN.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_10
DP  - Springer Link
SP  - 160
EP  - 178
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_10.pdf
ER  - 

TY  - CONF
TI  - Share with Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency
AU  - Monnier, Tom
AU  - Fisher, Matthew
AU  - Efros, Alexei A.
AU  - Aubry, Mathieu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Approaches for single-view reconstruction typically rely on viewpoint annotations, silhouettes, the absence of background, multiple views of the same instance, a template shape, or symmetry. We avoid all such supervision and assumptions by explicitly leveraging the consistency between images of different object instances. As a result, our method can learn from large collections of unlabelled images depicting the same object category. Our main contributions are two ways for leveraging cross-instance consistency: (i) progressive conditioning, a training strategy to gradually specialize the model from category to instances in a curriculum learning fashion; and (ii) neighbor reconstruction, a loss enforcing consistency between instances having similar shape or texture. Also critical to the success of our method are: our structured autoencoding architecture decomposing an image into explicit shape, texture, pose, and background; an adapted formulation of differential rendering; and a new optimization scheme alternating between 3D and pose learning. We compare our approach, UNICORN, both on the diverse synthetic ShapeNet dataset—the classical benchmark for methods requiring multiple views as supervision—and on standard real-image benchmarks (Pascal3D+ Car, CUB) for which most methods require known templates and silhouette annotations. We also showcase applicability to more challenging real-world collections (CompCars, LSUN), where silhouettes are not available and images are not cropped around the object.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_17
DP  - Springer Link
SP  - 285
EP  - 303
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - Share with Thy Neighbors
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_17.pdf
KW  - Single-view reconstruction
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - AlignSDF: Pose-Aligned Signed Distance Fields for Hand-Object Reconstruction
AU  - Chen, Zerui
AU  - Hasson, Yana
AU  - Schmid, Cordelia
AU  - Laptev, Ivan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Recent work achieved impressive progress towards joint reconstruction of hands and manipulated objects from monocular color images. Existing methods focus on two alternative representations in terms of either parametric meshes or signed distance fields (SDFs). On one side, parametric models can benefit from prior knowledge at the cost of limited shape deformations and mesh resolutions. Mesh models, hence, may fail to precisely reconstruct details such as contact surfaces of hands and objects. SDF-based methods, on the other side, can represent arbitrary details but are lacking explicit priors. In this work we aim to improve SDF models using priors provided by parametric representations. In particular, we propose a joint learning framework that disentangles the pose and the shape. We obtain hand and object poses from parametric models and use them to align SDFs in 3D space. We show that such aligned SDFs better focus on reconstructing shape details and improve reconstruction accuracy both for hands and objects. We evaluate our method and demonstrate significant improvements over the state of the art on the challenging ObMan and DexYCB benchmarks.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_14
DP  - Springer Link
SP  - 231
EP  - 248
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - AlignSDF
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_14.pdf
KW  - Hand-object reconstruction
KW  - Parametric mesh models
KW  - Signed distance fields (SDFs)
ER  - 

TY  - CONF
TI  - Structural Causal 3D Reconstruction
AU  - Liu, Weiyang
AU  - Liu, Zhen
AU  - Paull, Liam
AU  - Weller, Adrian
AU  - Schölkopf, Bernhard
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper considers the problem of unsupervised 3D object reconstruction from in-the-wild single-view images. Due to ambiguity and intrinsic ill-posedness, this problem is inherently difficult to solve and therefore requires strong regularization to achieve disentanglement of different latent factors. Unlike existing works that introduce explicit regularizations into objective functions, we look into a different space for implicit regularization – the structure of latent space. Specifically, we restrict the structure of latent space to capture a topological causal ordering of latent factors (i.e., representing causal dependency as a directed acyclic graph). We first show that different causal orderings matter for 3D reconstruction, and then explore several approaches to find a task-dependent causal factor ordering. Our experiments demonstrate that the latent space structure indeed serves as an implicit regularization and introduces an inductive bias beneficial for reconstruction.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_9
DP  - Springer Link
SP  - 140
EP  - 159
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_9.pdf
ER  - 

TY  - CONF
TI  - PS-NeRF: Neural Inverse Rendering for Multi-view Photometric Stereo
AU  - Yang, Wenqi
AU  - Chen, Guanying
AU  - Chen, Chaofeng
AU  - Chen, Zhenfang
AU  - Wong, Kwan-Yee K.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Traditional multi-view photometric stereo (MVPS) methods are often composed of multiple disjoint stages, resulting in noticeable accumulated errors. In this paper, we present a neural inverse rendering method for MVPS based on implicit representation. Given multi-view images of a non-Lambertian object illuminated by multiple unknown directional lights, our method jointly estimates the geometry, materials, and lights. Our method first employs multi-light images to estimate per-view surface normal maps, which are used to regularize the normals derived from the neural radiance field. It then jointly optimizes the surface normals, spatially-varying BRDFs, and lights based on a shadow-aware differentiable rendering layer. After optimization, the reconstructed object can be used for novel-view rendering, relighting, and material editing. Experiments on both synthetic and real datasets demonstrate that our method achieves far more accurate shape reconstruction than existing MVPS and neural rendering methods. Our code and model can be found at https://ywq.github.io/psnerf.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_16
DP  - Springer Link
SP  - 266
EP  - 284
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
ST  - PS-NeRF
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_16.pdf
KW  - Inverse rendering
KW  - Multi-view photometric stereo
KW  - Neural rendering
ER  - 

TY  - CONF
TI  - Self-supervised Human Mesh Recovery with Cross-Representation Alignment
AU  - Gong, Xuan
AU  - Zheng, Meng
AU  - Planche, Benjamin
AU  - Karanam, Srikrishna
AU  - Chen, Terrence
AU  - Doermann, David
AU  - Wu, Ziyan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Fully supervised human mesh recovery methods are data-hungry and have poor generalizability due to the limited availability and diversity of 3D-annotated benchmark datasets. Recent progress in self-supervised human mesh recovery has been made using synthetic-data-driven training paradigms where the model is trained from synthetic paired 2D representation (e.g., 2D keypoints and segmentation masks) and 3D mesh. However, on synthetic dense correspondence maps (i.e., IUV) few have been explored since the domain gap between synthetic training data and real testing data is hard to address for 2D dense representation. To alleviate this domain gap on IUV, we propose cross-representation alignment utilizing the complementary information from the robust but sparse representation (2D keypoints). Specifically, the alignment errors between initial mesh estimation and both 2D representations are forwarded into regressor and dynamically corrected in the following mesh regression. This adaptive cross-representation alignment explicitly learns from the deviations and captures complementary information: robustness from sparse representation and richness from dense representation. We conduct extensive experiments on multiple standard benchmark datasets and demonstrate competitive results, helping take a step towards reducing the annotation effort needed to produce state-of-the-art models in human mesh estimation.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-19769-7_13
DP  - Springer Link
SP  - 212
EP  - 230
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-19769-7
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-19769-7_13.pdf
KW  - Human mesh recovery
KW  - Representation alignment
KW  - Synthetic-to-real learning
ER  - 

TY  - CONF
TI  - LSTM-Exploit: Intelligent Penetration Based on LSTM Tool
AU  - Wang, Ximin
AU  - Huang, Luyi
AU  - Zhu, Junlan
AU  - He, Wenbo
AU  - Qin, Zhaopeng
AU  - Yuan, Ming
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - LSTM-Exploit based on the cyclic neural network “LSTM” will analyze existing exploit rules, explore the internal relationships between payloads applicable to different systems to design and create intelligent penetration tools.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_8
DP  - Springer Link
SP  - 84
EP  - 93
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
ST  - LSTM-Exploit
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_8.pdf
KW  - Intelligent penetration
KW  - Long short-term memory network
KW  - LSTM
KW  - Metasploit
KW  - Nmap
ER  - 

TY  - CONF
TI  - Robust Liver Vessel Extraction Using DV-Net with D-BCE Loss Function
AU  - Su, Jun
AU  - Liu, Zhe
AU  - Song, Yuqing
AU  - Wang, Wenqiang
AU  - Han, Kai
AU  - Tang, Yangyang
AU  - Liu, Xuesheng
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Recently, liver vessel segmentation has aroused widespread interests in medical image analysis. Accurately extracting blood vessels from the liver is a difficult task due to the complex vessel structures and image noise. To make the network better adapt to this complex feature, a deeper network is needed to fit this nonlinear transformation. In this work, we introduce the dense block structure into the V-net to construct a new Dense V-Net (DV-Net) and use data augmentation to segment the liver vessels from abdominal CT volumes with few training samples. Besides, we propose the D-BCE loss function to cope with the problem of dynamic changes in pixel ratio caused by 3D segmentation random patches, which can also control the trade-off between false positives and negatives. In this way, the proposed DV-Net structure can acquire a more powerful discrimination capability between vessel areas and non-vessel areas. Our method is tested on the public datasets from 3Dircadb. The average dice and sensitivity on the 3Dircadb dataset were 74.76% and 75.27% respectively. Experiments are also conducted in another public dataset from Medical Segmentation Decalthon and also obtain much higher accuracies. Moreover, our approach is automatic, accurate and robust for liver vessel extraction and can enjoy better convergence properties, making it more efficient and reliable in practice.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_5
DP  - Springer Link
SP  - 52
EP  - 61
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_5.pdf
KW  - D-BCE loss
KW  - Deep learning
KW  - DV-Net
KW  - Liver vessel segmentation
ER  - 

TY  - CONF
TI  - Pig Target Detection from Image Based on Improved YOLO V3
AU  - Yin, Dan
AU  - Tang, Wengsheng
AU  - Chen, Peng
AU  - Yang, Bo
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Smart farming has always been one of the current research hotspots. Reflected by the behaviors and moves, the physiological conditions of pigs can be detected. The inability to detect the behaviors of pigs at scale has become the urgent issues. This makes the recognition of pigs an extremely significant problem. Building on the prior work on picture-based recognition of target detection, this paper put forward an improved YOLO V3 to detect pigs from image. To overcome the lack of pig’s pictures training data, transfer learning is used. To improve the accuracy of algorithm, attention mechanism is introduced into YOLO V3. Results show the algorithm we exploited can efficiently complete the task for pig real-time detection. Compared with the classical YOLO V3, the improved YOLO V3 has better metrics on precision, recall, F1 score and average precision. The improved model achieves result: 94.12% AP. The result is encouraging enough to make people collect more labeled pig’s picture data to improve the generalization capability of the algorithm.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_9
DP  - Springer Link
SP  - 94
EP  - 104
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_9.pdf
KW  - Intelligent farming
KW  - Target detection
KW  - YOLO v3
ER  - 

TY  - CONF
TI  - A Load Balancing Mechanism for a Multi-controller Software Defined WiFi Network
AU  - Manzoor, Sohaib
AU  - Manzoor, Hira
AU  - Manzoor, Mahak
AU  - Mahmood, Anzar
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Software defined WiFi networks (SD-WiFi) lead to a promising evolution path, by supporting changes in network traffic, providing centralized network provisioning and allowing flexible resource allocation. Load balancing still remains a challenging issue due to the increased number of WiFi users. In this paper, we propose an efficient algorithmic approach to solve the load imbalance issue in SD-WiFi. Traffic generated by users constituting the load, arrive at WiFi access points (APs). Support vector machine (SVM) segregates the traffic into high priority class (HP) and low priority class (LP) by considering flow deadlines and flow types. Controllers are arranged in two-tiers: global and local controllers. The local controllers (LC) update their load information to the global controller (GC) periodically. Binary search tree (BST) is employed in the GC to find the least loaded LC for flow processing. OMNeT++ simulator is used to perform extensive simulations for performance evaluation of the proposed SVM-BST scheme. The proposed SVM-BST scheme outperforms load information strategy and EASM schemes in throughput by 50–200% and in response time by 20–30% respectively.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_1.pdf
KW  - Load balancing
KW  - Multi-controllers
KW  - SDN
KW  - WiFi
ER  - 

TY  - CONF
TI  - A Review on Named Entity Recognition in Chinese Medical Text
AU  - Zhou, Lu
AU  - Qu, Weiguang
AU  - Wei, Tingxin
AU  - Zhou, Junsheng
AU  - Gu, Yanhui
AU  - Li, Bin
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In this paper, a survey is done to introduce the named entity recognition task in Chinese medical text and its practical significance. First, the existing datasets for the named entity recognition task of Chinese medical text are presented, then the survey is given on the algorithms for this task, mainly from the perspectives on matching and sequence labeling. Finally, the future development of named entity recognition in Chinese medical text is discussed.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_4
DP  - Springer Link
SP  - 39
EP  - 51
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_4.pdf
KW  - Chinese medical text
KW  - Named entity recognition
ER  - 

TY  - CONF
TI  - Application of Lidar INS Integrated Positioning in Automatic Driving
AU  - Li, Zhiguo
AU  - Wang, Ying
AU  - Xiong, Zhenti
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Due to factors such as ground blockage, electromagnetic interference and malicious attacks, the satellite-inertial navigation system cannot provide stable and reliable high-precision positioning information. Therefore, it is necessary to provide an autonomous and reliable navigation system for the self driving vehicle as a supplement. In this study, vehicle-mounted radar is used to obtain point cloud information around the self-driving car, and the above point cloud information is filtered to find a road that can be driven, and a least squares calculation is performed on the area to obtain a fitted path. Finally, the real-time travel trajectory of autonomous vehicles is planned. Based on the above method, an unmanned experimental vehicle was used for engineering verification. The results show that the radar-inertial navigation mode can achieve stable and reliable L4 automatic driving.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_3
DP  - Springer Link
SP  - 28
EP  - 38
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_3.pdf
KW  - Autopilot
KW  - Positioning
KW  - Radar-inertial navigation
KW  - Trajectory planning
ER  - 

TY  - CONF
TI  - A New Method of Halftoning and Inverse Halftoning Based on GAN Network
AU  - Gu, Jianjin
AU  - Li, Li
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Halftoning is a method of quantifying a continuous tone image into a binary image. Halftone methods can be categorized into dithering, error diffusion and iterative method. We present a new method different from traditional halftoning algorithms for learning the mapping between continuous images and halftone images using conditional generative adversarial networks (conditional GANs). We regard halftoning and inverse halftoning as the process of image-to-image translation, and use the classic pix2pixHD network. In this work, we use multi-scale generator and discriminator architectures to perform both halftoning and its structural reconstruction. The experimental results show that this method can better fit some classical halftoning algorithms to realize halftoning and inverse halftoning. Compared with the existing methods, our method can better realize reconstruction of halftone images.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_11
DP  - Springer Link
SP  - 119
EP  - 131
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_11.pdf
KW  - GAN
KW  - Halftoning
KW  - Inverse Halftoning
ER  - 

TY  - CONF
TI  - HGC: Hybrid Gradient Compression in Distributed Deep Learning
AU  - Hu, Kaifan
AU  - Wu, Chengkun
AU  - Zhu, En
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Distributed stochastic gradient descent (SGD) algorithms are widely deployed in training large-scale deep learning models, while the communication overhead among workers becomes the new system bottleneck. Recently, two major categories of gradient compression techniques were proposed, including gradient quantization and sparsification. At best, the gradient quantization technique can obtain a compression ratio of 32, with little impact on model convergence accuracy. The gradient sparse technique can achieve a much higher compression ratio with some loss of model accuracy. To obtain a higher communication compression ratio with the minimum model accuracy loss, we proposed a mixed compression strategy named Hybrid Gradient Compression (HGC), which combines the merits of both quantization and sparsification. We validated the efficiency of our Hybrid Gradient Compression method by testing some complex models with millions of parameters (e.g., ResNet, VGG, LSTM, etc.) on the datasets including CIFAR-10, CIFAR-100 and Penn TreeBank on a GPU cluster. According to our tests, HGC can achieve a much higher gradient compression ratio at the cost of a small accuracy loss.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_2
DP  - Springer Link
SP  - 15
EP  - 27
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
ST  - HGC
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_2.pdf
KW  - Distributed computing
KW  - Distributed optimization
KW  - Gradient compression
KW  - Machine learning
ER  - 

TY  - CONF
TI  - Sow Estrus Diagnosis from Sound Samples Based on Improved Deep Learning
AU  - Chen, Peng
AU  - Tang, Wengsheng
AU  - Yin, Dan
AU  - Yang, Bo
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The inability to diagnose sow estrus at scale has become the burning issues in the livestock farming. An intelligent screening tool would be a game changer. Changing the dependence on the traditional method of artificial detection, this paper proposes, develops and uses an Artificial Intelligence-based screening solution for sow estrus detection. Sow estrus call is one of the significant calls which can reflect the physiological conditions. This makes the recognition of sow estrus call an exceedingly challenging problem. This problem is addressed by investigating the distinctness of Mel spectrum in the sound system generated in estrus when compared to other pig sounds. To overcome the lack of sow estrus sounds training data, transfer learning is exploited. To reduce the risk of misdiagnosis we raise a two-pronged AI architecture, one is collecting and transmitting sound to the detector, the other is identifying calls in sow estrus diagnosis system. Results show the AI architecture can distinguish among sow estrus calls and other non-sow-estrus-calls. The performance is good enough to encourage a large-scale collection of labeled sow estrus call data to improve the generalization capability of the AI architecture.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_12
DP  - Springer Link
SP  - 132
EP  - 143
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_12.pdf
KW  - Deep learning
KW  - Speech recognition
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - Asynchronous Compatible D-ML System for Edge Devices
AU  - Ge, Guangfu
AU  - Zhu, Feng
AU  - Huang, Yuchen
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The parameter server system (Parameter Server, PS) is the most widely used distributed machine learning system. Its core module is the communication module, which mainly includes three parts: communication content, communication frequency, and communication pace. The communication scheme of the existing PS system will have problems such as waste of computing power resources and a large proportion of communication overhead. This paper hopes to design and implement a distributed set that saves computing power and has a smaller communication overhead based on the communication module of the original PS system. Machine learning system, this article mainly has the following contributions: First, through the analysis and experiment of Bulk Synchronous Parallel (BSP) communication pace, based on the superiority of BSP algorithm level, it overcomes the waste of computing power of BSP at the system level, and designs and implements a new set of Communication pace, the new communication pace under the same training task can save more computing power and achieve higher model accuracy. Secondly, this article combines the quantization compression technology with the parameter server system, and uses the quantization technology to compress and decompress the communication content in the parameter server system, so that the volume of the communication content during the operation of the parameter server system is significantly reduced, thereby reducing the communication overhead and improving Speedup ratio of the system. Finally, based on the analysis and experiment of the change trend of the model accuracy rate, this paper designs and implements a dynamic communication frequency adjustment scheme based on the change trend of the model accuracy rate, which reduces the overall communication frequency during the operation of the parameter server system and reduces the parameter server. T Experiments show that the system designed in this paper is superior to the existing mainstream solutions in terms of communication pace, communication content, and communication frequency. When training the same model, this system compared with the existing parameter server system in model convergence time, model There is a noticeable improvement in the highest accuracy.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_15
DP  - Springer Link
SP  - 168
EP  - 179
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_15.pdf
KW  - BSP
KW  - Communication content
KW  - Communication frequency
KW  - Communication pace
KW  - Distributed
KW  - Machine learning
KW  - Quantization Compression
ER  - 

TY  - CONF
TI  - Intelligent Intrusion Detection of Measurement Automation System Based on Deep Learning
AU  - Liu, Tao
AU  - Wu, Shaocheng
AU  - Guo, Ziyv
AU  - Zhao, Jie
AU  - Sun, Wenlong
AU  - Cao, Xiaohong
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In the smart grid with measurement automation system, the intrusion detection system judges the intrusion event by analyzing the transmission data in the grid. Aiming at the characteristics of traditional intrusion detection, such as loss of features, low detection efficiency and poor adaptability, an intrusion detection method based on stacked denoising convolutional autoencoders is proposed, which combine convolutional neural network and denoising autoencoder to strengthen feature recognition ability, using Dropout and regularization methods to prevent overfitting, and using Adam algorithm to obtain optimal parameters. Finally, the NSL-KDD data set is used to verify the proposed method. Experimental results show that the overall recognition rate of this method is 97.25%, which is 11.59%, 9.63% and 4.07% higher than the existing NN, SVM, and ICNN accuracy rates respectively.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_7
DP  - Springer Link
SP  - 70
EP  - 83
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_7.pdf
KW  - Autoencoder
KW  - Convolutional neural network
KW  - Intrusion detection
KW  - Measurement automation system
ER  - 

TY  - CONF
TI  - Investigation on Loan Approval Based on Convolutional Neural Network
AU  - Wu, Mingli
AU  - Du, Chunlai
AU  - Huang, Yafei
AU  - Cui, Xianwei
AU  - Duan, Jianyong
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the economic development, loan business has rapidly developed in China. The risk that customers can’t repay their loans on time has increased. Therefore it is an important problem for financial organizations to approve the customers’ loan application or not. Typical machine learning methods for classification can be employed to mine customers’ financial information and give valuable judgments. However, these learning methods rely on shallow features, and the relationships between these features are not well studied. We investigate the function of Convolutional Neural Network (CNN) in this work, as it is successful in field of image recognition, speech recognition and natural language processing. We investigate four different CNN models. Experiments show that the fourth model with stochastic gradient descent algorithm and momentum achieves the best performance. Its accuracy and recall are 0.95 and 0.26 respectively.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_18
DP  - Springer Link
SP  - 203
EP  - 216
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_18.pdf
KW  - Classification
KW  - Convolutional neural network
KW  - Loan approval
KW  - Machine learning
ER  - 

TY  - CONF
TI  - Cloud Computing-Based Graph Convolutional Network Power Consumption Prediction Method
AU  - Ma, Yong
AU  - Sheng, Honglei
AU  - Wu, Shang
AU  - Gong, Shuai
AU  - Cheng, Hang
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the continuous increase of electricity consumption data in smart grids, the data storage and data analysis capabilities of traditional single-node data mining algorithms can no longer meet the requirements of electricity consumption forecasting. This paper designs a electricity consumption forecasting method based on cloud computing and graph convolutional network. The method first proposes a GCN-based electricity consumption forecasting model, then builds a Hadoop platform, uses MapReduce to parallelize and iteratively trains the GCN model on the platform, and then uses the trained model to predict electricity consumption. In addition, the prediction accuracy of this method is verified through experiments.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_6
DP  - Springer Link
SP  - 62
EP  - 69
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_6.pdf
KW  - Cloud computing
KW  - Data prediction
KW  - GCN
KW  - Hadoop
ER  - 

TY  - CONF
TI  - GVNP: Global Vectors for Node Representation
AU  - Zhang, Dongao
AU  - Chen, Ziyang
AU  - Zheng, Peijia
AU  - Liu, Hongmei
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Learning low-dimensional embeddings of nodes in networks is an effective way to solve the network analytic problem, from traffic network to recommender systems. However, most existing approaches are inherently transductive, their framework is built on a single fixed graph. Inspired by node2vec, we optimize the random walk strategy and propose GVNP, an unsupervised method that can learn continuous feature representations for nodes and leverage node feature information to efficiently generate node embeddings for previously unseen data in networks. Experimental results demonstrate that GVNP performs well on the transductive and inductive task.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_17
DP  - Springer Link
SP  - 193
EP  - 202
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
ST  - GVNP
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_17.pdf
KW  - Data mining
KW  - Deep networks
KW  - Graph learning
ER  - 

TY  - CONF
TI  - Ball K-Medoids: Faster and Exacter
AU  - Peng, Qiao
AU  - Zhang, Shibin
AU  - Zhang, Jinquan
AU  - Huang, Yuanyuan
AU  - Yao, Boyi
AU  - Tang, Haozhe
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Cluster analysis can be viewed as a result of the natural evolution of the vast amount of data from daily life, and can discover invisible feature information to contribute to the analysis. K-means algorithm is one of the wide data clustering methods in a variety of real-world applications thanks to its simpleness. However, the k-means is sensitive to noise and outlier data points because a small number of such data can substantially influence the mean value of the cluster. In light of this, the k-medoids algorithm selects a point as a new center that minimizes the sum of the dissimilarities in the cluster, to diminish such sensitivity to outliers. Nevertheless, the line of the k-medoids algorithm is limited by its amounts of computation and not to handle with data efficiently. To this end, we present a novel k-medoids algorithm motivated by the theory of ball cluster, relationship between clusters and partitioning cluster for assigning samples into their nearest medoids efficiently, called ball k-medoids, which drop the distance calculation of sample-medoid significantly. Moreover, a threshold is inferenced by the rollback method for reducing computation of medoid-medoid distance and accelerating clustering. Experiments finally demonstrate that the performance of ball k-medoids achieves more efficient in comparison with other k-medoids algorithms, and it performs exacter accuracy compared with k-means.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_16
DP  - Springer Link
SP  - 180
EP  - 192
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
ST  - Ball K-Medoids
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_16.pdf
KW  - Ball cluster
KW  - Ball K-Medoids
KW  - Cluster analysis
ER  - 

TY  - CONF
TI  - Research on YOLO Model and Its Application in Fault Status Recognition of Freight Trains
AU  - Li, Xueqi
AU  - Liu, Qing
AU  - Liu, Tongcai
AU  - Wang, Jingbo
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Compared with other object detection and recognition methods, YOLO is an end-to-end algorithm that integrates target region prediction and target category prediction into a single neural network model. It can realize rapid target detection and recognition with high accuracy, which is more suitable for field application. The network models of YOLOV3 and YOLOV4 are studied, aiming at the application environment of fault state detection in railway transportation and freight. In view of the shortcomings of YOLOV3 algorithm, the Dense block-BC is used to replace Darknet-53 to build the YOLOV3 backbone network. CIoU is used to replace the MSE to calculate the boundary box loss, and Focal loss is used to redesign the loss function to improve the YOLOV3 model. The improved YOLOV3 and YOLOV4 are respectively used to detect the fault state in railway locomotive transportation, and the better detection results are obtained.16,660 pictures are collected directly from the railway transportation site as train set, and other 3,000 pictures are used as test set. The omission factor can be reduced to 4.164%, and the error rate can be decreased to 4.218%.The detection speed of each picture is 0.4s, which can meet the requirements of non-stopping fault state detection in railway transportation.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_13
DP  - Springer Link
SP  - 144
EP  - 156
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_13.pdf
KW  - Fault status recognition of freight trains
KW  - Object detection
KW  - YOLOV3
KW  - YOLOV4
ER  - 

TY  - CONF
TI  - Feedforward Deep Neural Network-Based Model for the Forecast of Severe Convective Wind
AU  - Jing, Yu
AU  - Wang, Nan
AU  - Zhao, Qiang
AU  - Li, Pingyun
AU  - Hu, Qiyuan
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In this study, we compared and analyzed the environmental characteristics in Shaanxi between 2016–2018 (before and after the occurrence of convective wind) based on both severe and non-severe wind samples extracted from the fifth generation of European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis (ERA5) data and automatic weather station data from the China Meteorological Administration. Through the establishment of deep feedforward neural networks, these environmental characteristics were then used to define a model for the forecast of severe convective wind events. For $$\sim$$∼75% (or > 75%) severe convective wind samples, the differences between 1 h after the occurrence of severe convective wind and when it occurred, 1 h after it occurred and 1 h before it occurred in MLCAPE, MUCAPE, SBCAPE, MLCIN, MUCIN, SBCIN, MLEL, MUEL, SBEL, SBLCL and temperature were negative, while those in MLLI, MULI, SBLI, sea level pressure (SLP), and precipitation were positive. This suggests that, for $$\sim$$∼75% (or > 75%) severe convective wind samples, atmospheric stability increased or SLP increased, or temperature decreased; moreover, precipitation was found to occur after severe convective wind. Finally, a certain degree of differentiation was noted between the parameters associated with the severe and non-severe convective wind samples. We designed two schemes (each containing three kinds of experiments) and trained a feedforward deep neural network to predict severe convective wind events. The network experiment including the higher number of elements was found to provide the highest threat score (Ts).
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_14
DP  - Springer Link
SP  - 157
EP  - 167
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_14.pdf
KW  - Environmental characteristics
KW  - Feedforward deep neural network
KW  - Severe convective wind
ER  - 

TY  - CONF
TI  - ICPM: An Intelligent Compound Prediction Model Based on GA and GRNN
AU  - Chen, Fang
AU  - Zhang, Cong
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In order to reduce the prediction error of the heavy metal content of farmland soil by General Regression Neural Network (GRNN), an Intelligent Compound Prediction Model (ICPM) was proposed. As the result of Genetic Algorithm optimization is good or bad, it mainly depends on whether it can guarantee the diversity of the population in the optimization process. Based on this, an Improved Genetic Algorithm (IGA) is proposed. IGA introduces the probability adjustment of the sine function transformation and the better gene replacement criterion into the Genetic Algorithm (GA). In the process of IGA’s optimization, the crossover probability and mutation probability continue to increase, ensuring the continuity of the diversity of the population. ICPM is a combined forecasting model of GRNN and IGA. It optimizes the smoothing factor of GRNN through IGA. The process of repeated optimization of IGA is also the process of repeated learning of existing knowledge by GRNN. ICPM not only ensures the continuous optimization of the population, but also the diversity of the population. Combined with the simulation prediction of the content of heavy metals Cr, Cu and Pb in farmland soil in Dongxihu District of Wuhan City, it proved that ICPM has better prediction performance and better generalization performance than GRNN and other models.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_10
DP  - Springer Link
SP  - 105
EP  - 118
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78615-1
ST  - ICPM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78615-1_10.pdf
KW  - Generalized regression neural network
KW  - Genetic Algorithm
KW  - Heavy metal content prediction
KW  - Parameter optimization
KW  - Small sample prediction
ER  - 

TY  - CONF
TI  - Function Level Cross-Modal Code Similarity Detection with Jointly Trained Deep Encoders
AU  - Tian, Zhenzhou
AU  - Wang, Lumeng
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Binary source code matching, which matches a source code snippet to its similar binaries or vice versa, facilitates security-critical tasks such as software plagiarism detection and vulnerability confirmation; while the huge structural and syntactical gaps between the two different kind modalities, makes it challenging to calculating their similarity in an accurate manner. To this end, this work presents XMSim (Cross-Modal function Similarity detector), which compares directly between the source codes and the binary assemblies. XMSim resorts to an Transformer-based encoder and the TextCNN model respectively, to extract semantic vectors from the normalized source code tokens and the assembly instructions. To guarantee the effectiveness the semantic encoders, a large dataset consisting of 92,000 source-binary function pairs is constructed, on which the siamese neural network structure is adopted to get both encoders jointly trained. As the experimental evaluations show, XMSim can effectively identify similar or non-similar relationships between the source codes and the binaries, with the detection accuracy reaches 86.7%. Also, XMSim show good resilience against the disturbances from different compilers and optimization levels.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_8
DP  - Springer Link
SP  - 61
EP  - 68
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_8.pdf
KW  - Code similarity
KW  - Cross-modal
KW  - Siamese network
KW  - Transformer
ER  - 

TY  - CONF
TI  - Pain Expression Recognition Based on Dual-Channel Convolutional Neural Network
AU  - Xu, Xuebin
AU  - Lei, Meng
AU  - Liu, Dehua
AU  - Wang, Muyu
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - As an important branch in the field of artificial intelligence, deep learning has penetrated into all walks of life in society in recent years, especially in the recognition of human features has made great progress. Humans have a certain ability to feel pain, but there are some people who can’t put it into words. At present, the recognition of pain expression mainly relies on traditional manual testing methods. This testing method is time-consuming and cumbersome, and subject to subjective influence by professionals, which may lead to biased test results. Therefore, a convenient, efficient and objective pain expression recognition system is needed as an auxiliary tool to help professionals make judgments. The pain expression recognition method proposed in this paper is based on dual-channel convolutional neural network. Firstly, the pain data set is preprocessed. For the dual-channel input data, facial expression features are extracted by using convolution neural networks with different parameters. Then the feature maps of the classification network are fused, and finally softmax is used for classification. The accuracy of the improved convolutional neural network model on COPE data set is 97.5%.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_5
DP  - Springer Link
SP  - 35
EP  - 42
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_5.pdf
KW  - Deep learning
KW  - Dual-channel convolutional neural network
KW  - Pain expression recognition
ER  - 

TY  - CONF
TI  - DeSG: Towards Generating Valid Solidity Smart Contracts with Deep Learning
AU  - Tian, Zhenzhou
AU  - Wang, Fanfan
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Solidity being a young yet the most widely used programming language to develop smart contracts, which are programs that run on the blockchains, is frequently exposed of bugs and under continues improvement. To this end, this work presents DeSG to facilitate the fuzz testing of the fast-evolving Solidity compiler, by automatically generating massive solidity smart contracts of diversity in a deep learning based manner. An encoder-decoder model is designed to ensure the production of high-quality and valid smart contracts, by equipping with the powerful representation learning ability from the Transformer, as well as three carefully-designed generation strategies that well-match the features of the Solidity language. The experimental evaluations conducted show that, DeSG can effectively generate syntactically valid and highly compilable smart contracts. The impacts of different encoding neural networks and generation strategies to DeSG are also evaluated, with the best performance reaching 91.2% validity score.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_11
DP  - Springer Link
SP  - 85
EP  - 92
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
ST  - DeSG
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_11.pdf
KW  - Code generation
KW  - Deep learning
KW  - Smart contract
KW  - Solidity
ER  - 

TY  - CONF
TI  - Multiple Layers Global Average Pooling Fusion
AU  - Cao, Silei
AU  - Long, Shun
AU  - Zhu, Weiheng
AU  - Liao, Fangting
AU  - Yuan, Zeduo
AU  - Guan, Xinyi
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - We propose for deep convolutional neural network (CNN) a simple but effective feature fusion technique called multiple layers global average pooling fusion (MLGAPF). It adds a branch at each CNN layer or module which uses global average pooling to extract global features, and these features are then fused for classification. Empirical experiments show that this technique can effectively improve the accuracy of ResNet, GoogleNet, SqueezeNet, MobileNetv2 and others. On average, MLGAPF brought additional performance enhancement of 2.62% and 2.49% on CIFAR100 and Tiny-ImageNet respectively.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_1
DP  - Springer Link
SP  - 3
EP  - 10
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_1.pdf
KW  - Convolutional neural network
KW  - Feature fusion
KW  - Global average pooling
ER  - 

TY  - CONF
TI  - A Deep Learning-Based Innovative Points Extraction Method
AU  - Yu, Tao
AU  - Wang, Rui
AU  - Zhan, Hongfei
AU  - Lin, Yingjun
AU  - Yu, Junhe
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Most of the research on mining online reviews now focuses on the influence of reviews on consumers and the issue of sentiment analysis for analyzing consumer reviews, but few studies how to extract innovative ideas for products from review data. To this end, we propose a deep learning-based method to extract sentences with innovative ideas from a large amount of review data. First, we select a product review dataset from the Internet, and use a stacking integrated word embedding method to generate a rich semantic representation of review sentences, and then the resulting representation of each sentence will be feature extraction by a bidirectional gated recurrent unit (BiGRU) model combined with self-attention mechanism, and finally the extracted features are classified into innovative sentences through softmax. The method proposed in this paper can efficiently and accurately extract innovative sentences from class-imbalanced review data, and our proposed method can be applied in most information extraction studies.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_16
DP  - Springer Link
SP  - 130
EP  - 138
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_16.pdf
KW  - Class imbalance problem
KW  - Deep learning
KW  - Information extraction
KW  - Text classification
KW  - Word embedding
ER  - 

TY  - CONF
TI  - Ease Solidity Smart Contract Compilation through Version Pragma Identification
AU  - Tian, Zhenzhou
AU  - He, Ruikang
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Solidity, the most popular language for developing smart contracts that run on blockchains, has experienced a fast version changing since its first release. Yet, the fact that different Solidity versions are generally incompatible, makes it torturous for developers to correctly pick the Solidity version to compile a smart contract missing version-indicative information. This work presents SolCom to ease the compilation of a Solidity smart contract. It infers from the source code of a smart contract its version pragma, with which the developers can accurately determine the right-version Solidity compiler to get the source code compiled rather than aimless attempts. SolCom processes the source code into normalized tokens, and resorts to a carefully-designed attention augmented convolutional neural network model to capture version indicative features. As the experimental evaluations show, SolCom can identify the version pragma with a rather high accuracy of 96.30%.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_9
DP  - Springer Link
SP  - 69
EP  - 75
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_9.pdf
KW  - Neural networks
KW  - Smart contract
KW  - Solidity
KW  - Version pragma
ER  - 

TY  - CONF
TI  - Cross Architecture Function Similarity Detection with Binary Lifting and Neural Metric Learning
AU  - Tian, Zhenzhou
AU  - Li, Chen
AU  - Qiu, Sihao
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Binary code similarity detection has extensive and important applications in IoT device security, yet which suffers the challenges from the differentiated underlying architectures of the diverse IoT devices. To this end, this paper presents XFSim (Cross-architecture Function-level binary code Similarity detection), through binary lifting and neural similarity metric learning. Firstly, to make the detection method architecture agnostic, the binaries to be analyzed are lifted to an intermediate code called LLVM-IR and normalized for an uniform representation, so as to alleviate the discrepancies between the raw assemblies of different instruction set architectures (ISAs). Secondly, we utilize FastText, a widely used word embedding algorithm, that learns on the functions’ normalized intermediate codes to obtain high quality token embeddings. Then, an efficient CNN-based model is utilized to encode the semantics of each function into numerical vectors, meanwhile the siamese neural network structure is resorted to supervise the whole model training, with the goal of minimizing the contrastive loss. Finally, the similarity of two binary code snippets can measured by the cosine similarity of their encoded vectors. The experiments conducted on a public dataset show that, the strategy of lifting and normalizing the assemblies to uniform representations greatly alleviates the semantic-gaps between different ISAs, and XFSim outperforms two existing cross-architecture binary code similarity detectors.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_4
DP  - Springer Link
SP  - 27
EP  - 34
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_4.pdf
KW  - Binary code similarity detection
KW  - Binary lifting
KW  - Instruction set architecture
KW  - Neural network
ER  - 

TY  - CONF
TI  - Combining AST Segmentation and Deep Semantic Extraction for Function Level Vulnerability Detection
AU  - Tian, Zhenzhou
AU  - Tian, Binhui
AU  - Lv, Jiajun
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The explosive growth of software vulnerabilities poses a serious threat to computer system security and has become one of the urgent problems of the day. Yet, most existing vulnerability detection methods generally fail to capture the deep semantic features of code fragments, leading to the problem of high false negative rate easily. To this end, this paper proposes TrFVD (abstract syntax Tree based Function Vulnerability Detector), which mines deep semantics implied in source code fragments for accurate function level vulnerability detection. To ease the capture of fine-grained subtle semantic features, TrFVD converts the AST of a function into sequentially ordered sub-trees by splitting it in accordance with statements. The semantics of each sub-tree is then extracted with the Tree-LSTM, and a Text-RNN based model is utilized to summarize them up into a dense numerical vector to get the function represented. The experimental evaluations conducted on two C program vulnerability datasets show the effectiveness of TrFVD, which achieves 98.44% and 98.32% accuracy respectively. The averagely 12% more performance promotion against other vulnerability detection methods also indicates the superiority of TrFVD in capturing deeper subtle yet significant code semantics.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_12
DP  - Springer Link
SP  - 93
EP  - 100
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_12.pdf
KW  - Abstract syntax tree
KW  - Deep learning
KW  - Deep semantic extraction
KW  - Vulnerability detection
ER  - 

TY  - CONF
TI  - Towards Robust Similarity Detection of Smart Contracts with Masked Language Modelling
AU  - Tian, Zhenzhou
AU  - Ke, Xianqun
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Smart contracts are programs that run on blockchains. The whole smart contract ecosystem tends to be highly homogeneous, due to the immutable nature of contracts once deployed, as well as the copy-paste practice in developing smart contracts. Thus, similarity detection between smart contracts is of great value, which facilitates the quality assurance of the whole ecosystem, by providing a way to identify and track clones among the smart contracts. To this end, this work presents SoliSim, which encodes smart contracts into informative semantic vectors for effective and efficient similarity detection. The smart contract encoding procedure is enforced with masked language modelling on the Solidity programming language, which pre-trains a bert-like model by feeding in normalized token sequences extracted from the smart contracts’ abstract syntax trees (ASTs); while the similarity detection procedure is enforced via simply calculating a score on the encoded numerical vectors. As the experimental results show, the pre-trained strategy adopted by SoliSim is capable of capturing the contextual and semantic information of smart contracts’ code. The similarity scores calculated with SoliSim on pairs of real cloned contracts all exceed 96%, while the values between non-clone pairs are all below 50%.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_10
DP  - Springer Link
SP  - 76
EP  - 84
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_10.pdf
KW  - Pre-trained model
KW  - Similarity detection
KW  - Smart contract
ER  - 

TY  - CONF
TI  - A Novel Variational-Mode-Decomposition-Based Long Short-Term Memory for Foreign Exchange Prediction
AU  - Tan, Shyer Bin
AU  - Wang, Lipo
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The global foreign exchange (forex) market has a daily volume on the order of $5 trillion and is the largest financial market in the world. The importance of this market has attracted many research efforts. Numerous techniques have been developed, including technical analysis, where researchers attempt to predict forex rates based on past forex data. In this paper, we combine a signal processing technique Variational Mode Decomposition (VMD) and the Long Short-Term Memory Neural Network (LSTM) to predict forex and show significant improvements over other predicting models.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_13
DP  - Springer Link
SP  - 101
EP  - 108
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_13.pdf
KW  - Foreign exchange (forex)
KW  - Long short-term memory neural network (LSTM)
KW  - Variational mode decomposition (VMD)
ER  - 

TY  - CONF
TI  - Sheep Herd Recognition and Classification Based on Deep Learning
AU  - Halimu, Yeerjiang
AU  - Chao, Zhou
AU  - Sun, Jun
AU  - Zhang, Xiubin
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Automatic identification of sheep herd is always an unsolved technical problem. This is because there are many kinds of sheep, and there are great differences in individual morphology and characteristics. Moreover, human’s mastery of the individual characteristics of different breeds of sheep is only in the stage of experience. So far, people have not completely established the classification database of individual characteristics of sheep.This paper is a summary of the exploratory research on this technical problem. It provides a sheep recognition and classification algorithm based on deep learning. The algorithm adopts dual channel convolution neural network, and carries out reverse transmission according to the image characteristics in time to realize the adaptive adjustment of weight. Once the optimal or suboptimal weight is obtained, the iteration is ended, and the identified objects are located, counted and classified. The experimental results show that the algorithm can greatly reduce the calculation time and make the recognition and classification more accurate.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_15
DP  - Springer Link
SP  - 122
EP  - 129
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_15.pdf
KW  - Classification
KW  - Convolutional neural network
KW  - Deep learning
KW  - Recognition
KW  - Sheep herd
ER  - 

TY  - CONF
TI  - Han Dynasty Clothing Image Classification Model Based on KNN-Attention and CNN
AU  - Ziwei, Guan
AU  - Zhao, Lv
AU  - Jinbao, Teng
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Aiming at the problem that the traditional clothing image classification model cannot effectively extract the instance information of other samples in the training set, a clothing image classification model of Han Dynasty based on KNN-Attention and CNN was proposed. Firstly, KNN-Attention was used to extract the clothing image information of K instance samples similar to the original training samples. Secondly, CNN is used to further extract the local key features of clothing images. Finally, the output information of KNN-Attention and CNN is integrated, so as to achieve the purpose of effectively utilizing the training set instance information in the task of clothing image classification. The experimental results show that the proposed model is better than the traditional classification model and can effectively improve the classification effect of clothing images.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_2
DP  - Springer Link
SP  - 11
EP  - 17
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_2.pdf
KW  - Attention
KW  - Clothing image classification in Han Dynasty
KW  - CNN
KW  - KNN
ER  - 

TY  - CONF
TI  - Multi-title Attention Mechanism to Generate High-Quality Images on AttnGAN
AU  - Qiao, Pingan
AU  - Gao, Xiwang
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In the field of Text-to-image, text is essentially a constraint condition for the generated image, and the generation network guides to generate images that match the text according to the constraint conditions. However, if the image is generated only on the basis of a given text constraint condition, obviously, it can be imagined that the generated image without rich details, reducing the image visualization. With that in mind, we introduce Multi-title Attention Mechanism, regard the dataset as a prior condition, at first, select other titles in the dataset that are compatible with the given text according to given title, which is essentially the process of information retrieval, and then use the self-attention mechanism to integrate the embedding of multiple titles, the final text contains rich detail information, which guides the generation of high-quality images. In addition, in order to enable AttnGAN to generate clear image in the first stage, we introduce a mixed attention mechansim and an Residual Dense Block(RDB) model. The mixed attention mechanism includes: channel attention and pixel attention. Channel attention is mainly to guide what the image is generate, while pixel attention is responsible for where it is generated. Experiments on the CUB dataset show that the proposed approaches is significantly better than AttnGAN, and the lnception Score(IS) and R-precision of the evaluation index are improved by 4.12% and 10.43% respectively.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_18
DP  - Springer Link
SP  - 147
EP  - 156
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_18.pdf
KW  - Mixed attention
KW  - Muti-title attention
KW  - Residual dense block
KW  - Text-to-image
ER  - 

TY  - CONF
TI  - Code Summarization Through Learning Linearized AST Paths with Transformer
AU  - Tian, Zhenzhou
AU  - Zhang, Cuiping
AU  - Tian, Binhui
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The lack of code comments is common in software projects. This work proposes TFSum, which generates from a function’s source code a readable summary to describe its functionality, with a Transformer based model trained on sequences linearized from the function’s abstract syntax tree (AST). To ensure the quality of the generated summaries, TFSum firstly parses from the function’s source code an AST of semantic richness, as the raw representation of the function; but linearizes and pre-processes it into a set of normalized token sequences, for efficient and effective following semantic representation learning. On this basis, an encoder-decoder based generative model that adopts the Transformer architecture is designed and trained to automatically generate code comments. The experimental evaluations conducted on a public dataset show the superiority of TFSum over state-of-the-art neural code summarization methods, with the BLEU score reaching 46.84.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_7
DP  - Springer Link
SP  - 53
EP  - 60
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_7.pdf
KW  - AST
KW  - Attention mechanism
KW  - Code summarization
ER  - 

TY  - CONF
TI  - Self-Attention SSD Network Detection Method of X-ray Security Images
AU  - Zhang, Hong
AU  - Liu, Baoyang
AU  - Gao, Yue
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - For the manual omission of X-ray security images inspection, SSD network extracts image features with a large number of convolutional layers, and some object feature information is missed in the deep feature layer after multiple convolutions and pooling. The self-attention mechanism can obtain images global features, and reduce the missing of image feature information. This paper proposes two new target detection algorithm BoT-SSD and ResT-SSD based on self-attention neural network, they apply BoTNet and ResT as the backbone network to extract more important features. The multi-scale network structure of SSD is combined with FPN and CBAM, which can use underlying and high-level feature and strengthen target feature information. Moreover, the self-attention modules are used to enhance the global under-standing of the image by high-level features layers. The X-ray images detection results show that the targets with complex background can identified more accurately. Compared with the original SSD network, the proposed BoT-SSD and ResT-SSD networks improve MAP value by 5.63% and 7.52% respectively.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_3
DP  - Springer Link
SP  - 18
EP  - 26
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_3.pdf
KW  - BoTNet
KW  - ResT
KW  - Self-attention
KW  - SSD
KW  - X-ray security inspection
ER  - 

TY  - CONF
TI  - A Noval Air Quality Index Prediction Scheme Based on Long Short-Term Memory Technology
AU  - Ding, Lijiao
AU  - Sun, Jinze
AU  - Shen, Tingda
AU  - Jing, Changqiang
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - People have been paying more and more attention to their surroundings in recent years, and the problem of air quality, which affects a significant portion of our surroundings, warrants our attention. Ground-level ozone, particulate pollutants, carbon monoxide, sulfur dioxide, and nitrogen dioxide make up the five components of the Air Quality Index, which is a key index for describing the state of the air. Predicting Air Quality Index values using deep learning is crucial for addressing the issue of air pollution. This study compares the prediction accuracy of Long Short-Term Memory and Convolutional Neural Networks on time-series class data, and the results show that Long Short-Term Memory is significantly better than Convolutional Neural Networks in predicting Air Quality Index values. The study uses the actual Air Quality Index data of a specific city for 720 consecutive hours to predict Air Quality Index values using deep learning. When creating the model based on the visualization, a visual presentation is created to demonstrate the data, prediction model, and metrics for calculating the Air Quality Index. The visual display and model building of Air Quality Index indexes are beneficial to giving us a deeper understanding of air pollution problems, and play an important role in setting further policies to improve air quality and prevent respiratory diseases, etc.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_6
DP  - Springer Link
SP  - 43
EP  - 52
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_6.pdf
KW  - Air pollution
KW  - Air quality index
KW  - Long short-term memory
ER  - 

TY  - CONF
TI  - Multi-modal Scene Recognition Based on Global Self-attention Mechanism
AU  - Li, Xiang
AU  - Sun, Ning
AU  - Liu, Jixin
AU  - Chai, Lei
AU  - Sun, Haian
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid development of deep neural network and the emergence of multi-modal acquisition devices, multi-modal scene recognition based on deep neural network has been known as a research hotspot. In view of the characteristics of various objects and complex spatial layout in scene images, and the complementarity of multi-modal data, this paper proposes an end-to-end trainable network model based on global self-attention mechanism for multi-modal scene recognition. This model, which is named MSR-Trans, is mainly consisted of two transformer-based branches for extracting feature from RGB image and depth data, respectively. Then, a fusion layer is used to fuse these two features for final scene recognition. To further explore the relationship between multi-modal information, the lateral connections are added on some layers between the two branches. And, a dropout layer is embedded in transformer block for preventing the model from overfitting. Extensive experiments are conducted to test the performance of the proposed method on SUN RGB-D and NYUD2 datasets, and the recognition accuracies of multi-modal scene recognition can be achieved at 69.0% and 74.1%, respectively.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_14
DP  - Springer Link
SP  - 109
EP  - 121
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_14.pdf
KW  - Multi-modal
KW  - RGB-D
KW  - Scene recognition
KW  - Transformer
ER  - 

TY  - CONF
TI  - Deep Embedded Clustering with Random Projection Penalty
AU  - Song, Kang
AU  - Han, Wei
AU  - Lekamalage, Chamara Kasun Liyanaarachchi
AU  - Chen, Lihui
A2  - Xiong, Ning
A2  - Li, Maozhen
A2  - Li, Kenli
A2  - Xiao, Zheng
A2  - Liao, Longlong
A2  - Wang, Lipo
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Despite being studied for decades, current clustering approaches still face difficulties in handling high-dimensional datasets. For high-dimensional data, it is essential to get a good feature representation for the clustering algorithm to conduct on. Most of the clustering algorithms do not explicitly encourage the preservation of pairwise distance within the input data when learning feature representation. We proposed an improvement over the Deep Embedded Clustering (DEC) by including a penalty term in the loss function for the differences between the input data and the random projection of its corresponding feature embedding. The idea behind this penalty term is one of the properties of random projection, that is the pairwise distance is preserved between the low-dimensional manifold and the data space. In this way, the network encourages the learning towards preserving data similarities in the feature space. We named the proposed method as DEC-RPP. The experiments show significant improvements on clustering metrics over four datasets compared with the baseline DEC and another work IDEC that improves DEC by preserving local structure.
C1  - Cham
C3  - Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20738-9_17
DP  - Springer Link
SP  - 139
EP  - 146
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-20738-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20738-9_17.pdf
KW  - Deep clustering
KW  - Random projection
KW  - Representation learning
ER  - 

TY  - CONF
TI  - Video Deraining via Temporal Discrepancy Learning
AU  - Fan, Yirui
AU  - Ma, Long
AU  - Liu, Risheng
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Learning-based video deraining has attracted much attention and shown superior performance. However, existing methods mostly depict the temporal correspondence between the consecutive frames implicitly, leading to insufficient temporal exploration so that performing badly in unseen real-world scenarios. To settle these issues, we develop a novel Temporal Discrepancy Learning (TDL) framework to provide interpretability in modeling temporal correspondence and improve robustness in real-world scenarios. To be specific, we define a new explicit spatio-temporal video deraining model by reformulating the task from a set representation perspective. The model describes the intuitive correspondences between different frames in terms of rain regions. Inspired by this model, we further construct a TDL, that firstly learns the temporal correlation under temporal discrepancy sequences and attention mechanism, then recovers the clear frame by performing a spatial-aware ensemble deraining process. Performance evaluations on various scenarios verify our excellence compared with advanced video deraining networks.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_1.pdf
KW  - Discrepancy learning
KW  - Temporal correlation
KW  - Video deraining
ER  - 

TY  - CONF
TI  - CHENet: Image to Image Chinese Handwriting Eraser
AU  - Wang, Biao
AU  - Li, Jiayi
AU  - Jin, Xin
AU  - Yuan, Qiong
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Erasing Chinese handwritten words in images has many applications in our daily life. It can hide the private information in the archive images (home address, identity information), delete the signature information in the contract images, and clear the handwriting in the test paper to reuse it. However, the existing research mainly focuses on scene text removal. To fill this gap and facilitate this research direction, we propose a novel model called CHENet (Chinese Handwriting Eraser Network) that can automatically remove Chinese handwriting located on the images. In particular, we design two modules: CAB (Convolution Attention Block) and CAP (Chain Attention Pooling) that can improve the ability of the CHENet. Also, for information protection, we collect images with Chinese handwritten words from the archive, contract, and exam papers, and build the CH-dataset that consists of 1623 scrupulously annotated images. Qualitative and quantitative evaluations show that our CHENet can solve this task well.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_4
DP  - Springer Link
SP  - 40
EP  - 51
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
ST  - CHENet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_4.pdf
KW  - Attention network
KW  - Chinese handwriting removal
KW  - End-to-end network
KW  - Text removal
ER  - 

TY  - CONF
TI  - A Dense Prediction ViT Network for Single Image Bokeh Rendering
AU  - Wang, Zhifeng
AU  - Jiang, Aiwen
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Rendering bokeh effects has become a research hotspot in the field of computational photography. Its essence is to focus on foreground area of interest, and blur other background areas for vision aesthetic requirements. Witness of the great success of vision transformer on dense prediction tasks, in this paper, we further expand the ability of transformer on new task and propose a dense prediction ViT structure for single bokeh image rendering. We leverage vision transformers as the backbone networks and operates on “bag-of-words" representations of image at high levels. Image-like feature representations of different resolutions are aggregated to obtain the final dense prediction. The proposed network has been compared with several state-of-the-art methods on a public large-scale bokeh dataset- the “EBB!" Dataset. The experiment results demonstrate that the proposed network can achieve new state-of-the-art performances on SSIM, LPIPS and MOS criterions. Its predicted bokeh effects are more in line with popular perception. Related source codes and pre-trained models of the proposed model will be available soon on https://github.com/zfw-cv/BEViT.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_18
DP  - Springer Link
SP  - 213
EP  - 222
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_18.pdf
KW  - Bokeh rendering
KW  - Dense prediction
KW  - Vision tokens
KW  - Vision transformers
ER  - 

TY  - CONF
TI  - A RAW Burst Super-Resolution Method with Enhanced Denoising
AU  - Zheng, Qian
AU  - Gang, Ruipeng
AU  - Cao, Yuntian
AU  - Li, Chenghua
AU  - Fang, Ji
AU  - Liu, Chenming
AU  - Cao, Yizhen
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Deep learning-based burst super-resolution (SR) approaches are extensively studied in recent years, prevailing in the synthetic datasets and the real datasets. However, the existing networks rarely pay attention to the enhanced denoising problem in raw domain and they are not sufficient to restore complex texture relationships between frames. In this paper, we propose a new framework named A RAW Burst Super-Resolution Method with Enhanced Denoising (EDRBSR), which solves the BurstSR problem by jointly denoising structure and reconstruction enhancement structure. We adopt a Denoising Network to further improve the performance of noise-free SR images. Also, we propose a Reconstruction Network to enhance spatial feature representation and eliminate the influence of spatial noise. In addition, we introduce a new pipeline to compensate for lost information. Experimental results demonstrate that our method over the existing state-of-the-art in both synthetic datasets and real datasets. Furthermore, our approach takes the 5th place in synthetic track of the NTIRE 2022 Burst Super-Resolution Challenge.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_9
DP  - Springer Link
SP  - 103
EP  - 116
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_9.pdf
KW  - Burst super-resolution
KW  - Denoise
KW  - Reconstruction
ER  - 

TY  - CONF
TI  - DLMP-Net: A Dynamic Yet Lightweight Multi-pyramid Network for Crowd Density Estimation
AU  - Chen, Qi
AU  - Lei, Tao
AU  - Geng, Xinzhe
AU  - Liu, Hulin
AU  - Gao, Yangyi
AU  - Zhao, Weiqiang
AU  - Nandi, Asoke
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - The current deep neural networks used for crowd density estimation face two main problems. First, due to different surveillance distance from the camera, densely populated regions are characterized by dramatic scale change, thus using vanilla convolution kernels for feature extraction will inevitably miss discriminative information and reduce the accuracy of crowd density estimation results. Second, popular networks for crowd density estimation still depend on complex encoders with a large number of parameters, and adopt fixed convolutional kernels to extract image features at different spatial positions, resulting in spatial-invariance and computation-heavy. To remedy the above problems, in this paper, we propose a Dynamic yet Lightweight Multi-Pyramid Network (DLMP-Net) for crowd density estimation. The proposed DLMP-Net mainly makes two contributions. First, we design a shuffle-pyramid feature extraction and fusion module (SPFFM), which employs multi-dilated convolution to extract and fuse various scale features. In addition, we add group and channel shuffle operation to reduce the model complexity and improve the efficiency of feature fusion. Second, we introduce a Dynamic Bottleneck Block (DBB), which predicts exclusive kernels pixel by pixel and channel by channel dynamically conditioned on an input, boosting the model performance while decreasing the number of parameters. Experiments are conducted on five datasets: ShanghaiTech dataset, UCF_CC_50 dataset, UCF_QRNF dataset, GCC dataset and NWPU dataset and the ablation studies are performed on ShanghaiTech dataset. The final results show that the proposed DLMP-Net can effectively overcome the problems mentioned above and provides high crowd counting accuracy with smaller model size than state-of-the-art networks.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_3
DP  - Springer Link
SP  - 27
EP  - 39
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
ST  - DLMP-Net
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_3.pdf
KW  - Crowd density estimation
KW  - Dynamic bottleneck block
KW  - Feature fusion
ER  - 

TY  - CONF
TI  - SUDANet: A Siamese UNet with Dense Attention Mechanism for Remote Sensing Image Change Detection
AU  - Sun, Chengzhe
AU  - Du, Chun
AU  - Wu, Jiangjiang
AU  - Chen, Hao
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Change detection is one of the main applications of remote sensing images. Pixel-to-pixel change detection using deep learning has been a hot research spot. However, the current approach are not effective enough to fuse deep semantic features and raw spatial information, and the network does not have the ability to perform long-distance information aggregation due to the limitation of the convolutional kernel size. In this manuscript, we propose a Siamese UNet with a dense attention mechanism, named SUDANet to do change detection for remote sensing images. SUDANet add a channel attention mechanism and a self-attention mechanism to the dense skip connection between encoder and decoder which enable the model to fuse feature information in channel dimensions and spatial dimensions. Graph attention module is also added at the end of the encoder, enabling the model to perform correlation analysis and long-distance aggregation of deep semantic features. The experimental results on LEVIR dataset show that our method outperforms the state-of-the-art change detection methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_7
DP  - Springer Link
SP  - 78
EP  - 88
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
ST  - SUDANet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_7.pdf
KW  - Attention mechanism
KW  - Change detection
KW  - Deep learning
KW  - Remote sensing (RS) images
ER  - 

TY  - CONF
TI  - Multi-priors Guided Dehazing Network Based on  Knowledge Distillation
AU  - Wang, Nian
AU  - Cui, Zhigao
AU  - Li, Aihua
AU  - Su, Yanzhao
AU  - Lan, Yunwei
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Single image dehazing is a key prerequisite of high-level computer vision tasks since degraded images seriously affect the recognition ability of computers. Traditional prior-based methods conduct favorable dehazing effect but tend to cause artifacts and color distortions due to inaccurate parameter estimations. By contrast, recent learning-based methods can provide better color fidelity via the supervised training of synthetic images. But unfortunately, these methods always acquire under-dehazed results due to the domain differences between synthetic hazy images and their real-world ones. To combine the merits of these two categories, we propose a multi-priors guided dehazing network (MGDNet) based on knowledge distillation. Specifically, we adopt the dehazed images of dark channel prior and non-local dehazing prior as fake ground truths, and use them to pretrain two teacher networks. Then we build a student network based on encoder-decoder structure, and set up both feature-level and pixel-level knowledge distillation losses to guide the training process of the student network. Experimental results on some real-world datasets widely used in recent works demonstrate that our MGDNet can generate visually appealing images with more discriminative textures and vivid color when compared with the state-of-the-arts.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_2
DP  - Springer Link
SP  - 15
EP  - 26
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_2.pdf
KW  - Knowledge distillation
KW  - Multi-priors guiding
KW  - Single image dehazing
ER  - 

TY  - CONF
TI  - Image Derain Method for Generative Adversarial Network Based on Wavelet High Frequency Feature Fusion
AU  - Li, Jiao
AU  - Feng, Hao
AU  - Deng, Zhennan
AU  - Cui, Xintong
AU  - Deng, Hongxia
AU  - Li, Haifang
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Photos taken on rainy days can be affected by rain streaks that reduce the sharpness of the image. Due to insufficient attention on feature extraction of rain streaks area, the removal effect of noise area needs to be improved. Wavelet transform is used to separate the high frequency information of the image, convolution is used to extract the high frequency features of the image, and the features of the original image with rain streaks extracted by the network are superimposed and fused. High frequency information graph represents the location of image noise. By incorporating high frequency features, the network can further learn the features of the rain stripes region. Feature fusion is introduced into the generative network, and the generative network guided by the attention distribution map considers global information more on the precondition of paying attention to the rain stripes region, so as to improve the clarity of the image after removing the rain fringes. The comparison experiment of wavelet high frequency feature fusion generative adversarial network and other methods is completed. The evaluation metrics are peak signal-to-noise ratio (PSNR) and structure similarity (SSIM), which verify the superiority of the proposed method compared with other methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_14
DP  - Springer Link
SP  - 165
EP  - 178
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_14.pdf
KW  - Derain
KW  - Feature fusion
KW  - Generative adversarial network
KW  - Self-attention
KW  - Wavelet transform
ER  - 

TY  - CONF
TI  - Boundary-Aware Polyp Segmentation Network
AU  - Lu, Lu
AU  - Zhou, Xitong
AU  - Chen, Shuhan
AU  - Chen, Zuyu
AU  - Yu, Jinhao
AU  - Tang, Haonan
AU  - Hu, Xuelong
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Colorectal cancer (CRC) caused by polyps has a high mortality rate worldwide. Accurately segmenting the polyp from colonoscopy images is important for the clinical treatment of CRC. The traditional method of polyp segmentation involves the physician manually marking the location of the polyp, resulting in unreliable segmentation results. The complex structure of polyps, the low contrast with mucosal tissue, and the fact that polyp boundary is usually hidden in the background make the task of polyp segmentation extremely challenging. To address these issues, we propose a boundary-aware polyp segmentation network. Specifically, we first propose an attention-aware location module to accurately identify the primary location of polyp. In order to improve the missing polyp portion in the initial region prediction and to mine the polyp boundary hidden in the background, we propose a residual pyramid convolution. Further, we propose a boundary-guided refinement module for more accurate segmentation in order to use the boundary information provided from residual pyramid convolution for constrained polyp region prediction. Extensive experiments show that our proposed network has advantages over existing state-of-the-art methods on five challenging polyp datasets.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_6
DP  - Springer Link
SP  - 66
EP  - 77
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_6.pdf
KW  - Boundary guidance
KW  - Contextual attention
KW  - Polyp segmentation
KW  - Residual pyramid convolution
ER  - 

TY  - CONF
TI  - DMF-CL: Dense Multi-scale Feature Contrastive Learning for Semantic Segmentation of Remote-Sensing Images
AU  - Song, Mengxing
AU  - Li, Bicao
AU  - Wei, Pingjun
AU  - Shao, Zhuhong
AU  - Wang, Jing
AU  - Huang, Jie
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Recently, many segmentation methods based on supervised deep learning have been widely used in remote sensing images. However, these approaches often require a large number of labeled samples, which is difficult to obtain them for remote sensing images. Self-supervision is a new learning paradigm, and can solve the problem of lack of labeled samples. In this method, a large number of unlabeled samples are employed for pre-training, and then a few of labeled samples are leveraged for downstream tasks. Contrast learning is a typical self-supervised learning method. Inspired, we propose a Dense Multi-scale Feature Contrastive Learning Network (DMF-CLNet), which is divided into global and local feature extraction parts. Firstly, in the global part, instead of traditional ASPP, DenseASPP can obtain more context information of remote sensing images in a dense way without increasing parameters. Secondly, in the global and local parts, Coordinate Attention (CA) modules are introduced respectively to improve the overall performance of the segmentation model. Thirdly, in the global and local parts, the perceptual loss is calculated to extract deeper features. Two remote sensing image segmentation datasets are evaluated. The experimental results show that our model is superior to the current self-supervised contrastive learning methods and ImageNet pre-training techniques.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_13
DP  - Springer Link
SP  - 152
EP  - 164
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
ST  - DMF-CL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_13.pdf
KW  - Contrast learning
KW  - Coordinate attention
KW  - DenseASPP
KW  - Perceptual loss
ER  - 

TY  - CONF
TI  - A Local-Global Self-attention Interaction Network for RGB-D Cross-Modal Person Re-identification
AU  - Zhu, Chuanlei
AU  - Li, Xiaohong
AU  - Qi, Meibin
AU  - Liu, Yimin
AU  - Zhang, Long
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - RGB-D cross-modal person re-identification (Re-ID) task aims to match the person images between the RGB and depth modalities. This task is rather challenging for the tremendous discrepancy between these two modalities in addition to common issues such as lighting conditions, human posture, camera angle, etc. Nowadays only few types of research focus on this task, and existing Re-ID methods tend to learn homogeneous structural relationships in an image, which have limited discriminability and weak robustness to noisy images. In this paper, we propose A Local-Global Interaction Network dedicated to processing cross-modal problems. The network can constrain the center distance between two modals, and improve the intra-class cross-modality similarity. Besides, it can also learn the local and global features of different modalities to enrich the features extracted from different modes. We validate the effectiveness of our approach on public benchmark datasets. Experimental results demonstrate our method outperforms other state-of-the-arts in terms of visual quality and quantitative measurement.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_8
DP  - Springer Link
SP  - 89
EP  - 102
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_8.pdf
KW  - Cross-modal person re-identification
KW  - Global self-attention
KW  - Intra-class cross-modality similarity
ER  - 

TY  - CONF
TI  - Information Adversarial Disentanglement for Face Swapping
AU  - Chen, Tingting
AU  - Yu, Yang
AU  - Ni, Rongrong
AU  - Zhao, Yao
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Face swapping can provide data support for face forgery detection, which is a very significant topic in forensics. It is the task of converting the source identity to the target face while preserving target attributes, thus disentangling identity and identity-unrelated (i.e., attribute) features is still a challenging task. In this work, we focus on intra-class (i.e. identities) and inter-class (i.e. identity and attribute) relationships to comprehensively decouple identity and attribute features in an adversarial way for face swapping. The whole network includes Identity-Attribute Adversary (IAA) module, Identity Reconstruction (IR) module and Re-Feeding module. Specifically, for the inter-class relationship, we first propose the IAA module to initially extract independent identity and attribute features. Besides, the Re-Feeding module re-disentangles the generated images and reconstructs original images to further confirm the complete disentanglement of the inter-class information. Finally, for the intra-class relationship, we adopt the IR module based on the same identity image pairs to learn the consistent identity feature without being influenced by attributes. Extensive experiments and comparisons to the existing state-of-the-art face swapping methods demonstrate the effectiveness of our framework.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_17
DP  - Springer Link
SP  - 201
EP  - 212
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_17.pdf
KW  - Face forgery detection
KW  - Face swapping feature disentanglement
KW  - Identity reconstruction
KW  - Identity-attribute adversary
ER  - 

TY  - CONF
TI  - Unpaired and Self-supervised Optical Coherence Tomography Angiography Super-Resolution
AU  - Zeng, Chaofan
AU  - Yuan, Songtao
AU  - Chen, Qiang
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Optical coherence tomography angiography (OCTA) is usually used to observe the blood flow information of retina and choroid. It is meaningful for clinicians to observe more microvascular details by enhancing the resolution of OCTA images, which is conducive to the diagnosis of diseases. However, due to the limitation of imaging equipment, when the resolution of OCTA is improved, the field of view (FOV) will be reduced. In the existing methods to enhance the resolution of OCTA, paired training data from the same eye are generally required, but paired data are usually difficult to be obtained, and the resolution of enhanced images is difficult to exceed that of original high resolution (3 × 3 mm2) OCTA images. Therefore, to improve the resolution of low resolution (6 × 6 mm2) OCTA images, this paper proposes an unpaired and self-supervised OCTA super-resolution (USOSR) method by down sampling and enhancing the original 3 × 3 mm2 OCTA images. Experimental results demonstrate that the enhanced 6 × 6 mm2 OCTA images have significantly stronger contrast, sharper edges and higher information entropy than the original images.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_10
DP  - Springer Link
SP  - 117
EP  - 126
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_10.pdf
KW  - OCTA
KW  - Self-supervised
KW  - Super-resolution
KW  - Unpaired
ER  - 

TY  - CONF
TI  - GPU-Accelerated Infrared Patch-Image Model for Small Target Detection
AU  - Hao, Xuying
AU  - Liu, Yujia
AU  - Song, Fei
AU  - Lei, Tao
AU  - Cui, Yi
AU  - Zhang, Yunjing
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Infrared small target detection plays a significant role in precision guidance and infrared warning systems. Although existing methods based on infrared patch-image (IPI) model have achieved good detection results, most algorithms provide high detection accuracy but with low real-time performance, which limits their use in practical applications. In this paper, we presents a GPU based parallel implementation to focus on real-time performance of the small target detection by using IPI model and various optimization strategies. The parallel implementation is first analysed in details. Then, the speed of the method is tested on the embedded GPU Jetson AGX Xavier. Finally, the running time of the traditional algorithm on the CPU is compared. Experiments show a speedup of 20$$\times $$×over CPU implementation for images with a resolution of $$1024 \times 1024 $$1024×1024pixels, which has great potential for real-time applications. Our acceleration strategy is also useful for other infrared image-patch based small target detection algorithms.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_15
DP  - Springer Link
SP  - 179
EP  - 188
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_15.pdf
KW  - GPU
KW  - Infrared small target detection
KW  - IPI
KW  - Optimization strategies
KW  - Parallel implementation
ER  - 

TY  - CONF
TI  - Identification Method for Rice Pests with Small Sample Size Problems Combining Deep Learning and Metric Learning
AU  - Hu, Gensheng
AU  - Tang, Xin
AU  - Zeng, Weihui
AU  - Liang, Dong
AU  - Yang, Xiaowei
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - To achieve accurate identification of rice pests with small sample size problems under complex backgrounds, we proposed a rice pest identification method combining deep learning and metric learning. To overcome the effect of the complex background of the rice pest image, we used the U-Net network which can well retain target information and has a good segmentation effect on rice pests with small sample size problems to remove the background. We also improved the backbone network of VGG16 to extract a more effective feature for identification. Finally, we introduced metric learning to project the feature vector of the pest image to a new feature space for similarity matching and solve the lower accuracy caused by the small sample size. Experimental results showed that the accuracy of the proposed method is better than that of SVM, kNN, AlexNet, VGGNet and Mobilenet. Thus, our method could accurately identify rice pests with small sample size problems under complex rice backgrounds.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_5
DP  - Springer Link
SP  - 52
EP  - 65
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_5.pdf
KW  - Deep learning
KW  - Machine learning
KW  - Metric learning
KW  - Pest identification
KW  - Small sample size problems
ER  - 

TY  - CONF
TI  - LAGAN: Landmark Aided Text to Face Sketch Generation
AU  - Chao, Wentao
AU  - Chang, Liang
AU  - Xi, Fangfang
AU  - Duan, Fuqing
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Face sketch is a concise representation of the human face, and it has a variety of applications in criminal investigation, biometrics, and social entertainment. It is well known that facial attribute is an underlying representation of the facial description. However, generating vivid face sketches, especially sketches with rich details, from given facial attributes text is still a challenging task as the text information is limited. Existing work synthetic face sketch is not realistic, especially the facial areas are not natural enough, even distorted. We aim to relieve the situation by introducing face prior knowledge, such as landmarks. This paper proposes a method, called LAGAN, that Landmark Aided Text to Face Sketch Generation. Specifically, we design a novel scale translation-invariant similarity loss based on the facial landmarks. It can measure the mutual similarity between real sketch and synthetic sketch and also measure the self similarity based on the symmetry of face attributes. Further to counter data deficiency, we construct a novel facial attribute text to sketch dataset called TextCUFSF with CUFSF face sketch dataset. Each sketch has 4 manual annotations. Qualitative and quantitative experiments demonstrate the effectiveness of our proposed method for sketch synthesis with attribute text. The code and data are available: https://github.com/chaowentao/LAGAN.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_12
DP  - Springer Link
SP  - 137
EP  - 151
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
ST  - LAGAN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_12.pdf
KW  - Face sketch
KW  - Generative adversarial nets
KW  - Text to sketch
ER  - 

TY  - CONF
TI  - Hyperspectral and Multispectral Image Fusion Based on Unsupervised Feature Mixing and Reconstruction Network
AU  - Zhang, Rui
AU  - Fu, Peng
AU  - Geng, Leilei
AU  - Sun, Quansen
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Hyperspectral image (HSI) usually has rich spectral information and multispectral image (MSI) has higher spatial resolution. Thus, the fusion of HSI and MSI can achieve information complementarity and increase the reliability of information. Deep learning has been widely applied in the field of HSI/MSI fusion. In order to obtain a HSI with high spatial resolution without sufficient training data, in this paper, we propose a novel unsupervised HSI-MSI fusion network named UFMRS-net. Our model consists of three parts. First, two encoder networks are adopted to obtain the preliminary fusion feature. Second, multiscale preliminary fusion features are fed into the feature mixing and reconstruction module, which is designed to enhance the communication across different levels of backbone features. Finally a spatial attention network is devised to extract tiny textures and enhance the spatial structure. Experimental results compared with some state-of-the-art methods illustrate that our method is outstanding in both visual and numerical results.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_16
DP  - Springer Link
SP  - 189
EP  - 200
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_16.pdf
KW  - Hyperspectral image
KW  - Image fusion
KW  - Multispectral image
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Multi-feature Fusion Network for Single Image Dehazing
AU  - Luo, Jie
AU  - Chang, Tong
AU  - Bo, Qirong
A2  - Yu, Shiqi
A2  - Zhang, Zhaoxiang
A2  - Yuen, Pong C.
A2  - Han, Junwei
A2  - Tan, Tieniu
A2  - Guo, Yike
A2  - Lai, Jianhuang
A2  - Zhang, Jianguo
T3  - Lecture Notes in Computer Science
AB  - Existing image dehazing methods consider the learning-based methods as the mainstream. Most of them are trained on synthetic dataset, and may not be able to efficiently transfer to real outdoor scenes. In order to further improve the dehazing effect of the model in real outdoor scenes, this paper proposes an end-to-end Multi-Feature Fusion Network for Single Image Dehazing (MFFN). The proposed network combines the prior-based methods and learning-based methods. This paper first uses the method of supporting backpropagation in order to directly extract the dark channel prior and color attenuation prior features. It then designs a Multi-Feature Adaptive Fusion Module (MFAFM) which can adaptively fuse and enhance the two prior features. Finally, the prior features are added to the decoding stage of the backbone network in a multi-scale manner. The experimental results on the synthetic dataset and real-world dataset demonstrate that the proposed model performs favorably against the state-of-the-art dehazing algorithms.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-18916-6_11
DP  - Springer Link
SP  - 127
EP  - 136
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-18916-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-18916-6_11.pdf
KW  - Learning-based methods
KW  - Prior-based methods
KW  - Single Image Dehazing
ER  - 

TY  - CONF
TI  - BEVFormer: Learning Bird’s-Eye-View Representation from Multi-camera Images via Spatiotemporal Transformers
AU  - Li, Zhiqi
AU  - Wang, Wenhai
AU  - Li, Hongyang
AU  - Xie, Enze
AU  - Sima, Chonghao
AU  - Lu, Tong
AU  - Qiao, Yu
AU  - Dai, Jifeng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - 3D visual perception tasks, including 3D detection and map segmentation based on multi-camera images, are essential for autonomous driving systems. In this work, we present a new framework termed BEVFormer, which learns unified BEV representations with spatiotemporal transformers to support multiple autonomous driving perception tasks. In a nutshell, BEVFormer exploits both spatial and temporal information by interacting with spatial and temporal space through predefined grid-shaped BEV queries. To aggregate spatial information, we design spatial cross-attention that each BEV query extracts the spatial features from the regions of interest across camera views. For temporal information, we propose temporal self-attention to recurrently fuse the history BEV information. Our approach achieves the new state-of-the-art 56.9% in terms of NDS metric on the nuScenes test set, which is 9.0 points higher than previous best arts and on par with the performance of LiDAR-based baselines. The code is available at https://github.com/zhiqi-li/BEVFormer.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_1
DP  - Springer Link
SP  - 1
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - BEVFormer
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_1.pdf
KW  - 3D object detection
KW  - Autonomous driving
KW  - Bird’s-Eye-View
KW  - Map segmentation
KW  - Transformer
ER  - 

TY  - CONF
TI  - Open-Vocabulary DETR with Conditional Matching
AU  - Zang, Yuhang
AU  - Li, Wei
AU  - Zhou, Kaiyang
AU  - Huang, Chen
AU  - Loy, Chen Change
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Open-vocabulary object detection, which is concerned with the problem of detecting novel objects guided by natural language, has gained increasing attention from the community. Ideally, we would like to extend an open-vocabulary detector such that it can produce bounding box predictions based on user inputs in form of either natural language or exemplar image. This offers great flexibility and user experience for human-computer interaction. To this end, we propose a novel open-vocabulary detector based on DETR—hence the name OV-DETR—which, once trained, can detect any object given its class name or an exemplar image. The biggest challenge of turning DETR into an open-vocabulary detector is that it is impossible to calculate the classification cost matrix of novel classes without access to their labeled images. To overcome this challenge, we formulate the learning objective as a binary matching one between input queries (class name or exemplar image) and the corresponding objects, which learns useful correspondence to generalize to unseen queries during testing. For training, we choose to condition the Transformer decoder on the input embeddings obtained from a pre-trained vision-language model like CLIP, in order to enable matching for both text and image queries. With extensive experiments on LVIS and COCO datasets, we demonstrate that our OV-DETR—the first end-to-end Transformer-based open-vocabulary detector—achieves non-trivial improvements over current state of the arts. Code is available at https://github.com/yuhangzang/OV-DETR.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_7
DP  - Springer Link
SP  - 106
EP  - 122
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_7.pdf
ER  - 

TY  - CONF
TI  - SuperLine3D: Self-supervised Line Segmentation and Description for LiDAR Point Cloud
AU  - Zhao, Xiangrui
AU  - Yang, Sheng
AU  - Huang, Tianxin
AU  - Chen, Jun
AU  - Ma, Teng
AU  - Li, Mingyang
AU  - Liu, Yong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Poles and building edges are frequently observable objects on urban roads, conveying reliable hints for various computer vision tasks. To repetitively extract them as features and perform association between discrete LiDAR frames for registration, we propose the first learning-based feature segmentation and description model for 3D lines in LiDAR point cloud. To train our model without the time consuming and tedious data labeling process, we first generate synthetic primitives for the basic appearance of target lines, and build an iterative line auto-labeling process to gradually refine line labels on real LiDAR scans. Our segmentation model can extract lines under arbitrary scale perturbations, and we use shared EdgeConv encoder layers to train the two segmentation and descriptor heads jointly. Base on the model, we can build a highly-available global registration module for point cloud registration, in conditions without initial transformation hints. Experiments have demonstrated that our line-based registration method is highly competitive to state-of-the-art point-based approaches. Our code is available at https://github.com/zxrzju/SuperLine3D.git.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_16
DP  - Springer Link
SP  - 263
EP  - 279
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - SuperLine3D
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_16.pdf
KW  - 3D Line Feature
KW  - Point cloud registration
ER  - 

TY  - CONF
TI  - CPO: Change Robust Panorama to Point Cloud Localization
AU  - Kim, Junho
AU  - Jang, Hojun
AU  - Choi, Changwoon
AU  - Kim, Young Min
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We present CPO, a fast and robust algorithm that localizes a 2D panorama with respect to a 3D point cloud of a scene possibly containing changes. To robustly handle scene changes, our approach deviates from conventional feature point matching, and focuses on the spatial context provided from panorama images. Specifically, we propose efficient color histogram generation and subsequent robust localization using score maps. By utilizing the unique equivariance of spherical projections, we propose very fast color histogram generation for a large number of camera poses without explicitly rendering images for all candidate poses. We accumulate the regional consistency of the panorama and point cloud as 2D/3D score maps, and use them to weigh the input color values to further increase robustness. The weighted color distribution quickly finds good initial poses and achieves stable convergence for gradient-based optimization. CPO is lightweight and achieves effective localization in all tested scenarios, showing stable performance despite scene changes, repetitive structures, or featureless regions, which are typical challenges for visual localization with perspective cameras.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_11
DP  - Springer Link
SP  - 176
EP  - 192
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - CPO
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_11.pdf
KW  - Panorama
KW  - Point cloud
KW  - Visual localization
ER  - 

TY  - CONF
TI  - Calibration-Free Multi-view Crowd Counting
AU  - Zhang, Qi
AU  - Chan, Antoni B.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Deep learning based multi-view crowd counting (MVCC) has been proposed to handle scenes with large size, in irregular shape or with severe occlusions. The current MVCC methods require camera calibrations in both training and testing, limiting the real application scenarios of MVCC. To extend and apply MVCC to more practical situations, in this paper we propose calibration-free multi-view crowd counting (CF-MVCC), which obtains the scene-level count directly from the density map predictions for each camera view without needing the camera calibrations in the test. Specifically, the proposed CF-MVCC method first estimates the homography matrix to align each pair of camera-views, and then estimates a matching probability map for each camera-view pair. Based on the matching maps of all camera-view pairs, a weight map for each camera view is predicted, which represents how many cameras can reliably see a given pixel in the camera view. Finally, using the weight maps, the total scene-level count is obtained as a simple weighted sum of the density maps for the camera views. Experiments are conducted on several multi-view counting datasets, and promising performance is achieved compared to calibrated MVCC methods that require camera calibrations as input and use scene-level density maps as supervision.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_14
DP  - Springer Link
SP  - 227
EP  - 244
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_14.pdf
ER  - 

TY  - CONF
TI  - INT: Towards Infinite-Frames 3D Detection with an Efficient Framework
AU  - Xu, Jianyun
AU  - Miao, Zhenwei
AU  - Zhang, Da
AU  - Pan, Hongyu
AU  - Liu, Kaixuan
AU  - Hao, Peihan
AU  - Zhu, Jun
AU  - Sun, Zhengyang
AU  - Li, Hongmin
AU  - Zhan, Xin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - It is natural to construct a multi-frame instead of a single-frame 3D detector for a continuous-time stream. Although increasing the number of frames might improve performance, previous multi-frame studies only used very limited frames to build their systems due to the dramatically increased computational and memory cost. To address these issues, we propose a novel on-stream training and prediction framework that, in theory, can employ an infinite number of frames while keeping the same amount of computation as a single-frame detector. This infinite framework (INT), which can be used with most existing detectors, is utilized, for example, on the popular CenterPoint, with significant latency reductions and performance improvements. We’ve also conducted extensive experiments on two large-scale datasets, nuScenes and Waymo Open Dataset, to demonstrate the scheme’s effectiveness and efficiency. By employing INT on CenterPoint, we can get around 7% (Waymo) and 15% (nuScenes) performance boost with only 2$${}^{\tilde{}}$$~4 ms latency overhead, and currently SOTA on the Waymo 3D Detection leaderboard.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_12
DP  - Springer Link
SP  - 193
EP  - 209
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - INT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_12.pdf
KW  - 3D detection
KW  - Efficient
KW  - Infinite
KW  - Multi-frame
KW  - Pointcloud
ER  - 

TY  - CONF
TI  - Adversarially-Aware Robust Object Detector
AU  - Dong, Ziyi
AU  - Wei, Pengxu
AU  - Lin, Liang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Object detection, as a fundamental computer vision task, has achieved a remarkable progress with the emergence of deep neural networks. Nevertheless, few works explore the adversarial robustness of object detectors to resist adversarial attacks for practical applications in various real-world scenarios. Detectors have been greatly challenged by unnoticeable perturbation, with sharp performance drop on clean images and extremely poor performance on adversarial images. In this work, we empirically explore the model training for adversarial robustness in object detection, which greatly attributes to the conflict between learning clean images and adversarial images. To mitigate this issue, we propose a Robust Detector (RobustDet) based on adversarially-aware convolution to disentangle gradients for model learning on clean and adversarial images. RobustDet also employs the Adversarial Image Discriminator (AID) and Consistent Features with Reconstruction (CFR) to ensure a reliable robustness. Extensive experiments on PASCAL VOC and MS-COCO demonstrate that our model effectively disentangles gradients and significantly enhances the detection robustness with maintaining the detection ability on clean images. Our source code and trained models are publicly available at: https://github.com/7eu7d7/RobustDet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_18
DP  - Springer Link
SP  - 297
EP  - 313
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_18.pdf
KW  - Adversarial attack and defense
KW  - Adversarial robustness
KW  - Detection robustness bottleneck
KW  - Object detection
ER  - 

TY  - CONF
TI  - Exploiting Unlabeled Data with Vision and Language Models for Object Detection
AU  - Zhao, Shiyu
AU  - Zhang, Zhixing
AU  - Schulter, Samuel
AU  - Zhao, Long
AU  - Vijay Kumar, B.G
AU  - Stathopoulos, Anastasis
AU  - Chandraker, Manmohan
AU  - Metaxas, Dimitris N.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Building robust and generic object detection frameworks requires scaling to larger label spaces and bigger training datasets. However, it is prohibitively costly to acquire annotations for thousands of categories at a large scale. We propose a novel method that leverages the rich semantics available in recent vision and language models to localize and classify objects in unlabeled images, effectively generating pseudo labels for object detection. Starting with a generic and class-agnostic region proposal mechanism, we use vision and language models to categorize each region of an image into any object category that is required for downstream tasks. We demonstrate the value of the generated pseudo labels in two specific tasks, open-vocabulary detection, where a model needs to generalize to unseen object categories, and semi-supervised object detection, where additional unlabeled images can be used to improve the model. Our empirical evaluation shows the effectiveness of the pseudo labels in both tasks, where we outperform competitive baselines and achieve a novel state-of-the-art for open-vocabulary object detection. Our code is available at https://github.com/xiaofeng94/VL-PLM.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_10
DP  - Springer Link
SP  - 159
EP  - 175
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_10.pdf
ER  - 

TY  - CONF
TI  - Category-Level 6D Object Pose and Size Estimation Using Self-supervised Deep Prior Deformation Networks
AU  - Lin, Jiehong
AU  - Wei, Zewei
AU  - Ding, Changxing
AU  - Jia, Kui
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - It is difficult to precisely annotate object instances and their semantics in 3D space, and as such, synthetic data are extensively used for these tasks, e.g., category-level 6D object pose and size estimation. However, the easy annotations in synthetic domains bring the downside effect of synthetic-to-real (Sim2Real) domain gap. In this work, we aim to address this issue in the task setting of Sim2Real, unsupervised domain adaptation for category-level 6D object pose and size estimation. We propose a method that is built upon a novel Deep Prior Deformation Network, shortened as DPDN. DPDN learns to deform features of categorical shape priors to match those of object observations, and is thus able to establish deep correspondence in the feature space for direct regression of object poses and sizes. To reduce the Sim2Real domain gap, we formulate a novel self-supervised objective upon DPDN via consistency learning; more specifically, we apply two rigid transformations to each object observation in parallel, and feed them into DPDN respectively to yield dual sets of predictions; on top of the parallel learning, an inter-consistency term is employed to keep cross consistency between dual predictions for improving the sensitivity of DPDN to pose changes, while individual intra-consistency ones are used to enforce self-adaptation within each learning itself. We train DPDN on both training sets of the synthetic CAMERA25 and real-world REAL275 datasets; our results outperform the existing methods on REAL275 test set under both the unsupervised and supervised settings. Ablation studies also verify the efficacy of our designs. Our code is released publicly at https://github.com/JiehongLin/Self-DPDN.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_2
DP  - Springer Link
SP  - 19
EP  - 34
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_2.pdf
KW  - 6D pose estimation
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Towards Data-Efficient Detection Transformers
AU  - Wang, Wen
AU  - Zhang, Jing
AU  - Cao, Yang
AU  - Shen, Yongliang
AU  - Tao, Dacheng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Detection transformers have achieved competitive performance on the sample-rich COCO dataset. However, we show most of them suffer from significant performance drops on small-size datasets, like Cityscapes. In other words, the detection transformers are generally data-hungry. To tackle this problem, we empirically analyze the factors that affect data efficiency, through a step-by-step transition from a data-efficient RCNN variant to the representative DETR. The empirical results suggest that sparse feature sampling from local image areas holds the key. Based on this observation, we alleviate the data-hungry issue of existing detection transformers by simply alternating how key and value sequences are constructed in the cross-attention layer, with minimum modifications to the original models. Besides, we introduce a simple yet effective label augmentation method to provide richer supervision and improve data efficiency. Experiments show that our method can be readily applied to different detection transformers and improve their performance on both small-size and sample-rich datasets. Code will be made publicly available at https://github.com/encounter1997/DE-DETRs.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_6
DP  - Springer Link
SP  - 88
EP  - 105
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_6.pdf
KW  - Data efficiency
KW  - Detection transformer
KW  - Label augmentation
KW  - Rich supervision
KW  - Sparse feature
ER  - 

TY  - CONF
TI  - Point-to-Box Network for Accurate Object Detection via Single Point Supervision
AU  - Chen, Pengfei
AU  - Yu, Xuehui
AU  - Han, Xumeng
AU  - Hassan, Najmul
AU  - Wang, Kai
AU  - Li, Jiachen
AU  - Zhao, Jian
AU  - Shi, Humphrey
AU  - Han, Zhenjun
AU  - Ye, Qixiang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Object detection using single point supervision has received increasing attention over the years. However, the performance gap between point supervised object detection (PSOD) and bounding box supervised detection remains large. In this paper, we attribute such a large performance gap to the failure of generating high-quality proposal bags which are crucial for multiple instance learning (MIL). To address this problem, we introduce a lightweight alternative to the off-the-shelf proposal (OTSP) method and thereby create the Point-to-Box Network (P2BNet), which can construct an inter-objects balanced proposal bag by generating proposals in an anchor-like way. By fully investigating the accurate position information, P2BNet further constructs an instance-level bag, avoiding the mixture of multiple objects. Finally, a coarse-to-fine policy in a cascade fashion is utilized to improve the IoU between proposals and ground-truth (GT). Benefiting from these strategies, P2BNet is able to produce high-quality instance-level bags for object detection. P2BNet improves the mean average precision (AP) by more than 50% relative to the previous best PSOD method on the MS COCO dataset. It also demonstrates the great potential to bridge the performance gap between point supervised and bounding-box supervised detectors. The code will be released at www.github.com/ucas-vg/P2BNet.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_4
DP  - Springer Link
SP  - 51
EP  - 67
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_4.pdf
KW  - Object detection
KW  - Point supervised object detection
KW  - Single point annotation
ER  - 

TY  - CONF
TI  - End-to-End Weakly Supervised Object Detection with Sparse Proposal Evolution
AU  - Liao, Mingxiang
AU  - Wan, Fang
AU  - Yao, Yuan
AU  - Han, Zhenjun
AU  - Zou, Jialing
AU  - Wang, Yuze
AU  - Feng, Bailan
AU  - Yuan, Peng
AU  - Ye, Qixiang
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Conventional methods for weakly supervised object detection (WSOD) typically enumerate dense proposals and select the discriminative proposals as objects. However, these two-stage “enumerate-and-select” methods suffer object feature ambiguity brought by dense proposals and low detection efficiency caused by the proposal enumeration procedure. In this study, we propose a sparse proposal evolution (SPE) approach, which advances WSOD from the two-stage pipeline with dense proposals to an end-to-end framework with sparse proposals. SPE is built upon a visual transformer equipped with a seed proposal generation (SPG) branch and a sparse proposal refinement (SPR) branch. SPG generates high-quality seed proposals by taking advantage of the cascaded self-attention mechanism of the visual transformer, and SPR trains the detector to predict sparse proposals which are supervised by the seed proposals in a one-to-one matching fashion. SPG and SPR are iteratively performed so that seed proposals update to accurate supervision signals and sparse proposals evolve to precise object regions. Experiments on VOC and COCO object detection datasets show that SPE outperforms the state-of-the-art end-to-end methods by 7.0% mAP and 8.1% AP50. It is an order of magnitude faster than the two-stage methods, setting the first solid baseline for end-to-end WSOD with sparse proposals. The code is available at https://github.com/MingXiangL/SPE.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_13
DP  - Springer Link
SP  - 210
EP  - 226
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_13.pdf
KW  - End-to-end training
KW  - Proposal evolution
KW  - Sparse proposals
KW  - Weakly supervised object detection
ER  - 

TY  - CONF
TI  - Multimodal Object Detection via Probabilistic Ensembling
AU  - Chen, Yi-Ting
AU  - Shi, Jinghao
AU  - Ye, Zelin
AU  - Mertz, Christoph
AU  - Ramanan, Deva
AU  - Kong, Shu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Object detection with multimodal inputs can improve many safety-critical systems such as autonomous vehicles (AVs). Motivated by AVs that operate in both day and night, we study multimodal object detection with RGB and thermal cameras, since the latter provides much stronger object signatures under poor illumination. We explore strategies for fusing information from different modalities. Our key contribution is a probabilistic ensembling technique, ProbEn, a simple non-learned method that fuses together detections from multi-modalities. We derive ProbEn from Bayes’ rule and first principles that assume conditional independence across modalities. Through probabilistic marginalization, ProbEn elegantly handles missing modalities when detectors do not fire on the same object. Importantly, ProbEn also notably improves multimodal detection even when the conditional independence assumption does not hold, e.g., fusing outputs from other fusion methods (both off-the-shelf and trained in-house). We validate ProbEn on two benchmarks containing both aligned (KAIST) and unaligned (FLIR) multimodal images, showing that ProbEn outperforms prior work by more than 13% in relative performance!
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_9
DP  - Springer Link
SP  - 139
EP  - 158
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_9.pdf
KW  - Ensembling
KW  - Infrared
KW  - Multimodal detection
KW  - Multimodal fusion
KW  - Object detection
KW  - Probabilistic model
KW  - Thermal
KW  - Uncertainty
ER  - 

TY  - CONF
TI  - Dense Teacher: Dense Pseudo-Labels for Semi-supervised Object Detection
AU  - Zhou, Hongyu
AU  - Ge, Zheng
AU  - Liu, Songtao
AU  - Mao, Weixin
AU  - Li, Zeming
AU  - Yu, Haiyan
AU  - Sun, Jian
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - To date, the most powerful semi-supervised object detectors (SS-OD) are based on pseudo-boxes, which need a sequence of post-processing with fine-tuned hyper-parameters. In this work, we propose replacing the sparse pseudo-boxes with the dense prediction as a united and straightforward form of pseudo-label. Compared to the pseudo-boxes, our Dense Pseudo-Label (DPL) does not involve any post-processing method, thus retaining richer information. We also introduce a region selection technique to highlight the key information while suppressing the noise carried by dense labels. We name our proposed SS-OD algorithm that leverages the DPL as Dense Teacher. On COCO and VOC, Dense Teacher shows superior performance under various settings compared with the pseudo-box-based methods. Code is available at https://github.com/Megvii-BaseDetection/DenseTeacher.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_3
DP  - Springer Link
SP  - 35
EP  - 50
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - Dense Teacher
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_3.pdf
KW  - Dense pseudo-label
KW  - Semi-supervised object detection
ER  - 

TY  - CONF
TI  - Unsupervised Domain Adaptation for Monocular 3D Object Detection via Self-training
AU  - Li, Zhenyu
AU  - Chen, Zehui
AU  - Li, Ang
AU  - Fang, Liangji
AU  - Jiang, Qinhong
AU  - Liu, Xianming
AU  - Jiang, Junjun
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Monocular 3D object detection (Mono3D) has achieved unprecedented success with the advent of deep learning techniques and emerging large-scale autonomous driving datasets. However, drastic performance degradation remains an unwell-studied challenge for practical cross-domain deployment as the lack of labels on the target domain. In this paper, we first comprehensively investigate the significant underlying factor of the domain gap in Mono3D, where the critical observation is a depth-shift issue caused by the geometric misalignment of domains. Then, we propose STMono3D, a new self-teaching framework for unsupervised domain adaptation on Mono3D. To mitigate the depth-shift, we introduce the geometry-aligned multi-scale training strategy to disentangle the camera parameters and guarantee the geometry consistency of domains. Based on this, we develop a teacher-student paradigm to generate adaptive pseudo labels on the target domain. Benefiting from the end-to-end framework that provides richer information of the pseudo labels, we propose the quality-aware supervision strategy to take instance-level pseudo confidences into account and improve the effectiveness of the target-domain training process. Moreover, the positive focusing training strategy and dynamic threshold are proposed to handle tremendous FN and FP pseudo samples. STMono3D achieves remarkable performance on all evaluated datasets and even surpasses fully supervised results on the KITTI 3D object detection dataset. To the best of our knowledge, this is the first study to explore effective UDA methods for Mono3D.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_15
DP  - Springer Link
SP  - 245
EP  - 262
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_15.pdf
KW  - Domain adaptation
KW  - Monocular 3D object detection
KW  - Self-training
KW  - Unsupervised method
ER  - 

TY  - CONF
TI  - Exploring Plain Vision Transformer Backbones for Object Detection
AU  - Li, Yanghao
AU  - Mao, Hanzi
AU  - Girshick, Ross
AU  - He, Kaiming
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone network for object detection. This design enables the original ViT architecture to be fine-tuned for object detection without needing to redesign a hierarchical backbone for pre-training. With minimal adaptations for fine-tuning, our plain-backbone detector can achieve competitive results. Surprisingly, we observe: (i) it is sufficient to build a simple feature pyramid from a single-scale feature map (without the common FPN design) and (ii) it is sufficient to use window attention (without shifting) aided with very few cross-window propagation blocks. With plain ViT backbones pre-trained as Masked Autoencoders (MAE), our detector, named ViTDet, can compete with the previous leading methods that were all based on hierarchical backbones, reaching up to 61.3 AP$$^\text {box}$$boxon the COCO dataset using only ImageNet-1K pre-training. We hope our study will draw attention to research on plain-backbone detectors. Code for ViTDet is available (https://github.com/facebookresearch/detectron2/tree/main/projects/ViTDet).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_17
DP  - Springer Link
SP  - 280
EP  - 296
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_17.pdf
ER  - 

TY  - CONF
TI  - Domain Adaptive Hand Keypoint and Pixel Localization in the Wild
AU  - Ohkawa, Takehiko
AU  - Li, Yu-Jhe
AU  - Fu, Qichen
AU  - Furuta, Ryosuke
AU  - Kitani, Kris M.
AU  - Sato, Yoichi
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - We aim to improve the performance of regressing hand keypoints and segmenting pixel-level hand masks under new imaging conditions (e.g., outdoors) when we only have labeled images taken under very different conditions (e.g., indoors). In the real world, it is important that the model trained for both tasks works under various imaging conditions. However, their variation covered by existing labeled hand datasets is limited. Thus, it is necessary to adapt the model trained on the labeled images (source) to unlabeled images (target) with unseen imaging conditions. While self-training domain adaptation methods (i.e., learning from the unlabeled target images in a self-supervised manner) have been developed for both tasks, their training may degrade performance when the predictions on the target images are noisy. To avoid this, it is crucial to assign a low importance (confidence) weight to the noisy predictions during self-training. In this paper, we propose to utilize the divergence of two predictions to estimate the confidence of the target image for both tasks. These predictions are given from two separate networks, and their divergence helps identify the noisy predictions. To integrate our proposed confidence estimation into self-training, we propose a teacher-student framework where the two networks (teachers) provide supervision to a network (student) for self-training, and the teachers are learned from the student by knowledge distillation. Our experiments show its superiority over state-of-the-art methods in adaptation settings with different lighting, grasping objects, backgrounds, and camera viewpoints. Our method improves by $$4\%$$4%the multi-task score on HO3D compared to the latest adversarial adaptation method. We also validate our method on Ego4D, egocentric videos with rapid changes in imaging conditions outdoors.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_5
DP  - Springer Link
SP  - 68
EP  - 87
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_5.pdf
ER  - 

TY  - CONF
TI  - HEAD: HEtero-Assists Distillation for Heterogeneous Object Detectors
AU  - Wang, Luting
AU  - Li, Xiaojie
AU  - Liao, Yue
AU  - Jiang, Zeren
AU  - Wu, Jianlong
AU  - Wang, Fei
AU  - Qian, Chen
AU  - Liu, Si
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Conventional knowledge distillation (KD) methods for object detection mainly concentrate on homogeneous teacher-student detectors. However, the design of a lightweight detector for deployment is often significantly different from a high-capacity detector. Thus, we investigate KD among heterogeneous teacher-student pairs for a wide application. We observe that the core difficulty for heterogeneous KD (hetero-KD) is the significant semantic gap between the backbone features of heterogeneous detectors due to the different optimization manners. Conventional homogeneous KD (homo-KD) methods suffer from such a gap and are hard to directly obtain satisfactory performance for hetero-KD. In this paper, we propose the HEtero-Assists Distillation (HEAD) framework, leveraging heterogeneous detection heads as assistants to guide the optimization of the student detector to reduce this gap. In HEAD, the assistant is an additional detection head with the architecture homogeneous to the teacher head attached to the student backbone. Thus, a hetero-KD is transformed into a homo-KD, allowing efficient knowledge transfer from the teacher to the student. Moreover, we extend HEAD into a Teacher-Free HEAD (TF-HEAD) framework when a well-trained teacher detector is unavailable. Our method has achieved significant improvement compared to current detection KD methods. For example, on the MS-COCO dataset, TF-HEAD helps R18 RetinaNet achieve 33.9 mAP ($$+2.2$$+2.2), while HEAD further pushes the limit to 36.2 mAP ($$+4.5$$+4.5).
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_19
DP  - Springer Link
SP  - 314
EP  - 331
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
ST  - HEAD
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_19.pdf
KW  - Heterogeneous
KW  - Knowledge distillation
KW  - Object detection
ER  - 

TY  - CONF
TI  - Prediction-Guided Distillation for Dense Object Detection
AU  - Yang, Chenhongyi
AU  - Ochal, Mateusz
AU  - Storkey, Amos
AU  - Crowley, Elliot J.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Real-world object detection models should be cheap and accurate. Knowledge distillation (KD) can boost the accuracy of a small, cheap detection model by leveraging useful information from a larger teacher model. However, a key challenge is identifying the most informative features produced by the teacher for distillation. In this work, we show that only a very small fraction of features withinCrowley, Elliot J. a ground-truth bounding box are responsible for a teacher’s high detection performance. Based on this, we propose Prediction-Guided Distillation (PGD), which focuses distillation on these key predictive regions of the teacher and yields considerable gains in performance over many existing KD baselines. In addition, we propose an adaptive weighting scheme over the key regions to smooth out their influence and achieve even better performance. Our proposed approach outperforms current state-of-the-art KD baselines on a variety of advanced one-stage detection architectures. Specifically, on the COCO dataset, our method achieves between +3.1% and +4.6% AP improvement using ResNet-101 and ResNet-50 as the teacher and student backbones, respectively. On the CrowdHuman dataset, we achieve +3.2% and +2.0% improvements in MR and AP, also using these backbones. Our code is available at https://github.com/ChenhongyiYang/PGD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20077-9_8
DP  - Springer Link
SP  - 123
EP  - 138
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20077-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20077-9_8.pdf
KW  - Dense object detection
KW  - Knowledge distillation
ER  - 

TY  - CONF
TI  - Video-Based Reconstruction of Smooth 3D Human Body Motion
AU  - Zhang, Han
AU  - Wang, Jianming
AU  - Liu, Hui
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - We describe a method to directly recover a 3D human mesh from videos. The existing methods often show that the movement is not smooth and the motion jitter in a certain frame. The contribution of our method is to judge whether the difference between two frames exceeds the threshold range by adding constraint loss, and then optimize it. It effectively limits the changes of pose and shape parameters in the video sequence, and solves the jitter and mutation issues of the human model. Using an adversarial learning framework, the generator outputs the predicted human body parameters, and the discriminator to distinguish real human actions from those produced by our generator. Such adversarial training can produce kinematically plausible motion results. We use GRU network to effectively learn the temporal information which are hidden in the sequence. This is conducive to the continuity and smoothness of the human movement. We conduct some experiments to analyze the importance of constraint loss and demonstrate the effectiveness of our method on the challenging 3D pose estimation datasets.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_4
DP  - Springer Link
SP  - 42
EP  - 53
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_4.pdf
KW  - Adversarial learn
KW  - Constraint loss
KW  - Reconstruction of 3D human body
ER  - 

TY  - CONF
TI  - Slice Sequential Network: A Lightweight Unsupervised Point Cloud Completion Network
AU  - Chen, Bofeng
AU  - Fan, Jiaqi
AU  - Zhao, Ping
AU  - Wei, Zhihua
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - The point cloud is usually sparse and incomplete in reality, and the missing region of the point cloud is coherent when it is blocked by other objects. To tackle this problem, we propose a novel light-weight unsupervised model, namely the Slice Sequential Network, for point cloud completion. Our method only generates the missing parts with high fidelity, while many previous methods output the entire point cloud and leave out some important details. Specifically, we slice the incomplete point cloud and force the model to exploit the information lying between slices. In addition, we design a new algorithm for extracting geometric information, which can extract multi-scale features of points of the point cloud to enhance the use of slices. The qualitative and quantitative experiments show that our method is more lightweight and has better performance than the existing state-of-the-art methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_9
DP  - Springer Link
SP  - 103
EP  - 114
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - Slice Sequential Network
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_9.pdf
KW  - 3D point cloud completion
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Dual-Layer Barcodes
AU  - Fu, Kang
AU  - Jia, Jun
AU  - Zhai, Guangtao
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - With the emergence of mobile networks and smartphones, Quick Response Code (QR Code) has been widely used in many scenes in life, e.g. mobile payments, advertisement, and product traceability. However, when the encoded information of QR Codes is leaked, the QR Codes can be easily copied, which increases the risk of mobile payment and the difficulty of product traceability. To solve these problems, this paper proposes a novel approach to expand the information channels of QR Code based on invisible data hiding. The proposed architecture consists of an information encoder to hide messages into QR Codes while maintaining the original appearances of the QR codes and an information decoder to extract the hidden messages. To make the hidden messages detectable by smartphones, we use a series of noise layers to process the encoder output between the end-to-end training of the encoder and the decoder. The noise layers simulate the general distortions caused by camera imaging, e.g. noise, blur, JPEG compression, and light reflection. Experimental results show that the proposed method can achieve a high decoding accuracy of the hidden messages without affecting the decoding rate of the QR Codes used as the containers.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_18
DP  - Springer Link
SP  - 216
EP  - 227
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_18.pdf
KW  - Adversarial training
KW  - Convolutional networks
KW  - Information hiding
KW  - QR Code
ER  - 

TY  - CONF
TI  - VGG-CAE: Unsupervised Visual Place Recognition Using VGG16-Based Convolutional Autoencoder
AU  - Xu, Zhenyu
AU  - Zhang, Qieshi
AU  - Hao, Fusheng
AU  - Ren, Ziliang
AU  - Kang, Yuhang
AU  - Cheng, Jun
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Visual Place Recognition (VPR) is a challenging task in Visual Simultaneous Localization and Mapping (VSLAM), which expects to find out paired images corresponding to the same place in different conditions. Although most methods based on Convolutional Neural Network (CNN) perform well, they require a large number of annotated images for supervised training, which is time and energy consuming. Thus, to train the CNN in an unsupervised way and achieve better performance, we propose a new place recognition method in this paper. We design a VGG16-based Convolutional Autoencoder (VGG-CAE), which uses the features outputted by VGG16 as the label of images. In this case, VGG-CAE learns the latent representation from the label of images and improves the robustness against appearance and viewpoint variation. When deploying VGG-CAE, features are extracted from query images and reference images with post-processing, the Cosine similarities of features are calculated respectively and a matrix for feature matching is formed accordingly. To verify the performance of our method, we conducted experiments with several public datasets, showing our method achieves competitive results comparing to existing approaches.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_8
DP  - Springer Link
SP  - 91
EP  - 102
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - VGG-CAE
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_8.pdf
KW  - Convolutional autoencoder
KW  - VGG-16
KW  - Visual place recognition
ER  - 

TY  - CONF
TI  - FMixAugment for Semi-supervised Learning with Consistency Regularization
AU  - Lin, Huibin
AU  - Wang, Shiping
AU  - Liu, Zhanghui
AU  - Xiao, Shunxin
AU  - Du, Shide
AU  - Guo, Wenzhong
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Consistency regularization has witnessed tremendous success in the area of semi-supervised deep learning for image classification, which leverages data augmentation on unlabeled examples to encourage the model outputting the invariant predicted class distribution as before augmented. These methods have been made considerable progress in this area, but most of them are at the cost of utilizing more complex models. In this work, we propose a simple and efficient method FMixAugment, which combines the proposed MixAugment with Fourier space-based data masking and applies it on unlabeled examples to generate a strongly-augmented version. Our approach first generates a hard pseudo-label by employing a weakly-augmented version and minimizes the cross-entropy between it and the strongly-augmented version. Furthermore, to improve the robustness and uncertainty measurement of the model, we also enforce consistency constraints between the mixed augmented version and the weakly-augmented version. Ultimately, we introduce a dynamic growth of the confidence threshold for pseudo-labels. Extensive experiments are tested on CIFAR-10/100, SVHN, and STL-10 datasets, which indicate that our method outperforms the previous state-of-the-art methods. Specifically, with 40 labeled examples on CIFAR-10, we achieve 90.21% accuracy, and exceed 95% accuracy with 1000 labeled examples on STL-10.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_11
DP  - Springer Link
SP  - 127
EP  - 139
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_11.pdf
KW  - Consistency regularization
KW  - Data augmentation
KW  - Image classification
KW  - Semi-supervised learning
ER  - 

TY  - CONF
TI  - Dynamic Fusion Network for Light Field Depth Estimation
AU  - Zhang, Yukun
AU  - Piao, Yongri
AU  - Ji, Xinxin
AU  - Zhang, Miao
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Focus-based methods have shown promising results for the task of depth estimation in recent years. However, most existing focus-based depth estimation approaches depend on maximal sharpness of the focal stack. These methods ignore the spatial relationship between the focal slices. The problem of information loss caused by the out-of-focus areas in the focal stack poses challenges for this task. In this paper, we propose a dynamically multi-modal learning strategy which incorporates RGB data and the focal stack in our framework. Our goal is to deeply excavate the spatial correlation in the focal stack by designing the pyramid ConvGRU and dynamically fuse multi-modal information between RGB data and the focal stack in a adaptive way by designing the multi-modal dynamic fusion module. The success of our method is demonstrated by achieving the state-of-the-art performance on two light field datasets.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_1.pdf
KW  - Dynamic fusion.
KW  - Focal slices
KW  - Light field depth estimation
ER  - 

TY  - CONF
TI  - Metric Calibration of Aerial On-Board Multiple Non-overlapping Cameras Based on Visual and Inertial Measurement Data
AU  - Zhang, Xiaoqiang
AU  - Zhong, Liangtao
AU  - Liang, Chao
AU  - Chu, Hongyu
AU  - Shao, Yanhua
AU  - Ran, Lingyan
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Recently, the on-board cameras of the unmanned aerial vehicles are widely used for remote sensing and active visual surveillance. Compared to a conventional single aerial on-board camera, the multi-camera system with limited or non-overlapping field of views (FoVs) could make full use the FoVs and would therefore capture more visual information simultaneously, benefiting various aerial vision applications. However, the lack of common FoVs makes it difficult to adopt conventional calibration approaches. In this paper, a metric calibration method for aerial on-board multiple non-overlapping cameras is proposed. Firstly, based on the visual consistency of a static scene, pixel correspondence among different frames obtained from the moving non-overlapping cameras are established and are utilized to estimate the relative poses via structure from motion. The extrinsic parameters of non-overlapping cameras is then computed up to an unknown scale. Secondly, by aligning the linear acceleration differentiated from visual estimated poses and that obtained from inertial measurements, the metric scale factor is estimated. Neither checkerboard nor calibration pattern is needed for the proposed method. Experiments of real aerial and industrial on-board non-overlapping cameras calibrations are conducted. The average rotational error is less than $$0.2^{\circ }$$0.2∘, the average translational error is less than 0.015 m, which shows the accuracy of the proposed approach.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_2
DP  - Springer Link
SP  - 16
EP  - 28
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_2.pdf
KW  - Camera-imu system
KW  - Metric calibration
KW  - Non-overlapping field of view
KW  - Unmanned aerial vehicle
ER  - 

TY  - CONF
TI  - A Unified Modular Framework with Deep Graph Convolutional Networks forMulti-label Image Recognition
AU  - Lin, Qifan
AU  - Chen, Zhaoliang
AU  - Wang, Shiping
AU  - Guo, Wenzhong
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of handheld photographic devices, a large number of unlabeled images have been uploaded to the Internet. In order to retrieve these images, image recognition techniques have become particularly important. As there is often more than one object in a picture, multi-label image annotation techniques are of practical interest. To enhance its performance by fully exploiting the interrelationships between labels, we propose a unified modular framework with deep graph convolutional networks (MDGCN). It consists of two modules for extracting image features and label semantic respectively, after which the features are fused to obtain the final recognition results. With classical multi-label soft-margin loss, our model can be trained in an end-to-end schema. It is important to note that a deep graph convolutional network is used in our framework to learn semantic associations. Moreover, a special normalization method is employed to strengthen its own connection and avoid features from disappearing in the deep graph network propagation. The results of experiments on two multi-label image classification benchmark datasets show that our framework has advanced performance compared to the state-of-the-art methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_5
DP  - Springer Link
SP  - 54
EP  - 65
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_5.pdf
KW  - Convolutional neural networks
KW  - Feature extraction
KW  - Graph convolutional networks
KW  - Multi-label image recognition
ER  - 

TY  - CONF
TI  - IDANet: Iterative D-LinkNets with Attention for Road Extraction from High-Resolution Satellite Imagery
AU  - Xu, Benzhu
AU  - Bao, Shengshuai
AU  - Zheng, Liping
AU  - Zhang, Gaofeng
AU  - Wu, Wenming
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Road information plays a fundamental role in many application fields, while satellite images are able to capture a large area of the ground with high resolution. Therefore, extracting roads has become a hot research topic in the field of remote sensing. In this paper, we propose a novel semantic segmentation model, named IDANet, which adopts iterative D-LinkNets with attention modules for road extraction from high-resolution satellite images. Our road extraction model is built on D-LinkNet, an effective network which adopts encoder-decoder structure, dilated convolution, and pretrained encoder for road extraction task. The attention mechanism can be used to achieve a better fusion of features from different levels. To this end, a modified D-LinkNet with attention is proposed for more effective feature extraction. With this network as the basic refinement module, we further adopt an iterative architecture to maximize the network performance, where the output of the previous network serves as the input of the next network to refine the road segmentation and obtain enhanced results. The evaluation demonstrates the superior performance of our proposed model. Specifically, the performance of our model exceeds the original D-LinkNet by 2.2% of the IoU on the testing dataset of DeepGlobe for road extraction.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_12
DP  - Springer Link
SP  - 140
EP  - 152
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - IDANet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_12.pdf
KW  - Attention mechanism
KW  - Convolutional neural network
KW  - Iterative architecture
KW  - Road extraction
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - 3D Correspondence Grouping with Compatibility Features
AU  - Yang, Jiaqi
AU  - Chen, Jiahao
AU  - Huang, Zhiqiang
AU  - Cao, Zhiguo
AU  - Zhang, Yanning
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - We present a simple yet effective method for 3D correspondence grouping. The objective is to accurately classify initial correspondences obtained by matching local geometric descriptors into inliers and outliers. Although the spatial distribution of correspondences is irregular, inliers are expected to be geometrically compatible with each other. Based on such observation, we propose a novel feature representation for 3D correspondences, dubbed compatibility feature (CF), to describe the consistencies within inliers and inconsistencies within outliers. CF consists of top-ranked compatibility scores of a candidate to other correspondences, which purely relies on robust and rotation-invariant geometric constraints. We then formulate the grouping problem as a classification problem for CF features, which is accomplished via a simple multilayer perceptron (MLP) network. Comparisons with nine state-of-the-art methods on four benchmarks demonstrate that: 1) CF is distinctive, robust, and rotation-invariant; 2) our CF-based method achieves the best overall performance and holds good generalization ability.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_6
DP  - Springer Link
SP  - 66
EP  - 78
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_6.pdf
KW  - 3D correspondence grouping
KW  - 3D point cloud
KW  - Compatability feature
ER  - 

TY  - CONF
TI  - SEINet: Semantic-Edge Interaction Network for Image Manipulation Localization
AU  - Zhu, Ye
AU  - Qi, Na
AU  - Guo, Yingchun
AU  - Li, Bin
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Previous manipulation detection methods usually utilize semantic to detect suspected regions but the edge is abridged, which poses a greater challenge in manipulation location. We propose a novel dual framework named Semantic-Edge Interaction Network (SEINet) for locating the manipulated regions, including splicing, copy-move and removal. The dual streams and Cross Interaction (CI) pattern aim to extract semantic and edge features under the supervision of semantic and edge Ground-Truth, respectively. In addition, we propose a Bidirectional Fusion Module (BFM) to incorporate the dual stream feature maps with the decoder of U-net. Extensive experiments, which are evaluated on Synthetic, CASIA and NIST16 datasets, prove that the proposed SEINet can locate the manipulated regions more accurate than state-of-the-art methods, and is more robustness to noise, blur, and JPEG recompression attacks.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_3
DP  - Springer Link
SP  - 29
EP  - 41
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - SEINet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_3.pdf
KW  - Bidirectional fusion
KW  - Cross interaction
KW  - Dual-streams network
KW  - Image manipulation location
ER  - 

TY  - CONF
TI  - From Digital Model to Reality Application: A Domain Adaptation Method for Rail Defect Detection
AU  - Cui, Wenkai
AU  - Wang, Jianzhu
AU  - Yu, Haomin
AU  - Peng, Wenjuan
AU  - Wang, Le
AU  - Wang, Shengchun
AU  - Dai, Peng
AU  - Li, Qingyong
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Recently, vision-based rail defect detection has attracted much attention owing to its practical significance. However, it still faces some challenges, such as high false alarm rate and poor feature robustness. With the development of deep neural networks (DNNs), deep learning based models have shown the potential to solve the problems. Nevertheless, these models usually require a large number of training samples, while collecting and labeling sufficient defective rail images is somewhat impractical. On the one hand, the probability of defect occurrence is low. On the other hand, we are not able to annotate samples that include all types of defects. To this end, we propose to generate defective training images in the digital space. In order to bridge the gap between virtual and real defective samples, this paper presents a domain adaptation based model for rail defect detection. The proposed method is evaluated on a real-world dataset. Experimental results show that our proposed method is superior to five established baselines.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_10
DP  - Springer Link
SP  - 115
EP  - 126
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - From Digital Model to Reality Application
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_10.pdf
KW  - 3D point cloud
KW  - Digital model
KW  - Domain adaptation
KW  - Object detection
KW  - Rail defect detection
ER  - 

TY  - CONF
TI  - Immersive Traditional Chinese Portrait Painting: Research on Style Transfer and Face Replacement
AU  - Li, Jiayue
AU  - Wang, Qing
AU  - Li, Shiji
AU  - Zhong, Qiang
AU  - Zhou, Qian
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Traditional Chinese portrait is popular all over the world because of its unique oriental charm. However, how to use neural network to express the aesthetic and feelings in instantiated Chinese portrait effectively is still a challenging problem. This paper proposes a Photo to Chinese Portrait method (P-CP) providing immersive traditional Chinese portrait painting experience. Our method can produce two groups intriguing pictures. One is Chinese Portrait Style Picture, the other is Immersive Chinese Portrait Picture. We pay attention to neural style transfer for traditional Chinese portrait for the first time, and have trained a fast feedforward generative network to extract the corresponding style. The generative network principle is explored to guide the style transfer adjustment in detail. Face replacement is added to form a more appealing stylized effect. We also solve the problems of color and light violation, and unnatural seam. We hope this work offers a deeper and immersive conversation between modern society and antiques, and provides a useful step towards related interdisciplinary areas.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_16
DP  - Springer Link
SP  - 192
EP  - 203
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - Immersive Traditional Chinese Portrait Painting
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_16.pdf
KW  - Face replacement
KW  - Style transfer
KW  - Traditional Chinese portrait
ER  - 

TY  - CONF
TI  - Multi-camera Extrinsic Auto-calibration Using Pedestrians in Occluded Environments
AU  - Guan, Junzhi
AU  - Geng, Hujun
AU  - Gao, Feng
AU  - Li, Chenyang
AU  - Zhang, Zeyong
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - In this paper, we propose a novel extrinsic calibration method for camera networks based on a pedestrian who walks on a horizontal surface. Unlike existing methods which require both the feet and head of the person to be visible in all views, our method only assumes that the upper body of the person is visible, which is more realistic in occluded environments. Firstly, we propose a method to calculate the normal of the plane containing all head positions of a single pedestrian. We then propose an easy and accurate method to estimate the 3D positions of a head w.r.t. to each local camera coordinate system. We apply orthogonal procrustes analysis on the 3D head positions to compute relative extrinsic parameters connecting the coordinate systems of cameras in a pairwise fashion. Finally, we refine the extrinsic calibration matrices using a method which minimizes the reprojection error. Experimental results show that the proposed method provides an accurate estimation of the extrinsic parameters.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_17
DP  - Springer Link
SP  - 204
EP  - 215
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_17.pdf
KW  - Camera network
KW  - Extrinsic calibration
KW  - Normal
KW  - Orthogonal procrustes
KW  - Pedestrians
ER  - 

TY  - CONF
TI  - AnchorConv: Anchor Convolution for Point Clouds Analysis
AU  - Pan, Youngsun
AU  - Ma, Andy J.
AU  - Lin, Yiqi
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Point cloud, especially in 3D, is a common and important data structure. Recently, many point convolution methods have been proposed for point cloud processing, in which features of each point is updated by aggregating those of its neighbor points. Though existing methods can achieve satisfactory performance for point cloud analysis on several tasks, the performance may degrade when the distribution is non-uniform. In this paper, we present a new point convolution method namely Anchor Convolution (AnchorConv) for analysis of irregular and unordered point clouds. Inspired by standard grid convolution for images, each point in a point cloud is updated by fusing information from uniformly distributed anchors instead of non-uniformly distributed neighbor points. Features of each anchor are estimated by aggregating features of its neighborhood and distance relative to the anchor. Since the estimation biases and variances of different anchors are not the same, anchors are reweighted to obtain better feature representation of the center point. Experiments on ModelNet40, ShapeNetPart, S3DIS, and Semantic3D datasets show that the proposed AnchorConv outperforms state-of-the-art methods for classification and segmentation of 3D point clouds.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_14
DP  - Springer Link
SP  - 167
EP  - 179
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - AnchorConv
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_14.pdf
ER  - 

TY  - CONF
TI  - Contour-Aware Panoptic Segmentation Network
AU  - Xu, Yue
AU  - Zhu, Dongchen
AU  - Zhang, Guanghui
AU  - Shi, Wenjun
AU  - Li, Jiamao
AU  - Zhang, Xiaolin
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Panoptic segmentation incorporating semantic segmentation and instance segmentation plays an important role in scene understanding. Although current research has made remarkable progress, it has great potential for improvement in the contour region. In this paper, we propose a Contour-Aware Panoptic Segmentation Network (CAPSNet) with a panoptic contour branch and a new structure loss. The panoptic contour branch is designed to enhance structural cues perception by guiding feature extraction. The novel structure loss is presented for associating the consistency between panoptic segmentation and contour. Experimental results on the Cityscapes dataset show that CAPSNet achieves 60.0 in PQ metric, improving by 0.9% over baseline, and the proposed panoptic contour branch and structure loss are able to realize promising boosts on panoptic segmentation task.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_7
DP  - Springer Link
SP  - 79
EP  - 90
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_7.pdf
KW  - Contour-aware
KW  - Panoptic segmentation
KW  - Structure loss
ER  - 

TY  - CONF
TI  - IFR: Iterative Fusion Based Recognizer for Low Quality Scene Text Recognition
AU  - Jia, Zhiwei
AU  - Xu, Shugong
AU  - Mu, Shiyi
AU  - Tao, Yue
AU  - Cao, Shan
AU  - Chen, Zhiyong
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Although recent works based on deep learning have made progress in improving recognition accuracy on scene text recognition, how to handle low-quality text images in end-to-end deep networks remains a research challenge. In this paper, we propose an Iterative Fusion based Recognizer (IFR) for low quality scene text recognition, taking advantage of refined text images input and robust feature representation. IFR contains two branches which focus on scene text recognition and low quality scene text image recovery respectively. We utilize an iterative collaboration between two branches, which can effectively alleviate the impact of low quality input. A feature fusion module is proposed to strengthen the feature representation of the two branches, where the features from the Recognizer are Fused with image Restoration branch, referred to as RRF. Without changing the recognition network structure, extensive quantitative and qualitative experimental results show that the proposed method significantly outperforms the baseline methods in boosting the recognition accuracy of benchmark datasets and low resolution images in TextZoom dataset.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_15
DP  - Springer Link
SP  - 180
EP  - 191
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
ST  - IFR
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_15.pdf
KW  - Feature fusion
KW  - Iterative collaboration
KW  - Scene text recognition
ER  - 

TY  - CONF
TI  - Disentangling Deep Network for Reconstructing 3D Object Shapes from Single 2D Images
AU  - Yang, Yang
AU  - Han, Junwei
AU  - Zhang, Dingwen
AU  - Cheng, De
A2  - Ma, Huimin
A2  - Wang, Liang
A2  - Zhang, Changshui
A2  - Wu, Fei
A2  - Tan, Tieniu
A2  - Wang, Yaonan
A2  - Lai, Jianhuang
A2  - Zhao, Yao
T3  - Lecture Notes in Computer Science
AB  - Recovering 3D shapes of deformable objects from single 2D images is an extremely challenging and ill-posed problem. Most existing approaches are based on structure-from-motion or graph inference, where a 3D shape is solved by fitting 2D keypoints/mask instead of directly using the vital cue in the original 2D image. These methods usually require multiple views of an object instance and rely on accurate labeling, detection, and matching of 2D keypoints/mask across multiple images. To overcome these limitations, we make effort to reconstruct 3D deformable object shapes directly from the given unconstrained 2D images. In training, instead of using multiple images per object instance, our approach relaxes the constraint to use images from the same object category (with one 2D image per object instance). The key is to disentangle the category-specific representation of the 3D shape identity and the instance-specific representation of the 3D shape displacement from the 2D training images. In testing, the 3D shape of an object can be reconstructed from the given image by deforming the 3D shape identity according to the 3D shape displacement. To achieve this goal, we propose a novel convolutional encoder-decoder network—the Disentangling Deep Network (DisDN). To demonstrate the effectiveness of the proposed approach, we implement comprehensive experiments on the challenging PASCAL VOC benchmark and use different 3D shape ground-truth in training and testing to avoiding overfitting. The obtained experimental results show that DisDN outperforms other state-of-the-art and baseline methods.
C1  - Cham
C3  - Pattern Recognition and Computer Vision
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-88007-1_13
DP  - Springer Link
SP  - 153
EP  - 166
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-88007-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-88007-1_13.pdf
KW  - 3D shape reconstruction
KW  - Disentangling deep network
KW  - Point cloud
ER  - 

TY  - CONF
TI  - Machine Learning or Lexicon Based Sentiment Analysis Techniques on Social Media Posts
AU  - John, David L.
AU  - Stantic, Bela
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Social media provides an accessible and effective platform for individuals to offer thoughts and opinions across a wide range of interest areas. It also provides a great opportunity for researchers and businesses to understand and analyse a large volume of online data for decision-making purposes. Opinions on social media platforms, such as Twitter, can be very important for many industries due to the wide variety of topics and large volume of data available. However, extracting and analysing this data can prove to be very challenging due to its diversity and complexity. Recent methods of sentiment analysis of social media content rely on Natural Language Processing techniques on a fundamental sentiment lexicon, as well as machine learning oriented techniques. In this work, we evaluate representatives of different sentiment analysis methods, make recommendations and discuss advantages and disadvantages. Specifically we look into: 1) variation of VADER, a lexicon based method; 2) a machine learning neural network based method; and 3) a Sentiment Classifier using Word Sense Disambiguation, Maximum Entropy and Naive Bayes Classifiers. The results indicate that there is a significant correlation among all three sentiment analysis methods, which demonstrates their ability to accurately determine the sentiment of social media posts. Additionally, the modified version of VADER, a lexicon based method, is considered to be the most accurate and most appropriate method to use for the semantic analysis of social media posts, based on its strong correlation and low computational time. Obtained findings and recommendations can be valuable for researchers working on sentiment analysis techniques for large data sets.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_1
DP  - Springer Link
SP  - 3
EP  - 12
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_1.pdf
KW  - Machine learning
KW  - Natural language processing
KW  - Sentiment analysis
KW  - Social media
ER  - 

TY  - CONF
TI  - Prediction of Lung Cancer Survival Based on Multiomic Data
AU  - Jaksik, Roman
AU  - Śmieja, Jarosław
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Lung cancer is the leading cause of cancer death among both men and women, which mainly results from low effectiveness of the screening programs and late occurrence of symptoms, that are usually associated with advanced disease stages. Lung cancer shows high heterogeneity which was many times associated with its molecular background, providing the possibility to utilize machine learning approaches to aid both the diagnosis as well as the development of personalized treatments.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_10
DP  - Springer Link
SP  - 116
EP  - 127
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_10.pdf
KW  - Lung cancer
KW  - Machine learning
KW  - Multiomic data
KW  - Next generation sequencing
ER  - 

TY  - CONF
TI  - A Survey of Network Features for Machine Learning Algorithms to Detect Network Attacks
AU  - Rubab, Joveria
AU  - Afzal, Hammad
AU  - Shahid, Waleed Bin
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - The immeasurable amount of data in network traffic has increased its vulnerability. Therefore, monitoring and analyzing traffic for threat hunting is inevitable. Analyzing and capturing real-time network traffic is challenging due to privacy and space concerns. However, many simulated datasets are available. Machine-learning based intrusion detection systems are trained on these datasets for attack detection. Selection of correct features has significant importance in determining the efficiency of various Ml-based algorithms. Hence, this paper provides a literature survey of the various machine learning based IDS. Features, attacks, machine learning algorithms and their corresponding datasets are identified in the survey. The survey may help researchers in identifying benchmark features correlated to network attacks. At the time of writing this paper there is no such IDS that associates network features to attacks.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_7
DP  - Springer Link
SP  - 77
EP  - 88
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_7.pdf
KW  - Cyber space
KW  - DoS- Denial of Service
KW  - IDS-Intrusion Detection System
KW  - NetFlow
ER  - 

TY  - CONF
TI  - The Quality of Clustering Data Containing Outliers
AU  - Nowak-Brzezińska, Agnieszka
AU  - Gaibei, Igor
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - This article evaluates the efficiency and performance of both clustering algorithms: an agglomerative hierarchical clustering AHC (with various linkage options and distance measures) and the $$K-Means$$K-Meansalgorithm. We assess the quality of clustering using Davies-Bouldin and Dunn cluster validity indices. Our goal is to compare and analyze outlier detection algorithms depending on the applied clustering algorithm. We also wanted to verify whether the quality of clusters without outliers is higher than of those with outliers. In our research, we compare the LOF (Local Outlier Factor) and COF (Connectivity-based Outlier Factor) algorithms for detecting outliers (selecting $$1\%$$1%, $$5\%$$5%, and 10% of the most outlier instances in a given dataset). Next, we analyze how clustering quality has improved after excluding such outliers. In the experiments, three real datasets were used with a different number of instances. We wanted to investigate whether it is essential what clustering algorithm and outlier detection method we will use? Our goal was to check whether the clustering parameters impact the obtained clustering results. To the best of our knowledge, no research would combine these issues in one study.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_8
DP  - Springer Link
SP  - 89
EP  - 102
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_8.pdf
KW  - Clustering
KW  - Clustering quality indices
KW  - Outlier detection
ER  - 

TY  - CONF
TI  - Machine Learning Approach to Predict Metastasis in Lung Cancer Based on Radiomic Features
AU  - Fujarewicz, Krzysztof
AU  - Wilk, Agata
AU  - Borys, Damian
AU  - d’Amico, Andrea
AU  - Suwiński, Rafał
AU  - Świerniak, Andrzej
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Lung cancer is the most common cause of cancer-related death worldwide. One of the most significant negative prognostic factors is the occurrence of metastasis. Recently, one of the promising way to diagnose cancer samples is to use the image data (PET, CT etc.) and calculated on the basis of these images so called radiomic features. In this paper we present the attempt to use the radiomic features to predict the metastasis for lung cancer patients. We applied and compared three feature selection methods and two classification methods: logistic regression and support vector machines. The obtained accuracy of the best classifier confirms the potential of the radiomic data in prediction of metastasis in lung cancer.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_4
DP  - Springer Link
SP  - 40
EP  - 50
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_4.pdf
KW  - Lung cancer
KW  - Machine learning
KW  - Metastasis
KW  - Radiomic features
ER  - 

TY  - CONF
TI  - Parameter Distribution Ensemble Learning for Sudden Concept Drift Detection
AU  - Nguyen, Khanh-Tung
AU  - Tran, Trung
AU  - Nguyen, Anh-Duc
AU  - Phan, Xuan-Hieu
AU  - Ha, Quang-Thuy
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Concept drift is a big challenge in data stream mining (including process mining) since it seriously decreases the accuracy of a model in online learning problems. Model adaptation to changes in data distribution before making new predictions is very necessary. This paper proposes a novel ensemble method called E-ERICS, which combines multiple Bayesian-optimized ERICS models into one model and uses a voting mechanism to determine whether each instance of a data stream is a concept drift point or not. The experimental results on the synthetic and classic real-world streaming datasets showed that the proposed method is much more precise and more sensitive (shown in F1-score, precision, and recall metrics) than the original ERICS models in detecting concept drift, especially a sudden drift.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_16
DP  - Springer Link
SP  - 192
EP  - 203
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_16.pdf
KW  - Bayesian optimization
KW  - Concept drift
KW  - Data stream
KW  - Ensemble learning
ER  - 

TY  - CONF
TI  - A Comparative Study of Classification and Clustering Methods from Text of Books
AU  - Probierz, Barbara
AU  - Kozak, Jan
AU  - Hrabia, Anita
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Book collections in libraries are an important means of information, but without proper assignment of books into appropriate categories, searching for books on similar topics is very troublesome for both librarians and readers. This is a difficult problem due to the analysis of large sets of real text data, such as the content of books. For this purpose, we propose to create an appropriate model system, the use of which will allow for automatic assignment of books to appropriate categories by analyzing the text from the content of the books. Our research was tested on a database consisting of 552 documents. Each document contains the full content of the book. All books are from Project Gutenberg in the Art, Biology, Mathematics, Philosophy, or Technology category. Well-known techniques of natural language processing (NLP) were used for the proper preprocessing of the book content and for data analysis. Then, two different machine learning approaches were used: classification (as supervised learning) and clustering (as unsupervised learning) in order to properly assign books to selected categories. Measures of accuracy, precision and recall were used to evaluate the quality of classification. In our research, good classification results were obtained, even above 90% accuracy. Also, the use of clustering algorithms allowed for effective assignment of books to categories.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_2
DP  - Springer Link
SP  - 13
EP  - 25
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_2.pdf
KW  - Book classification
KW  - Clustering
KW  - Machine learning
KW  - Natural language processing
KW  - Text analysis
ER  - 

TY  - CONF
TI  - A Novel Neural Network Training Method for Autonomous Driving Using Semi-Pseudo-Labels and 3D Data Augmentations
AU  - Matuszka, Tamás
AU  - Kozma, Dániel
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Training neural networks to perform 3D object detection for autonomous driving requires a large amount of diverse annotated data. However, obtaining training data with sufficient quality and quantity is expensive and sometimes impossible due to human and sensor constraints. Therefore, a novel solution is needed for extending current training methods to overcome this limitation and enable accurate 3D object detection. Our solution for the above-mentioned problem combines semi-pseudo-labeling and novel 3D augmentations. For demonstrating the applicability of the proposed method, we have designed a convolutional neural network for 3D object detection which can significantly increase the detection range in comparison with the training data distribution.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_18
DP  - Springer Link
SP  - 216
EP  - 229
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_18.pdf
KW  - 3D data augmentation
KW  - 3D object detection
KW  - Machine learning
KW  - Neural network training
KW  - Semi-pseudo-labeling
ER  - 

TY  - CONF
TI  - A Lightweight and Efficient GA-Based Model-Agnostic Feature Selection Scheme for Time Series Forecasting
AU  - Nguyen, Minh Hieu
AU  - Nguyen, Viet Huy
AU  - Huynh, Thanh Trung
AU  - Nguyen, Thanh Hung
AU  - Nguyen, Quoc Viet Hung
AU  - Nguyen, Phi Le
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Time series prediction, which obtains historical data of multiple features to predict values of features of interest in the future, is widely used in many fields. One of the critical issues in dealing with the time series prediction task is how to choose appropriate input features. This paper proposes a novel approach to select a sub-optimal feature combination automatically. Our proposed method is model-agnostic that can be integrated with any prediction model. The basic idea is to use a Genetic Algorithm to discover a near-optimal feature combination; the fitness of a solution is calculated based on the accuracy obtained from the prediction model. In addition, to reduce the time complexity, we introduce a strategy to generate training data used in the fitness calculation. The proposed strategy aims to satisfy at the same time two objectives: minimizing the amount of training data, thereby saving the model’s training time, and ensuring the diversity of the data to guarantee the prediction accuracy. The experimental results show that our proposed GA-based feature selection method can improve the prediction accuracy by an average of 28.32% compared to other existing approaches. Moreover, by using the proposed training data generation strategy we can shorten the time complexity by 25.67% to 85.34%, while the prediction accuracy is degraded by only 2.97% on average.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_3
DP  - Springer Link
SP  - 26
EP  - 39
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_3.pdf
KW  - Feature selection
KW  - Genetic algorithm
KW  - Time series prediction
ER  - 

TY  - CONF
TI  - An Empirical Experiment on Feature Extractions Based for Speech Emotion Recognition
AU  - Duong, Binh Van
AU  - Ha, Chien Nhu
AU  - Nguyen, Trung T.
AU  - Nguyen, Phuc
AU  - Do, Trong-Hop
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - In recent years, the virtual assistant has become an essential part of many applications on smart devices. In these applications, users talk to virtual assistants in order to give commands. This makes speech emotion recognition to be a serious problem in improving the service and the quality of virtual assistants. However, speech emotion recognition is not a straightforward task as emotion can be expressed through various features. Having a deep understanding of these features is crucial to achieving a good result in speech emotion recognition. To this end, this paper conducts empirical experiments on three kinds of speech features: Mel-spectrogram, Mel-frequency cepstral coefficients, Tempogram, and their variants for the task of speech emotion recognition. Convolutional Neural Networks, Long Short-Term Memory, Multi-layer Perceptron Classifier, and Light Gradient Boosting Machine are used to build classification models used for the emotion classification task based on the three speech features. Two popular datasets: The Ryerson Audio-Visual Database of Emotional Speech and Song, and The Crowd-Sourced Emotional Multimodal Actors Dataset are used to train these models.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_15
DP  - Springer Link
SP  - 180
EP  - 191
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_15.pdf
KW  - Mel-spectrogram
KW  - MFCCs
KW  - Speech emotion
KW  - Tempogram
ER  - 

TY  - CONF
TI  - Graph Neural Networks-Based Multilabel Classification of Citation Network
AU  - Lachaud, Guillaume
AU  - Conde-Cespedes, Patricia
AU  - Trocan, Maria
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - There is an increasing number of applications where data can be represented as graphs. Besides, it is well-known that artificial intelligence approaches have become a very active and promising research field, mostly due to deep learning technologies. However popular deep learning architectures were designed to treat mostly image and text data. Graph Neural Network is the branch of machine learning which builds neural networks for graph data. In this context, many authors have recently proposed to adapt existing approaches to graphs and networks. In this paper we train three models of Graph Neural Networks on an academic citation network of Computer Science papers, and we explore the advantages of turning the problem into a multilabel classification problem.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_11
DP  - Springer Link
SP  - 128
EP  - 140
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_11.pdf
KW  - Citation network
KW  - Graph neural networks
KW  - Multilabel classification
ER  - 

TY  - CONF
TI  - Speeding Up Recommender Systems Using Association Rules
AU  - Kannout, Eyad
AU  - Nguyen, Hung Son
AU  - Grzegorowski, Marek
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Recommender systems are considered one of the most rapidly growing branches of Artificial Intelligence. The demand for finding more efficient techniques to generate recommendations becomes urgent. However, many recommendations become useless if there is a delay in generating and showing them to the user. Therefore, we focus on improving the speed of recommendation systems without impacting the accuracy In this paper, we suggest a novel recommender system based on Factorization Machines and Association Rules (FMAR). We introduce an approach to generate association rules using two algorithms: (i) apriori and (ii) frequent pattern (FP) growth. These association rules will be utilized to reduce the number of items passed to the factorization machines recommendation model. We show that FMAR has significantly decreased the number of new items that the recommender system has to predict and hence, decreased the required time for generating the recommendations. On the other hand, while building the FMAR tool, we concentrate on making a balance between prediction time and accuracy of generated recommendations to ensure that the accuracy is not significantly impacted compared to the accuracy of using factorization machines without association rules.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_14
DP  - Springer Link
SP  - 167
EP  - 179
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_14.pdf
KW  - Apriori algorithm
KW  - Association rules
KW  - Factorization machines
KW  - Frequent pattern growth algorithm
KW  - Prediction’s time
KW  - Quality of recommendations
KW  - Recommendation system
ER  - 

TY  - CONF
TI  - MLP-Mixer Approach for Corn Leaf Diseases Classification
AU  - Li, Li-Hua
AU  - Tanone, Radius
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Corn is one of the staple foods in Indonesia. However, corn leaf disease poses a threat to corn farmers in increasing production. Farmers find it difficult to identify the type of corn leaf that is affected by the disease. Seeing the development of corn that continues to increase, prevention of common corn leaf disease needs to be prevented to increase production. By using an open dataset, the modern MLP-Mixer model is used to train the smaller size of datasets for further use in predicting the classification of diseases that attack corn leaves. This experiment uses an MLP-Mixer with a basic Multi-Layer Perceptron which is repeatedly applied in feature channels. This makes the MLP-Mixer model more resource efficient in carrying out the process to classify corn leaf disease. In this research, a well-designed method ranging from data preparation related to corn leaf disease images to pre-training and model evaluation is proposed. The performance of our model shows 98.09% of test accuracy. This result is certainly a new trend in image classification, so that it can be a solution in handling computer vision problems in general. Furthermore, the high precision achieved in this experiment can be applied to small devices such as smartphones, drones, or embedded systems. Based on the images obtained, these results can undoubtedly be a solution for corn farmers in recognizing the types of leaf diseases in order to achieve smart farming in Indonesia.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_17
DP  - Springer Link
SP  - 204
EP  - 215
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_17.pdf
KW  - Corn leaf diseases
KW  - Image classification
KW  - MLP-Mixer
ER  - 

TY  - CONF
TI  - Towards Efficient Discovery of Partial Periodic Patterns in Columnar Temporal Databases
AU  - Ravikumar, Penugonda
AU  - Raj, Venus Vikranth
AU  - Likhitha, Palla
AU  - Kiran, Rage Uday
AU  - Watanobe, Yutaka
AU  - Ito, Sadanori
AU  - Zettsu, Koji
AU  - Toyoda, Masashi
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Finding partial periodic patterns in temporal databases is a challenging problem of great importance in many real-world applications. Most previous studies focused on finding these patterns in row temporal databases. To the best of our knowledge, there exists no study that aims to find partial periodic patterns in columnar temporal databases. One cannot ignore the importance of the knowledge that exists in very large columnar temporal databases. It is because real-world big data is widely stored in columnar temporal databases. With this motivation, this paper proposes an efficient algorithm, Partial Periodic Pattern-Equivalence Class Transformation (3P-ECLAT), to find desired patterns in a columnar temporal database. Experimental results on synthetic and real-world databases demonstrate that 3P-ECLAT is not only memory and runtime efficient but also highly scalable. Finally, we present the usefulness of 3P-ECLAT with a case study on air pollution analytics.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_12
DP  - Springer Link
SP  - 141
EP  - 154
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_12.pdf
KW  - Columnar databases
KW  - Pattern mining
KW  - Periodic patterns
ER  - 

TY  - CONF
TI  - Covariance Controlled Bayesian Rose Trees
AU  - Pęszor, Damian
AU  - Probierz, Eryka
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - This paper aims to present a modified version of Bayesian Rose Trees (BRT). The classical BRT approach performs data clustering without restricting the resulting hierarchy to the binary tree. The proposed method allows for constraining the resulting hierarchies on the basis of additional knowledge. Thanks to this modification, it is possible to analyse not only the raw structure of the data but also the nature of a cluster. This allows an automatic interpretation of the resulting hierarchies while differentiating between clusters of different magnitudes, or those that extend significantly through one pair of dimensions while being coherent in a different one. On the basis of the resulting modifications, it is possible to analyse the depth level as a function of likelihood. The developed method allows maximising customisation possibilities and comparative analysis between the nature of clusters. It can be applied to the clustering of different types of content, e.g. visual, textual, or in a modern approach to the construction of container databases.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_5
DP  - Springer Link
SP  - 51
EP  - 63
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_5.pdf
KW  - Bayesian Rose Tree
KW  - Hierarchical clustering
KW  - Hierarchy constraining
ER  - 

TY  - CONF
TI  - Avoiding Time Series Prediction Disbelief with Ensemble Classifiers in Multi-class Problem Spaces
AU  - Huk, Maciej
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Time series data is everywhere: it comes e.g. from IoT devices, financial transactions as well as medical and scientific observations. Time series analysis provides powerful tools and methodologies for modeling many kinds of related processes. Predictions based on such models often are of great value for many applications. But even the most accurate prediction will be useless if potential users will not want to accept and further use it. The article presents the problem of prediction disbelief and its relation with acceptance tests of predictions during lifecycle of time series analysis. The main contribution of the paper is classification and modeling of possible types of organization of acceptance tests of the outcomes of forecasting tools. This is done in the form of ensembles of classifiers working contextually in multi-class problem spaces. This allows to formulate, analyze and select the best methods of avoiding influence of prediction disbelief problem during time series analysis lifecycle.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_13
DP  - Springer Link
SP  - 155
EP  - 166
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_13.pdf
KW  - Context
KW  - Ensemble of classifiers
KW  - Selective exposure
KW  - Time series
ER  - 

TY  - CONF
TI  - Potential of Radiomics Features for Predicting Time to Metastasis in NSCLC
AU  - Wilk, Agata
AU  - Borys, Damian
AU  - Fujarewicz, Krzysztof
AU  - d’Amico, Andrea
AU  - Suwiński, Rafał
AU  - Świerniak, Andrzej
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - Lung cancer is the most deadly malignancy, with distant metastasis being a major negative prognostic factor. Recently, interest is growing in imaging data as a source of predictors due to the low invasiveness of their acquisition. Using a cohort of 131 patients and a total of 356 ROIs we built a Cox regression model which predicts metastasis and time to its occurrence based on radiomic features extracted from PET/CT images. We employed several variable selection methods, including filtering based on correlation, univariate analysis, recursive elimination and LASSO, and obtained a C-index of 0.7 for the best model. This result shows that radiomic features have great potential as predictors of metastatic relapse, knowledge of which could aid clinicians in planning treatment.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_6
DP  - Springer Link
SP  - 64
EP  - 76
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_6.pdf
KW  - Lung cancer
KW  - Metastasis
KW  - Radiomics features
KW  - Survival analysis
ER  - 

TY  - CONF
TI  - Aggregated Performance Measures for Multi-class Classification
AU  - Pȩszor, Damian
AU  - Wojciechowski, Konrad
A2  - Nguyen, Ngoc Thanh
A2  - Tran, Tien Khoa
A2  - Tukayev, Ualsher
A2  - Hong, Tzung-Pei
A2  - Trawiński, Bogdan
A2  - Szczerbicki, Edward
T3  - Lecture Notes in Computer Science
AB  - This paper aims to present an approach to generalisation of performance measures commonly used in binary classification to the field of multinomial classification to use them in hyperparameter estimation for various machine learning methods and similar techniques. The classical approach is to use a binary classification wherein each representative of any incorrect class is considered as a representative of an umbrella class being a union of all incorrect classes. Such an approach leads to the removal of important information from the classification process and therefore to the lower value of each experiment for the determination of the gradient when trying to optimise hyperparameters. We propose aggregated performance measures that can be thought of as an analogue of classical ones. The proposed measures better represent the multinomial nature of such algorithms and obtain more valuable information that allows selecting the correct direction while analysing the gradient of the resulting measures.
C1  - Cham
C3  - Intelligent Information and Database Systems
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21967-2_9
DP  - Springer Link
SP  - 103
EP  - 115
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-21967-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-21967-2_9.pdf
KW  - Accuracy
KW  - Multi-class classification
KW  - Multiclass classification
KW  - Multinomial classification
KW  - Performance
KW  - Sensitivity
KW  - Specificity
ER  - 

TY  - CHAP
TI  - HiEve Challenge on VOT
AU  - Xu, Ning
AU  - Lin, Weiyao
AU  - Lu, Xiankai
AU  - Wei, Yunchao
T2  - Video Object Tracking: Tasks, Datasets, and Methods
A2  - Xu, Ning
A2  - Lin, Weiyao
A2  - Lu, Xiankai
A2  - Wei, Yunchao
T3  - Synthesis Lectures on Computer Vision
AB  - Along with the development of modern smart cities, human-centric video analysis has been encountering the challenge of analyzing diverse and complex events in real scenes. A complex event relates to dense crowds, anomalous individuals, or collective behaviors.
CY  - Cham
DA  - 2024///
PY  - 2024
DP  - Springer Link
SP  - 117
EP  - 123
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-44660-3
UR  - https://doi.org/10.1007/978-3-031-44660-3_3
Y2  - 2024/01/31/07:13:09
ER  - 

TY  - CHAP
TI  - Introduction
AU  - Xu, Ning
AU  - Lin, Weiyao
AU  - Lu, Xiankai
AU  - Wei, Yunchao
T2  - Video Object Tracking: Tasks, Datasets, and Methods
A2  - Xu, Ning
A2  - Lin, Weiyao
A2  - Lu, Xiankai
A2  - Wei, Yunchao
T3  - Synthesis Lectures on Computer Vision
AB  - The ubiquity of cameras in various devices (e.g., mobile phones, surveillance cameras, in-vehicle cameras) has led to an exponential increase in video data.
CY  - Cham
DA  - 2024///
PY  - 2024
DP  - Springer Link
SP  - 1
EP  - 2
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-44660-3
UR  - https://doi.org/10.1007/978-3-031-44660-3_1
Y2  - 2024/01/31/07:13:09
ER  - 

TY  - CHAP
TI  - Tracking
AU  - Xu, Ning
AU  - Lin, Weiyao
AU  - Lu, Xiankai
AU  - Wei, Yunchao
T2  - Video Object Tracking: Tasks, Datasets, and Methods
A2  - Xu, Ning
A2  - Lin, Weiyao
A2  - Lu, Xiankai
A2  - Wei, Yunchao
T3  - Synthesis Lectures on Computer Vision
AB  - In this chapter, we will elaborate on the task of video object tracking (VOT), which aims at producing tight bounding boxes around one or multiple target objects in the video.
CY  - Cham
DA  - 2024///
PY  - 2024
DP  - Springer Link
SP  - 3
EP  - 115
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-44660-3
UR  - https://doi.org/10.1007/978-3-031-44660-3_2
Y2  - 2024/01/31/07:13:11
ER  - 

TY  - CONF
TI  - Global-to-Local Feature Mining Network for RGB-Infrared Person Re-Identification
AU  - Chen, Qiang
AU  - He, Fuxiao
AU  - Xiao, Guoqiang
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - RGB-Infrared person Re-Identification (RGB-IR ReID) is a challenging matching task that retrieves a RGB/infrared pedestrian image from the existing infrared/RGB set captured by non-overlapping visible or infrared cameras. Existing works mainly focus on how to alleviate the intra-modality variations and inter-modality discrepancies by data augmentation or feature alignment. Although these methods enlarge the diversity of the training set and, to some extent, reduce the gap between modalities, insufficient mining of discriminative and invariant features between modalities limits the performance of RGB-IR ReID algorithms. To remedy this, we propose a global-to-local feature mining network (GFMNet) to further mine discriminative and invariant features. Specifically, GFMNet contains two feature mining modules: Attention-aware Feature Mining Module (AFMM) and Local Information Mining Module (LIMM). AFMM aims to learn global discriminative features by attention mechanism; LIMM mines potential local invariant features between modalities by shortest path exploration. Besides, to reduce modality discrepancies and define a unified convergence direction, we introduce distribution consistency (DC) loss, which encourages RGB and infrared modalities toward intermediate modality. Extensive experiments on the SYSU-MM01 and RegDB datasets show that GFMNet achieves competitive RGB-IR ReID performance. The code will be announced at https://github.com/cq0907/GFMNet.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_1
DP  - Springer Link
SP  - 1
EP  - 13
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - attention mechanism
KW  - distribution consistency
KW  - feature mining
KW  - RGB-Infrared person Re-Identification
KW  - shortest path
ER  - 

TY  - CONF
TI  - Multi-task Collaborative Network for Image-Text Retrieval
AU  - Qin, Xueyang
AU  - Li, Lishuang
AU  - Hao, Jing
AU  - Ge, Meiling
AU  - Huang, Jiayi
AU  - Pang, Guangyao
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Image-text retrieval aims to capture semantic relevance between images and texts. Most existing approaches rely solely on the image-text pairs to learn visual-semantic representation through fine-grained alignments while neglecting the potential beneficial impact of unimodal tasks on cross-modal retrieval. To this end, we present a Multi-Task Collaborative Network (MTCN) that leverages the synergy between multiple tasks to enhance the performance of image-text retrieval. Specifically, we introduce three unimodal tasks, including text-text matching, image multi-label classification, and text multi-label classification, and train together with target task image-text retrieval from the perspective of semantic constraints. Additionally, we employ a modality interaction module for image-text retrieval to discover interrelationships between these two modalities. Subsequently, a cascaded graph convolutional network combined with a multi-layer perceptron is used to infer the correlation scores between images and texts. We conduct comprehensive experiments on two benchmark datasets, Flickr30K and MSCOCO, and the quantitative and qualitative experimental results demonstrate the effectiveness of the proposed method. The source code is available at https://github.com/FlyCuteBird/MTCN.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_3
DP  - Springer Link
SP  - 28
EP  - 42
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Cross-modal retrieval
KW  - Graph convolutional network
KW  - Image-text retrieval
KW  - Multi-task learning
ER  - 

TY  - CONF
TI  - Semantic Transition Detection for Self-supervised Video Scene Segmentation
AU  - Chen, Lu
AU  - Tan, Jiawei
AU  - Yang, Pingan
AU  - Wang, Hongxing
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Video scene segmentation is a crucial task in temporally parsing long-form videos into basic story units. Most advanced self-supervised methods of video scene segmentation focus heavily on learning video shot features in the pre-training stage. However, these methods ignore to encode shot relations, which are essential to video scene segmentation, resulting in over-segmentation of video scenes. A straightforward solution to the above problem is to use sufficient scene boundaries to model the shot relations. In this paper, we introduce a high-quality pseudo-scene boundary generation method, Semantic Transition Detection (STD), by discovering semantic inconsistencies in temporal video chunks. Taking scene boundary prediction as the pretext task, we propose a self-supervised method for video scene segmentation, by which we can fine-tune a STD pre-trained model with limited scene boundary ground truths. In addition, considering the impact of shot duration on the segmentation results, we integrate the shot duration information into the fine-tuning stage. Experiments on widely used benchmark datasets demonstrate that our approach effectively mitigates over-segmentation and achieves remarkable results in comparison with the state of the arts.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_2
DP  - Springer Link
SP  - 14
EP  - 27
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Pseudo-Scene Boundary
KW  - Self-Supervised Learning
KW  - Semantic Transition
KW  - Video Scene Segmentation
ER  - 

TY  - CONF
TI  - Co-speech Gesture Generation with Variational Auto Encoder
AU  - Ka, Shinichi
AU  - Shinoda, Koichi
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - The research field of generating natural gestures from speech input is called co-speech gesture generation. Co-speech generation methods should suffice two requirements: fidelity and diversity. Several previous researches have utilized deterministic methods to establish a one-to-one mapping between speech and motion to achieve fidelity to speech, but the variety of gestures produced is limited. Other methods generate gestures probabilistically to make them various, but they often lack fidelity to the speech. To overcome these limitations, we propose Speaker-aware Audio2Gesture (SA2G) that uses a variational autoencoder (VAE) with the input of randomized speaker-aware features, an extension of the previously proposed A2G. By using ST-GCNs as encoders and controlling the variance for randomization, it can generate gestures faithful to speech content, which also have a large variety. In our evaluation on TED datasets, it improves the fidelity of the generated gestures from the baseline by 85.4, while increasing the Multimodality by $$9.0 \times 10^{-3}$$9.0×10-3.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_12
DP  - Springer Link
SP  - 155
EP  - 168
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Co-speech gesture generation
KW  - Human motion synthesis
KW  - Pre-training
KW  - Variational autoencoder
ER  - 

TY  - CONF
TI  - MSMV-UNet: A 2.5D Stroke Lesion Segmentation Method Based on Multi-slice Feature Fusion
AU  - Xie, Jingjing
AU  - Hong, JiXuan
AU  - Sheng, Manjin
AU  - Yang, Chenhui
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Stroke is a severe and life-threatening disease. MRI plays a crucial role in the diagnosis and treatment of stroke, enabling comprehensive analysis of MRI images for accurate localization and qualitative assessment of stroke lesions. A 2.5D stroke lesion segmentation method based on the fusion of multi-slice features is proposed in this study. This method introduces the time information feature between slices in three-dimensional (3D) image data on the basis of a two-dimensional (2D) segmentation model. Multiple encoding paths are densely connected between adjacent slices to utilize the time information feature. To address the problem of difficult segmentation of stroke lesions edges, a Slice-Context Attention Module is proposed to reinforce the differences between adjacent slices in the feature maps. Additionally, considering the multi-perspective features in stroke lesions imaging data, this method proposes to train the segmentation model from three different perspectives: cross section, sagittal plane and coronal plane, and uses soft voting strategy to fuse the results of the three models to form a 2.5D method. Qualitative and quantitative experimental results demonstrate that this method has certain superiority compared to existing methods.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_5
DP  - Springer Link
SP  - 57
EP  - 69
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
ST  - MSMV-UNet
KW  - Computer-aided Diagnosis
KW  - Deep Learning
KW  - MRI
KW  - Stroke Lesion Segmentation
ER  - 

TY  - CONF
TI  - Two-Stage Reasoning Network with Modality Decomposition for Text VQA
AU  - Ling, Shengrong
AU  - You, Sisi
AU  - Bao, Bing-Kun
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Text-based Visual Question Answering (Text VQA) is a challenging task that requires a comprehensive understanding of scene texts in an image. Scene texts encompass information from both textual and visual modalities. Most existing methods typically treat information of different modalities indiscriminately. However, such approaches may restrict the detailed interaction between textual and visual modalities, leading to biased or incorrect semantic understanding. To address the limitation, we propose a two-stage reasoning network with modality decomposition for Text VQA. In the first stage, we separately handle OCR textual and visual modalities through a modality-specific attention module which is adopted to capture the crucial information of each modality. In the second stage, we aim to enhance the interaction between textual and visual modalities. To achieve this, we introduce a semantic-guided interaction module that incorporates the semantic context to facilitate the alignment of the two modalities. Extensive experiments on the TextVQA and ST-VQA datasets demonstrate that our network achieves competitive performance compared with current state-of-the-art methods.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_10
DP  - Springer Link
SP  - 127
EP  - 140
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Scene Text Recognition
KW  - Semantic Reasoning
KW  - Text VQA
ER  - 

TY  - CONF
TI  - Non-Local Spatial-Wise and Global Channel-Wise Transformer for Efficient Image Super-Resolution
AU  - Gao, Xiang
AU  - Wu, Sining
AU  - Wang, Fan
AU  - Hu, Xiaopeng
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Transformer-based methods have made favorable breakthroughs in image super-resolution (SR) due to the strong ability of capturing long-range dependencies in images. However, these methods mainly concentrate on capturing spatial interaction information, often ignoring to explore the global characteristics across the channel dimension. In this paper, we propose a novel Non-local Spatial-wise and Global Channel-wise Transformer (NSGCT) for efficient image SR. To comprehensively investigate inherent similarity information in both spatial and channel dimensions, we design a hybrid of Non-local Spatial-wise Self-Attention (NSSA) and Global Channel-wise Self-Attention (GCSA) within the Transformer layer. Specifically, NSSA is shifted-window-based and concentrates on the non-local spatial similarity features, while GCSA calculates the cross-covariance across the channels to exploit the global long-range image relationships. We also design an Efficient Gated Depth-wise-conv Feed-forward Network (EGDFN) as the feed-forward network to enhance and control the information flow in Transformer with an efficient implementation for further restoring the accurate texture information. Extensive quantitative and qualitative evaluations on benchmark datasets demonstrate that the proposed NSGCT performs favorably against other state-of-the-art efficient image SR methods in terms of computation costs and image reconstruction quality.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_6
DP  - Springer Link
SP  - 70
EP  - 85
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Efficient
KW  - Image Super-Resolution
KW  - Self-Attention
KW  - Transformer
ER  - 

TY  - CONF
TI  - ASF-Conformer: Audio Scoring Conformer with FFC for Speaker Verification in Noisy Environments
AU  - Zhang, Xiran
AU  - Liu, Haiyan
AU  - Liu, Caixia
AU  - Zhang, Haiyang
AU  - Huo, Zhiwei
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Background noise significantly impacts speech intelligibility, reducing the accuracy and reliability of the speaker verification system. Most existing noise reduction algorithms are specific to certain types of noise and have limitations, making them ineffective on eliminating background noise. Therefore, the extraction of robust features and the development of noise-resistant models that adapt to various noisy environments remain crucial challenges in the field of speaker verification. In this paper, we propose a Conformer-based Audio Scoring Conformer with Fast Fourier Convolution (ASF-Conformer), which is a speaker verification model. Firstly, the audio scoring module is introduced to evaluate and weight the audio features, aiming to select more robust features in noisy environments. Secondly, we introduce Fast Fourier Convolution as a replacement for the Conformer’s convolution module, improving the model’s ability to capture global features while reducing the model parameters. Finally, this paper conducts comparative tests with the current mainstream models on public dataset VoxCeleb1, and synthesized noisy dataset Mu-VoxCeleb1. The experimental results demonstrate that the proposed ASF-Conformer model, compared to the ECAPA-TDNN model with essentially the same parameters, outperforms ECAPA-TDNN by 2% and 18% respectively when evaluated using the EER metrics on the VoxCeleb1 and Mu-VoxCeleb1 datasets. These results highlight the effectiveness of the proposed model in enhancing the accuracy of speaker verification tasks, especially in noisy environments.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_8
DP  - Springer Link
SP  - 101
EP  - 111
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
ST  - ASF-Conformer
KW  - Conformer
KW  - Noisy environment
KW  - Speaker verification
ER  - 

TY  - CONF
TI  - Learning Collaborative Reinforcement Attention for 3D Face Reconstruction and Dense Alignment
AU  - Yang, Zhengwei
AU  - Wang, Yange
AU  - Ma, Lei
AU  - Li, Xiangzheng
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - 3D face reconstruction from monocular outdoor images has long been a challenging problem. Traditional attention network methods that directly regress parameters may suffer from inadequate learning of discriminative features. In this paper, we propose a method called collaborative reinforcement attention module (CRAM). CRAM comprises three major modules: the perception module (PM), the channel selection module (CSM), and the multi-level feature interaction module (MFIM). CRAM leverages contextual information to simultaneously focus on multiple prominent features in facial photos. It employs multi-level and multi-angle feature extraction and fusion techniques to adaptively learn the relationship between facial regions and key feature points. This results in enhanced accuracy in 3D face reconstruction and meticulous dense alignment. Furthermore, to enhance the model’s generalization performance, we introduce a regional noise injection and image composition module (RNICM) as a preprocessing step for sample data which help capture more local details and handle occluded faces, particularly under significant head rotations. Extensive experiments conducted on the AFLW2000-3D and AFLW datasets validate the effectiveness of the proposed approach.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_14
DP  - Springer Link
SP  - 184
EP  - 197
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Collaborative reinforcement attention module
KW  - Face alignment
KW  - Face reconstruction
ER  - 

TY  - CONF
TI  - Fractional-Order Image Moments and Applications
AU  - Xu, Liyun
AU  - Zhang, Min
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Image moments, as a global feature descriptor for images, have become a powerful tool for pattern recognition and image analysis. Most of the currently existing fractional-order image moments are polynomial-based. Three novel moments, namely Zernike fractional Fourier moment, Merlin fractional Fourier moment, and exponential fractional Fourier moment, combined with classical moments and fractional Fourier transform, are introduced based on angular functions. Additionally, we propose a zero watermarking algorithm based on these moments. We present robustness and comparative analysis experiments, including the effects of noise, filtering, rotation, and scaling. The experimental results demonstrate that the zero watermarking algorithm utilizing fractional-order moments can effectively withstand image processing attacks and geometric attacks. In both cases, their performance surpasses that of their corresponding integer-order image moments.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_19
DP  - Springer Link
SP  - 257
EP  - 269
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Fractional Fourier transform
KW  - Information security
KW  - Orthogonal moment
KW  - Zero watermarking
ER  - 

TY  - CONF
TI  - Exploring Multi-modal Fusion for Image Manipulation Detection and Localization
AU  - Triaridis, Konstantinos
AU  - Mezaris, Vasileios
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Recent image manipulation localization and detection techniques usually leverage forensic artifacts and traces that are produced by a noise-sensitive filter, such as SRM and Bayar convolution. In this paper, we showcase that different filters commonly used in such approaches excel at unveiling different types of manipulations and provide complementary forensic traces. Thus, we explore ways of merging the outputs of such filters and aim to leverage the complementary nature of the artifacts produced to perform image manipulation localization and detection (IMLD). We propose two distinct methods: one that produces independent features from each forensic filter and then fuses them (this is referred to as late fusion) and one that performs early mixing of different modal outputs and produces early combined features (this is referred to as early fusion). We demonstrate that both approaches achieve competitive performance for both image manipulation localization and detection, outperforming state-of-the-art models across several datasets (Code is publicly available at https://github.com/IDT-ITI/MMFusion-IML).
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_15
DP  - Springer Link
SP  - 198
EP  - 211
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Image forensics
KW  - Image manipulation detection
KW  - Image manipulation localization
KW  - Multi-modal fusion
ER  - 

TY  - CONF
TI  - Exploring Imperceptible Adversarial Examples in $$YC_bC_r$$Color Space
AU  - Chen, Pei
AU  - Feng, Zhiyong
AU  - Xing, Meng
AU  - Zhang, Yiming
AU  - Zheng, Jinqing
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Numerous studies have shown that well-designed perturbations can easily fool deep neural networks. Existing attacks are mainly conducted on the low-level pixels of RGB images, resulting in noise-like perturbations distributed over the entire image, highly vulnerable and low attack transferability. Furthermore, they delve into the data space with point-wise perturbation, which may neglect the geometric characteristics and fail to study the role and impact of various image components. Compared with RGB images, $$YC_bC_r$$YCbCrimages can express various image components more intuitively. In this paper, we propose generating semantically preserved adversarial examples by perturbing the frequency band energy corresponding to inconspicuous colors and textures in the $$YC_bC_r$$YCbCrcolor space. Specifically, we first transform clean images from spatial to frequency domain, followed by applying a fusion module to indirectly inject perturbations. Moreover, the low-frequency constraint and luma-chroma optimization strategy are further introduced to ensure visual imperceptibility. Extensive experiments on multiple datasets indicate that our attack retains a high attack success rate while significantly improving visual quality.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_18
DP  - Springer Link
SP  - 242
EP  - 256
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - \(YC_bC_r\)
KW  - Adversarial examples
KW  - Imperceptibility
ER  - 

TY  - CONF
TI  - FGENet: Fine-Grained Extraction Network for Congested Crowd Counting
AU  - Ma, Hao-Yuan
AU  - Zhang, Li
AU  - Wei, Xiang-Yi
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Crowd counting has gained significant popularity due to its practical applications. However, mainstream counting methods ignore precise individual localization and suffer from annotation noise because of counting from estimating density maps. Additionally, they also struggle with high-density images. To address these issues, we propose an end-to-end model called Fine-Grained Extraction Network (FGENet). Different from methods estimating density maps, FGENet directly learns the original coordinate points that represent the precise localization of individuals. This study designs a fusion module, named Fine-Grained Feature Pyramid (FGFP), that is used to fuse feature maps extracted by the backbone of FGENet. The fused features are then passed to both regression and classification heads, where the former provides predicted point coordinates for a given image, and the latter determines the confidence level for each predicted point being an individual. At the end, FGENet establishes correspondences between prediction points and ground truth points by employing the Hungarian algorithm. For training FGENet, we design a robust loss function, named Three-Task Combination (TTC), to mitigate the impact of annotation noise. Extensive experiments are conducted on four widely used crowd counting datasets. Experimental results demonstrate the effectiveness of FGENet. Notably, our method achieves a remarkable improvement of 3.14 points in Mean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing its superiority over the existing state-of-the-art methods. Even more impressively, FGENet surpasses previous benchmarks on the UCF_CC_50 dataset with an astounding enhancement of 30.16 points in MAE.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_4
DP  - Springer Link
SP  - 43
EP  - 56
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
ST  - FGENet
KW  - Computer vision
KW  - Convolutional neural network
KW  - Crowd counting
ER  - 

TY  - CONF
TI  - Localization and Local Motion Magnification of Pulsatile Regions in Endoscopic Surgery Videos
AU  - Zheng, Honglei
AU  - Fan, Wenkang
AU  - Chen, Yinran
AU  - Luo, Xiongbiao
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Localization of neurovascular bundles or vessels is critical in endoscopic surgery. It still remains challenging to identify neurovascular bundles and vessels due to limited field-of-view and tactile perception loss. This paper presents a new framework for local motion magnification of the pulsatile region in endoscopic surgical videos, which can help surgeons localize these pulsatile regions from complex surgical fields. Our method consists of an autocorrelated dynamic linear model, a pulsatile region localization module, and a local motion magnification module. Specifically, the autocorrelated dynamic linear model and pulsatile region localization module can extract periodic features and position information of pulsatile regions. Then, the local motion magnification module performs local motion magnification, minimizing post-magnification artifacts. Importantly, our method also avoids distorting the surgical instruments during magnification. Experimental validations on both synthetic and clinical surgical videos demonstrate that our method outperforms the existing methods in both qualitative and quantitative assessments.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_11
DP  - Springer Link
SP  - 141
EP  - 154
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Endoscopic surgery
KW  - Local motion magnification
KW  - Periodic features extraction
KW  - Pulsatile regions localization
ER  - 

TY  - CONF
TI  - Prior-Knowledge-Free Video Frame Interpolation with Bidirectional Regularized Implicit Neural Representations
AU  - He, Yuanjian
AU  - Zhang, Weile
AU  - Deng, Junyuan
AU  - Cong, Yulai
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Prevalent deep-learning-based video frame interpolation (VFI) methods are mostly pre-trained and require an optical-flow model to obtain prior knowledge. However, pre-training is often time-consuming, and may introduce unexpected artifacts when applied to a test domain that differs significantly from the training one. Alternatively, implicit neural representations have shown the ability to synthesize novel views from sparse images without pre-training. In this paper, we consider VFI as a special case of novel view synthesis and leverage implicit neural representations to perform VFI without pre-training or an optical-flow model. We propose Bidirectional Regularization Framework (BiRF), a novel VFI method that is trained per scene requiring only two input frames, which is fundamentally different from existing methods that utilize pre-trained weights containing extensive prior knowledge. We demonstrate that our BiRF, even without using prior knowledge, can generate comparable or even superior interpolated frames to prevalent pre-trained models.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_9
DP  - Springer Link
SP  - 112
EP  - 126
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Implicit neural representations
KW  - Neural fields
KW  - Video frame interpolation
ER  - 

TY  - CONF
TI  - MobileViT-FocR: MobileViT with Fixed-One-Centre Loss and Gradient Reversal for Generalised Fake Face Detection
AU  - Peng, Ting
AU  - Zhou, Yihang
AU  - Sun, Rong
AU  - Luo, Yizhi
AU  - Li, Yuqi
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Fake face detection is one of the most important face detection technologies, which plays an important role in preventing malicious actors from using generated fake faces for malicious purposes. However, current fake face detection techniques have poor generalisation detection ability to recognise different types of fake face images, which makes it difficult to apply this technology to real-life scenarios. Therefore, it is important to construct a fake face detection model with stronger cross-domain generalisation capabilities. In order to enhance the generalisation detection capability of the model on different face datasets, we propose a MobileViT-FocR model, which uses MobileViT to extract local and global features, and proposes the Fixed-One-Centre(FOC) loss, that is, to select a fixed centre point and focus only on similar features of real face images. The model is tuned with some of the parameters of focal loss to enhance its ability to detect more difficult fake face images. The GRL(Gradient Reversal Layer) is added based on the network to make the model better focus on the generic category differences between fake and real faces rather than the domain differences. Through experimental verification, our model has good detection capability for fake face images of different styles generated by various algorithms. Compared to the original MobileViT model, our model improved by 9.79$$\%$$%, 8.58$$\%$$%, 7.70$$\%$$%, and 8.23$$\%$$%on Internet Celebrity, Celeb-DF, DFDC, and ForgeryNet datasets respectively.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_7
DP  - Springer Link
SP  - 86
EP  - 100
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
ST  - MobileViT-FocR
KW  - Fake Face Detection
KW  - Fixed One Centre Loss
KW  - Generalisation Detection Capability
KW  - ViT model
ER  - 

TY  - CONF
TI  - Appearance-Motion Dual-Stream Heterogeneous Network for VideoQA
AU  - Xu, Feifei
AU  - Zhong, Zheng
AU  - Zhu, Yitao
AU  - Zhou, Yingchen
AU  - Li, Guangzhen
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Capturing spatio-temporal information in videos related to the question remains a key challenge in video question answering task (VideoQA). Though great success has been achieved in VideoQA, most of the existing methods do not sufficiently consider the correlation among appearance, motion, and object features, making it difficult to fully exploit the spatio-temporal relationships at different granularities. Besides, recent researches typically use the same interaction method when different features in the video interact with the question features separately, which ignores the spatio-temporal characteristics of the appearance and motion features in the video which leads to the problem of spatio-temporal mismatch. In this paper, we propose an Appearance-Motion Dual-stream Heterogeneous Network for VideoQA (AMHN), which pays attention to the synergy among three different features by heterogeneous interactions in terms of their spatio-temporal characteristics. AMHN unites object features with appearance features and motion features respectively to obtain two high-level visual representations containing object information. Then they are fed into the object-relational reasoning module to acquire relation-aware visual features. We use a bilinear attention network for appearance and put forward a Video-Text Symmetric Attention Network (VTSAN) for motion to achieve diverse features, which are fused under the guidance of the question to predict the final answer. We evaluate the performance of AMHN on two VideoQA benchmark datasets and perform an extensive ablation study. The experimental results demonstrate its state-of-the-art.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_16
DP  - Springer Link
SP  - 212
EP  - 227
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Dual-stream
KW  - Heterogeneous Network
KW  - Video Question Answering
ER  - 

TY  - CONF
TI  - Differentiable Neural Architecture Search Based on Efficient Architecture for Lightweight Image Super-Resolution
AU  - Sheng, Chunyin
AU  - Gao, Xiang
AU  - Hu, Xiaopeng
AU  - Wang, Fan
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - With the advancement of deep neural networks, image Super-Resolution (SR) has witnessed remarkable improvements in performance. However, the increasing number of parameters and computational complexity has posed challenges for the practical deployment of SR models. To address these challenges, we propose a novel approach called Differentiable Neural Architecture Search (NAS) based on Efficient Architecture for lightweight image Super-Resolution, referred to as DNAS-EASR. In DNAS-EASR, we employ the information distillation mechanism (IDM) at the cell-level space to search for key operations. Additionally, we search for attention modules at the cell-level space to determine the most suitable attention module for our architecture. Furthermore, we adopt a hierarchical architecture as our backbone network to enable multi-scale information processing and fusion. Extensive experiments conducted on benchmark datasets demonstrate that DNAS-EASR is lightweight, efficient and capable of achieving comparable performance to other lightweight methods.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_13
DP  - Springer Link
SP  - 169
EP  - 183
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - attention
KW  - differentiable NAS
KW  - hierarchical architecture
KW  - information distillation mechanism (IDM)
KW  - lightweight SR
ER  - 

TY  - CONF
TI  - Adaptive Token Selection and Fusion Network for Multimodal Sentiment Analysis
AU  - Li, Xiang
AU  - Lu, Ming
AU  - Guo, Ziming
AU  - Zhang, Xiaoming
A2  - Rudinac, Stevan
A2  - Hanjalic, Alan
A2  - Liem, Cynthia
A2  - Worring, Marcel
A2  - Jónsson, Björn Þór
A2  - Liu, Bei
A2  - Yamakata, Yoko
T3  - Lecture Notes in Computer Science
AB  - Multimodal sentiment analysis aims to predict human sentiment polarity with multiple modalities. Most existing methods focus on directly integrating original modal features into multimodal fusion, ignoring the redundancy and heterogeneity across modalities. In this paper, we propose a simple but efficient Adaptive Token Selection and Fusion Network (ATSFN) to mitigate the effect of redundancy and heterogeneity. ATSFN employs adaptive trainable tokens to extract unimodal informative tokens and perform dynamic multimodal token fusion. Specifically, we first integrate critical information from original features into adaptive selection tokens through token selection transformers. Sentiment features flow through these smaller sequences of tokens to capture important information while reducing redundancy. Next, we introduce a token fusion transformer to fuse multimodal features dynamically. It adaptively estimates the unique contribution of each modality to sentiment tendencies through learnable fusion tokens. Experiments on two benchmark datasets demonstrate that our proposed approach achieves competitive performance and significant improvements.
C1  - Cham
C3  - MultiMedia Modeling
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-3-031-53311-2_17
DP  - Springer Link
SP  - 228
EP  - 241
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-53311-2
KW  - Adaptive token
KW  - Heterogeneity
KW  - Multimodal fusion
KW  - Multimodal sentiment analysis
KW  - Redundancy
ER  - 

TY  - CONF
TI  - An Improved CNN Model for Fast Salient Object Detection
AU  - Zhang, Bin
AU  - Wu, Yang
AU  - Zhang, Jiaqiang
AU  - Ma, Ming
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In an image, how to quickly and effectively extract the useful regions named target regions in the scene according to the saliency features such as spatial domain, frequency domain etc. for further analysis of salient object detection is one of the challenging topics in the field of image segmentation. Most of the existing salient target detection methods use convolution network to extract high-order semantic features, combine pyramid pooling model to fuse high-order and low-order semantic features, and use Adam or SGD optimizer to optimize the model to obtain the salient object. However, the traditional convolution network model is not optimized for the model parameters, and finally redundant parameters will appear in the model, which will aggravate the training time and practical application detection time of the model. Although SGD is fast, it will fall into a large number of local suboptimal solutions or saddle points in the process of non-convex error function optimization. Adam has better performance, but the speed is slightly slower then t -> ∞ that will not have a good generalization performance. In order to solve the above problems, a new optimization strategy is proposed to compress the model. At the same time, AdaX, an optimizer with SGD speed and Adam performance, is used to optimize the model. Through the test on the open data set DUTS, ESSCD and etc., the proposed optimization model method reduces the parameters of the original model, and also improves the training speed and application detection speed of the model.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_6
DP  - Springer Link
SP  - 64
EP  - 74
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_6.pdf
KW  - Deep learning
KW  - Optimization strategy
KW  - Salient target detection
ER  - 

TY  - CONF
TI  - The Identification of Slope Crack Based on Convolutional Neural Network
AU  - Li, Yaoyao
AU  - Liu, Pengyu
AU  - Chen, Shanji
AU  - Jia, Kebin
AU  - Liu, Tianyu
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In the process of construction and operation of mountain roads, slope disasters such as landslide and collapse are often encountered, which seriously affect the transportation infrastructure and safe operation in China. Cracks are the early symptoms of most slope diseases. By monitoring the change trend of cracks, the displacement trajectory of the slope body can be reflected in time, which is of great significance for landslide monitoring and early warning, so the safety detection is concentrated in this stage. In recent years, great progress has been made in deep learning-based computer vision methods, which have the advantages of simple observation method, low cost, wide detection area and sustainable monitoring. In view of this, a pixel level segmentation method of slope cracks based on deep convolutional neural network is proposed in this paper. According to the shape characteristics of slope cracks, a deep convolutional neural network was designed. The network was trained on the self-made slope image data set, and the IOU on the validation set reached 75.26%, which realized the precise segmentation and recognition of cracks. Experimental results show that the model has a good ability to characterize the slope cracks, can accurately extract the slope cracks, and provides a reliable basis for the formulation of slope early warning and disaster relief programs.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_2
DP  - Springer Link
SP  - 16
EP  - 26
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_2.pdf
KW  - Convolutional neural networks
KW  - Crack
KW  - Slope hazards
ER  - 

TY  - CONF
TI  - On-Chain and Off-Chain Collaborative Management System Based on Consortium Blockchain
AU  - Wang, Kete
AU  - Yan, Yong
AU  - Guo, Shaoyong
AU  - Wei, Xin
AU  - Shao, Sujie
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The blockchain system can provide a trust infrastructure for sharing data among untrusted parties. However, storing the original shared data directly on the blockchain is not suitable for large-scale data sharing scenarios. Therefore, we designed a data sharing system architecture in which data hashing and response records are stored on the blockchain and the original data is stored in the off-chain database. This architecture can alleviate the system overload and protect privacy problems to a certain extent. This paper proposes a three-tier system structure to ensure the function of the network. Subsequently, formulate request rules, deploy smart contracts, and build a platform based on the alliance chain. Finally, the system functions and performance are analyzed and compared through experiments. The results show that the system can realize efficient and transparent information sharing while satisfying on-chain and off-chain collaborative management, and the system has certain advantages in function, overall performance and throughput performance.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_14
DP  - Springer Link
SP  - 172
EP  - 187
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_14.pdf
KW  - Collaborative management
KW  - Consortium blockchain
KW  - Data share
ER  - 

TY  - CONF
TI  - Control System Design of Transport Robot Based on Multi-color Recognition
AU  - Liu, Long-fei
AU  - Kang, Jie
AU  - Chen, Xiao-ying
AU  - Wang, Jing-jia
AU  - Ma, Xiao
AU  - Yang, Cheng-han
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - According to the rules and requirements of the handling project of the China Engineering Robot Contest, an intelligent handling robot with Freescale KL25 chip as the core controller and capable of automatically identifying multiple colors was designed. Based on the completion of the hardware circuit and mechanical structure, the robot’s trajectory on the field is planned through software programming. Establishing a handling strategy allows the robot to efficiently grasp, transport, and stack objects. The focus is on the infrared tracking module, the color recognition module software design and the robot path planning strategy research. After the completion of the robot construction, through experiments in various links, the total number of loops compared to the traditional handling scheme has increased by about 11.1%, and the running time has been reduced by about 41.5%. The effect is good.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_7
DP  - Springer Link
SP  - 75
EP  - 88
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_7.pdf
KW  - Handling robot
KW  - Modular design
KW  - Multi-color recognition
ER  - 

TY  - CONF
TI  - Patent Citation Network Analysis Based on Improved Main Path Analysis: Mapping Key Technology Trajectory
AU  - Lu, Zikui
AU  - Ma, Yue
AU  - Song, Luona
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Nowadays, more and more people realize the importance of patent for innovation activities. Patent citation network analysis is one of the most important methods for patent measurement, patent mining, and core patent identification. In nowadays, finding technology trajectories and analyzing major technologies in patent networks are intensively used in technological competition. Main path analysis (MPA) is a famous directed graph-based method to extract main paths in certain networks, such as a citation network. However, the accuracy of main path identification may be distracted due to a large volume of wrong references when using MPA in patent citation networks solely. To tackle this challenge and extract reasonable main paths from patent citation network, in this paper, we combined the classic MPA with the PageRank algorithm and we tested this new combined method on authorized patent datasets. The results show that the improved method achieved better performance in average cited frequency and other indicators of core patents comparing with traditional MPA.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_13
DP  - Springer Link
SP  - 158
EP  - 171
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
ST  - Patent Citation Network Analysis Based on Improved Main Path Analysis
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_13.pdf
KW  - Citation network
KW  - Main path analysis
KW  - PageRank
ER  - 

TY  - CONF
TI  - An Approach Based on Demand Prediction with LSTM for Solving Multi-batch 2D Cutting Stock Problems
AU  - Pang, Kaimin
AU  - Zhu, Bo
AU  - Zhang, Hongshuo
AU  - Liu, Ning
AU  - Xu, Miao
AU  - Zhang, Lianfu
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In order to improve the 2D cutting stock under the condition of small batch and multiple batches production, we propose to predict the parts demand of subsequent batches first, and then take advantage of the idea of centralized cutting to integrate the predicted parts demand of multiple batches into a larger scale problem to solve. As a supplement, the shortages of actual parts demand caused by prediction error are settled by compensating cutting as it occurred. A model is built for that and it uses the long short-term memory (LSTM) neural networks to predict parts demand, and solve the integrated cutting problem by the classical method of column generation combined with strip construction. To check the effectiveness of this model, an experiment is exerted on it with some simulated historical parts demand data generated by Monte-Carlo simulation method. The experiment results show that the model predicts the parts demands of subsequent batches accurately, and achieves higher overall material utilization rate than that of cutting for each batch without considering use of surplus materials and inventory-based cutting approach proposed by other researchers.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_1.pdf
KW  - Long short-term memory neural networks
KW  - Method of column generation combined with strips construction
KW  - Monte-Carlo simulation
KW  - Multiple batches cutting stock problem
KW  - Parts demand prediction
ER  - 

TY  - CONF
TI  - Experiments of Federated Learning for COVID-19 Chest X-ray Images
AU  - Yan, Bingjie
AU  - Wang, Jun
AU  - Cheng, Jieren
AU  - Zhou, Yize
AU  - Zhang, Yixian
AU  - Yang, Yifan
AU  - Liu, Li
AU  - Zhao, Haojiang
AU  - Wang, Chunjuan
AU  - Liu, Boyi
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - AI plays an important role in COVID-19 identification. Computer vision and deep learning techniques can assist in determining COVID-19 infection with Chest X-ray Images. However, for the protection and respect of the privacy of patients, the hospital’s specific medical-related data did not allow leakage and sharing without permission. Collecting such training data was a major challenge. To a certain extent, this has caused a lack of sufficient data samples when performing deep learning approaches to detect COVID-19. Federated Learning is an available way to address this issue. It can effectively address the issue of data silos and get a shared model without obtaining local data. In the work, we propose the use of federated learning for COVID-19 data training and deploy experiments to verify the effectiveness. And we also compare performances of four popular models (MobileNet_v2, ResNet18, ResNeXt, and COVID-Net) with the federated learning framework and without the framework. This work aims to inspire more researches on federated learning about COVID-19.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_4
DP  - Springer Link
SP  - 41
EP  - 53
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_4.pdf
KW  - Chest X-ray image
KW  - COVID-19
KW  - Federated learning
ER  - 

TY  - CONF
TI  - SACache: Size-Aware Load Balancing for Large-Scale Storage Systems
AU  - Su, Yihong
AU  - Jin, Hang
AU  - Liu, Fang
AU  - Li, Weijun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The fast cache could be used in storage clusters to alleviate load imbalance caused by highly-skewed requests between storage nodes. In a smaller cluster, we can use a single cache node to solve the I/O bottleneck caused by load imbalance. However, in a Large-scale cluster, we may need more than one cache node to afford enough capacity, which brings a new load balance problem in cache nodes. DistCache successfully solved this problem by applying the power-of-two-choices. In the above storage clusters, cache nodes cache the hottest objects while ignoring the size of objects, which leads to poor performance when meeting objects with variable sizes. We present SACache, a size-aware mechanism for large-scale storage clusters, which can improve I/O performance by maximizing the benefit of the unit cache. In this mechanism, we set an object admission filter to filter out objects with lower caching benefit. To adapt to changing request patterns, we record recently requested objects and their size, then replay those requests periodically in a cache simulator to find the best cache admission parameter using a greedy algorithm and apply it to the object admission filter. We apply this mechanism in a prototype distributed storage system. Experimental results show that it can increase the system’s overall bandwidth when the object’s size is different.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_8
DP  - Springer Link
SP  - 89
EP  - 105
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
ST  - SACache
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_8.pdf
KW  - Caching
KW  - Large-scale storage
KW  - Load balancing
KW  - Size-aware
ER  - 

TY  - CONF
TI  - A Novel Network Covert Channel Model Based on Blockchain Transaction Parity
AU  - Qin, Jiaohua
AU  - Luo, YuanJing
AU  - Xiang, Xuyu
AU  - Tan, Yun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - As information security is constantly challenged, it is very necessary to construct a practical and secure new model of information hiding. The existing cover channel models often has the risk of being easily disturbed and destroyed, and the different characteristics of shared resources are needs to be utilized to guarantee its concealment. Due to the security and reliability, decentralization, robustness and other characteristics, Blockchain has been applied to information hiding field (steganography), however, its concealment and practicality are difficult to meet the actual demand. In order to overcome the defects of the covert storage channel and blockchain-based information hiding scheme, we propose a novel network covert channel model based on Blockchain transaction addresses parity and formalize this network covert channel under the blockchain environment. By modulating the parity of the transaction address, the sender can transmit the secret message to the receiver through adding addresses when processing the business without occupying additional block chain space. Meanwhile, the relevant technologies of Blockchain (cryptography, P2P, etc.) ensure that the scheme has good tamper-resistant, multi-line communication and receiver anonymity, guarantying the concealment of communication and the security of information.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_5
DP  - Springer Link
SP  - 54
EP  - 63
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_5.pdf
KW  - Blockchain
KW  - Information hiding
KW  - Network covert channel
ER  - 

TY  - CONF
TI  - Heterogeneous-ISA Application Migration in Edge Computing: Challenges, Techniques and Open Issues
AU  - Jin, Hang
AU  - Su, Yihong
AU  - Liang, Fengzhou
AU  - Liu, Fang
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the development of mobile edge computing, more and more services are moved to the edge of the network, and devices there are usually with low computational abilities and little storage resources. To make it lightweight and elastic, containers can be adopted in the edge environment when migrating a certain application. With the host OS kernel shared, applications can be deployed with the least computational resources they need, making it possible to deploy more of them on relatively low-end devices. Migration is also used in scenarios like maintenance or load balance, etc. We noticed that in edge environment, devices and servers are usually built with heterogeneous Instruction Set Architectures (ISAs) processors. X86 processors are widely used in desktop PCs, laptops and servers while smart-phones are built with an ARM processor, which leads to a serious problem that a container cannot be migrated to a heterogeneous machine to continue running directly. In this paper, we firstly give an overview of heterogeneous-ISA migration, and its applications and techniques. Then we discuss the existing heterogeneous execution solution from the perspective of applicable scenarios, latency, power consumption, requirements for computational resources, etc. Next, a comparison study is given on each of the characteristics to depict the details and differences in existing works. At last, challenges and open research issues which are waiting for further studies on container migration are listed.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_9
DP  - Springer Link
SP  - 106
EP  - 118
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
ST  - Heterogeneous-ISA Application Migration in Edge Computing
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_9.pdf
KW  - Container
KW  - Edge computing
KW  - Heterogeneous migration
ER  - 

TY  - CONF
TI  - The Implementation of Aeronautical Information Exchange Model in SWIM
AU  - Ren, Bingjie
AU  - Jiang, Yuanchun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - System Wide Information Management (SWIM), as an advanced civil aeronautical information management method, aims to solve the problems of global civil aeronautical information systems such as difficulty in obtaining common data in a timely manner and high information exchange costs. SWIM was first proposed by Europe and the United States and was recognized and valued by the International Civil Aviation Organization. It is to ensure the correct information transmission at the correct time. In order for the consistent information in the “virtual information pool” to be efficiently, accurately and securely transmitted, the information and data in the SWIM environment need to be defined in detail and standardized, so the two sides of data interaction can maintain the consistency in syntax and semantics. The Aeronautical Information Exchange Model (AIXM) is a core standard model for data transmission and format conversion, which mainly involves information in the aeronautical intelligence field. It covers multiple thematic elements such as airspace, airports and air routes, and provides a standardized description for data conversion and transmission in this field. The article analyzes the model composition of AIXM in the SWIM information exchange model, the modeling process, and the key technologies involved in model establishment, and preliminary design and implementation of AIXM.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_15
DP  - Springer Link
SP  - 188
EP  - 199
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_15.pdf
KW  - AIXM
KW  - Information exchange model
KW  - SWIM
ER  - 

TY  - CONF
TI  - Multi-dimensional Fatigue Driving Detection Method Based on SVM Improved by the Kernel Function
AU  - Sun, Yilong
AU  - Cheng, Jieren
AU  - Chen, Minghan
AU  - Zeng, Manling
AU  - Fan, Zhiwei
AU  - Sun, Jingzheng
AU  - Liu, Jiang
AU  - Chen, Zhuoxian
AU  - Wang, Yixiu
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Driver fatigue is one of the leading causes of traffic accidents. At present, fatigue driving detection has disadvant ages such as low practical application effect and high equipment requirements. This paper proposes a multi-feature point non-invasive fatigue monitoring system based on a support vector machine with a hybrid kernel function. The system detects feature points through a gradient descent tree algorithm based on a cascaded regression and calculates the eye aspect ratio (EAR) and mouth aspect ratio (MAR). The heart rate is obtained through RGB image analysis combined with Euler’s video magnification algorithm. Classify facial features to get fatigued. This paper is based on the Logistic and Radial Basis Polynomial Kernel (RBPK) function to improve the support vector machine, which has better learning and generalization. Finally, this paper uses the Driver Drowsiness Detection Dataset and the author’s dataset to test. The classification accuracy rate for a single picture is 96.92%. In summary, the system proposed in this paper has a better recognition rate for fatigue driving detection.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_3
DP  - Springer Link
SP  - 27
EP  - 40
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_3.pdf
KW  - Driver fatigue
KW  - Fatigue detection
KW  - Support vector machine
ER  - 

TY  - CONF
TI  - CCTL: Cascade Classifier Text Localization Algorithm in Natural Scene Image
AU  - Qiao, Xueming
AU  - Yin, Mingli
AU  - Kong, Liang
AU  - Wang, Bin
AU  - Chang, Xiuli
AU  - Ma, Qi
AU  - Zhu, Dongjie
AU  - Cao, Ning
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Natural scene images often contain a lot of important texts, which carry the information we need, so it has important practical value to locate text information. This paper proposes a Cascade Classifier Text Localization (CCTL) algorithm. Firstly, a cascade classification algorithm based on Real AdaBoost is proposed to improve the accuracy of text localization. Secondly, a perceptual-based grouping algorithm is proposed to establish a perceptual organization framework. The use of adjacency and similar rules to group texts can improve the effect of text grouping. The proposed algorithm is verified and evaluated on the ICDAR dataset. At the same time, it is compared with other algorithms. The experimental results show that the proposed method has superiority in natural scene text detection.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_16
DP  - Springer Link
SP  - 200
EP  - 210
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
ST  - CCTL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_16.pdf
KW  - Cascade classifier
KW  - Perceptual organizational framework
KW  - Real AdaBoost
KW  - Scene text detection
ER  - 

TY  - CONF
TI  - Research on the Application of Big Data Analysis in University Library
AU  - Hu, Juan
AU  - Xu, Shunhang
AU  - Hu, Yuhui
AU  - Shi, Wenhao
AU  - Xiao, Yangfei
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Big data is built on the foundation of today’s horse racing technology. The rise and development of big data has become one of the most typical features of the industry’s Internetization in the new IT era. The data stored in the world has overflowed every database, and industry big data has become the focus of attention of all walks of life. Governments at all levels and all enterprises and institutions hope to dig out high-quality, high-value-added data from big data. Information, and use it to improve their profit and service model, and enhance their status in the public and industry. In the era of big data, for libraries that provide teaching and scientific research services to the teachers and students of the school, they can use efficient and fast information technology, such as big data analysis, to conduct in-depth analysis and analysis of various data in university libraries. Digging, effectively understanding the reading situation of the whole school, and analyzing their reading hobbies and reading habits, the library can effectively use this information to improve the types of books purchased by the library, which can more effectively increase resource utilization.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_17
DP  - Springer Link
SP  - 211
EP  - 223
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_17.pdf
KW  - Big data
KW  - Big data analysis
KW  - University library
ER  - 

TY  - CONF
TI  - The Interaction Between Probe and Cavity Field Assists Quantum Synchronization
AU  - Meng, Qing-Yu
AU  - Hu, Yong
AU  - Yang, Qing
AU  - Zhu, Qin-Sheng
AU  - Li, Xiao-Yu
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - As an important technology of the quantum detection, the quantum synchronization detection is always used in the detection or measurement of some quantum systems. A detection schemes are key to the study of quantum system. The quantum synchronization detection which is presented between the probe and the quantum system is always used in detection application. A probing model is established to describe the probing a qubit system in the cavity field and to reveal the effect of the environment (cavity) on the quantum synchronization occurrence as well as the interactions among environment, a qubit system and probing equipment. By adjusting the frequency of the probe, the in-phase and out-of-phase synchronization can be achieved. So the information of the probe can be used to obtain the quantum system. Simultaneously, the effect of $${\gamma }_{3}$$γ3which describes the interaction strength between the probe and environments for quantum synchronization is discussed under different the values of Ohmic dissipation index s. Finally, the machine learning method is applied to present an optimization for classification and regression of synchronization transition dependent on s and $${\gamma }_{3}$$γ3. This opens the way for studying the generalized form of quantum synchronization through machine learning algorithms (Artificial neural network) in the future.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_10
DP  - Springer Link
SP  - 119
EP  - 129
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_10.pdf
KW  - Machine learning
KW  - Ohmic index
KW  - Quantum synchronization
ER  - 

TY  - CONF
TI  - W-Louvain: A Group Detection Algorithm Based on Synthetic Vectors
AU  - Qiao, Xueming
AU  - Zhang, Xiangkun
AU  - Xu, Ming
AU  - Zhai, Mingyuan
AU  - Wu, Mingrui
AU  - Zhu, Dongjie
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Most of the hidden dangers of network system security are caused by group events. Group analysis and data mining for them are of great significance to ensure network security. Although the existing group detection algorithms have achieved a series of results, they can only be divided on one of the network structure and group attributes, but cannot combine them together, which has certain limitations. The comprehensive vector can be constructed by collecting and mining the group data which cause the hidden danger of security, which can analyze the hidden danger of security from the aspects of network structure and node attribute, so as to realize the guidance and control of group behavior. Therefore, in view of the above problems, this paper proposes a group detection algorithm based on synthesis vector, which can finally find a special group which is closely connected in structure and very similar in attribute. Firstly, the comprehensive similarity is calculated based on the fusion vector in the sharing layer of the comprehensive vector computing model. Then, reconstruct the weighted network diagram. Finally, based on Louvain algorithm, the improvement is carried out. The improved algorithm is referred to as the W-Louvain algorithm. The W-Louvain algorithm is used to divide the groups, and the closely connected vectors in the structure and the very similar vectors in the attributes are divided into the same group. Experiments show that on multiple datasets the evaluation indexes of W-Louvain algorithm, such as modularity Q, number k of community, density D of community and similarity degree S of comprehensive vector attribute, are better than the existing methods.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_11
DP  - Springer Link
SP  - 133
EP  - 144
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
ST  - W-Louvain
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_11.pdf
KW  - Comprehensive vector
KW  - Data mining
KW  - Group detection
KW  - Information security
ER  - 

TY  - CONF
TI  - Application of Non-negative Matrix Factorization in Fault Detection of Distribution Network
AU  - Wang, Shilin
AU  - Cui, Huiyuan
AU  - Han, Xueyu
AU  - Zhang, Nan
AU  - Liu, Zhu
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The application and promotion of smart distribution transformer terminal based on software definition has played a positive role in promoting the construction of distribution Internet of Things. This paper presents a new non-negative matrix factorization algorithm, generalized projection non-negative matrix factorization algorithm. Based on this algorithm, the statistical monitoring model is constructed, and the monitoring statistics suitable for the new monitoring model are designed. Then, the monitoring model is deployed in the form of a software APP to the smart distribution transformer terminal to realize the operation state monitoring and fault detection function of the distribution network. Finally, using the Simulink in MATLAB as the simulation plat-form to simulate the single-phase grounding fault of distribution network, the result shows that the fault monitoring model based on generalized projection non-negative matrix decomposition can better complete the detection task of single-phase grounding fault, and which detection effect is to meet the real-time requirements of fault detection in the field.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78618-2_12
DP  - Springer Link
SP  - 145
EP  - 157
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78618-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78618-2_12.pdf
KW  - Distribution network
KW  - Fault detection
KW  - Generalized projection non-negative matrix factorization
KW  - Single-phase to ground fault
KW  - Smart distribution transformer terminal
ER  - 

TY  - CONF
TI  - Where to Focus: Investigating Hierarchical Attention Relationship for Fine-Grained Visual Classification
AU  - Liu, Yang
AU  - Zhou, Lei
AU  - Zhang, Pengcheng
AU  - Bai, Xiao
AU  - Gu, Lin
AU  - Yu, Xiaohan
AU  - Zhou, Jun
AU  - Hancock, Edwin R.
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Object categories are often grouped into a multi-granularity taxonomic hierarchy. Classifying objects at coarser-grained hierarchy requires global and common characteristics, while finer-grained hierarchy classification relies on local and discriminative features. Therefore, humans should also subconsciously focus on different object regions when classifying different hierarchies. This granularity-wise attention is confirmed by our collected human real-time gaze data on different hierarchy classifications. To leverage this mechanism, we propose a Cross-Hierarchical Region Feature (CHRF) learning framework. Specifically, we first design a region feature mining module that imitates humans to learn different granularity-wise attention regions with multi-grained classification tasks. To explore how human attention shifts from one hierarchy to another, we further present a cross-hierarchical orthogonal fusion module to enhance the region feature representation by blending the original feature and an orthogonal component extracted from adjacent hierarchies. Experiments on five hierarchical fine-grained datasets demonstrate the effectiveness of CHRF compared with the state-of-the-art methods. Ablation study and visualization results also consistently verify the advantages of our human attention-oriented modules. The code and dataset are available at https://github.com/visiondom/CHRF.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_4
DP  - Springer Link
SP  - 57
EP  - 73
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
ST  - Where to Focus
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_4.pdf
KW  - Fine-grained visual classification
KW  - Human attention
KW  - Multi-granularity
KW  - Orthogonal fusion
ER  - 

TY  - CONF
TI  - Dynamic Metric Learning with Cross-Level Concept Distillation
AU  - Zheng, Wenzhao
AU  - Huang, Yuanhui
AU  - Zhang, Borui
AU  - Zhou, Jie
AU  - Lu, Jiwen
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - A good similarity metric should be consistent with the human perception of similarities: a sparrow is more similar to an owl if compared to a dog but is more similar to a dog if compared to a car. It depends on the semantic levels to determine if two images are from the same class. As most existing metric learning methods push away interclass samples and pull closer intraclass samples, it seems contradictory if the labels cross semantic levels. The core problem is that a negative pair on a finer semantic level can be a positive pair on a coarser semantic level, so pushing away this pair damages the class structure on the coarser semantic level. We identify the negative repulsion as the key obstacle in existing methods since a positive pair is always positive for coarser semantic levels but not for negative pairs. Our solution, cross-level concept distillation (CLCD), is simple in concept: we only pull closer positive pairs. To facilitate the cross-level semantic structure of the image representations, we propose a hierarchical concept refiner to construct multiple levels of concept embeddings of an image and then pull closer the distance of the corresponding concepts. Extensive experiments demonstrate that the proposed CLCD method outperforms all other competing methods on the hierarchically labeled datasets. Code is available at: https://github.com/wzzheng/CLCD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_12
DP  - Springer Link
SP  - 197
EP  - 213
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_12.pdf
ER  - 

TY  - CONF
TI  - Learning to Detect Every Thing in an Open World
AU  - Saito, Kuniaki
AU  - Hu, Ping
AU  - Darrell, Trevor
AU  - Saenko, Kate
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Many open-world applications require the detection of novel objects, yet state-of-the-art object detection and instance segmentation networks do not excel at this task. The key issue lies in their assumption that regions without any annotations should be suppressed as negatives, which teaches the model to treat any unannotated (hidden) objects as background. To address this issue, we propose a simple yet surprisingly powerful data augmentation and training scheme we call Learning to Detect Every Thing (LDET). To avoid suppressing hidden objects, we develop a new data augmentation method, BackErase, which pastes annotated objects on a background image sampled from a small region of the original image. Since training solely on such synthetically-augmented images suffers from domain shift, we propose a multi-domain training strategy that allows the model to generalize to real images. LDET leads to significant improvements on many datasets in the open-world instance segmentation task, outperforming baselines on cross-category generalization on COCO, as well as cross-dataset evaluation on UVO, Objects365, and Cityscapes. https://ksaito-ut.github.io/openworld_ldet/.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_16
DP  - Springer Link
SP  - 268
EP  - 284
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_16.pdf
KW  - Open world instance segmentation
ER  - 

TY  - CONF
TI  - Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay
AU  - Liu, Huan
AU  - Gu, Li
AU  - Chi, Zhixiang
AU  - Wang, Yang
AU  - Yu, Yuanhao
AU  - Chen, Jun
AU  - Tang, Jin
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Few-shot class-incremental learning (FSCIL) has been proposed aiming to enable a deep learning system to incrementally learn new classes with limited data. Recently, a pioneer claims that the commonly used replay-based method in class-incremental learning (CIL) is ineffective and thus not preferred for FSCIL. This has, if truth, a significant influence on the fields of FSCIL. In this paper, we show through empirical results that adopting the data replay is surprisingly favorable. However, storing and replaying old data can lead to a privacy concern. To address this issue, we alternatively propose using data-free replay that can synthesize data by a generator without accessing real data. In observing the effectiveness of uncertain data for knowledge distillation, we impose entropy regularization in the generator training to encourage more uncertain examples. Moreover, we propose to relabel the generated data with one-hot-like labels. This modification allows the network to learn by solely minimizing the cross-entropy loss, which mitigates the problem of balancing different objectives in the conventional knowledge distillation approach. Finally, we show extensive experimental results and analysis on CIFAR-100, miniImageNet and CUB-200 to demonstrate the effectiveness of our proposed one.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_9
DP  - Springer Link
SP  - 146
EP  - 162
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_9.pdf
ER  - 

TY  - CONF
TI  - Anti-retroactive Interference for Lifelong Learning
AU  - Wang, Runqi
AU  - Bao, Yuxiang
AU  - Zhang, Baochang
AU  - Liu, Jianzhuang
AU  - Zhu, Wentao
AU  - Guo, Guodong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Humans can continuously learn new knowledge. However, machine learning models suffer from drastic dropping in performance on previous tasks after learning new tasks. Cognitive science points out that the competition of similar knowledge is an important cause of forgetting. In this paper, we design a paradigm for lifelong learning based on meta-learning and associative mechanism of the brain. It tackles the problem from two aspects: extracting knowledge and memorizing knowledge. First, we disrupt the sample’s background distribution through a background attack, which strengthens the model to extract the key features of each task. Second, according to the similarity between incremental knowledge and base knowledge, we design an adaptive fusion of incremental knowledge, which helps the model allocate capacity to the knowledge of different difficulties. It is theoretically analyzed that the proposed learning paradigm can make the models of different tasks converge to the same optimum. The proposed method is validated on the MNIST, CIFAR100, CUB200 and ImageNet100 datasets. The code is available at https://github.com/bhrqw/ARI.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_10
DP  - Springer Link
SP  - 163
EP  - 178
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_10.pdf
KW  - Associative learning
KW  - Background attack
KW  - Lifelong learning
KW  - Meta learning
ER  - 

TY  - CONF
TI  - Learning Hierarchy Aware Features for Reducing Mistake Severity
AU  - Garg, Ashima
AU  - Sani, Depanshu
AU  - Anand, Saket
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Label hierarchies are often available apriori as part of biological taxonomy or language datasets WordNet. Several works exploit these to learn hierarchy aware features in order to improve the classifier to make semantically meaningful mistakes while maintaining or reducing the overall error. In this paper, we propose a novel approach for learning Hierarchy Aware Features (HAF) that leverages classifiers at each level of the hierarchy that are constrained to generate predictions consistent with the label hierarchy. The classifiers are trained by minimizing a Jensen-Shannon Divergence with target soft labels obtained from the fine-grained classifiers. Additionally, we employ a simple geometric loss that constrains the feature space geometry to capture the semantic structure of the label space. HAF is a training time approach that improves the mistakes while maintaining top-1 error, thereby, addressing the problem of cross-entropy loss that treats all mistakes as equal. We evaluate HAF on three hierarchical datasets and achieve state-of-the-art results on the iNaturalist-19 and CIFAR-100 datasets. The source code is available at https://github.com/07Agarg/HAF.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_15
DP  - Springer Link
SP  - 252
EP  - 267
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_15.pdf
ER  - 

TY  - CONF
TI  - KVT: k-NN Attention for Boosting Vision Transformers
AU  - Wang, Pichao
AU  - Wang, Xue
AU  - Wang, Fan
AU  - Lin, Ming
AU  - Chang, Shuning
AU  - Li, Hao
AU  - Jin, Rong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Convolutional Neural Networks (CNNs) have dominated computer vision for years, due to its ability in capturing locality and translation invariance. Recently, many vision transformer architectures have been proposed and they show promising performance. A key component in vision transformers is the fully-connected self-attention which is more powerful than CNNs in modelling long range dependencies. However, since the current dense self-attention uses all image patches (tokens) to compute attention matrix, it may neglect locality of images patches and involve noisy tokens (e.g., clutter background and occlusion), leading to a slow training process and potential degradation of performance. To address these problems, we propose the k-NN attention for boosting vision transformers. Specifically, instead of involving all the tokens for attention matrix calculation, we only select the top-k similar tokens from the keys for each query to compute the attention map. The proposed k-NN attention naturally inherits the local bias of CNNs without introducing convolutional operations, as nearby tokens tend to be more similar than others. In addition, the k-NN attention allows for the exploration of long range correlation and at the same time filters out irrelevant tokens by choosing the most similar tokens from the entire image. Despite its simplicity, we verify, both theoretically and empirically, that k-NN attention is powerful in speeding up training and distilling noise from input tokens. Extensive experiments are conducted by using 11 different vision transformer architectures to verify that the proposed k-NN attention can work with any existing transformer architectures to improve its prediction performance. The codes are available at https://github.com/damo-cv/KVT.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_17
DP  - Springer Link
SP  - 285
EP  - 302
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
ST  - KVT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_17.pdf
ER  - 

TY  - CONF
TI  - Out-of-distribution Detection with Boundary Aware Learning
AU  - Pei, Sen
AU  - Zhang, Xin
AU  - Fan, Bin
AU  - Meng, Gaofeng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - There is an increasing need to determine whether inputs are out-of-distribution (OOD) for safely deploying machine learning models in the open world scenario. Typical neural classifiers are based on the closed world assumption, where the training data and the test data are drawn i.i.d. from the same distribution, and as a result, give over-confident predictions even faced with OOD inputs. For tackling this problem, previous studies either use real outliers for training or generate synthetic OOD data under strong assumptions, which are either costly or intractable to generalize. In this paper, we propose boundary aware learning (BAL), a novel framework that can learn the distribution of OOD features adaptively. The key idea of BAL is to generate OOD features from trivial to hard progressively with a generator, meanwhile, a discriminator is trained for distinguishing these synthetic OOD features and in-distribution (ID) features. Benefiting from the adversarial training scheme, the discriminator can well separate ID and OOD features, allowing more robust OOD detection. The proposed BAL achieves state-of-the-art performance on classification benchmarks, reducing up to 13.9% FPR95 compared with previous methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_14
DP  - Springer Link
SP  - 235
EP  - 251
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_14.pdf
KW  - Boundary aware learning
KW  - GAN
KW  - OOD detection
ER  - 

TY  - CONF
TI  - Towards Calibrated Hyper-Sphere Representation via Distribution Overlap Coefficient for Long-Tailed Learning
AU  - Wang, Hualiang
AU  - Fu, Siming
AU  - He, Xiaoxuan
AU  - Fang, Hangxiang
AU  - Liu, Zuozhu
AU  - Hu, Haoji
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Long-tailed learning aims to tackle the crucial challenge that head classes dominate the training procedure under severe class imbalance in real-world scenarios. However, little attention has been given to how to quantify the dominance severity of head classes in the representation space. Motivated by this, we generalize the cosine-based classifiers to a von Mises-Fisher (vMF) mixture model, denoted as vMF classifier, which enables to quantitatively measure representation quality upon the hyper-sphere space via calculating distribution overlap coefficient. To our knowledge, this is the first work to measure representation quality of classifiers and features from the perspective of distribution overlap coefficient. On top of it, we formulate the inter-class discrepancy and class-feature consistency loss terms to alleviate the interference among the classifier weights and align features with classifier weights. Furthermore, a novel post-training calibration algorithm is devised to zero-costly boost the performance via inter-class overlap coefficients. Our method outperforms previous work with a large margin and achieves state-of-the-art performance on long-tailed image classification, semantic segmentation, and instance segmentation tasks (e.g., we achieve 55.0% overall accuracy with ResNetXt-50 in ImageNet-LT). Our code is available at https://github.com/VipaiLab/vMF_OP.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_11
DP  - Springer Link
SP  - 179
EP  - 196
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_11.pdf
KW  - Distribution overlap coefficient
KW  - Long-tailed learning
KW  - Representation learning
KW  - von Mises-Fisher Distribution
ER  - 

TY  - CONF
TI  - Improving Robustness by Enhancing Weak Subnets
AU  - Guo, Yong
AU  - Stutz, David
AU  - Schiele, Bernt
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Despite their success, deep networks have been shown to be highly susceptible to perturbations, often causing significant drops in accuracy. In this paper, we investigate model robustness on perturbed inputs by studying the performance of internal sub-networks (subnets). Interestingly, we observe that most subnets show particularly poor robustness against perturbations. More importantly, these weak subnets are correlated with the overall lack of robustness. Tackling this phenomenon, we propose a new training procedure that identifies and enhances weak subnets (EWS) to improve robustness. Specifically, we develop a search algorithm to find particularly weak subnets and explicitly strengthen them via knowledge distillation from the full network. We show that EWS greatly improves both robustness against corrupted images as well as accuracy on clean data. Being complementary to popular data augmentation methods, EWS consistently improves robustness when combined with these approaches. To highlight the flexibility of our approach, we combine EWS also with popular adversarial training methods resulting in improved adversarial robustness.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_19
DP  - Springer Link
SP  - 320
EP  - 338
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_19.pdf
KW  - Model robustness
KW  - Sub-networks
KW  - Training method
ER  - 

TY  - CONF
TI  - Optimal Transport for Label-Efficient Visible-Infrared Person Re-Identification
AU  - Wang, Jiangming
AU  - Zhang, Zhizhong
AU  - Chen, Mingang
AU  - Zhang, Yi
AU  - Wang, Cong
AU  - Sheng, Bin
AU  - Qu, Yanyun
AU  - Xie, Yuan
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Visible-infrared person re-identification (VI-ReID) has been a key enabler for night intelligent monitoring system. However, the extensive laboring efforts significantly limit its applications. In this paper, we raise a new label-efficient training pipeline for VI-ReID. Our observation is: RGB ReID datasets have rich annotation information and annotating infrared images is expensive due to the lack of color information. In our approach, it includes two key steps: 1) We utilize the standard unsupervised domain adaptation technique to generate the pseudo labels for visible subset with the help of well-annotated RGB datasets; 2) We propose an optimal-transport strategy trying to assign pseudo labels from visible to infrared modality. In our framework, each infrared sample owns a label assignment choice, and each pseudo label requires unallocated images. By introducing uniform sample-wise and label-wise prior, we achieve a desirable assignment plan that allows us to find matched visible and infrared samples, and thereby facilitates cross-modality learning. Besides, a prediction alignment loss is designed to eliminate the negative effects brought by the incorrect pseudo labels. Extensive experimental results on benchmarks demonstrate the effectiveness of our approach. Code will be released at https://github.com/wjm-wjm/OTLA-ReID.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_6
DP  - Springer Link
SP  - 93
EP  - 109
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_6.pdf
KW  - Label-efficient learning
KW  - Optimal-transport
KW  - VI-ReID
ER  - 

TY  - CONF
TI  - DaViT: Dual Attention Vision Transformers
AU  - Ding, Mingyu
AU  - Xiao, Bin
AU  - Codella, Noel
AU  - Luo, Ping
AU  - Wang, Jingdong
AU  - Yuan, Lu
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - In this work, we introduce Dual Attention Vision Transformers  (DaViT), a simple yet effective vision transformer architecture that is able to capture global context while maintaining computational efficiency. We propose approaching the problem from an orthogonal angle: exploiting self-attention mechanisms with both “spatial tokens” and “channel tokens”. With spatial tokens, the spatial dimension defines the token scope, and the channel dimension defines the token feature dimension. With channel tokens, we have the inverse: the channel dimension defines the token scope, and the spatial dimension defines the token feature dimension. We further group tokens along the sequence direction for both spatial and channel tokens to maintain the linear complexity of the entire model. We show that these two self-attentions complement each other: (i) since each channel token contains an abstract representation of the entire image, the channel attention naturally captures global interactions and representations by taking all spatial positions into account when computing attention scores between channels; (ii) the spatial attention refines the local representations by performing fine-grained interactions across spatial locations, which in turn helps the global information modeling in channel attention. Extensive experiments show DaViT backbones achieve state-of-the-art performance on four different tasks. Specially, DaViT-Tiny, DaViT-Small, and DaViT-Base achieve 82.8%, 84.2%, and 84.6% top-1 accuracy on ImageNet-1K without extra training data, using 28.3M, 49.7M, and 87.9M parameters, respectively. When we further scale up DaViT with 1.5B weakly supervised image and text pairs, DaViT-Giant reaches 90.4% top-1 accuracy on ImageNet-1K. Code is available at https://github.com/microsoft/DaViT.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_5
DP  - Springer Link
SP  - 74
EP  - 92
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
ST  - DaViT
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_5.pdf
ER  - 

TY  - CONF
TI  - Neural Architecture Search for Spiking Neural Networks
AU  - Kim, Youngeun
AU  - Li, Yuhang
AU  - Park, Hyoungseob
AU  - Venkatesha, Yeshwanth
AU  - Panda, Priyadarshini
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Spiking Neural Networks (SNNs) have gained huge attention as a potential energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their inherent high-sparsity activation. However, most prior SNN methods use ANN-like architectures (e.g., VGG-Net or ResNet), which could provide sub-optimal performance for temporal sequence processing of binary information in SNNs. To address this, in this paper, we introduce a novel Neural Architecture Search (NAS) approach for finding better SNN architectures. Inspired by recent NAS approaches that find the optimal architecture from activation patterns at initialization, we select the architecture that can represent diverse spike activation patterns across different data samples without training. Moreover, to further leverage the temporal information among the spikes, we search for feed-forward connections as well as backward connections (i.e., temporal feedback connections) between layers. Interestingly, SNASNet found by our search algorithm achieves higher performance with backward connections, demonstrating the importance of designing SNN architecture for suitably using temporal information. We conduct extensive experiments on three image recognition benchmarks where we show that SNASNet achieves state-of-the-art performance with significantly lower timesteps (5 timesteps). Code is available on Github.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_3
DP  - Springer Link
SP  - 36
EP  - 56
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_3.pdf
KW  - Neural architecture search
KW  - Neuromorphic computing
KW  - Spiking Neural Networks
ER  - 

TY  - CONF
TI  - MENet: A Memory-Based Network with Dual-Branch for Efficient Event Stream Processing
AU  - Sun, Linhui
AU  - Zhang, Yifan
AU  - Cheng, Ke
AU  - Cheng, Jian
AU  - Lu, Hanqing
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Event cameras are bio-inspired sensors that asynchronously capture per-pixel brightness change and trigger a stream of events instead of frame-based images. Each event stream is generally split into multiple sliding windows for subsequent processing. However, most existing event-based methods ignore the motion continuity between adjacent spatiotemporal windows, which will result in the loss of dynamic information and additional computational costs. To efficiently extract strong features for event streams containing dynamic information, this paper proposes a novel memory-based network with dual-branch, namely MENet. It contains a base branch with a full-sized event point-wise processing structure to extract the base features and an incremental branch equipped with a light-weighted network to capture the temporal dynamics between two adjacent spatiotemporal windows. For enhancing the features, especially in the incremental branch, a point-wise memory bank is designed, which sketches the representative information of event feature space. Compared with the base branch, the incremental branch reduces the computational complexity up to 5 times and improves the speed by 19 times. Experiments show that MENet significantly reduces the computational complexity compared with previous methods while achieving state-of-the-art performance on gesture recognition and object recognition.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_13
DP  - Springer Link
SP  - 214
EP  - 234
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
ST  - MENet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_13.pdf
KW  - Dual-branch structure
KW  - Event-based model
KW  - Memory bank
ER  - 

TY  - CONF
TI  - Locality Guidance for Improving Vision Transformers on Tiny Datasets
AU  - Li, Kehan
AU  - Yu, Runyi
AU  - Wang, Zhennan
AU  - Yuan, Li
AU  - Song, Guoli
AU  - Chen, Jie
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - While the Vision Transformer (VT) architecture is becoming trendy in computer vision, pure VT models perform poorly on tiny datasets. To address this issue, this paper proposes the locality guidance for improving the performance of VTs on tiny datasets. We first analyze that the local information, which is of great importance for understanding images, is hard to be learned with limited data due to the high flexibility and intrinsic globality of the self-attention mechanism in VTs. To facilitate local information, we realize the locality guidance for VTs by imitating the features of an already trained convolutional neural network (CNN), inspired by the built-in local-to-global hierarchy of CNN. Under our dual-task learning paradigm, the locality guidance provided by a lightweight CNN trained on low-resolution images is adequate to accelerate the convergence and improve the performance of VTs to a large extent. Therefore, our locality guidance approach is very simple and efficient, and can serve as a basic performance enhancement method for VTs on tiny datasets. Extensive experiments demonstrate that our method can significantly improve VTs when training from scratch on tiny datasets and is compatible with different kinds of VTs and datasets. For example, our proposed method can boost the performance of various VTs on tiny datasets (e.g., 13.07% for DeiT, 8.98% for T2T and 7.85% for PVT), and enhance even stronger baseline PVTv2 by 1.86% to 79.30%, showing the potential of VTs on tiny datasets. The code is available at https://github.com/lkhl/tiny-transformers.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_7
DP  - Springer Link
SP  - 110
EP  - 127
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_7.pdf
ER  - 

TY  - CONF
TI  - Registration Based Few-Shot Anomaly Detection
AU  - Huang, Chaoqin
AU  - Guan, Haoyan
AU  - Jiang, Aofan
AU  - Zhang, Ya
AU  - Spratling, Michael
AU  - Wang, Yan-Feng
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - This paper considers few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection (AD), where only a limited number of normal images are provided for each category at training. So far, existing FSAD studies follow the one-model-per-category learning paradigm used for standard AD, and the inter-category commonality has not been explored. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we here leverage registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. As far as we know, this is the first FSAD method that trains a single generalizable model and requires no re-training or parameter fine-tuning for new categories. Experimental results have shown that the proposed method outperforms the state-of-the-art FSAD methods by 3%–8% in AUC on the MVTec and MPDD benchmarks. Source code is available at: https://github.com/MediaBrain-SJTU/RegAD.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_18
DP  - Springer Link
SP  - 303
EP  - 319
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_18.pdf
KW  - Anomaly detection
KW  - Few-shot learning
KW  - Registration
ER  - 

TY  - CONF
TI  - Neighborhood Collective Estimation for Noisy Label Identification and Correction
AU  - Li, Jichang
AU  - Li, Guanbin
AU  - Liu, Feng
AU  - Yu, Yizhou
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Learning with noisy labels (LNL) aims at designing strategies to improve model performance and generalization by mitigating the effects of model overfitting to noisy labels. The key success of LNL lies in identifying as many clean samples as possible from massive noisy data, while rectifying the wrongly assigned noisy labels. Recent advances employ the predicted label distributions of individual samples to perform noise verification and noisy label correction, easily giving rise to confirmation bias. To mitigate this issue, we propose Neighborhood Collective Estimation, in which the predictive reliability of a candidate sample is re-estimated by contrasting it against its feature-space nearest neighbors. Specifically, our method is divided into two steps: 1) Neighborhood Collective Noise Verification to separate all training samples into a clean or noisy subset, 2) Neighborhood Collective Label Correction to relabel noisy samples, and then auxiliary techniques are used to assist further model optimization. Extensive experiments on four commonly used benchmark datasets, i.e., CIFAR-10, CIFAR-100, Clothing-1M and Webvision-1.0, demonstrate that our proposed method considerably outperforms state-of-the-art methods.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_8
DP  - Springer Link
SP  - 128
EP  - 145
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_8.pdf
KW  - Confirmation bias
KW  - Learning with noisy labels
KW  - Neighborhood collective estimation
ER  - 

TY  - CONF
TI  - Improving Vision Transformers by Revisiting High-Frequency Components
AU  - Bai, Jiawang
AU  - Yuan, Li
AU  - Xia, Shu-Tao
AU  - Yan, Shuicheng
AU  - Li, Zhifeng
AU  - Liu, Wei
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - The transformer models have shown promising effectiveness in dealing with various vision tasks. However, compared with training Convolutional Neural Network (CNN) models, training Vision Transformer (ViT) models is more difficult and relies on the large-scale training set. To explain this observation we make a hypothesis that ViT models are less effective in capturing the high-frequency components of images than CNN models, and verify it by a frequency analysis. Inspired by this finding, we first investigate the effects of existing techniques for improving ViT models from a new frequency perspective, and find that the success of some techniques (e.g., RandAugment) can be attributed to the better usage of the high-frequency components. Then, to compensate for this insufficient ability of ViT models, we propose HAT, which directly augments high-frequency components of images via adversarial training. We show that HAT can consistently boost the performance of various ViT models (e.g., +1.2% for ViT-B, +0.5% for Swin-B), and especially enhance the advanced model VOLO-D5 to 87.3% that only uses ImageNet-1K data, and the superiority can also be maintained on out-of-distribution data and transferred to downstream tasks. The code is available at: https://github.com/jiawangbai/HAT.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_1
DP  - Springer Link
SP  - 1
EP  - 18
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_1.pdf
ER  - 

TY  - CONF
TI  - Recurrent Bilinear Optimization for Binary Neural Networks
AU  - Xu, Sheng
AU  - Li, Yanjing
AU  - Wang, Tiancheng
AU  - Ma, Teli
AU  - Zhang, Baochang
AU  - Gao, Peng
AU  - Qiao, Yu
AU  - Lü, Jinhu
AU  - Guo, Guodong
A2  - Avidan, Shai
A2  - Brostow, Gabriel
A2  - Cissé, Moustapha
A2  - Farinella, Giovanni Maria
A2  - Hassner, Tal
T3  - Lecture Notes in Computer Science
AB  - Binary Neural Networks (BNNs) show great promise for real-world embedded devices. As one of the critical steps to achieve a powerful BNN, the scale factor calculation plays an essential role in reducing the performance gap to their real-valued counterparts. However, existing BNNs neglect the intrinsic bilinear relationship of real-valued weights and scale factors, resulting in a sub-optimal model caused by an insufficient training process. To address this issue,  Recurrent Bilinear Optimization  is proposed to improve the learning process of  BNNs  (RBONNs) by associating the intrinsic bilinear variables in the back propagation process. Our work is the first attempt to optimize BNNs from the bilinear perspective. Specifically, we employ a recurrent optimization and Density-ReLU to sequentially backtrack the sparse real-valued weight filters, which will be sufficiently trained and reach their performance limits based on a controllable learning process. We obtain robust RBONNs, which show impressive performance over state-of-the-art BNNs on various models and datasets. Particularly, on the task of object detection, RBONNs have great generalization performance. Our code is open-sourced on https://github.com/SteveTsui/RBONN.
C1  - Cham
C3  - Computer Vision – ECCV 2022
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20053-3_2
DP  - Springer Link
SP  - 19
EP  - 35
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-20053-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-20053-3_2.pdf
KW  - Bilinear optimization
KW  - Binary neural network
KW  - Image classification
KW  - Object detection
ER  - 

TY  - CONF
TI  - File System for Digital Signal Processing Equipment Based on FPGA
AU  - Chen, Dong-cheng
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - A file system for digital signal processing equipment based on FPGA is designed. The ZYNQ-7000 FPGA is the processing center of the file system. An NVMe hard disk is connected to the GTx bank of FPGA as a PCIe device. FPGA and DSP chips interconnect through SRIO switch chip. Data which needs to be memorized comes from DSP through X4 SRIO interface. In FPGA, PL side receives command and data from DSP. PL buffers data to be memorized in different double port RAMs according to the command.PS reads data from buffer rams according to command data reading from command buffer rams and writes data to a responding subarea. Experiments show the designed file system memorizes data from DSP in real time. When data packet is 128 KB, writing data rate can be 550 MB/s.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_11
DP  - Springer Link
SP  - 119
EP  - 124
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - DSP
KW  - NVMe hard disk
KW  - SRIO
KW  - ZYNQ-7000
ER  - 

TY  - CONF
TI  - Combining Image Caption and Aesthetic Description Using Siamese Network
AU  - Song, Xinghui
AU  - Zhu, Peipei
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - In recent decades, the confluence of CV and NLP technologies has grown in popularity. Many researchers have focused their attention on Image caption task. In recent years, academics have been more interested in image aesthetic description because of image aesthetic indicative of the level. In this study, we present an aesthetic description technique that combines image description and aesthetic description at the same time. We use a Siamese network to acquire datasets for training from two data domains: Image caption task and Image aesthetic description task. The parameters gained from training were migrated back to the conventional Encoder-Decoder model for testing after training. On image caption task, we chose the flickr8k datasets to reduce computing cost. On aesthetic task, the PCCD datasets was used. The final findings indicate that our technique is capable of simultaneously training datasets from two data domains and producing both kinds of image descriptions.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_4
DP  - Springer Link
SP  - 41
EP  - 51
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Aesthetic description
KW  - Image caption
KW  - Image quality evaluation
KW  - Siamese network
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - Architecture of Integrated Resource System Based on Dataspace
AU  - Yan, Hui
AU  - Chen, Bo
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - At present, there are some urgent problems in the process of data element circulation, which hinder the marketization process of data elements and block the circulation channel of data elements. It includes the difficulty of transforming original data into data resources, the difficulty of defining data ownership, the difficulty of standard governance of data assets, the difficulty of data element circulation pricing, and the difficulty of data application security and mutual trust. The emergence of these problems has brought great challenges to enterprises in large-scale distributed data governance and data mining. The architecture of this study loads the data space component of closed-loop management of data value circulation, and provides SaaS-level services, which users can subscribe to directly without considering the underlying resource deployment, network configuration and business system development and deployment. In addition, cloud, network, data are separated from each other, enterprises need to deploy these resources separately when perform business-oriented data services. That means to build a set of exclusive infrastructure services, involving cloud services, network services, privacy security services, etc. Such a format is cumbersome for enterprises, not only requires a lot of construction funds and also cause a lot of manpower and time costs. This study provides a custom PaaS-level service, the business system loaded on this architecture does not need to consider the underlying resource deployment and network configuration.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_7
DP  - Springer Link
SP  - 74
EP  - 85
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Data flow
KW  - Dataspace
KW  - Resource allocation
KW  - Resource scheduling
KW  - Secure and trusted
ER  - 

TY  - CONF
TI  - An Improved Path Planning Algorithm Based on A* Algorithm
AU  - Li, Dongdong
AU  - Shi, Xiaohou
AU  - Dai, Meiling
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Path planning is a crucial aspect of vehicle navigation, and this paper presents an enhancement to the classic A* algorithm to address key challenges in this domain. The proposed method aims to improve both the efficiency and safety of path planning. In practical applications, path planning encounters various issues, such as an excessive number of unnecessary nodes during the search process, resulting in suboptimal planning efficiency. Additionally, obstacles may be present along the route between the starting point and the target node, requiring obstacle path search. Moreover, traditional cost functions often fail to fully account for vehicle safety, thereby increasing the risk of collisions. To overcome these challenges, the proposed method incorporates two key enhancements. Firstly, it employs a node marking technique on the grid map to identify key nodes and reduce the search process for unnecessary nodes, thus enhancing planning efficiency. Secondly, an incremental expansion of search nodes is utilized, employing an improved A* algorithm with a modified cost function. This enables the algorithm to plan collision-free paths from the starting point to the key nodes while considering the distance cost associated with potential collisions, thereby enhancing vehicle safety. Experimental results demonstrate that the proposed method significantly enhances path planning efficiency by reducing the search efforts for unnecessary nodes, resulting in accelerated path planning. Furthermore, the improved cost function enables the generation of safe and feasible paths, thereby enhancing vehicle safety.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_19
DP  - Springer Link
SP  - 187
EP  - 196
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - A* algorithm
KW  - Path planning
KW  - Vehicle navigation
ER  - 

TY  - CONF
TI  - Design of Self-serve DUI Detection System Based on STM32
AU  - Wu, Yang
AU  - Zhao, Linxiang
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Drink driving accounts for a very large proportion of accidents arising from vehicle driving, which seriously threatens people’s life safety This question designs a DUI detection system based on STM32F103C6 microcontroller. Combine IOT technology with machine vision technology to contribute to social security. The MQ-3 alcohol concentration sensor is used to detect the concentration level of the driver’s breath alcohol content, OpenMV is used to detect the closing of the driver’s eyes, and the information is summarized by the STM32 microcontroller and a warning reminder is issued by voice to reduce DUI and reduce the risk of accidents.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_14
DP  - Springer Link
SP  - 146
EP  - 152
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - DUI
KW  - Fatigue detection
KW  - OpenMV
KW  - STM32
ER  - 

TY  - CONF
TI  - Controller Architecture and Performance Optimization for Intensive Deployment Scenarios
AU  - Zhu, Chuanming
AU  - Chen, Huiguang
AU  - Li, Jingwen
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - As the scale and complexity of the network increase, SDN controller in the intensive deployment scenario has problems in architecture and performance. Combined with the controller collection and control framework, the acquisition and control separation mode is designed by isolating the underlying protocols, and data collection and configuration delivery operations are performed on NE devices to improve the controller collection and control performance. Ensure that service delivery does not affect operation and maintenance; The controller acquisition and control architecture is optimized to ensure a balanced distribution of tasks within the framework and improve controller performance. Through key capability research and development, framework optimization and performance improvement, SDN controller technology is gradually mature, enabling intelligent operation of cloud network.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_17
DP  - Springer Link
SP  - 170
EP  - 175
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Architecture optimization
KW  - Intensive deployment
KW  - SDN controller
KW  - SDN/NFV
ER  - 

TY  - CONF
TI  - Task Allocation Method of Blockchain-Based Multi-robot System
AU  - Bao, Fengbo
AU  - Peng, Jiansheng
AU  - Guo, Jingsong
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - With the continuous development of multi-robot systems, the main problems are task assignment and multi-robot task planning. This paper will combine blockchain technology with the design of multi-robot system task allocation architecture, and make use of the nature of blockchain information sharing to carry out multi-robot system task allocation. Firstly, the main problems faced by multi-robot systems in recent years are introduced. The application of blockchain technology should not be able to solve the problem of multi-robot task allocation, but also can solve the problem of multi-robot system node intrusion. Then describe the concept of dividing tasks and how individual blocks in a blockchain store information. Finally, the architecture of blockchain multi-robot system is designed, and the assumptions of application scenarios are made.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_8
DP  - Springer Link
SP  - 86
EP  - 92
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Blockchain
KW  - Multi-robot system
KW  - System architecture
KW  - Task allocation
ER  - 

TY  - CONF
TI  - A Review of the Research on Temperature and Humidity Control Systems in Silkworm Rooms
AU  - Chen, Yuanji
AU  - Zheng, Sen
AU  - Li, Danfeng
AU  - Tang, Yuna
AU  - Xu, Yong
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - With the continuous development of social progress, automatic control system has been widely used in temperature and humidity control. This paper first introduces the development status and prospect of silkworm houses, reviews the influence of silkworms under different temperature and humidity conditions, then discusses the research and development trend of temperature and humidity control system, and finally summarises the application of temperature and humidity control system in silkworm rooms.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_2
DP  - Springer Link
SP  - 18
EP  - 28
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Algorithm
KW  - Control system
KW  - Silkworm
KW  - Temperature and humidity
ER  - 

TY  - CONF
TI  - Video Encryption Transmission in GCM Mode Based on SM4 Algorithm
AU  - Zhou, Yiting
AU  - Zhang, Jian
AU  - Liu, Lin
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - The leakage of Tesla vehicle camera video and image data seriously infringes on users’ confidential information and personal privacy. Therefore, the security, reliability and privacy of video information in cameras have become one of the issues that all sectors of society pay more and more attention to, researchers mainly use AES encryption algorithm to encrypt video data. This paper takes the secure transmission of camera video data as the research object, and encrypts the original camera data by using Base64 coding and SM4 encryption algorithm, which can ensure the security and privacy of information data. The study compares six encryption modes of the SM4 algorithm and selects the GCM mode, which is more efficient and provides authentication functions. The encryption effect of the scheme was tested by using the microprocessor STM32F407 and OV2640 cameras, and the results showed that the encrypted transmission of video data and real-time decryption and playback could be completed, and the client video frame rate could reach 15fps, which effectively protected the user’s video privacy.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_15
DP  - Springer Link
SP  - 153
EP  - 160
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Encryp
KW  - GCM mode
KW  - SM4
KW  - Video
ER  - 

TY  - CONF
TI  - Design and Implementation of Warning Signs for Vehicles Based on Automatic Navigation Algorithms
AU  - Wang, Fangyan
AU  - Jiao, Ge
AU  - Lu, Jinjia
AU  - Yuan, Yiping
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Traditional warning signs use human retrograde placement; there are problems such as short warning distances, imprecise placement positions, and difficult positioning of accident points. According to statistics, the user's reaction time after facing a car accident is generally 1.05–1.28 s, and the reaction time to light is 0.225 s. The reaction time for the user to deal with a car accident independently is completely insufficient, and these reasons are the main reasons for secondary traffic accidents. In order to solve this social pain point, we designed a new intelligent triangle warning sign. The intelligent warning sign is installed with an intelligent base at the bottom, and it gets the traffic accident point precisely located when the intelligent warning sign is working, and the system gets the vehicle accident point and reminds the vehicles behind to pay attention to avoid, realizing the three-way interconnection of drivers and passengers, traffic control departments, and the personnel of the vehicles behind, and using the automatic navigation algorithm to realize the automatic navigation of the warning sign to protect the safety of drivers and passengers.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_6
DP  - Springer Link
SP  - 63
EP  - 73
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Automatic navigation
KW  - Precise positioning
KW  - Remote control
KW  - Three-way alert
KW  - Warning signs
ER  - 

TY  - CONF
TI  - Research on Mobile Robot Path Planning Based on Improved A* and DWA Algorithms
AU  - Qian, Wei
AU  - Peng, Jiansheng
AU  - Zhang, Hongyu
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - This paper explores the navigation of robots, which involves two key aspects: global path planning and local path planning. The current approach utilizes the A* algorithm for global planning and the DWA algorithm for local planning. However, the traditional A* algorithm often fails to consider obstacles, leading to impractical paths that robots struggle to navigate. As a result, success rates are narrow. To address these issues, we propose an enhanced A* algorithm that optimizes the search approach, heuristic function as well as path smoothing. This modification ensures that the generated paths align better with the robot's motion while still prioritizing the shortest distance. Additionally, we refine the evaluation function of the DWA algorithm to account for the robot's angular velocity at different linear velocities. This adjustment enables smoother steering through curves while maintaining a consistent linear velocity at the same time. The improved algorithm greatly improves the speed of the robot when cornering and has a more reasonable completion path, while the success rate of cornering is greatly improved. In our physical map, the robot with the improved algorithm consumes 33.95% less time than the robot with the traditional algorithm, and the robot's path is much better.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_10
DP  - Springer Link
SP  - 105
EP  - 118
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - A* algorithm
KW  - DWA algorithm
KW  - Mobile robot
KW  - ROS
ER  - 

TY  - CONF
TI  - A Text Sentiment Classification Method Enhanced by Bi-GRU and Attention Mechanism
AU  - Li, Dongdong
AU  - Shi, Xiaohou
AU  - Dai, Meiling
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Text sentiment analysis is a natural language processing technique designed to identify the emotional tendencies expressed in text. In recent years, this field has garnered significant attention and is widely used in practical applications. For example, sentiment analysis is employed for brand reputation management on social media, public opinion monitoring, and risk control in fields such as finance, medicine, and politics. Sentiment analysis is also utilized in tasks such as personalized recommendation and natural language generation. Despite the numerous methods and techniques proposed and applied in text sentiment analysis research, challenges and problems persist. During the sentiment classification process, text data exhibits problems such as uncertainty and semantic diversity, noise, and errors, leading to low accuracy and efficiency of sentiment analysis models. To enhance sentiment analysis accuracy and efficiency, this paper proposes an improved text sentiment classification method based on Bi-GRU and self-attention mechanism. The attention mechanism is initially fused with the update gate of the Bi-GRU gating unit to obtain important feature information in the text content. Subsequently, the Bi-GRU is followed by a self-attention mechanism to perform secondary screening on the text features, and the softmax function is applied to text vectors for sentiment classification, significantly enhancing the accuracy of sentiment classification. The proposed method is tested on the public dataset Yelp Dataset Challenge, and the experimental results indicate a considerable improvement in the accuracy of sentiment classification.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_18
DP  - Springer Link
SP  - 176
EP  - 186
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Attention mechanism
KW  - Bi-GRU
KW  - Sentiment classification
ER  - 

TY  - CONF
TI  - Research on User Profile Analysis Method Based on LGIM Model
AU  - Zong, Teng
AU  - Wang, Fengsi
AU  - Guo, Liang
AU  - Liu, Yibo
AU  - Feng, Xiaonan
AU  - Qin, Zifu
AU  - Xia, Yinxiang
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Student profile analysis is a depiction of the characteristics of individual learning behavior and group learning development law of students during college. This study focused on 12,181 students surveyed between 2018 and 2021, and mainly based on the LGIM model. We tried to conduct in-depth research and analyze the characteristics of student profiles from multiple dimensions. Firstly, LGIM Model is tested for moderating effects based on categorical variables, and the models of management and engineering students are compared and analyzed. Then, the trend of students' learning gains was analyzed for different statistical years and student grades. Through the above analysis, this study scientifically summarizes the learning characteristics of college students in different disciplines during their studies, the development characteristics and transformation direction of school education concepts, and the general laws of students' learning and growth during college. The research results are helpful to improve the exploration and utilization of students' potential, improve the quality of university education, and provide some reference for teachers to teach according to their aptitude.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_5
DP  - Springer Link
SP  - 52
EP  - 62
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - LGIM model
KW  - Moderating effects
KW  - Student characteristics
KW  - User profile
ER  - 

TY  - CONF
TI  - Target Spatial Positioning System Based on Dual Cameras
AU  - Sun, Yaqi
AU  - Tang, Peng
AU  - Bu, Jiayi
AU  - Lin, Mugang
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - With the rapid development of computer graphics, binocular stereo vision technology has been widely used in robot navigation, autonomous driving, medicine and other fields. This paper focuses on the research and implementation of binocular positioning system using object tracking and binocular localization technology. Firstly, in order to obtain the image information of the target, a target tracking algorithm based on KCF kernel correlation filtering is used to track the target object. Then, OpenCV-based binocular positioning is applied to calculate the three-dimensional spatial coordinates of the target including camera calibration, stereo rectification, stereo matching and depth map calculation. Finally, this paper discusses practical applications and possible future research directions for binocular localization technology.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_16
DP  - Springer Link
SP  - 161
EP  - 169
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Binocular positioning system
KW  - KCF kernel correlation filtering
KW  - OpenCv
KW  - Python programming language
ER  - 

TY  - CONF
TI  - UAV-Assisted NOMA Network Power Allocation Under Offshore Multi-energy Complementary Power Generation System
AU  - Shao, Wenyi
AU  - Lin, Fei
AU  - Xu, Ren
AU  - Meng, Fanping
AU  - Wang, Haoran
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - To solve the shortage of non-renewable energy sources, the development and utilization of abundant renewable energy sources at sea are gradually attracting attention. For the acquisition and analysis of offshore energy sources, we propose a new offloading framework for grid communication under offshore multi-energy power generation systems. This framework can enhance the performance of offshore communication and provide a good basis for command transmission of multi-energy complementary power generation systems. In this paper, we consider network offloading with the help of unmanned aerial vehicles (UAVs), while adopting non-orthogonal multiple access (NOMA) techniques on each UAV. The system hardware loss and incomplete successive interference cancellation (SIC) are jointly optimized for UAV trajectory and power allocation to minimize the system energy loss. To solve the non-convex problem, we use a two-step Deep Reinforcement Learning (DRL) based algorithm. Numerical results are based on the number of iterations and the variation of the signal-to-noise ratio magnitude to evaluate the effectiveness of the proposed algorithm in the system in terms of system energy consumption, transmission rate, interruption probability, and error rate. This research was funded by the National Natural Science Foundation of China, grant number U2006222 and Natural Science Foundation of Shandong Province, grant number ZR2020MF138.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_12
DP  - Springer Link
SP  - 125
EP  - 136
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Multi-agent
KW  - NOMA
KW  - Power allocation
KW  - UAV
ER  - 

TY  - CONF
TI  - PassDiff: A New Approach for Password Guessing Using Diffusion Model
AU  - Guo, Sheng
AU  - Duan, Ming
AU  - Du, Yibin
AU  - Wang, Wei
AU  - Guo, Lulu
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - Password guessing models can be broadly divided into three classes: dictionary-based password guessing model, password guessing model based on probability statistics and password guessing model based on deep learning. Recurrent neural networks and generative adversarial networks are the main deep learning techniques used for password guessing in the past. In this paper, we propose a novel PassDiff method for password guessing using denoising diffusion probabilistic models (DDPMs). Considering the similarity between the password space and the text space, we incorporate a byte-level tokenizer in the input phase and optimize the sampling process by modifying the source code. We encode a special character, and it makes PassDiff can handle input of variable length and obtain variable output without manual truncation. The experimental results show that PassDiff produces high-quality passwords even with minimal denoising steps. We recommend setting the denoising steps to 5–50, which can increase the sampling speed by tens of times. Compared with PassGAN, the training process of PassDiff is more stable and the cracking rate is also significantly improved. Specifically, when the denoising steps is set to 10 and 108 passwords are generated, PassDiff increases the cracking rate by 3.17%, 6.33% and 13.22% on 12306, CSDN and RockYou datasets, respectively.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_3
DP  - Springer Link
SP  - 29
EP  - 40
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
ST  - PassDiff
KW  - Deep learning
KW  - Denoising diffusion probabilistic models
KW  - Passwords
ER  - 

TY  - CONF
TI  - Research on Improving TEB Algorithm for Mobile Robot Path Planning
AU  - Zhang, Hongyu
AU  - Peng, Jiansheng
AU  - Qian, Wei
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - To address the issue of unstable velocity output in the TEB algorithm during multi-point navigation, this paper introduces the TEB-confidence algorithm. This algorithm resolves the problem by incorporating buffer and expansion zones around the target points, which impose velocity constraints as the points are approached. Moreover, the Chebyshev series method is utilized to accurately fit the decay function, erf(x), enhancing the precision of the fitting process. Experimental evaluations were conducted using the Robot Operating System (ROS) with an Ackermann motion model robot. The experiments involved navigating through seven target points using both the TEB-confidence algorithm and the classical TEB algorithm. The TEB-confidence algorithm successfully completed the multi-point navigation task in 22.5 s, whereas the classical TEB algorithm required 25.9 s. This demonstrates a significant 15.11% reduction in execution time when using the TEB-confidence algorithm compared to the classical TEB algorithm. Additionally, during the experiments, the classical TEB algorithm resulted in a collision, leading to a complete stop. The experimental results provide solid evidence that the enhanced TEB-confidence algorithm effectively prevents collisions resulting from velocity instability.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_9
DP  - Springer Link
SP  - 93
EP  - 104
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Mobile robot
KW  - Path planning
KW  - ROS
KW  - TEB
ER  - 

TY  - CONF
TI  - Bearings-Only Passive Localization in Unmanned Aerial Vehicle Formation Based on Mathematical Model
AU  - Meng, Bingqian
AU  - Hou, Xinqiao
AU  - Wu, Haiyan
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - In recent years, with the improvement of electronic technology, the maturity of satellite positioning system and the emergence of new UAVs, UAVs have entered a stage of rapid development. In order to ensure the concealment of UAVs and avoid external interference as much as possible, passive location and tracking system has gradually become a research hotspot when UAVs are flying in formation. The method of passive location has strong anti-interference ability and good concealment, which is a bridge between positioning technology and algorithm performance analysis. In this paper, aiming at the problem of how to maintain the formation of UAV cluster in the process of formation flight, the positioning coordinates of UAV are obtained by optimizing the particle swarm optimization algorithm, and the appropriate positioning model is constructed by using the bearing-only passive positioning algorithm. The position adjustment scheme of UAV is studied and extended to other formation scenarios.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_13
DP  - Springer Link
SP  - 137
EP  - 145
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Bearings-only passive positioning
KW  - Mathematical model
KW  - Unmanned aerial vehicle
ER  - 

TY  - CONF
TI  - Research Status and Application of Water and Fertilizer Integrated Machine for Smart Mulberry Garden
AU  - Cen, Dingjie
AU  - Lei, Lei
AU  - Liu, Zuojian
AU  - Chen, Zhiling
AU  - Qin, Yong
AU  - Xu, Yong
A2  - Zhang, Yonghong
A2  - Qi, Lianyong
A2  - Liu, Qi
A2  - Yin, Guangqiang
A2  - Liu, Xiaodong
T3  - Lecture Notes in Electrical Engineering
AB  - The water fertilizer integrated machine is a new agricultural technology equipment used for irrigation and fertilization in agricultural planting. Unlike traditional irrigation and fertilization, the water fertilizer integrated machine controls irrigation and fertilization based on artificial intelligence technology. Scientific water fertilizer replenishment can enable mulberry trees in mulberry gardens to obtain appropriate and sufficient nutrients at all stages of the growth process. This article discusses the research of mulberry garden water fertilizer integrated machine from the aspects of mulberry garden growth and water fertilizer integration technology, and analyzes and prospects the future development trend of mulberry garden water fertilizer integrated machine.
C1  - Singapore
C3  - Proceedings of the 13th International Conference on Computer Engineering and Networks
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-9239-3_1
DP  - Springer Link
SP  - 1
EP  - 17
LA  - en
PB  - Springer Nature
SN  - 978-981-9992-39-3
KW  - Artificial intelligence technology
KW  - Intelligent control
KW  - Scientific replenishment
KW  - Smart mulberry garden
KW  - Water fertilizer integrated machine
ER  - 

TY  - CONF
TI  - VoxelPose: Towards Multi-camera 3D Human Pose Estimation in Wild Environment
AU  - Tu, Hanyue
AU  - Wang, Chunyu
AU  - Zeng, Wenjun
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We present VoxelPose to estimate 3D poses of multiple people from multiple camera views. In contrast to the previous efforts which require to establish cross-view correspondence based on noisy and incomplete 2D pose estimates, VoxelPose directly operates in the 3D space therefore avoids making incorrect decisions in each camera view. To achieve this goal, features in all camera views are aggregated in the 3D voxel space and fed into Cuboid Proposal Network (CPN) to localize all people. Then we propose Pose Regression Network (PRN) to estimate a detailed 3D pose for each proposal. The approach is robust to occlusion which occurs frequently in practice. Without bells and whistles, it outperforms the previous methods on several public datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_12
DP  - Springer Link
SP  - 197
EP  - 212
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - VoxelPose
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_12.pdf
KW  - 3D human pose estimation
ER  - 

TY  - CONF
TI  - Conditional Convolutions for Instance Segmentation
AU  - Tian, Zhi
AU  - Shen, Chunhua
AU  - Chen, Hao
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We propose a simple yet effective instance segmentation framework, termed CondInst (conditional convolutions for instance segmentation). Top-performing instance segmentation methods such as Mask R-CNN rely on ROI operations (typically ROIPool or ROIAlign) to obtain the final instance masks. In contrast, we propose to solve instance segmentation from a new perspective. Instead of using instance-wise ROIs as inputs to a network of fixed weights, we employ dynamic instance-aware networks, conditioned on instances. CondInst enjoys two advantages: (1) Instance segmentation is solved by a fully convolutional network, eliminating the need for ROI cropping and feature alignment. (2) Due to the much improved capacity of dynamically-generated conditional convolutions, the mask head can be very compact (e.g., 3 conv. layers, each having only 8 channels), leading to significantly faster inference. We demonstrate a simpler instance segmentation method that can achieve improved performance in both accuracy and inference speed. On the COCO dataset, we outperform a few recent methods including well-tuned Mask R-CNN baselines, without longer training schedules needed. Code is available: https://git.io/AdelaiDet.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_17
DP  - Springer Link
SP  - 282
EP  - 298
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_17.pdf
KW  - Conditional convolutions
KW  - Instance segmentation
ER  - 

TY  - CONF
TI  - DeepFit: 3D Surface Fitting via Neural Network Weighted Least Squares
AU  - Ben-Shabat, Yizhak
AU  - Gould, Stephen
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We propose a surface fitting method for unstructured 3D point clouds. This method, called DeepFit, incorporates a neural network to learn point-wise weights for weighted least squares polynomial surface fitting. The learned weights act as a soft selection for the neighborhood of surface points thus avoiding the scale selection required of previous methods. To train the network we propose a novel surface consistency loss that improves point weight estimation. The method enables extracting normal vectors and other geometrical properties, such as principal curvatures, the latter were not presented as ground truth during training. We achieve state-of-the-art results on a benchmark normal and curvature estimation dataset, demonstrate robustness to noise, outliers and density variations, and show its application on noise removal.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_2
DP  - Springer Link
SP  - 20
EP  - 34
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - DeepFit
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_2.pdf
KW  - 3D point cloud deep learning
KW  - Least squares
KW  - Normal estimation
KW  - Surface fitting
KW  - Unstructured 3D point clouds
ER  - 

TY  - CONF
TI  - Fashionpedia: Ontology, Segmentation, and an Attribute Localization Dataset
AU  - Jia, Menglin
AU  - Shi, Mengyun
AU  - Sirotenko, Mikhail
AU  - Cui, Yin
AU  - Cardie, Claire
AU  - Hariharan, Bharath
AU  - Adam, Hartwig
AU  - Belongie, Serge
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - In this work we explore the task of instance segmentation with attribute localization, which unifies instance segmentation (detect and segment each object instance) and fine-grained visual attribute categorization (recognize one or multiple attributes). The proposed task requires both localizing an object and describing its properties. To illustrate the various aspects of this task, we focus on the domain of fashion and introduce Fashionpedia as a step toward mapping out the visual aspects of the fashion world. Fashionpedia consists of two parts: (1) an ontology built by fashion experts containing 27 main apparel categories, 19 apparel parts, 294 fine-grained attributes and their relationships; (2) a dataset with everyday and celebrity event fashion images annotated with segmentation masks and their associated per-mask fine-grained attributes, built upon the Fashionpedia ontology. In order to solve this challenging task, we propose a novel Attribute-Mask R-CNN model to jointly perform instance segmentation and localized attribute recognition, and provide a novel evaluation metric for the task. Fashionpedia is available at: https://fashionpedia.github.io/home/.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_19
DP  - Springer Link
SP  - 316
EP  - 332
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - Fashionpedia
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_19.pdf
KW  - Attribute
KW  - Dataset
KW  - Fashion
KW  - Fine-grained
KW  - Instance segmentation
KW  - Ontology
ER  - 

TY  - CONF
TI  - Self6D: Self-supervised Monocular 6D Object Pose Estimation
AU  - Wang, Gu
AU  - Manhardt, Fabian
AU  - Shao, Jianzhun
AU  - Ji, Xiangyang
AU  - Navab, Nassir
AU  - Tombari, Federico
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - 6D object pose estimation is a fundamental problem in computer vision. Convolutional Neural Networks (CNNs) have recently proven to be capable of predicting reliable 6D pose estimates even from monocular images. Nonetheless, CNNs are identified as being extremely data-driven, and acquiring adequate annotations is oftentimes very time-consuming and labor intensive. To overcome this shortcoming, we propose the idea of monocular 6D pose estimation by means of self-supervised learning, removing the need for real annotations. After training our proposed network fully supervised with synthetic RGB data, we leverage recent advances in neural rendering to further self-supervise the model on unannotated real RGB-D data, seeking for a visually and geometrically optimal alignment. Extensive evaluations demonstrate that our proposed self-supervision is able to significantly enhance the model’s original performance, outperforming all other methods relying on synthetic data or employing elaborate techniques from the domain adaptation realm.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_7
DP  - Springer Link
SP  - 108
EP  - 125
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - Self6D
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_7.pdf
KW  - 6D pose estimation
KW  - Self-supervised learning
ER  - 

TY  - CONF
TI  - Empowering Relational Network by Self-attention Augmented Conditional Random Fields for Group Activity Recognition
AU  - Pramono, Rizard Renanda Adhi
AU  - Chen, Yie Tarng
AU  - Fang, Wen Hsien
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - This paper presents a novel relational network for group activity recognition. The core of our network is to augment the conditional random fields (CRF), amenable to learning inter-dependency of correlated observations, with the newly devised temporal and spatial self-attention to learn the temporal evolution and spatial relational contexts of every actor in videos. Such a combination utilizes the global receptive fields of self-attention to construct a spatio-temporal graph topology to address the temporal dependency and non-local relationships of the actors. The network first uses the temporal self-attention along with the spatial self-attention, which considers multiple cliques with different scales of locality to account for the diversity of the actors’ relationships in group activities, to model the pairwise energy of CRF. Afterward, to accommodate the distinct characteristics of each video, a new mean-field inference algorithm with dynamic halting is also addressed. Finally, a bidirectional universal transformer encoder (UTE), which combines both of the forward and backward temporal context information, is used to aggregate the relational contexts and scene information for group activity recognition. Simulations show that the proposed approach surpasses the state-of-the-art methods on the widespread Volleyball and Collective Activity datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_5
DP  - Springer Link
SP  - 71
EP  - 90
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_5.pdf
KW  - Bidirectional universal transformer encoder
KW  - Conditional random field
KW  - Graph cliques
KW  - Group activity
KW  - Self-attention mechanism
ER  - 

TY  - CONF
TI  - Segment as Points for Efficient Online Multi-Object Tracking and Segmentation
AU  - Xu, Zhenbo
AU  - Zhang, Wei
AU  - Tan, Xiao
AU  - Yang, Wei
AU  - Huang, Huan
AU  - Wen, Shilei
AU  - Ding, Errui
AU  - Huang, Liusheng
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - Current multi-object tracking and segmentation (MOTS) methods follow the tracking-by-detection paradigm and adopt convolutions for feature extraction. However, as affected by the inherent receptive field, convolution based feature extraction inevitably mixes up the foreground features and the background features, resulting in ambiguities in the subsequent instance association. In this paper, we propose a highly effective method for learning instance embeddings based on segments by converting the compact image representation to un-ordered 2D point cloud representation. Our method generates a new tracking-by-points paradigm where discriminative instance embeddings are learned from randomly selected points rather than images. Furthermore, multiple informative data modalities are converted into point-wise representations to enrich point-wise features. The resulting online MOTS framework, named PointTrack, surpasses all the state-of-the-art methods including 3D tracking methods by large margins (5.4% higher MOTSA and 18 times faster over MOTSFusion) with the near real-time speed (22 FPS). Evaluations across three datasets demonstrate both the effectiveness and efficiency of our method. Moreover, based on the observation that current MOTS datasets lack crowded scenes, we build a more challenging MOTS dataset named APOLLO MOTS with higher instance density. Both APOLLO MOTS and our codes are publicly available at https://github.com/detectRecog/PointTrack.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_16
DP  - Springer Link
SP  - 264
EP  - 281
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_16.pdf
KW  - Motion and tracking
KW  - Tracking
KW  - Vision for robotics
ER  - 

TY  - CONF
TI  - Quaternion Equivariant Capsule Networks for 3D Point Clouds
AU  - Zhao, Yongheng
AU  - Birdal, Tolga
AU  - Lenssen, Jan Eric
AU  - Menegatti, Emanuele
AU  - Guibas, Leonidas
AU  - Tombari, Federico
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We present a 3D capsule module for processing point clouds that is equivariant to 3D rotations and translations, as well as invariant to permutations of the input points. The operator receives a sparse set of local reference frames, computed from an input point cloud and establishes end-to-end transformation equivariance through a novel dynamic routing procedure on quaternions. Further, we theoretically connect dynamic routing between capsules to the well-known Weiszfeld algorithm, a scheme for solving iterative re-weighted least squares (IRLS) problems with provable convergence properties. It is shown that such group dynamic routing can be interpreted as robust IRLS rotation averaging on capsule votes, where information is routed based on the final inlier scores. Based on our operator, we build a capsule network that disentangles geometry from pose, paving the way for more informative descriptors and a structured latent space. Our architecture allows joint object classification and orientation estimation without explicit supervision of rotations. We validate our algorithm empirically on common benchmark datasets.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_1
DP  - Springer Link
SP  - 1
EP  - 19
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_1.pdf
KW  - 3D
KW  - Disentanglement
KW  - Equivariance
KW  - Quaternion
KW  - Rotation
ER  - 

TY  - CONF
TI  - End-to-End Object Detection with Transformers
AU  - Carion, Nicolas
AU  - Massa, Francisco
AU  - Synnaeve, Gabriel
AU  - Usunier, Nicolas
AU  - Kirillov, Alexander
AU  - Zagoruyko, Sergey
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster R-CNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_13
DP  - Springer Link
SP  - 213
EP  - 229
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_13.pdf
ER  - 

TY  - CONF
TI  - House-GAN: Relational Generative Adversarial Networks for Graph-Constrained House Layout Generation
AU  - Nauata, Nelson
AU  - Chang, Kai-Hung
AU  - Cheng, Chin-Yi
AU  - Mori, Greg
AU  - Furukawa, Yasutaka
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - This paper proposes a novel graph-constrained generative adversarial network, whose generator and discriminator are built upon relational architecture. The main idea is to encode the constraint into the graph structure of its relational networks. We have demonstrated the proposed architecture for a new house layout generation problem, whose task is to take an architectural constraint as a graph (i.e., the number and types of rooms with their spatial adjacency) and produce a set of axis-aligned bounding boxes of rooms. We measure the quality of generated house layouts with the three metrics: the realism, the diversity, and the compatibility with the input graph constraint. Our qualitative and quantitative evaluations over 117,000 real floorplan images demonstrate that the proposed approach outperforms existing methods and baselines. We will publicly share all our code and data.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_10
DP  - Springer Link
SP  - 162
EP  - 177
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - House-GAN
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_10.pdf
KW  - Floorplan
KW  - GAN
KW  - Generation
KW  - Graph-constrained
KW  - Layout
ER  - 

TY  - CONF
TI  - MutualNet: Adaptive ConvNet via Mutual Learning from Network Width and Resolution
AU  - Yang, Taojiannan
AU  - Zhu, Sijie
AU  - Chen, Chen
AU  - Yan, Shen
AU  - Zhang, Mi
AU  - Willis, Andrew
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - We propose the width-resolution mutual learning method (MutualNet) to train a network that is executable at dynamic resource constraints to achieve adaptive accuracy-efficiency trade-offs at runtime. Our method trains a cohort of sub-networks with different widths (i.e., number of channels in a layer) using different input resolutions to mutually learn multi-scale representations for each sub-network. It achieves consistently better ImageNet top-1 accuracy over the state-of-the-art adaptive network US-Net under different computation constraints, and outperforms the best compound scaled MobileNet in EfficientNet by 1.5%. The superiority of our method is also validated on COCO object detection and instance segmentation as well as transfer learning. Surprisingly, the training strategy of MutualNet can also boost the performance of a single network, which substantially outperforms the powerful AutoAugmentation in both efficiency (GPU search hours: 15000 vs. 0) and accuracy (ImageNet: 77.6% vs. 78.6%). Code is available at https://github.com/taoyang1122/MutualNet.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_18
DP  - Springer Link
SP  - 299
EP  - 315
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - MutualNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_18.pdf
ER  - 

TY  - CONF
TI  - Synthesize Then Compare: Detecting Failures and Anomalies for Semantic Segmentation
AU  - Xia, Yingda
AU  - Zhang, Yi
AU  - Liu, Fengze
AU  - Shen, Wei
AU  - Yuille, Alan L.
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - The ability to detect failures and anomalies are fundamental requirements for building reliable systems for computer vision applications, especially safety-critical applications of semantic segmentation, such as autonomous driving and medical image analysis. In this paper, we systematically study failure and anomaly detection for semantic segmentation and propose a unified framework, consisting of two modules, to address these two related problems. The first module is an image synthesis module, which generates a synthesized image from a segmentation layout map, and the second is a comparison module, which computes the difference between the synthesized image and the input image. We validate our framework on three challenging datasets and improve the state-of-the-arts by large margins, i.e., 6% AUPR-Error on Cityscapes, 7% Pearson correlation on pancreatic tumor segmentation in MSD and 20% AUPR on StreetHazards anomaly segmentation.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_9
DP  - Springer Link
SP  - 145
EP  - 161
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - Synthesize Then Compare
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_9.pdf
KW  - Anomaly segmentation
KW  - Failure detection
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - NSGANetV2: Evolutionary Multi-objective Surrogate-Assisted Neural Architecture Search
AU  - Lu, Zhichao
AU  - Deb, Kalyanmoy
AU  - Goodman, Erik
AU  - Banzhaf, Wolfgang
AU  - Boddeti, Vishnu Naresh
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - In this paper, we propose an efficient NAS algorithm for generating task-specific models that are competitive under multiple competing objectives. It comprises of two surrogates, one at the architecture level to improve sample efficiency and one at the weights level, through a supernet, to improve gradient descent training efficiency. On standard benchmark datasets (C10, C100, ImageNet), the resulting models, dubbed NSGANetV2, either match or outperform models from existing approaches with the search being orders of magnitude more sample efficient. Furthermore, we demonstrate the effectiveness and versatility of the proposed method on six diverse non-standard datasets, e.g. STL-10, Flowers102, Oxford Pets, FGVC Aircrafts etc. In all cases, NSGANetV2s improve the state-of-the-art (under mobile setting), suggesting that NAS can be a viable alternative to conventional transfer learning approaches in handling diverse scenarios such as small-scale or fine-grained datasets. Code is available at https://github.com/mikelzc1990/nsganetv2.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_3
DP  - Springer Link
SP  - 35
EP  - 51
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - NSGANetV2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_3.pdf
KW  - Evolutionary algorithms
KW  - NAS
KW  - Surrogate-assisted search
ER  - 

TY  - CONF
TI  - Invertible Image Rescaling
AU  - Xiao, Mingqing
AU  - Zheng, Shuxin
AU  - Liu, Chang
AU  - Wang, Yaolong
AU  - He, Di
AU  - Ke, Guolin
AU  - Bian, Jiang
AU  - Lin, Zhouchen
AU  - Liu, Tie-Yan
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - High-resolution digital images are usually downscaled to fit various display screens or save the cost of storage and bandwidth, meanwhile the post-upscaling is adopted to recover the original resolutions or the details in the zoom-in images. However, typical image downscaling is a non-injective mapping due to the loss of high-frequency information, which leads to the ill-posed problem of the inverse upscaling procedure and poses great challenges for recovering details from the downscaled low-resolution images. Simply upscaling with image super-resolution methods results in unsatisfactory recovering performance. In this work, we propose to solve this problem by modeling the downscaling and upscaling processes from a new perspective, i.e. an invertible bijective transformation, which can largely mitigate the ill-posed nature of image upscaling. We develop an Invertible Rescaling Net (IRN) with deliberately designed framework and objectives to produce visually-pleasing low-resolution images and meanwhile capture the distribution of the lost information using a latent variable following a specified distribution in the downscaling process. In this way, upscaling is made tractable by inversely passing a randomly-drawn latent variable with the low-resolution image through the network. Experimental results demonstrate the significant improvement of our model over existing methods in terms of both quantitative and qualitative evaluations of image upscaling reconstruction from downscaled images. Code is available at https://github.com/pkuxmq/Invertible-Image-Rescaling.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_8
DP  - Springer Link
SP  - 126
EP  - 144
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_8.pdf
ER  - 

TY  - CONF
TI  - Ladybird: Quasi-Monte Carlo Sampling for Deep Implicit Field Based 3D Reconstruction with Symmetry
AU  - Xu, Yifan
AU  - Fan, Tianqi
AU  - Yuan, Yi
AU  - Singh, Gurprit
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - Deep implicit field regression methods are effective for 3D reconstruction from single-view images. However, the impact of different sampling patterns on the reconstruction quality is not well-understood. In this work, we first study the effect of point set discrepancy on the network training. Based on Farthest Point Sampling algorithm, we propose a sampling scheme that theoretically encourages better generalization performance, and results in fast convergence for SGD-based optimization algorithms. Secondly, based on the reflective symmetry of an object, we propose a feature fusion method that alleviates issues due to self-occlusions which makes it difficult to utilize local image features. Our proposed system Ladybird is able to create high quality 3D object reconstructions from a single input image. We evaluate Ladybird on a large scale 3D dataset (ShapeNet) demonstrating highly competitive results in terms of Chamfer distance, Earth Mover’s distance and Intersection Over Union (IoU).
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_15
DP  - Springer Link
SP  - 248
EP  - 263
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - Ladybird
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_15.pdf
KW  - 3D reconstruction
KW  - Deep learning
KW  - Sampling
KW  - Symmetry
ER  - 

TY  - CONF
TI  - Describing Textures Using Natural Language
AU  - Wu, Chenyun
AU  - Timm, Mikayla
AU  - Maji, Subhransu
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - Textures in natural images can be characterized by color, shape, periodicity of elements within them, and other attributes that can be described using natural language. In this paper, we study the problem of describing visual attributes of texture on a novel dataset containing rich descriptions of textures, and conduct a systematic study of current generative and discriminative models for grounding language to images on this dataset. We find that while these models capture some properties of texture, they fail to capture several compositional properties, such as the colors of dots. We provide critical analysis of existing models by generating synthetic but realistic textures with different descriptions. Our dataset also allows us to train interpretable models and generate language-based explanations of what discriminative features are learned by deep networks for fine-grained categorization where texture plays a key role. We present visualizations of several fine-grained domains and show that texture attributes learned on our dataset offer improvements over expert-designed attributes on the Caltech-UCSD Birds dataset.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_4
DP  - Springer Link
SP  - 52
EP  - 70
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_4.pdf
ER  - 

TY  - CONF
TI  - AiR: Attention with Reasoning Capability
AU  - Chen, Shi
AU  - Jiang, Ming
AU  - Yang, Jinhui
AU  - Zhao, Qi
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - While attention has been an increasingly popular component in deep neural networks to both interpret and boost performance of models, little work has examined how attention progresses to accomplish a task and whether it is reasonable. In this work, we propose an Attention with Reasoning capability (AiR) framework that uses attention to understand and improve the process leading to task outcomes. We first define an evaluation metric based on a sequence of atomic reasoning operations, enabling quantitative measurement of attention that considers the reasoning process. We then collect human eye-tracking and answer correctness data, and analyze various machine and human attentions on their reasoning capability and how they impact task performance. Furthermore, we propose a supervision method to jointly and progressively optimize attention, reasoning, and task performance so that models learn to look at regions of interests by following a reasoning process. We demonstrate the effectiveness of the proposed framework in analyzing and modeling attention with better reasoning capability and task performance. The code and data are available at https://github.com/szzexpoi/AiR.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_6
DP  - Springer Link
SP  - 91
EP  - 107
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - AiR
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_6.pdf
KW  - Attention
KW  - Eye-tracking dataset
KW  - Reasoning
ER  - 

TY  - CONF
TI  - DeepSFM: Structure from Motion via Deep Bundle Adjustment
AU  - Wei, Xingkui
AU  - Zhang, Yinda
AU  - Li, Zhuwen
AU  - Fu, Yanwei
AU  - Xue, Xiangyang
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - Structure from motion (SfM) is an essential computer vision problem which has not been well handled by deep learning. One of the promising trends is to apply explicit structural constraint, e.g. 3D cost volume, into the network. However, existing methods usually assume accurate camera poses either from GT or other methods, which is unrealistic in practice. In this work, we design a physical driven architecture, namely DeepSFM, inspired by traditional Bundle Adjustment (BA), which consists of two cost volume based architectures for depth and pose estimation respectively, iteratively running to improve both. The explicit constraints on both depth (structure) and pose (motion), when combined with the learning components, bring the merit from both traditional BA and emerging deep learning technology. Extensive experiments on various datasets show that our model achieves the state-of-the-art performance on both depth and pose estimation with superior robustness against less number of inputs and the noise in initialization.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_14
DP  - Springer Link
SP  - 230
EP  - 247
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
ST  - DeepSFM
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_14.pdf
ER  - 

TY  - CONF
TI  - Crowdsampling the Plenoptic Function
AU  - Li, Zhengqi
AU  - Xian, Wenqi
AU  - Davis, Abe
AU  - Snavely, Noah
A2  - Vedaldi, Andrea
A2  - Bischof, Horst
A2  - Brox, Thomas
A2  - Frahm, Jan-Michael
T3  - Lecture Notes in Computer Science
AB  - Many popular tourist landmarks are captured in a multitude of online, public photos. These photos represent a sparse and unstructured sampling of the plenoptic function for a particular scene. In this paper, we present a new approach to novel view synthesis under time-varying illumination from such data. Our approach builds on the recent multi-plane image (MPI) format for representing local light fields under fixed viewing conditions. We introduce a new DeepMPI representation, motivated by observations on the sparsity structure of the plenoptic function, that allows for real-time synthesis of photorealistic views that are continuous in both space and across changes in lighting. Our method can synthesize the same compelling parallax and view-dependent effects as previous MPI methods, while simultaneously interpolating along changes in reflectance and illumination with time. We show how to learn a model of these effects in an unsupervised way from an unstructured collection of photos without temporal registration, demonstrating significant improvements over recent work in neural rendering. More information can be found at crowdsampling.io.
C1  - Cham
C3  - Computer Vision – ECCV 2020
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-58452-8_11
DP  - Springer Link
SP  - 178
EP  - 196
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-58452-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-58452-8_11.pdf
ER  - 

TY  - CONF
TI  - Research on Improved Image Classification Algorithm Based on Darknet53 Model
AU  - Zou, Shangchen
AU  - Zhang, Baoju
AU  - Zhang, Bo
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - An improved Image classification algorithm based on Darknet53 model is proposed in this paper to solve the problem that a large amount of the same gradient information is repeatedly used to update the weights of different dense layers in the Darknet53 network in the process of back propagation. Firstly, the residual block in the original network is replaced by THE CSP module, referring to the idea of cutting off the gradient flow in CSPnet to prevent too much repeated gradient information. Second, the Mish activation function is used to replace the Leaky ReLU function, which can transmit information more smoothly and achieve better accuracy and generalization. Finally, a SPP module is added to the end of the original network structure to solve the multi-scale problem of the main part of image classification. The experimental results show that the improved Darknet has achieved better performance, and the accuracy is improved by 1.3% compared with the original network; At the same time, compared with resnet50 and resnet101, the improved Darknet has better effect on image classification.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_10
DP  - Springer Link
SP  - 73
EP  - 80
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_10.pdf
KW  - CNN
KW  - Deep learning
KW  - Image classification
ER  - 

TY  - CONF
TI  - Design of an IoT-Based Cross-Modality Pedestrian Monitoring System for Contact Tracing in COVID-19 Prevention
AU  - Bian, Ziyang
AU  - Ma, Liang
AU  - Li, Jianan
AU  - Xu, Tingfa
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - COVID-19 epidemic prevention and control has become a regular part of life, and tracking people’s trajectory (especially fever patients) in public areas can help curb the spread of the epidemic. IoT technology has dramatically improved the efficiency of epidemic prevention and control. In this paper, we propose an IoT-based cross-modality pedestrian surveillance system architecture with the following characteristics: (1) robust, the system accesses multiple modal information (visible light, infrared, temperature, mobile phone signals), and can achieve trajectory tracking in non-cooperative situations; (2) with flexibility, we develop a nodal visual artificial intelligence software platform for deep neural network training and optimization, using which the deployment can be iteratively optimized intuitively and quickly. Finally, we also discuss the research prospects of artificial intelligence and IoT technologies in the direction of epidemic prevention and control.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_8
DP  - Springer Link
SP  - 57
EP  - 64
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_8.pdf
KW  - COVID-19 Epidemic
KW  - cross-modality
KW  - Internet of things
KW  - pedestrian monitoring systems
ER  - 

TY  - CONF
TI  - A Time Jitter DDMA MIMO Automotive Radar Waveform
AU  - Liu, Jianhu
AU  - Lian, Hongfei
AU  - Chen, Qiao
AU  - Chen, Sijia
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problems of low utilization of time and space and Doppler ambiguity of high-velocity targets in the traditional multiple input multiple output (MIMO) waveform of automotive radar, a time jitter Doppler frequency division multiplexing automotive radar waveform is proposed. This waveform jitters the pulse repetition interval stagger in the time domain, uses the phase difference between odd and even sequences to realize velocity ambiguity resolution, and realizes waveform orthogonality in the frequency domain through unequal spacing Doppler frequency modulation between multiple antennas, which improves the time-space transmission efficiency. In addition, an echo separation method based on non coherent accumulation is proposed, which can effectively solve the problem of target matching under Doppler frequency division multiplexing waveform. The effectiveness of the proposed waveform and signal processing method is verified by simulation experiments, and the waveform has strong application value in automotive radar engineering practice.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_4
DP  - Springer Link
SP  - 26
EP  - 32
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_4.pdf
KW  - Automotive radar
KW  - Doppler frequency division multiplexing
KW  - Incoherent accumulation
KW  - Multiple input multiple output
KW  - Time jitter
ER  - 

TY  - CONF
TI  - Fall Detection for Surveillance Video Based on Deep Learning
AU  - Liu, Hongwei
AU  - Mu, Jiasong
AU  - Zhang, Zhao
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Accidental falls constantly threaten the lives of the elderly, and failing to detect them in time after a fall can cause the person to miss the best time to rescue, causing severe injury or even death. This paper proposes a video-based fall detection method to solve this problem. This method first performs motion detection of inter-frame difference on the video, performs feature extraction through deep learning, and finally completes classification by support vector machine to determine whether a fall occurs. The main application scene of this method is the surveillance video of the elderly living alone. The experimental results show that the proposed fall detection method has high accuracy and recall rate and can complete the fall detection task.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_16
DP  - Springer Link
SP  - 123
EP  - 129
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_16.pdf
KW  - Deep learning
KW  - Fall detection
KW  - Support vector machine
ER  - 

TY  - CONF
TI  - Research on the Improved Design and Implementation of Signal Processing and Detection Algorithm for High Speed Moving Target
AU  - Zhang, Xinyu
AU  - Wang, Shangyue
AU  - Zhang, Ran
AU  - Zhao, Pengcheng
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Signal processing and detection technology is one of the important directions of radar signal processing. In order to track high speed moving target stably, the selection of reasonable signal detection technology is particularly important in radar signal processing. In this paper, the common filter of constant false alarm detection in signal detection algorithm is analyzed. The relationship among detection probability false alarm probability and signal to noise ratio in signal detection is introduced. Then, a signal detection method for high speed moving target is proposed. Based on the real data of high speed moving target, several detection methods in radar signal processing algorithm are compared and analyzed, and the advantages and disadvantages of different methods are described.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_2
DP  - Springer Link
SP  - 9
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_2.pdf
KW  - Constant False-Alarm Rate
KW  - Radar Signal Processing
KW  - Target Detection
ER  - 

TY  - CONF
TI  - The Optimization of the Safety and Energy Efficiency in a UAV-Assisted Communication System
AU  - Yang, Maolin
AU  - Gao, Jing
AU  - Han, Tingting
AU  - Ma, Junchi
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - It is well known that both safety and energy consumption should be of great concern in unmanned aerial vehicles (UAVs)-assisted communication technology. In this paper, we studied the safety and energy efficiency in a UAV-assisted communication system in which there is a UAV, a ground terminal (GT) and an eavesdropper. The safety and energy efficiency was defined as the total secrecy rate in the case of considering UAV propulsion energy consumption only during its service period. Since the objective function formulated as maximizing the safety and energy efficiency is non-convex, we proposed an iterative sequential convex programming (SCP)-based algorithm to seek a suboptimal solution. Simulation results show that the method proposed in this paper can effectively improve the safety and energy efficiency of the system.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_6
DP  - Springer Link
SP  - 41
EP  - 49
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_6.pdf
KW  - safety and energy efficiency
KW  - trajectory design
KW  - UAV-assisted communication
ER  - 

TY  - CONF
TI  - A Low Complexity Decoding Algorithm for Polar Codes with Flexible Path Expansion and List Size
AU  - Fu, Chenxuan
AU  - Wu, Xiaoyong
AU  - Zhang, Zhilong
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - To reduce the complexity of polar codes, an improved multi-segment CRC-aided and partial path expansion successive-cancellation list algorithm (MP-SCL) is proposed in this paper. This algorithm determines decoding path expansion parameters based on the reliability of each polarization splitting sub-channel. At the same time, it dynamically modifies the size of decoding list according to the current CRC decoding results and the previous decoding list size. Simulation results show that when the bit error rate reaches $$10^{-6}$$10-6, the complexity of our proposed algorithm can be reduced by 69.29% and 43.16% compared with cancellation list decoding of polar codes based on path metric and traditional MP-SCL, respectively.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_15
DP  - Springer Link
SP  - 114
EP  - 122
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_15.pdf
KW  - Flexible path expansion
KW  - List size adjuster
KW  - Low complexity decoding
KW  - Polar codes
ER  - 

TY  - CONF
TI  - An Improved Grey Wolf Optimizer for Numerical Optimization
AU  - Ma, Linyun
AU  - Tong, Ying
AU  - Han, Baozhu
AU  - Zhang, Xing
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problems of Grey Wolf Optimizer (GWO), such as slow convergence rate in the late iteration, lack of mechanism to jump out of local optimum. In this paper, an improved Grey Wolf Optimizer (IGWO) is proposed. In this algorithm, a new update equation is used to improve the search speed of the algorithm. Meanwhile, the forgetting mechanism is introduced, which improves the diversification of the population and enables the algorithm to jump out of local optimum. Simulation experiments on the CEC2017 test set show that compared with standard GWO, the results obtained by IGWO have higher accuracy, which proves that the algorithm has better performance in dealing with complex optimization problems.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_17
DP  - Springer Link
SP  - 130
EP  - 137
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_17.pdf
KW  - forgetting mechanism
KW  - global optimization
KW  - grey wolf optimizer
KW  - meta-heuristic algorithm
ER  - 

TY  - CONF
TI  - The Study of Multi-channel SAR Sub-band Receiver and Pulse Compression Technology
AU  - Xu, Feng
AU  - Pan, Wen
AU  - Shen, Defeng
AU  - Xu, Fan
AU  - Lu, Jun
AU  - Xu, Bin
AU  - Li, Haixia
AU  - Zhang, Xinguang
AU  - Jin, Wen
AU  - Zhu, Min
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - The demand of high-resolution SAR system is the wide bandwidth and the wide swath. The direct sampling is impossible for so high speed data streaming. The common solution is parallel receiving echo data by multi-channel. According to the character of synthetic aperture radar, this paper proposes the technology of the multi-channel receiver and sub-band pulse compression. Finally, the computer simulation confirms the validity of the method successfully.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_13
DP  - Springer Link
SP  - 98
EP  - 105
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_13.pdf
KW  - Multi-channel sub-band receiver
KW  - SAR
KW  - Sub-band pulse compression
ER  - 

TY  - CONF
TI  - Emotion Recognition of EEG Signals Based on Channel Attention Convolution Neural Network
AU  - Zhang, Xiu
AU  - Pei, Xun
AU  - Zhang, Xin
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Electroencephalography (EEG) is more likely to respond to emotional changes compared to facial expressions and voice because it is not subject to external interference and is not easily disguised. By classifying the emotions of EEG signals, it can provide an aid for future treatment of depression, epilepsy and other diseases. Therefore, this article uses the publicly available EEG emotion dataset and uses a ratio of 80%–20% to divide the training set and test set. The features of EEG data are extracted using Fast fourier transform (FFT), and the Convolutional neural network (CNN) in deep learning is used as the basic premise to incorporate the channel attention mechanism. An EEG emotion recognition model combining CNN and channel attention mechanism is designed, which includes three convolutional layers, three channel attention blocks, three maximum pooling layers, three fully connected layers, a dense layer and a softmax layer, and batch normalization is used to suppress the overfitting of the model. Experimental results show that the sentiment recognition accuracy of the DEAP dataset reaches 90%, which achieves a significant improvement over existing emotion recognition models.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_12
DP  - Springer Link
SP  - 90
EP  - 97
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_12.pdf
KW  - Convolutional neural networks
KW  - Deep learning
KW  - EEG
KW  - Emotion recognition
ER  - 

TY  - CONF
TI  - Low-Light Image Enhancement Algorithm Based on the Fusion of Multi-scale Features and Attention Mechanism
AU  - Sun, Youchen
AU  - Zhang, Baoju
AU  - Zhang, Bo
AU  - Zhang, Cuiping
AU  - Zhang, Jin
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Aiming at the problems of Retinex-Net such as large noise of reflection component, low brightness of illumination component and insufficient feature extraction, a low-light image enhancement algorithm based on fusion of multi-scale features and attention mechanism is proposed. First, the Retinex-Net network is used as the basic model to decompose the input image, and the atrous convolution and ordinary convolution are fused to achieve multi-scale feature extraction to obtain more detailed information; multi-layer attention is introduced into the enhanced network. The force mechanism module enhances the brightness of the details and illumination components; finally, the denoised reflection components and the enhanced illumination components are fused into a normal illumination image output. Experiments show that the algorithm can effectively improve the details of the image and improve the visual effect of the image.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_9
DP  - Springer Link
SP  - 65
EP  - 72
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_9.pdf
KW  - attention mechanism
KW  - convolutional neural network
KW  - Low-light image enhancement
KW  - multiscale feature extraction
KW  - Retinex-Net
ER  - 

TY  - CONF
TI  - Research on Blockchain-Based Mobile Edge Computing System in Smart City
AU  - Hai, MingCi
AU  - Yang, Cheng
AU  - Liu, Jun
AU  - Huang, XinQian
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Massive data produced by a growing number of smart devices accessed to the communication network gives a great transmission burden to the network, when implementing smart city service. Along with the security problem, Mobile Edge Computing(MEC) and Blockchain techniques are applied to relieve these problems. This paper proposes a MEC system based on Blockchain, and models the resource allocation problem taking into account the mining time and mining reward. The modeled problem is optimized using Asynchronous Advanced Actor-Critic(A3C) algorithm and Sychronous Advanced Actor-Critic(SA2C) algrorithm. The simulation results show the effectiveness of the methods and compare the efficiency between two algorithms.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_19
DP  - Springer Link
SP  - 147
EP  - 154
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_19.pdf
KW  - blockchain
KW  - mobile edge computing
KW  - resource allocation
KW  - smart city
ER  - 

TY  - CONF
TI  - A Transformer-Based Network for Hyperspectral Image Classification
AU  - Yu, Jizhen
AU  - Li, Zhengtao
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - For hyperspectral classification, many pixel-based approaches have been developed to deal with multidimensional hyperspectral data, in addition to the orderless vector-based feature extraction, the sequence-based feature representation approaches also prove its effect on hyper-spectral classification. Based on the sequence-based data structure, we borrow the Transformer architecture from the knowledge of NLP (Natural Language Processing) to analyze hyperspectral pixels as sequential data and then decide information categories via network reasoning. In the proposed model, after first obtaining the spatial features of single band, we can obtain the spectral embeddings and position embeddings in hyperspectral sequence; Secondly, with adopting multilayer encoder module derived from Transformer which has powerful sequence expression ability, we can dig depth correlation between sequence data; Finally, a feedforward layer and a softmax layer are used to predict class categories. The experimental results on two publicly accessible images demonstrate that our proposed approach can obtain competitive performance compared with other state-of-the-art methods.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_3
DP  - Springer Link
SP  - 16
EP  - 25
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_3.pdf
KW  - Hyperspectral classification
KW  - self-attention
KW  - sequential correlation
KW  - transformer
ER  - 

TY  - CONF
TI  - A Fault Diagnosis Method for Power Transformer Using Canonical Variate Analysis and Support Vector Machine
AU  - Luo, Long
AU  - Li, Yan
AU  - Shi, Yan
AU  - Han, Ting
AU  - Yang, Wencui
AU  - Jin, Xiaojun
AU  - Han, Di
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - The transformer is one of the most important units in the power grid. Due to the potential failures and costs of the power system, it is necessary to pay attention to the fault diagnosis of power transformers. This paper proposes a fault diagnosis method based on Canonical Variate Analysis and Support Vector Machine (CVA-SVM). As a system identification method, CVA is widely used for fault detection because of its ability to identify multivariate state space models using experimental data. The support vector machine is a new machine learning method and is a powerful tool for solving problems with nonlinear and non-Gaussian distributed data. Dissolved gas analysis (DGA) has shown great potential for detecting faults in power transformers. For fault diagnosis based on DGA, a CVA model is first constructed for the process variables to generate a series of feature vectors, and then the fault types are classified using SVM. A real power transformer process is employed to verify the effectiveness of the proposed method.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_18
DP  - Springer Link
SP  - 138
EP  - 146
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_18.pdf
KW  - Canonical Variate Analysis
KW  - fault diagnosis
KW  - Power transformer
KW  - Support Vector Machine
ER  - 

TY  - CONF
TI  - Input Design Analysis for the Capacity of Finite Impulse Response Actuator
AU  - Zhang, Deseng
AU  - Xu, Dazhuan
AU  - Hua, Boyu
AU  - Bao, Junwei
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Mutual information (MI) is usually a computational heavy work when used as optimal metric in control system. In this paper, the modeling of Finite Impulse Response (FIR) system with entropy-rate framework is shown. A practical signal sampling algorithm to calculate the MI in the case of probability density function (PDF) with regenerative property is given. The MI calculation method is based on random sampling, which can reduce the computational complexity. The simulation results show our entropy-rate framework can be employed in analysis for the capacity of FIR actuator.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_1
DP  - Springer Link
SP  - 1
EP  - 8
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_1.pdf
KW  - Entropy
KW  - FIR Actuator
KW  - Information Theory
ER  - 

TY  - CONF
TI  - Depth Completion Using Infinity Laplacian Based on Steering Positive Definite Metric Operator Plus Convolutional Stage
AU  - Lazcano, Vanel
AU  - Calderero, Felipe
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - Depth completion is an important task for autonomous vehicles, video games, and many others applications. Frequently depth maps present holes or data with low confidence level. This paper is devoted to the guided depth completion problem using a scene color reference image to guide the completion of a sparse depth map. In this paper we propose a model to complete the depth map based on an interpolator model and convolution stages enforcing color features of the reference image. In one hand, the interpolator we used is the infinity Laplacian (which is the simplest interpolator that holds a set of axioms). In the other hand, The convolutional stage is constructed using either Gabor filters (GF) or steering filters (SF). We tested different configuration of our proposal to find the best performance: i) SF Stage-infinity Laplacian-GF Stage. ii) SF Stage-Steering kernel-GF Stage. iii) SF Stage-infinity Laplacian (based on Steering Positive Definite Operator)-GF Stage. These models were assessed in the publicly available KITTI Depth Completion Suite. Best performance was obtained by the model iii) outperforming our model previous version, and others contemporaneous models.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_14
DP  - Springer Link
SP  - 106
EP  - 113
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_14.pdf
ER  - 

TY  - CONF
TI  - Multi-scale Channel Attention for Image Registration
AU  - Zhang, Jin
AU  - Zhang, Baoju
AU  - Zhang, Bo
AU  - Zhang, Cuiping
AU  - Sun, Youchen
AU  - Guo, Cong
AU  - Wang, Jiayuan
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - In recent years, image registration methods based on convolutional neural networks have achieved good results and operational advantages in deformable image registration. However, due to the intrinsic property of convolution, namely the limited size of the convolution kernel, the learning of global contextual information is lacking. In order to solve the above problems, this paper proposes a multi-scale channel attention image registration model (MCAReg-Net), which can learn multi-scale contextual information and effectively fuse features of different scales for more accurate image registration. To demonstrate the effectiveness of the experiments, we conduct a series of experiments on the OASIS dataset. The experimental results show that our method can achieve better performance compared with other state-of-the-art methods, which proves the effectiveness of our proposed method.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_7
DP  - Springer Link
SP  - 50
EP  - 56
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_7.pdf
KW  - channel attention
KW  - convolutional neural network
KW  - deformable image registration
KW  - multi-scale features
ER  - 

TY  - CONF
TI  - Heterogeneous Physical Layer Network Coding in the Presence of Symbol Asynchrony
AU  - Li, Shenshen
AU  - Xie, L. F.
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - In this paper, we address the vulnerability of Heterogeneous Physical-Layer Network Coding (HePNC) to a phase offset in end users’ signals. A measure studied previously is to have different network coding schemes for different phase offsets. Our study, however, considers symbol asynchrony between the end users in HePNC and investigates the joint effect of the phase and symbol offsets on HePNC. For this, we adopt an oversampling method on superimposed signals, construct a factor graph to capture the correlation between the signal samples, and design a belief propagation algorithm on the graph to detect the users’ transmit symbols. Several network coding schemes including the simple bitwise XOR are considered in our study. By simulation, we show that the symbol asynchrony can be a remedy to counter the adverse effect of the phase offset and in particular, for a symbol offset around half a symbol duration, the XOR coding suffices for all phase offsets.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_5
DP  - Springer Link
SP  - 33
EP  - 40
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_5.pdf
KW  - belief propagation
KW  - Heterogeneous physical-layer network coding
KW  - phase offset
KW  - symbol asynchrony
ER  - 

TY  - CONF
TI  - Location-Aware Heterogeneous Graph Neural Network for Region Recommendation
AU  - Bai, Liantao
AU  - Liu, Yaxing
AU  - Wang, Jun
AU  - Xu, Hengpeng
A2  - Liang, Qilian
A2  - Wang, Wei
A2  - Liu, Xin
A2  - Na, Zhenyu
A2  - Zhang, Baoju
T3  - Lecture Notes in Electrical Engineering
AB  - With the diversification of human activity and travel demand in urban space, recommending ROIs (region-of-interest) to users is important for both satisfying commercial demands and better understanding user urban lifestyles. Current researches mainly resort to the traditional POI-level (point-of-interest) or neural network-based recommendation methods for ROI recommendation, in disregard of the rich heterogeneous graph information, such as user-region-user, region-category-region, just to name a few. In this work, we employ the heterogeneous graph to address this issue, considering heterogeneous graph contains more comprehensive information and rich semantics. We propose a novel meta-path based graph attention network for ROI recommendation, called MRec. MRec is a newly devised heterogeneous graph neural network, which is equipped with both node-level and semantic-level attentions. Specially, the node-level attention aims to learn the importance between a node and its meta-path based neighbors, while the semantic-level attention is to learn the importance of different meta-paths. This mechanism contributes to effectively embedding users and ROIs in a hierarchical manner of fully considering both node and semantic-level component information. An extensive experiment on two real-world datasets demonstrates the effectiveness of the proposed framework.
C1  - Singapore
C3  - Communications, Signal Processing, and Systems
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2362-5_11
DP  - Springer Link
SP  - 81
EP  - 89
LA  - en
PB  - Springer Nature
SN  - 978-981-9923-62-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-2362-5_11.pdf
KW  - Attention network
KW  - Graph neural network
KW  - Heterogeneous information network
KW  - ROI recommendation
ER  - 

TY  - CONF
TI  - Design of Automatic Call-Test System for Charging Pile IoT Data Based on NB-IoT
AU  - Li, Haoran
AU  - Wang, Qian
AU  - Prabu, S.
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid development of electric vehicles, charging piles that provide charging behavior to meet the cruising range have been widely used. In order to facilitate remote monitoring and management of charging piles, Narrow Band Internet of Tings (NB-IoT) technology is widely used in the development and management of charging piles, helping to ensure the safe operation of charging piles. Therefore, this article combines the NB-IoT technology to design an automatic test system for charging pile IoT data. This article first designs the hardware structure of the data acquisition layer, and designs the hardware interfaces of the temperature and humidity acquisition circuit, the smart card information acquisition circuit, and the electrical energy information acquisition circuit. Based on the analysis of the fault types and characteristics of the charging facilities, by introducing the random forest model, the fault warning of the charging pile data is completed. The experimental data shows that the charging time of the charging pile port 2 has reached 10.7 h, and the charge is 2 times, and the cost is 19.26 yuan. It can be seen that various charging data will be generated during the charging operation of the charging pile, and the system can realize the automatic collection and monitoring of the charging pile IoT data.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_5
DP  - Springer Link
SP  - 34
EP  - 41
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_5.pdf
KW  - Charging Pile
KW  - Data Collection
KW  - Narrowband Internet of Things Technology
KW  - Random Forest
ER  - 

TY  - CONF
TI  - A Framework of Computer Network Security (NS) System and Its Application
AU  - Zhou, Huikui
AU  - Gu, Mudan
AU  - Puttamadappa, C.
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid improvement and development of computer technology and Internet technology, a global integrated information society has been formed. Therefore, people's dependence on computer network has increased rapidly. Computer network has become one of the important tools in people's daily work, life and learning. The development of society cannot leave the network. Only by continuously improving security protection technology, strengthening security management and discovering the security threats that enterprises may face, can we better use information tools to promote the better development of society. This paper roughly tests the risk value of computer network through DS theory and conducts a questionnaire survey on NS problems. The survey results show that more than 70% of people believe that NS problems are due to imperfect supervision, And 84% said that the risk to the network should be punished, which also shows that the NS problem in the Internet environment has become a highly valued security problem at present; At the same time, combined with DS theory and algorithm, the risk value of computer network is evaluated, and the framework and application of computer NS system are studied.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_8
DP  - Springer Link
SP  - 58
EP  - 65
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_8.pdf
KW  - Application of Safety System
KW  - Computer Network
KW  - Frame Structure
KW  - Security System
ER  - 

TY  - CONF
TI  - Traffic Spatial Data Management System Based on Data Mining
AU  - Xia, Li
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Data mining is an important research field emerging in the field of information technology in recent years. How to use advanced data mining to develop and implement a large-scale and diverse traffic spatial data management system has important research significance. The purpose of this paper is to study the traffic spatial data management system based on data mining. In this paper, the realization framework of the software system for short-term traffic flow prediction based on data mining and the application of intelligent traffic data mining platform are given. This paper proposes a road traffic flow spatial data mining algorithm, which uses the spatial distribution characteristics of traffic flow to divide the road traffic network into real-time and dynamic traffic areas. This paper focuses on the theory of data mining and big data, as well as the related processing technologies involved in the research process, and then expounds the application of data mining technology in the intelligent transportation spatial data management system, and the specific ideas and concepts used in the research process. In this paper, the absolute error is used to represent the size of the error, and the absolute error at all time points (time period 8:45 to 11:45) is statistically analyzed. The results show that the improved GM (1, 1) model is smaller than other methods. The GM (1, 1) model has better prediction stability.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_3
DP  - Springer Link
SP  - 17
EP  - 25
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_3.pdf
KW  - Data Management
KW  - Data Mining
KW  - Traffic Management
KW  - Traffic System
ER  - 

TY  - CONF
TI  - Intelligent Traffic Signal Control System Based on Machine Learning Algorithm
AU  - Wang, Jing
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Urban traffic signal control is an important part of modern intelligent transportation system. Traffic lights play an important role in regulating traffic flow at intersections and major road sections. How to use advanced control technology to achieve reasonable time allocation optimization of traffic lights, maximize the use of traffic time for traffic lights, and ensure smooth roads is one of the key contents of intelligent transportation research. This paper aims to study the intelligent traffic signal control system (ITSCS) based on machine learning algorithm. This paper analyzes the support vector machine algorithm in the machine learning algorithm, and analyzes the advantages and disadvantages of the support vector machine algorithm. It also analyzes the hardware structure of the ITSCS and the communication process between the devices of the ITSCS. Finally, the experimental results are obtained. The empirical analysis results show that the traditional ITSCS becomes more concise and convenient after the machine learning algorithm is adopted, and we conducted a questionnaire and found that more than 87% of the people feel that the design of the ITSCS applies machine learning algorithm, and found that the design efficiency has become higher.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_2
DP  - Springer Link
SP  - 9
EP  - 16
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_2.pdf
KW  - Intelligent Transportation
KW  - Machine Learning
KW  - Signal  Control
KW  - Support Vector Machines
ER  - 

TY  - CONF
TI  - Online Teaching System of French on Demand Based on Streaming Media Technology
AU  - Han, Lu
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Streaming media technology is a technical means that integrates data collection, compression, storage, transmission and communication, allowing users to obtain high-quality streaming media services anytime, anywhere, making the core technology of audio and video transmission more and more popular. It has injected new vitality and vitality into online teaching. The campus wireless WIFI has basically achieved full coverage, and the streaming media technology has flourished, providing the basic conditions for the online teaching of French listening on demand. Designing an online teaching system for French listening on demand based on streaming media, the main work includes three aspects: first, the composition of the VOD system; the second, the composition of the Nginx server; the third is the system architecture composed of data layer, service layer, processing layer and functional layer. The research results are advanced and applicable.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_11
DP  - Springer Link
SP  - 82
EP  - 91
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_11.pdf
KW  - Online On Demand
KW  - Streaming Media Technology
KW  - System Architecture
KW  - Teaching System
ER  - 

TY  - CONF
TI  - Using Deep Neural Network Learning Technology to Design of Intelligent Network Crawler on Big Data Platform
AU  - Zhang, Jing
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The paper first analyzes the working principle and technology analysis of intelligent network crawler based on big data platform. In particular, the working mechanism and improvement method of distributed network crawler are deeply discussed. The search strategy for the network crawler is optimized. This paper discusses the integration method of deep learning and convolutional neural network technology. The paper presents using deep neural network learning technology to design of intelligent network crawler on big data platform.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_6
DP  - Springer Link
SP  - 42
EP  - 49
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_6.pdf
KW  - Big data
KW  - Deep Learning
KW  - Hadoop
KW  - Internet Crawler
KW  - Neural Network
ER  - 

TY  - CONF
TI  - Development of Industry-University-Research Institute Collaborative Innovation Information Platform Based on Spring MVC Framework
AU  - Liu, Na
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Spring MVC framework is actually the Spring Web MVC module in the Spring Framework to provide greater security and scalability to the system users. Spring MVC framework is designed around DispatcherServlet, similar to the function of Struts ActionServle, the whole process of user requests to processing, effectively solving the complexities of application development. This paper analyses the principle of Spring MVC framework, constructs a three-dimensional model of Industry-University-Research Collaborative Innovation, designs the system functions through the use case diagram of Industry-University- Research Collaborative Innovation Information Platform, and realizes the Industry-University-Research Collaborative Innovation Information Platform based on Spring MVC framework. The research results provide guarantee for universities, research institutions and enterprises to carry out industry-university-research activities.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_12
DP  - Springer Link
SP  - 92
EP  - 98
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_12.pdf
KW  - 3D Model
KW  - Collaborative Innovation Information Platform
KW  - Platform Implementation
KW  - Spring MVC Framework
KW  - Use Case Diagram
ER  - 

TY  - CONF
TI  - Urban Electric Vehicle Public Charging Network Based on 5G and Big Data
AU  - Yao, Weijing
AU  - Zhang, Cheng
AU  - Deng, Guoru
AU  - Qi, Fang
AU  - Hu, Chen
AU  - Li, Lei
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In view of the current environment, electric vehicles are the most possible means of transportation to avoid air deterioration. The area of environmental pollution has also been greatly reduced, and problems such as lack of resources have been gradually solved. The birth of the electric vehicle is very in line with the needs of the public, solving most of the residents’ travel problems and reducing travel costs. Due to the rapid power consumption of electric vehicles, the public charging equipment of urban electric vehicles is needed. The public charging network is a huge architecture, which needs to consider the location and power supply of the grid. Therefore, this paper puts forward the research of urban electric vehicle public charging network based on 5G and big data. Taking 5G as the network service foundation of public charging network equipment, it provides efficient support for the transmission of big data and makes the public charging facilities quickly connected to achieve the effectiveness of charging facilities. To meet the needs of users, and avoid the work delay caused by untimely charging, the bus cannot run smoothly.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_18
DP  - Springer Link
SP  - 145
EP  - 152
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_18.pdf
KW  - 5G Network
KW  - Big Data
KW  - Electric Vehicle
KW  - Public Charging Network
ER  - 

TY  - CONF
TI  - Machine Translation Quality Evaluation Model Based on Data Mining Algorithm
AU  - Liu, Lei
AU  - Lu, Nan
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the development of today's society, the contact between countries is getting closer and closer. People in different countries use different languages. It is very important to enable people in different countries to solve the first communication barrier and solve the language problem. In this environment, the technology of machine translation is becoming more and more mature. Relying on machine translation, people can not only understand the literature of different countries and regions, but also help complete the basic daily work. Moreover, the efficiency of machine translation is also higher than that of manual translation, which can not only save human resources, but also speed up the work efficiency and greatly improve the speed of social development. Similarly, there is the amount of data with the improvement of technology, so it is particularly important to apply data mining algorithms to design a model that can meet the needs of machine translation and its quality evaluation in the era of big data. This paper makes some research on the machine translation quality evaluation model based on the data mining algorithm. Based on the basic attributes of the algorithm and the background significance of machine translation, the quality evaluation model is obtained through relevant experimental simulation. By analyzing the experimental data, it can be seen that the machine translation quality evaluation model can basically meet the needs.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_7
DP  - Springer Link
SP  - 50
EP  - 57
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_7.pdf
KW  - Data Mining Algorithm
KW  - Evaluation Model
KW  - Machine Translation
KW  - Quality Evaluation
ER  - 

TY  - CONF
TI  - Construction of Operation and Maintenance System of 5G New Media Platform Big Data System
AU  - Wu, Qinghai
AU  - Zhang, Zhiheng
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The arrival of 5G era and the mutual promotion and development of new media platform have become the inevitable trend of future development. By constructing the construction of big data system operation and maintenance system of new media platform, this paper explains in detail the current operation and maintenance system failure problems, and summarizes the new trend of 5G era from two aspects of big data system operation and maintenance system analysis and system construction.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_17
DP  - Springer Link
SP  - 137
EP  - 144
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_17.pdf
KW  - 5G
KW  - Big Data System
KW  - New Media Platform
KW  - Operation and Maintenance System
ER  - 

TY  - CONF
TI  - Design of Intelligent Prefabricated Building Real-Time Safety Management Monitoring Platform Based on Optimization Algorithm
AU  - Xiao, Chuanghai
AU  - Xiao, Bin
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid development of the national economy, the construction industry has become more and more important, and the construction industry has become an important pillar of the Chinese economy. However, with the rise of the construction industry, the number of workers is also increasing, among which casualties due to construction are not A few, which makes the construction industry gradually become a high-risk industry. This paper designs a real-time management and monitoring platform for intelligent prefabricated buildings combined with optimization algorithms. The real-time safety management monitoring platform is of great help to improve management efficiency and reduce potential safety hazards. Prefabricated building construction aims to improve the efficiency of land resource use, tap the potential of the city and improve People's living standards, optimization of traffic and other aspects can have a positive effect. In this paper, a real-time safety management and monitoring platform for prefabricated buildings is designed according to the relevant characteristics of the BIM optimization algorithm. The most obvious advantage of the BIM algorithm is that it can identify technical problems and safety hazards that may be encountered during the construction process as early as possible. Therefore, the use of BIM optimization algorithm for platform design can minimize the problems that workers may encounter in actual construction, thereby improving safety. 77 times, of which the accuracy rate is 96.25%, and the accuracy rate of reading books from the data remains above 94%. The reason for the error may be the error caused by the time delay.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_4
DP  - Springer Link
SP  - 26
EP  - 33
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_4.pdf
KW  - Construction Industry
KW  - Optimization Algorithms
KW  - Prefabricated Buildings
KW  - Safety Management Monitoring
ER  - 

TY  - CONF
TI  - Design of Public Health Incident Warning System Based on Decision Tree Model ID3 Algorithm
AU  - Xu, Jiaqi
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - The development of science and technology and the rapid development of economy have greatly increased the complexity and uncertainty of human society, and created a good hotbed for the occurrence of emergencies. Health emergencies, as a common emergency in all social emergencies, have a significant negative impact on citizens’ safety, health, economic development and social stability. The high mobility of social personnel and things brought about by modern convenient transportation also provides a channel for the rapid spread of public health emergencies. Therefore, the state attaches great importance to the monitoring and rapid response of public health emergencies, and the research on the emergency decision-making methods of public health emergencies is also a research hotspot of scientists around the world. We find that many of these components are difficult to quantify for public health, and are semi-structured or unstructured problems with a variety of uncertainties. In addition, there are many factors in historical data that do not have corresponding statistics, so it is difficult to conduct scientific calculation and evaluation. Therefore, it is urgent to use advanced information technology to strengthen the management of public health emergencies. Among them, data mining is an information technology with development potential in recent years. It extracts potentially useful information and knowledge from datasets that people do not know in advance. This is an extraordinary process, represented by the model of the final understanding. This technology can effectively strengthen government emergency management. The paper uses the literature research method and investigation method, using the data mining technology, analysis and test the data mining method in public health event early warning, management, analysis and evaluation, such as original ratio, neural network, decision tree, case-based argument analysis, provide new research perspective and problem solving methods.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_13
DP  - Springer Link
SP  - 99
EP  - 107
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_13.pdf
KW  - Data Mining
KW  - Decision Tree Model
KW  - ID3 Algorithm
KW  - Public Health Emergencies
ER  - 

TY  - CONF
TI  - Algorithm Design of Online Education Platform Based on Simulation Experiment
AU  - Meng, Ji
AU  - Liu, Xingna
AU  - Sridhar, Venugopal
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - This paper analyzes the design content of online simulation experiment platform from the perspectives of necessity, functionality, sub-modules, basic components and deployment. Its necessity is based on the consideration of cost and epidemic situation teaching. Its functionality includes user registration, cloud synchronization, simulation teaching, process recording, educational resource sharing, self-assessment and convergence learning. The sub-modules include user management, experimental teaching, online communication and evaluation. The basic components include database, human-computer interaction, simulation experiment, online video editing, basic communication, etc. The deployment design covers the dimensions of platform operation efficiency, security, ease of use and operation and maintenance cost. With the rise of online education industry of simulation experiment, the corresponding systematic design scheme will gradually mature and perfect.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_15
DP  - Springer Link
SP  - 118
EP  - 127
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_15.pdf
KW  - Algorithm
KW  - Online Education
KW  - Simulation Experiment
ER  - 

TY  - CONF
TI  - Vehicle Engineering Smart Device Based on Wearable Technology
AU  - Yan, Feifei
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid development of science and technology, wearable devices such as glasses, watches and so on have gradually come into people’s sight. At the major Internet events, the renewal speed of wearable devices is astonishing. In view of the good expectations of wearable devices in various consulting institutions, this paper carries out the development status quo of wearable intelligent devices in vehicle engineering today. Sort out the analysis. Based on the analysis of the renewal and development of high and new technologies such as operating system and mobile chip, the impact of wearable smart devices on future mobile application system and its surrounding areas is predicted.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_14
DP  - Springer Link
SP  - 108
EP  - 117
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_14.pdf
KW  - Smart Device
KW  - Technology Application
KW  - Vehicle Engineering
KW  - Wearable Technology
ER  - 

TY  - CONF
TI  - Big Data Direct Search Algorithm Based on Linear Programming
AU  - Ma, Xiaoxiao
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In some optimization problems, the expression of the objective function is more complex or difficult to express with an obvious analytical formula, so it is difficult or impossible to obtain its derivative, and only some calculations are required for the value of the objective function. The derivative method of the objective function is not involved. The purpose of this work is to study a direct search algorithm for big data based on linear programming. Analysis of market friction factors will be studied separately. In the empirical analysis of this work, the simulation analysis method is used to calculate the actual efficiency of the investment portfolio from the eligibility reduction model, and then the DEA model is used to carry out a modular evaluation of the effectiveness of the investment portfolio, and the correlation calculates the sum of the two return values. Taking into account the conscience constraints, the DEA model is used to evaluate the rationality and efficiency of portfolio efficiency. After sorting the portfolio DEA efficiency and real return ranking, the average correlation coefficient at K = 3 is 0.998, which is quite high.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_1
DP  - Springer Link
SP  - 1
EP  - 8
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_1.pdf
KW  - Algorithm Solution
KW  - Big Data Technology
KW  - Direct Search
KW  - Linear Programming
ER  - 

TY  - CONF
TI  - Bridge Structure Reinforcement and Reconstruction Technology Based on Mobile Navigation BIM
AU  - Fu, Junxi
AU  - Zhao, Kunpeng
AU  - Chen, Jiangxue
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the development of the world’s social economy, governments around the world pay more and more attention to the field of infrastructure construction. The bridge has gradually become an important node in the world’s infrastructure construction. The number of related projects of large and super large bridges has also increased rapidly. At the same time, the social demand for bridge construction and construction wages is also increasing. At present, BIM Technology has slowly spread from the construction industry to the whole urban field. Based on the analysis of bridge structure reinforcement and reconstruction technology of BIM based on mobile navigation, this paper discusses and analyzes the design process of BIM Technology Applied to bridge reinforcement and reconstruction, remembers the overall design of mobile navigation, selects a bridge to test the normal service index of the whole bridge through the bridge evaluation algorithm, and tests the lower edge stress of the section in the service stage of the bridge under effective prestress when evaluating the bridge after strengthening with the lower edge stress of the beam. The test results show that the normal performance indexes of the bridge are less than 0.4. The test data of prestress loss of intelligent CFRP plate show that the strengthened bridge is in good condition and has no impact on the operation safety; The calculated stress at the lower edge of the section follows that the pressure is positive and the tension is negative. At this time, the structure is in the compression stage of the whole section and the bridge is in good condition.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_16
DP  - Springer Link
SP  - 128
EP  - 136
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_16.pdf
KW  - BIM Technology
KW  - Bridge Engineering
KW  - Bridge Structure Reinforcement
KW  - Mobile Navigation
KW  - Reconstruction Technology
ER  - 

TY  - CONF
TI  - Application of Mobile Virtual Reality to Computer Graphics and Image Processing Technology
AU  - Lyu, Mingming
AU  - Liu, Maomao
AU  - Lu, Zhaoqing
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the in-depth development of intelligent computer equipment and its related product technology, the direct interaction between human and intelligent computer software and hardware has gradually become an important part of daily life. Virtual reality technology to bring readers a new perceptual experience, can achieve that ordinary readers can directly by the body, sound and virtual reality scene in the world takes the form of digital reading content directly to communicate interaction, experience to perceive the real completely different from traditional planar read content of three dimensional interactive mode. This paper uses the mobile virtual reality technology to carry on the relevant experimental research on the computer image processing technology, and through the simulation experiment to establish the promotion of mobile virtual reality to the computer image processing technology.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_10
DP  - Springer Link
SP  - 74
EP  - 81
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_10.pdf
KW  - Algorithm
KW  - Graphic Image Processing
KW  - Mobile Virtual Reality
KW  - The Computer
ER  - 

TY  - CONF
TI  - Voice Compression Coding Scheme of Ground Penetrating Wireless Communication in Mines Based on Fuzzy Delta Modulation
AU  - Zhao, Hongyu
AU  - Ma, Zhenxing
AU  - Zhang, Zhiyong
AU  - Huo, Dayong
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Ground penetrating wireless communication in mines is a kind of wireless communication suitable for mine disaster relief, which has the problem of voice transmission difficulty, so it is necessary to compress and preprocess the voice signal to achieve the purpose of saving bandwidth. By analyzing the problems of the delta modulation voice compression coding scheme, this paper puts forward the fuzzy delta modulation as the voice compression coding scheme in ground penetrating wireless communication in mines, and establishes the simulation model. Matlab simulation results show that without considering the signal channel loss, when the sampling frequency is 32 kHz with the input of daily male voice signal, the recovered voice signal can be clearly recognized by the human ear, which can meet the needs of mine wireless communication.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_19
DP  - Springer Link
SP  - 153
EP  - 160
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_19.pdf
KW  - Fuzzy Delta Modulation
KW  - Ground Penetrating Communication
KW  - Voice Compression
ER  - 

TY  - CONF
TI  - Application of Computer Technology (CT) in 5G Communication Network
AU  - Mai, Zhijian
AU  - Chen, Chongjia
A2  - Atiquzzaman, Mohammed
A2  - Yen, Neil Yuwen
A2  - Xu, Zheng
T3  - Lecture Notes on Data Engineering and Communications Technologies
AB  - With the rapid development of Internet technology and intelligent technology, the wide application of 5g mobile communication technology has greatly improved the service quality of the communication industry and brought users a more smooth, convenient and fast communication experience. However, with the continuous progress of science and technology, the future mobile communication network will face more huge user groups and more complex business scenarios, which brings challenges such as massive data transmission and ultra-low delay communication to the bearer network. In order to use the limited network resources to create a better communication experience, there is an urgent need for more efficient and flexible resource allocation strategies to achieve high load transmission in high mobility and high timeliness business scenarios and optimize the resource utilization efficiency of the network. This paper discusses the resource optimization and task unloading technology of computer cloud computing. Combined with the transmission rate algorithm of communication network, this paper tests the service path delay and resource occupation of CT applied to 5g communication network, and compares it with traditional technology. The results show that the path delay of CT is reduced by about 13% compared with traditional technology. CT realizes the cross layer resource optimization under 5g architecture and provides more running resources for services; Compared with traditional technology, CT shows a decreasing trend in the occupation of resources, because CT can effectively improve the utilization of network resources by reasonably allocating the overall network across layers, so as to release some unnecessary carrying resources.
C1  - Singapore
C3  - Proceedings of the 4th International Conference on Big Data Analytics for Cyber-Physical System in Smart City - Volume 2
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-1157-8_9
DP  - Springer Link
SP  - 66
EP  - 73
LA  - en
PB  - Springer Nature
SN  - 978-981-9911-57-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-981-99-1157-8_9.pdf
KW  - 5g Communication
KW  - Application Research
KW  - Communication Network
KW  - Computer Technology
ER  - 

TY  - CONF
TI  - Off-Policy Training for Truncated TD($$\lambda $$) Boosted Soft Actor-Critic
AU  - Huang, Shiyu
AU  - Wang, Bin
AU  - Su, Hang
AU  - Li, Dong
AU  - Hao, Jianye
AU  - Zhu, Jun
AU  - Chen, Ting
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - TD($$\lambda $$λ) has become a crucial algorithm of modern reinforcement learning (RL). By introducing the trace decay parameter $$\lambda $$λ, TD($$\lambda $$λ) elegantly unifies Monte Carlo methods ($$\lambda =1$$λ=1) and one-step temporal difference prediction ($$\lambda =0$$λ=0), which can learn the optimal value significantly faster than extreme cases with an intermediate value of $$\lambda $$λ. However, it is mainly used in tabular or linear function approximation cases, which limits its practicality in large-scale learning and prevents it from adapting to modern deep RL methods. The main challenge of combining TD($$\lambda $$λ) with deep RL methods is the “deadly triad” problem between function approximation, bootstrapping and off-policy learning. To address this issue, we explore a new deep multi-step RL method, called SAC($$\lambda $$λ), to relieve this dilemma. Firstly, our method uses a new version of Soft Actor-Critic algorithm which stabilizes the learning of non-linear function approximation. Secondly, we introduce truncated TD($$\lambda $$λ) to reduce the impact of bootstrapping. Thirdly, we further use importance sampling as the off-policy correction. And the time complexity of the training process can be reduced via parallel updates and parameter sharing. Our experimental results show that SAC($$\lambda $$λ) can improve the training efficiency and the stability of off-policy learning. Our ablation study also shows the impact of changes in trace decay parameter $$\lambda $$λand emerges some insights on how to choose an appropriate $$\lambda $$λ.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_4
DP  - Springer Link
SP  - 46
EP  - 59
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_4.pdf
KW  - Deep reinforcement learning
KW  - Off-policy
KW  - Soft Actor-Critic
KW  - TD(\(\lambda \))
ER  - 

TY  - CONF
TI  - ANF: Attention-Based Noise Filtering Strategy for Unsupervised Few-Shot Classification
AU  - Ni, Guangsen
AU  - Zhang, Hongguang
AU  - Zhao, Jing
AU  - Xu, Liyang
AU  - Yang, Wenjing
AU  - Lan, Long
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - How to learn concepts from few-shot samples remains an open challenge in the deep learning era. The previous meta-learning methods require a large number of annotated samples in the training phase, which still contributes to high manual-labeling costs. In this paper, we propose a unsupervised few-shot learning framework and pointed out that negative queue constructed via randomly sampling contains many false-negative samples (noise), which has negative impacts on the model’s generalized performance especially when only few samples are available. Specially, we propose an Attention-based Noise Filtering (ANF) strategy to make momentum contrastive loss more applicable to few-shot learning scenario. In addition, we also propose a dynamic momentum update method, which can greatly improve the classification accuracy. Our evaluations demonstrate state-of-the-art unsupervised few-shot learning performance, which is comparable to supervised baseline models.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_9
DP  - Springer Link
SP  - 109
EP  - 123
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
ST  - ANF
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_9.pdf
KW  - Attention mechanism
KW  - Computer vision
KW  - Self-supervised
KW  - Unsupervised few-shot learning
ER  - 

TY  - CONF
TI  - Diversity-Based Trajectory and Goal Selection with Hindsight Experience Replay
AU  - Dai, Tianhong
AU  - Liu, Hengyan
AU  - Arulkumaran, Kai
AU  - Ren, Guangyu
AU  - Bharath, Anil Anthony
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Hindsight experience replay (HER) is a goal relabelling technique typically used with off-policy deep reinforcement learning algorithms to solve goal-oriented tasks; it is well suited to robotic manipulation tasks that deliver only sparse rewards. In HER, both trajectories and transitions are sampled uniformly for training. However, not all of the agent’s experiences contribute equally to training, and so naive uniform sampling may lead to inefficient learning. In this paper, we propose diversity-based trajectory and goal selection with HER (DTGSH). Firstly, trajectories are sampled according to the diversity of the goal states as modelled by determinantal point processes (DPPs). Secondly, transitions with diverse goal states are selected from the trajectories by using k-DPPs. We evaluate DTGSH on five challenging robotic manipulation tasks in simulated robot environments, where we show that our method can learn more quickly and reach higher performance than other state-of-the-art approaches on all tasks.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_3
DP  - Springer Link
SP  - 32
EP  - 45
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_3.pdf
KW  - Deep reinforcement learning
KW  - Determinantal point processes
KW  - Hindsight experience replay
ER  - 

TY  - CONF
TI  - Consistency Regularization for Ensemble Model Based Reinforcement Learning
AU  - Jia, Ruonan
AU  - Li, Qingming
AU  - Huang, Wenzhen
AU  - Zhang, Junge
AU  - Li, Xiu
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - It’s generally believed that model-based reinforcement learning (RL) is more sample efficient than model-free RL. However, model-based RL methods typically suffer from model bias, which severely limits the asymptotic performance of the algorithm. Although previous model-based RL approaches use ensemble models to reduce the model error, we find that vanilla ensemble learning does not consider the model discrepancy. The discrepancy between different models is huge, which is not conducive to policy optimization. To alleviate the problem, this paper proposes an Ensemble Model Consistency Actor-Critic (EMC-AC) method to decrease the discrepancy between models while maintaining the model diversity. Specifically, we design ablation experiments to analyze the effects of the trade-off between diversity and consistency on the EMC-AC algorithm performance. Finally, extensive experiments on the continuous control benchmarks demonstrate that our approach achieves the significant performance to exceed the sample efficiency of prior model-based RL methods and to match the asymptotic performance of the state-of-the-art model-free RL algorithm.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_1
DP  - Springer Link
SP  - 3
EP  - 16
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_1.pdf
KW  - Consistency
KW  - Ensemble model
KW  - Model-based reinforcement learning
KW  - Sample efficiency
ER  - 

TY  - CONF
TI  - Batch-Constraint Inverse Reinforcement Learning
AU  - Chen, Mao
AU  - Wan, Li
AU  - Gou, Chunyan
AU  - Liao, Jiaolu
AU  - Wu, Shengjiang
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - We consider a completely offline inverse reinforcement learning setup, i.e., where the reward function is unknown and the interaction with the environment is not possible. This typically occurs in situations where data collection is risky or costly, such as healthcare or industrial controls. Establishing explainable rewards for decision-making is critical to quantifying and adapting policy. However, existing methods hardly learn an interpretable reward in offline setting. In this paper, we introduce an offline inverse reinforcement learning algorithm, BCIRL, to recover the implicit reward function and optimal policy from expert demonstrations in off-policy model-free settings. To address challenges in offline settings, we restrict the action space to behave close to the policy on the given data. We demonstrate that BCIRL performs strongly on control environment, that recovered rewards provide useful insights on experts’ preferences.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_6
DP  - Springer Link
SP  - 72
EP  - 82
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_6.pdf
KW  - Interpretable rewards
KW  - Inverse reinforcement learning
KW  - Offline reinforcement learning
ER  - 

TY  - CONF
TI  - Occlusion-Aware Facial Expression Recognition Based Region Re-weight Network
AU  - Zhang, Xinghai
AU  - Zhang, Xingming
AU  - Zhou, Jinzhao
AU  - Lin, Yubei
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Occlusion is a major obstacle for facial expression recognition (FER) in the wild, which can change facial appearance significantly. Current FER methods, although having achieved much progress in lab-constrained scenarios, suffers from partial occlusion remarkably. In this paper, we propose a novel Region Re-Weight Network (RRWN), to adaptively capture and emphasize the non-occluded areas of the face. RRWN contains two modules: Occlusion-Aware Module (OAM) and Block-Loss Module (BLM). More specifically, OAM works as an adaptive region selector in a convolutional neural network. It selects areas whose features made the best approximation to that of the whole face based on their feature similarity. BLM contains a region biased loss called Block-Loss to emphasize the role of key blocks. We validate our RRWN in four public expression datasets with occlusions: RAF-DB, FERPlus, AffectNet, and SFEW. Experiments show that our RRWN largely improves the performance of FER with occlusion.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_16
DP  - Springer Link
SP  - 209
EP  - 222
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_16.pdf
KW  - Facial expression recognition
KW  - Occlusion
KW  - Sparse representation
ER  - 

TY  - CONF
TI  - A Semi-supervised Defect Detection Method Based on Image Inpainting
AU  - Cao, Huibin
AU  - Lai, Yongxuan
AU  - Chen, Quan
AU  - Yang, Fan
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Defect detection plays an important role in the industrial field. Because the defective images are often insufficient and defects can be various, defective image synthesis is commonly used and models always tend to learn the distribution of defects. However, the complexity of defective image synthesis and difficulty of detecting unseen defects are still the main challenges. To solve these problems, this paper proposes a semi-supervised defect detection method based on image inpainting, denoted as SDDII, which combines the training strategies of CycleGAN and Pix2Pix. First, we train a defect generator unsupervisedly to generate defective images. Second, we train the defect inpaintor supervisedly using the generated images. Finally, the defect inpaintor is used to inpainting the defects, and the defective areas can be segmented by comparing images before and after inpainting. Without ground truth for training, SDDII achieves better results than the naive CycleGAN, and comparable results with UNET which is supervised learning. In addition, SDDII learns the distribution of contents in defect-free images so it has good adaptability for defects unseen before.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_8
DP  - Springer Link
SP  - 97
EP  - 108
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_8.pdf
KW  - Automated optical inspection
KW  - Defect detection
KW  - Generative adversarial networks
ER  - 

TY  - CONF
TI  - KG-RL: A Knowledge-Guided Reinforcement Learning for Massive Battle Games
AU  - Zhou, Shiyang
AU  - Ren, Weiya
AU  - Ren, Xiaoguang
AU  - Mi, Xianya
AU  - Yi, Xiaodong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - In a multi-agent game, the complexity of the environment increases exponentially as the number of agents increases. Learning becomes difficult when there are so many agents. Mean field multi-agent reinforcement learning (MFRL) uses the average action of the neighbors to increase the input of the value network, which can be applied in the environment with hundreds of agents. However, inefficient exploration and slow convergence speed limit the performance of the algorithm. In this article, we propose a new Knowledge-Guided Reinforcement Learning (KG-RL) method, which can be divided into rule-mix and plan-extend. We use the rule-mix to encode knowledge into plans which can reduce redundant information and invalid actions in the state. And the plan-extend can combine the result of rule-mix with reinforcement learning to achieve more efficient joint exploration. Through experiments in Magent environment, we prove that the win rate of our proposed KG-RL is 22% higher than that of knowledge-based decision tree and 39% higher than that of MFRL. Thus, the KG-RL can perform well in massive battle games due to its high exploration efficiency and fast convergence.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_7
DP  - Springer Link
SP  - 83
EP  - 94
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
ST  - KG-RL
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_7.pdf
KW  - Knowledge-guided
KW  - Massive battle games
KW  - Multi-agent
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - Adaptive Warm-Start MCTS in AlphaZero-Like Deep Reinforcement Learning
AU  - Wang, Hui
AU  - Preuss, Mike
AU  - Plaat, Aske
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - AlphaZero has achieved impressive performance in deep reinforcement learning by utilizing an architecture that combines search and training of a neural network in self-play. Many researchers are looking for ways to reproduce and improve results for other games/tasks. However, the architecture is designed to learn from scratch, tabula rasa, accepting a cold-start problem in self-play. Recently, a warm-start enhancement method for Monte Carlo Tree Search was proposed to improve the self-play starting phase. It employs a fixed parameter $$I^\prime $$I′to control the warm-start length. Improved performance was reported in small board games. In this paper we present results with an adaptive switch method. Experiments show that our approach works better than the fixed $$I^\prime $$I′, especially for “deep”, tactical, games (Othello and Connect Four). We conjecture that the adaptive value for $$I^\prime $$I′is also influenced by the size of the game, and that on average $$I^\prime $$I′will increase with game size. We conclude that AlphaZero-like deep reinforcement learning benefits from adaptive rollout based warm-start, as Rapid Action Value Estimate did for rollout-based reinforcement learning 15 years ago.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_5
DP  - Springer Link
SP  - 60
EP  - 71
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_5.pdf
KW  - AlphaZero
KW  - Deep reinforcement learning
KW  - MCTS
ER  - 

TY  - CONF
TI  - Object Bounding Box-Aware Embedding for Point Cloud Instance Segmentation
AU  - Cheng, Lixue
AU  - Yang, Taihai
AU  - Ma, Lizhuang
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - In 2D image domain, recent researches have made significant progress in encoding context information for instance segmentation. While the counterpart in point cloud is still left far behind. Previous works mostly focus on leveraging semantic information and aggregating point local information through K-Nearest-Neighbor method. Such methods are unaware of object boundary information which is important to separating nearby objects. We propose a novel module to integrate object bounding box information into embedding for Point Cloud Instance Segmentation. The proposed module called Object Bounding Box-aware module (OBAM) boosts the instance segmentation performance by encoding Object Bounding Box information. Through attention mechanism, the module removes redundant boundary information. Comprehensive experiments on two popular benchmarks (S3DIS and ScanNetV2) show the effectiveness of our method. Our method achieves the State-of-the-art instance segmentation performance on S3DIS benchmark.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_14
DP  - Springer Link
SP  - 182
EP  - 194
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_14.pdf
KW  - 3D point cloud
KW  - Instance segmentation
KW  - Object bounding box-aware
ER  - 

TY  - CONF
TI  - Detecting and Learning Against Unknown Opponents for Automated Negotiations
AU  - Wu, Leling
AU  - Chen, Siqi
AU  - Gao, Xiaoyang
AU  - Zheng, Yan
AU  - Hao, Jianye
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Learning in automated negotiations, while successful for many tasks in recent years, is still hard when coping with different types of opponents with unknown strategies. It is critically essential to learn about the opponents from observations and then find the best response in order to achieve efficient agreements. In this paper, we propose a novel framework named Deep BPR+ (DBPR+) negotiating agent framework, which includes two key components: a learning module to learn a new coping policy when encountering an opponent using a previously unseen strategy, and a policy reuse mechanism to efficiently detect the strategy of an opponent and select the optimal response policy from the policy library. The performance of the proposed DBPR+ agent is evaluated against winning agents of ANAC competitions under varied negotiation scenarios. The experimental results show that DBPR+ agent outperforms existing state-of-the-art agents, and is able to make efficient detection and optimal response against unknown opponents.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_2
DP  - Springer Link
SP  - 17
EP  - 31
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_2.pdf
KW  - Automated negotiation
KW  - Multi-agent system
KW  - Policy reuse
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - Learning to Synthesize and Remove Rain Unsupervisedly
AU  - Qi, Yinhe
AU  - Pan, Meng
AU  - Jin, Zhi
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Most existing single image deraining networks are trained in a supervised way, which relies on paired images including one clean image and one rain image. In most cases, the rain images are synthesized from the clean ones manually to obtain sufficient paired images. However, not only huge time costs but expert knowledge are needed to ensure the synthesized images are realistic enough. In addition, the superior performance of these deraining networks trained on manually synthesized rain images is hard to be maintained when testing on real rain images. To address these issues, we propose a scene adaptive asymmetric CycleGAN (SAA-CycleGAN) which transfers clean images to their rainy counterparts automatically so that adequate realistic rain images can be obtained for training deraining networks in a supervised way. Moreover, SAA-CycleGAN can both remove rain from rainy images and synthesize rain on clean images benefiting from the cycle consistency strategy. Since the information is not symmetric during the rain synthesis process and the deraining process, the generators are designed with different architecture accordingly for these two processes. Comprehensive experiments show that the SAA-CycleGAN is able to synthesize more lifelike rain images and achieve similar deraining performance compared with the state-of-the-art deraining methods.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_13
DP  - Springer Link
SP  - 166
EP  - 181
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_13.pdf
KW  - Attention mechanism
KW  - CycleGAN
KW  - Image deraining
KW  - Rain synthesis
ER  - 

TY  - CONF
TI  - Asymmetric Mutual Learning for Unsupervised Cross-Domain Person Re-identification
AU  - Huang, Danyang
AU  - Zhang, Lei
AU  - Diao, Qishuai
AU  - Wu, Wei
AU  - Zhou, Zhong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Unsupervised domain adaptation in person re-identification is a challenging task. The performance of models trained on a specific domain generally degrades significantly on other domains due to the domain gaps. State-of-the-art clustering-based cross-domain methods inevitably introduce noisy labels. The negative effects of noisy labels gradually accumulate during iterative training. Besides, optimizing with conventional triplet loss could make the model stuck in local optima in the late stage of domain adaptation. To mitigate the effects of noisy labels, this paper proposes an asymmetric mutual learning framework which cooperates two models with asymmetric labels. The learned asymmetric information is helpful for the two models to complement with each other. Specifically, we propose a merging clusters algorithm to generate asymmetric labels. We also introduce a similarity weighted loss which can further adapt the model to target domain. Extensive experiments demonstrate that our approach outperforms the state-of-the-art methods on three popular person re-identification datasets.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_10
DP  - Springer Link
SP  - 124
EP  - 137
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_10.pdf
KW  - Asymmetric mutual learning
KW  - Cross-domain
KW  - Person re-identification
KW  - Unsupervised
ER  - 

TY  - CONF
TI  - Online Multi-Object Tracking with Pose-Guided Object Location and Dual Self-Attention Network
AU  - Zhang, Xin
AU  - Wang, Shihao
AU  - Yang, Yuanzhe
AU  - Chu, Chengxiang
AU  - Zhou, Zhong
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - The recent trend in Multi-Object Tracking (MOT) is heading towards using deep learning to detect objects and extract features. Although tracking frameworks using detection network have achieved outstanding performance in object locating on MOT, it is still challenging for crowded occlusion. In this paper, we propose to alleviate this difficulty by combining bounding boxes from outputs of both object detection and pose estimation. The motivation behind generating redundant candidates is that object detection and pose estimation can complement each other in tracking scenes. In order to get optimal tracking objects from candidates, we present Soft-Pose-NMS. For similarity calculation, we design a Dual Self-Attention Network (DSAN) with the self-attention mechanism. The network generates the self-attention map that enables the network to focus on the object area of detection and tracklet images. Simultaneously, the network can extract the temporal self-attention feature map to suppress noisy images in the tracklet. Experiments are conducted on the MOT benchmark datasets. Results show that our tracker achieves competitive results and is state-of-the-art in half of the metrics.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_17
DP  - Springer Link
SP  - 223
EP  - 235
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_17.pdf
KW  - Dual self-attention network
KW  - Multi-object tracking
KW  - Person re-identification
ER  - 

TY  - CONF
TI  - Collaborative Positional-Motion Excitation Module for Efficient Action Recognition
AU  - Alsarhan, Tamam
AU  - Lu, Hongtao
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Massive progress for vision-based action recognition has been made in the last few years, owing to the advancement of deep convolutional neural networks (CNNs). In contrast with 2D CNN-based approaches, 3D CNN-based approaches can effectively capture spatial and temporal features. However, they are computationally intensive. To boost 2D-CNN performance, most of the existing methods leverage channel attention (e.g. squeeze and excitation), which despite its strong impact on the model performance, operates only on the channel space and ignores the spatial space. In this work, we design a generic and collaborative excitation module, namely the Collaborative Positional-Motion Excitation Module (CPME) for action recognition. CPME is a dual-pathway excitation module designed to embed the crucial types of information, mainly the positional information and the motion information, for efficient action recognition. Positional Enhancement Pathway (PEP), the first pathway of CPME, considers encoding direction-aware and position-sensitive information. Motion Enhancement Pathway (MEP), the second pathway, encodes the motion information by emphasizing the informative features in each frame and excite motion-sensitive channels. We integrate the proposed CPME into 2D CNNs to form a simple yet effective CPME-Net with limited extra computational cost. Finally, a discriminative and diverse video-level representation for action recognition is generated by end-to-end training. Experiments on two popular action recognition datasets demonstrate that CPME blocks bring performance improvements on 2D CNN baseline, and our method achieves competitive results against the state-of-the-art methods.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_11
DP  - Springer Link
SP  - 138
EP  - 151
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_11.pdf
KW  - Motion encoding
KW  - Spatio-temporal learning
KW  - Video action recognition
ER  - 

TY  - CONF
TI  - Graph Attention Convolutional Network with Motion Tempo Enhancement for Skeleton-Based Action Recognition
AU  - Bai, Ruwen
AU  - Meng, Xiang
AU  - Meng, Bo
AU  - Jiang, Miao
AU  - Ren, Junxing
AU  - Yang, Yang
AU  - Li, Min
AU  - Sun, Degang
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Graph convolutional network (GCN) exhibits advantages in handling non-Euclidean data. Previous works using spatio-temporal graph convolution for skeleton action recognition achieve good performance. However, several limitations still exist. First, the uniform modeling of joint motion assumes that the motion tempo of different joints remains constant, which ignores the dynamic changes in the position offset of each joint during the action. In this work, we propose a robust action feature extractor, graph attention convolutional network with motion tempo enhancement (MTEA-GCN), which captures different joint motion tempos with two streams. Second, the dependencies among bone-connected and spatially separated joints cannot be adequately considered from the graph topology based on the human physical connections. For this reason, we propose a multi-neighborhood graph attention convolution module that fully considers the dependencies among each joint and different neighborhood joints while focusing on discriminative joints. This study experiments on two large-scale skeleton datasets, including Kinetics-Skeleton and NTU RGB+D. Our proposed MTEA-GCN shows good performance with comparable computational complexity and fewer parameters.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_12
DP  - Springer Link
SP  - 152
EP  - 165
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_12.pdf
KW  - Graph convolution network
KW  - Human motion
KW  - Skeleton-based action recognition
ER  - 

TY  - CONF
TI  - Objects as Extreme Points
AU  - Yang, Yang
AU  - Li, Min
AU  - Meng, Bo
AU  - Huang, Zihao
AU  - Ren, Junxing
AU  - Sun, Degang
A2  - Pham, Duc Nghia
A2  - Theeramunkong, Thanaruk
A2  - Governatori, Guido
A2  - Liu, Fenrong
T3  - Lecture Notes in Computer Science
AB  - Object detection can be regarded as a pixel clustering task, and its boundary is determined by four extreme points (leftmost, top, rightmost, and bottom). However, most studies focus on the center or corner points of the object, which are conditional results of the extreme points. In this paper, we present an Extreme-Point-Prediction-Based object detector (EPP-Net), which directly regresses the relative displacement vector between each pixel and the four extreme points. We also propose a new metric to measure the similarity between two groups of extreme points, namely, Extreme Intersection over Union (EIoU), and incorporate this EIoU as a new regression loss. Moreover, we propose a novel branch to predict the EIoU between the ground-truth and the prediction results, and take it as the localization confidence to filter out poor detection results. On the MS-COCO dataset, our method achieves an average precision (AP) of 44.0% with ResNet-50 and an AP of 50.3% with ResNeXt-101-DCN. The proposed EPP-Net provides a new method to detect objects and achieves very competitive performance among the state-of-the-art anchor-free detectors.
C1  - Cham
C3  - PRICAI 2021: Trends in Artificial Intelligence
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89370-5_15
DP  - Springer Link
SP  - 195
EP  - 208
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89370-5
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89370-5_15.pdf
KW  - Extreme points
KW  - Localization
KW  - Object detection
KW  - Regression loss
ER  - 

TY  - CONF
TI  - Research on Intelligent Manufacturing Training System Based on Industrial Metaverse
AU  - Zhou, Yuqi
AU  - Li, Tan
AU  - Li, Bohu
AU  - Wu, Gang
AU  - Meng, Xianghui
AU  - Guo, Jin
AU  - Wan, Nengwen
AU  - Zhu, Jingyu
AU  - Li, Shimei
AU  - Song, Weining
AU  - Su, Chunhui
AU  - Chen, Nanjiang
AU  - Xing, Yalan
AU  - Wang, Qi
AU  - Lin, Yanwen
AU  - Li, Runqiang
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Skilled human resource becomes an essential resource for implementing intelligent manufacturing in the new era, prompting high demands on Intelligent Manufacturing Training (IMT). Empowering the effective IMT, the new mode of IMT based on Industrial Metaverse is proposed as well as detailed comparison with traditional training modes. The layered technical architecture is discussed as a guidance for training system construction, as well as specific solutions for the six key technologies based on primary research, including rapid modeling, natural interaction, real-time communication, industrial avatar/agent, industrial tools access, industrial AIGC, etc. Verifying the effectiveness of Industrial Metaverse based IMT, a prototype system “TrAiN” for industrial internet skill training is built, constructing a private Industrial Metaverse based on specific industrial equipment and fields in certain factory, facilitating the virtual training. Future research hotspots on Industrial Metaverse based IMT are prospected at the end based on the primary research and application.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_3
DP  - Springer Link
SP  - 28
EP  - 43
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Industrial Metaverse
KW  - Intelligent manufacturing
KW  - Training
ER  - 

TY  - CONF
TI  - A Multiview Approach to Tracking People in Crowded Scenes Using Fusion Feature Correlation
AU  - Chen, Kai
AU  - Huang, Yujie
AU  - Wang, Ziyuan
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Most of the current tracking methods for multi-target pedestrian tracking are unable to solve the problem where the tracking targets are blocked and reappears after disappearing in the camera perspectives, which brings great challenges to its practical application. To tackle this problem in dense crowds, we propose a multi-target pedestrian tracking method based on fusion feature correlation under multi-vision: Updating the pedestrian feature pool based on GMM to reduce the feature pollution; Then dynamically calculating the similarity threshold of target features based on K-means algorithm; Use the idea of voting to match pedestrian features and determine the addition and reappearance of pedestrians. The results on open dataset Shelf show that our method improve the accuracy and success rate of tracking under the condition of occlusion and reappearance after disappearance.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_16
DP  - Springer Link
SP  - 204
EP  - 217
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Dynamic threshold
KW  - Fusion feature
KW  - GMM
KW  - Multi-vision
KW  - Reappearance detection
ER  - 

TY  - CONF
TI  - Conceive-Design-Implement-Operate (CDIO) Approach in Producing Wiring Projects for Domestic Electrical Wiring Course
AU  - Jambari, Hanifah
AU  - Ismail, Nurul Farahin
AU  - Taman, Ishak
AU  - Pairin, Mohamad Rasidi
AU  - Hamzah, Muhammad Fathullah
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - This descriptive study aims to evaluate the Conceive-Design-Implement-Operate (CDIO) approach in producing wiring projects for the Domestic Electrical Wiring course among students from the Technical with Education courses at Universiti Teknologi Malaysia. This study is based on four main objectives, which are to evaluate the elements of “conceive, design, implement and operate” among students completing wiring projects in the Domestic Electrical Wiring course. The methodology used in this study is a quantitative. A set of questionnaires was used as a research instrument for data collection by distributing a Google form to respondents based on the research questions that have been constructed. The questionnaire used in this study was divided into five parts, namely Part A about demographics, Part B about the “conceive” element in electrical wiring, Part C about the “design” element in electrical wiring, Part D about the “implement” element in electrical wiring and Part E about the “operate” element in electrical wiring. The selection of respondents is random. The respondents of this study consisted of 110 students in the fourth and third year of electric and electronics, and life skills education programme. The results of the study were analysed using the Statistical Package for Social Science (SPSS) software version 26.0. Overall, the results of the study showed that students can design their work process according to the actual CDIO standards. In conclusion, this study is very important for students to complete their project properly on time, especially for students at the Institute of Technical and Vocational Education, Engineering and other related fields, as well as for teaching staff at the institutes related to the production of a project that is implemented.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_5
DP  - Springer Link
SP  - 60
EP  - 70
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Conceive
KW  - Design
KW  - Domestic Electrical Wiring Course
KW  - Implement
KW  - Operate
ER  - 

TY  - CONF
TI  - Enhancing Face Recognition Accuracy through Integration of YOLO v8 and Deep Learning: A Custom Recognition Model Approach
AU  - Daasan, Mahmoud Jameel Atta
AU  - Ishak, Mohamad Hafis Izran Bin
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Student attendance and being present during lectures plays a very important role in the value of the lesson and understanding of each student. There are a number of methods to record the attendance of the students such as signature on paper, QR code, RFID method and finally model based system. The most used method is signature of students even though it is mostly used it suffers from unethical behavior by some students and students forgetting to register their attendance. This research will develop a system to improve attendance registration accuracy by integrating it with custom recognition model. The class will be installed with a device that consists of a microcontroller and camera. The system will take an image of the class and send it to the database to be analyzed and then after recognizing the faces each face will be registered followed by the date and time it has been detected. All data will be stored in a database. The database can be accessed by the lecturers at the end of the class to review the attendance of students without the need to waste time on manually registering it.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_19
DP  - Springer Link
SP  - 242
EP  - 253
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
ST  - Enhancing Face Recognition Accuracy through Integration of YOLO v8 and Deep Learning
KW  - CNN
KW  - Deep learning
KW  - YOLO v8
ER  - 

TY  - CONF
TI  - Factors Influencing the Digital Skills of Technical Education Students
AU  - Hussin, Mohammad Fitri Hakimi Mat
AU  - Jambari, Hanifah
AU  - Taman, Ishak
AU  - Hamzah, Muhamad Fathullah
AU  - Mihad, Umi Salmah
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Digital skills are crucial technical competencies for students in higher education institutions. Weaknesses among students in utilizing digital technology can lead to moderate levels of learning achievement, consequently impacting the future graduates’ marketability in the job sector. Hence, the purpose of this study is to identify the factors influencing the acquisition of digital skills among Technology with Education (TE) students at Universiti Teknologi Malaysia (UTM). This quantitative survey involved a total of 87 final-year TE students from four programmes: Bachelor of Technology with Education; Electric and Electronics, Mechanical Engineering, Building Construction and Living Skills at UTM. The study utilized a questionnaire with 21 items, encompassing three key factors: facilities, quality of teaching by lecturers, and study environment. Data analysis was conducted using Statistical Package for the Social Sciences (SPSS) software version 26.0. The findings revealed that the mean scores for all three factors were at a moderate level. Consequently, enhancing TE students’ digital learning experiences should concentrate on these three factors to augment their academic achievements in today's digital era.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_8
DP  - Springer Link
SP  - 96
EP  - 104
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Digital Skills
KW  - Factors
KW  - Technical Education
ER  - 

TY  - CONF
TI  - Structured Teaching Using Drone Simulators for Students' Confidence in Real Flight
AU  - Nasir, Ahmad Nabil Md
AU  - Arsat, Mahyuddin
AU  - Noordin, Muhammad Khair
AU  - Sidek, Mohd Akhmal Muhamad
AU  - Tarmidi, Mohammad Zakri
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - A structured learning approach through the constructivism approach is a method that helps students build understanding in phases, from easy to difficult. The use of drone simulators in the subject of drone handling is a practical way to build understanding for students in phases. Good student understanding gives them the confidence to operate drones from virtual simulators to real through real drone operators. The study wants to see the relationship between the use of drone simulators and students’ confidence in operating real drones. A questionnaire served as the main research instrument. 35 students participated as purposive samples. This investigation can be divided into three sections; initial knowledge data before entering class, drone simulator data as simulator data, and real flight data collected afterward as final data - using both descriptive analyses such as mean, frequency analysis as well as inferential paired-sample T-Test to find relationships among them all. The findings of the study show that there is a significant difference between the students’ confidence before and after participating in the class on the actual handling of drones. This shows that the handling of dangerous drones in terms of safety needs to start with structured drone simulators to ensure that students can master the knowledge, technical and practical aspects of drones. It is hoped that this structured and phased teaching and management process can be done and developed for other courses as well. The findings of the study indicate that using structured drone simulators positively impacts students’ confidence in operating real drones. The results highlight the importance of starting with simulators to ensure that students can master the necessary knowledge, technical skills, and practical aspects of drone handling. This approach is seen as a safer way to introduce students to handling potentially dangerous drones while building their competence and self-assurance.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_10
DP  - Springer Link
SP  - 125
EP  - 136
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Drone Simulator
KW  - Structured Teaching Method
KW  - Student’s Confidence
ER  - 

TY  - CONF
TI  - Implementing Blockchain Technology for Accreditation and Degree Verification
AU  - Azli, Az Mukhlis Iskandar
AU  - Wahab, Nur Haliza Abdul
AU  - Zhang, DaYong
AU  - Kadir, Khairunnisa A.
AU  - Sunar, Noorhazirah
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - In the evolving academic landscape, the integrity of educational certificates is paramount. These documents serve as formal attestations of one's educational attainment, however, the increasing prevalence of document fraud undermines their credibility. To combat this, we introduce a robust, web-based certificate validation system Universiti Teknologi Malaysia's Blockchain-Based Accreditation and Verification System (UTM-BADVES). Built upon the transparent and immutable infrastructure of Blockchain technology, complemented with a diverse array of advanced technologies, UTM-BADVES offers a secure, efficient, and intuitive solution for real-time validation of academic credentials. The system focuses on data privacy, enabling transcript verification, selective data dissemination, and efficient credential revocation. By doing so, it significantly reduces the potential for academic credential fraud. Consequently, UTM-BADVES safeguards the integrity of educational qualifications, while simultaneously providing immense benefits for educational institutions, employers, and society as a whole. This paper delves into the design and application of UTM-BADVES, elucidating the crucial role it plays in maintaining the sanctity of academic certifications in the digital age.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_7
DP  - Springer Link
SP  - 81
EP  - 95
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Blockchain
KW  - Blockchain-based Verification
KW  - Decentralized Applications
ER  - 

TY  - CONF
TI  - FPGA Based Accelerator for Image Steganography
AU  - Sabeeh, Liqaa N.
AU  - Al-Ibadi, Mohammed A.
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - In this study, a novel approach is proposed for enhancing the speed and efficiency of steganography system by designing a hardware model that adopts the image-in-image (grey-in-color) method and utilizes the Least Significant Bit (LSB) algorithm. The sizes of secret and cover images are chosen so that all secret bits can be embedded inside the LSB bits of the pixels for the three RBG matrices for the cover image and produce the color stego-image. On the receiving part, these embedded secret bits will be extracted from stego-image and reform the original secret image. Using XSG and Vivado design suite, a successful FPGA-based steganography system was developed as an accelerator tool with high-speed processing that reaches 250 times faster than the software-based system. The quality of the stego-image and the extracted secret image was calculated by three metrics, which are the Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), and Cross Correlation (CCR). The comparison metrics values affirm a high level of trust in the generated stego-image, and the extracted secret image being identical to the original. The FPGA chip utilized in the implemented system consumes only 1% of the hardware resources, and a remarkable speedup factor of 250 is achieved, indicating that expanding the system for larger image sizes becomes highly feasible. Moreover, this expansion can be accomplished economically by utilizing low-cost field-programmable gate array (FPGA) chips.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_1
DP  - Springer Link
SP  - 1
EP  - 12
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - FPGA
KW  - LSB algorithm
KW  - Steganography
KW  - XSG
ER  - 

TY  - CONF
TI  - Use of Drone Flight Simulator for Bridging Theories of UAV Systems into Practice: A Pilot Study
AU  - Arsat, Mahyuddin
AU  - Nasir, Ahmad Nabil Md
AU  - Ismail, Lukman Hakim
AU  - Noordin, Muhammad Khair
AU  - Latif, Adibah Abdul
AU  - Arsat, Zainal Abidin
AU  - Rosli, Khairul Mirza
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Unmanned aerial vehicles (UAVs) are used in a variety of industries for a wide range of purposes. The UAV industry in Malaysia is experiencing an increase in demand for qualified workers, which has prompted Technical and Vocational Education and Training (TVET) institutions to introduce certification programs. These programs often rely on actual UAVs for training, which can be costly, restrict possibilities for hands-on practice, and present safety issues. Therefore, drone simulators have emerged as a learning tool to address the issue, recreating real-world operational environments for virtual pilot training and interaction. In order to comprehend participants’ understanding with learning through drone simulators, a qualitative research approach was adopted in this study. The researchers used an Unmanned Aerial Vehicle Technology Laboratory course as a pilot study to evaluate how students developed their understanding of flying principles while using UAV simulators. Semi-structured interviews were selected. A purposive sampling strategy was used to identify individuals who had completed the drone simulator sessions. Individual interviews were carried out to delve deeper into the experiences of the individuals. The findings of the study reveal three main categories: self-awareness, contextual understanding, and evaluating the effectiveness of practice. Self-awareness refers to students’ ability to reflect on their learning process and recognize how their theoretical understanding informs their practical application. Contextual understanding relates to students’ capacity to apply theoretical concepts within specific contexts. Evaluating the effectiveness of practice involves students critically assessing their own practice and identifying areas for improvement.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_11
DP  - Springer Link
SP  - 137
EP  - 145
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
ST  - Use of Drone Flight Simulator for Bridging Theories of UAV Systems into Practice
KW  - Drone Simulator
KW  - Simulation-based Learning
KW  - Students Learning Outcomes
ER  - 

TY  - CONF
TI  - Research on Data Acquisition and Real-Time Communication for Intelligent Manufacturing Training Equipment Based on Model of Things and Intranet Penetration
AU  - Wan, Nengwen
AU  - Zhang, Wenjun
AU  - Li, Tan
AU  - Chen, Meng
AU  - Song, Weining
AU  - Chen, Honglin
AU  - Zhu, Jingyu
AU  - Cao, Huifeng
AU  - Chen, Nanjiang
AU  - Wang, Qi
AU  - Lin, Yanwen
AU  - Li, Runqiang
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Intelligent Manufacturing Training Equipment (IMTE) are featured with high-value shareable training property and high security requirement on human-machine interaction, which prompt urgent demands on equipment sharing and virtual training of IMTEs based on Digital Twin (DT). Enabling the effective data acquisition and real-time interaction for the DT system construction for IMTEs, Data Acquisition Interface Definition and Cross-Network Real-Time Communication technologies are researched, including the universal IMTE data acquisition interface definition method based on Model of Things (MoT) and the real-time cross-network communication technology based on Intranet Penetration. A prototype IMTE DT system is built for the effectiveness verification on interface definition, acquisition and transferring of IMTE data, where the MoT of IMTE facilitates the PLC data collection and Intranet Penetration accelerates the data transfer, thus drive the real-time interaction between IMTE and the DT system, realizing the simplification of data acquisition and real-time cross-network communication for IMTEs.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_2
DP  - Springer Link
SP  - 13
EP  - 27
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Digital Twin
KW  - Intelligent Manufacturing
KW  - Intranet Penetration
KW  - IOT
KW  - Model of Things
KW  - Training equipment
ER  - 

TY  - CONF
TI  - Enhancement of System Network Based on Voltage Stability Indices Using FACTS Controllers
AU  - Aslan, Nur Izzati
AU  - Sapari, Norazliani Md.
AU  - Yusoff, Muhammad Syafiq Bin Md
AU  - Yusof, Khairul Huda
AU  - Dahalan, Mohd Rohaimi Mohd
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - As a result of rising load demand (particularly reactive load) and a lack of available generation sources, the power system is being operated close to its voltage instability point which may lead to voltage collapse. Therefore, to prevent voltage collapse, it is imperative to constantly monitor the power system’s voltage stability. This study uses Flexible AC Transmission System (FACTS) controllers to improve voltage stability in power systems. The goal is to assess how well voltage stability is improved by FACTS controllers. The MATPOWER toolbox in MATLAB is used to conduct load flow analysis on the IEEE 30 bus test system as a case study. Two voltage stability indices, the Fast Voltage Stability Index (FVSI) and the Novel Line Stability Index (NLSI) were used in the study to evaluate the system’s voltage stability. These indicators offer important details about the system’s capacity to sustain acceptable voltage levels under various operating circumstances. The simulation results reveal that the SVC-enabled shunt compensation method is the most successful at improving voltage stability. It is followed by shunt-series compensation, which uses the UPFC and exhibits notable improvements. Comparatively less successful at improving voltage stability is series correction, as represented by the TCSC. The result of this study provides insight into how FACTS controllers should be used to improve voltage stability. According to the findings, shunt compensation-based FACTS controllers perform better than series compensation-based controllers. This paper highlights the contribution to improving system stability by using FACTS devices.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_12
DP  - Springer Link
SP  - 146
EP  - 160
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - FACTS Controllers
KW  - Fast Voltage Stability Index (FVSI)
KW  - Load Flow Analysis
KW  - Novel Line Stability Index (NLSI)
KW  - SVC
KW  - TCSC
KW  - UPFC
KW  - Voltage Stability
ER  - 

TY  - CONF
TI  - Research on Matrix Factorization Recommendation Algorithm Based on Local Differential Privacy
AU  - Li, Yong
AU  - Song, Xiao
AU  - Zeng, Ruilin
AU  - Liu, Songsong
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Mobile Edge Computing (MEC) has gained significant attention in enhancing the efficiency of Recommendation systems. However, the trustworthiness of servers poses a challenge as they can potentially compromise user privacy. To address this issue, we propose a framework for matrix factorization-based recommendation using Local Differential Privacy (LDP). Initially, user data is perturbed using Piecewise Mechanism (a kind of LDP algorithm) and published to an edge server. The edge server performs basic computations on the perturbed data, while the cloud server employs matrix factorization to compute latent factors for users and items, which are then sent back to the edge server. Finally, the edge server computes similarity values and generates personalized recommendations for users. Through extensive simulations, our algorithm ensures recommendation accuracy while preserving user privacy. By comparing with the generalized differential privacy mechanism, the Piecewise Mechanism used in this paper has a better recommendation effect, thereby demonstrating its practical utility.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_18
DP  - Springer Link
SP  - 230
EP  - 241
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - LDP
KW  - Matrix Factorization
KW  - Recommendation Algorithm
ER  - 

TY  - CONF
TI  - Prototype Learning Based Realistic 3D Terrain Generation from User Semantics
AU  - Gao, Yan
AU  - Li, Jimeng
AU  - Xu, Jianzhong
AU  - Song, Xiao
AU  - Quan, Hongyan
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Customizing 3D terrain based on user semantics plays an important role in military simulation, but it is difficult to realize realistic results because of the limited ability of some simple Convolutional neural network (CNN) models. In order to meet the personalized needs of users, this article proposes a prototype learning based terrain generation network (ProTG Net). Concretely, it extracts terrain semantics based prototype features from a small number of terrain surface samples, and then transfers the pre-learned features to user customization. Specifically, a prototype learning based framework is designed, including a terrain texture generation module (TGM), prototype feature generation module (PGM), and multiple prototype features matching module (FMM). TGM is designed as the CGAN based Pix2pix (Pixel to Pixel) structure, which can generate realistic terrain textures based on user semantics, providing a reliable terrain texture data source for prototype learning. Based on the semantic terrain texture generated by TGM, multi-features are extracted in PGM including the adaptive super-pixel guided features and the terrain spatial feature. In addition, multiple feature matching strategy is proposed for achieving the better matching between prototype matching and user semantic features. Taking a public dataset of real terrain as an example, it was verified that the prototype based method can generate realistic 3D terrain and achieve user customization to obtain realistic results.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_17
DP  - Springer Link
SP  - 218
EP  - 229
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Feature
KW  - Prototype learning
KW  - Superpixel
KW  - Terrain
ER  - 

TY  - CONF
TI  - Ballet Gesture Recognition and Evaluation System (Posé Ballet): System Thinking, Design Thinking, and Dynamic Improvement in Three Versions from Laboratory to Art Gallery
AU  - Limmanee, Apirath
AU  - Sayyot, Peeraphon
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - This paper elaborates the design and implementation of “Posé Ballet,” the ballet gesture recognition and evaluation system using MS Kinect camera. “Posé Ballet” has gone through continual development which can be divided into three phases according to requirements from three different user groups. These three groups are ballet students, ballet teachers and dancers, as well as beginners and laypersons. After the technical side of the system is explained, we describe our “design thinking” concepts. With these concepts, our new and improved third-version software as well as GUI are developed to serve the visitors at Bangkok Art and Culture Centre (BACC). At the end, some results and feedback are collected. These give us insight on how to improve our system further toward the goal of being standardized or commercialized.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_9
DP  - Springer Link
SP  - 105
EP  - 124
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
ST  - Ballet Gesture Recognition and Evaluation System (Posé Ballet)
KW  - ballet
KW  - education technology
KW  - gesture recognition
KW  - human computer interaction
KW  - MS Kinect
KW  - serious games
ER  - 

TY  - CONF
TI  - Convolutional Transformer Network: Future Pedestrian Location in First-Person Videos Using Depth Map and 3D Pose
AU  - Chen, Kai
AU  - Huang, Yujie
AU  - Song, Xiao
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Future pedestrian trajectory prediction in first-person videos (egocentric videos) offers great prospects for autonomous vehicles and social robots. Given a first-person video stream, we aim to predict that person’s location and depth (distance between the observed person and the camera) in future frames. To locate the future trajectory of the person, we mainly consider the following three key factors: a) The image in the video sequence is the mapping of the actual 3D space scene on the 2D plane. We restore the spatial distribution of pedestrians in two-dimensional images to three-dimensional space. The distance of the pedestrian from the camera, which can be represented by the depth of the image, is the third dimension of information that is lost. b) First-person videos can utilize people’s 3D poses to represent intention interactions among people. c) The rules governing a pedestrian's historical trajectory are very important for the prediction of pedestrian's future trajectory. We incorporate these three factors into a multi-channel tensor to represent a deployment of the scene in three-dimensional space. We put this tensor into an end-to-end fully convolutional framework based on transformer architecture. Experimental results reveal our method to be effective on public benchmark MOT16.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_4
DP  - Springer Link
SP  - 44
EP  - 59
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
ST  - Convolutional Transformer Network
KW  - 3D pose
KW  - Attention
KW  - Convolutional Neural Network
KW  - Image depth
ER  - 

TY  - CONF
TI  - Analysis of Multi Criteria Decision Making (MCDM) Techniques for Load Shedding in Islanded Distributed System
AU  - Md Yusoff, Muhammad Syafiq Bin
AU  - Md Sapari, Norazliani
AU  - Aslan, Nur Izzati
AU  - Mohd Dahalan, Mohd Rohaimi
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - The modelling of a load shedding scheme in the islanded IEEE 33 bus system utilizing AHP and TOPSIS with voltage stability index and load value requirement is an important piece of research that attempts to improve the stability and reliability of power systems. Load shedding is an essential part of the operation of a power system, as it prevents blackouts and system failures. This research seeks to investigate and evaluate AHP and TOPSIS, two multi-criteria decision-making methodologies, for the selection of loads to be shed in a power system. In the analysis, the voltage stability index and load value requirements are also examined. The value of this study can be utilized to enhance the stability and dependability of power systems. This work can also serve as a basis for future research on power systems and multi-criteria decision-making. This study concludes with a complete examination of the AHP and TOPSIS methods for load shedding in power systems, demonstrating the potential for these methods to improve the stability and dependability of power systems.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_13
DP  - Springer Link
SP  - 161
EP  - 176
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Analytical Hierarchy Process
KW  - Distribution Network
KW  - Load Shedding
KW  - Multi-Criterion Decision Making method
KW  - Technique for Order of Preference by Similarity to Ideal Solution
KW  - Under Frequency Load Shedding Scheme
ER  - 

TY  - CONF
TI  - A Model Validation Method Based on Convolutional Neural Network
AU  - Fang, Ke
AU  - Huo, Ju
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Conventional model validation methods analyze outputs similarity between simulation and real world with same inputs. However, it is hard to guarantee the condition in practice. In order to solve the problem, a method based on convolutional neural network (CNN) is proposed, including data preprocessing, activation function, loss function, and optimization algorithm. Meanwhile, a CNN is established for model validation training and test. Finally, a case study of model validation is presented. The result shows that, the method can obtain 98.5% validation accuracy under the condition of same inputs, and can discriminate credibility levels with different inputs as well.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_15
DP  - Springer Link
SP  - 194
EP  - 203
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Convolutional Neural Network
KW  - Different Inputs
KW  - GRA
KW  - Model Validation
KW  - TIC
ER  - 

TY  - CONF
TI  - Students’ Digital Readiness in Vocational College for Industrial Revolution 4.0
AU  - Rosly, Nurul Azlynie
AU  - Jambari, Hanifah
AU  - Hamzah, Muhammad Fathullah
AU  - Mihad, Umi Salmah
AU  - Osman, Sharifah
AU  - Pairin, Mohamad Rasidi
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Students often encounter challenges in developing their digital technology skills, primarily due to a lack of proficiency in using computer applications, internet-based apps, and similar tools. The failure of graduates in mastering the digital technology has a negative effect on their ability to get a job related to Industrial Revolution 4.0 (IR4.0). Thus, the objective of this study is to identify students’ digital readiness for IR4.0 in the aspects of attitude, knowledge and technical skills at one of Vocational College in the Southern Zone in Malaysia. A total of 306 respondents were selected using the stratified random sampling. This study is quantitative method and the research instrument consists of a set of questionnaires containing 28 question items divided into Sections A, B, C and D. All the data collected through the questionnaires were analysed descriptively, using the Statistical Package for Social Science Version 20.0 (SPSS), to obtain frequency values, percentages, means and standard deviations. The results of the study reveal that the level of the students’ digital readiness for IR4.0 from the aspects of attitude, knowledge and technical skills is at a satisfactory level. The mean average value obtained for all the research questions is 3.34, and it is at a moderate score level. Therefore, vocational colleges need to pay more attention to students’ digital readiness for IR4.0 from the aspect of attitude, knowledge and technical skills, so that the graduates can meet the needs of the industry now, and propel the nation towards IR4.0.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_6
DP  - Springer Link
SP  - 71
EP  - 80
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - Attitude
KW  - Digital Skills
KW  - Knowledge
KW  - Technical Skills
ER  - 

TY  - CONF
TI  - Comparison of Diesel and Green Ship Carbon Emissions with A-Star Route Optimization
AU  - Ridwan, Mohammad Zakir Bin Mohd
AU  - Low, Malcolm Yoke Hean
AU  - Lin, Weidong
A2  - Hassan, Fazilah
A2  - Sunar, Noorhazirah
A2  - Mohd Basri, Mohd Ariffanan
A2  - Mahmud, Mohd Saiful Azimi
A2  - Ishak, Mohamad Hafis Izran
A2  - Mohamed Ali, Mohamed Sultan
T3  - Communications in Computer and Information Science
AB  - Approximately 2% of the world's carbon dioxide (CO2) emissions are attributed to international shipping, with the main source of carbon emissions from ships coming from the marine engines’ consumption of fossil fuels, especially heavy fuel oil. With the use of the A* algorithm for route optimization, this study compares the carbon emissions of diesel and greener ships by simulating the routing of 5000 TEU container ships through different weather conditions. In the study, data from dependable sources are gathered, carbon emissions are calculated, and routes are optimised utilising the A* algorithm. The outcomes show the discrepancies in carbon emissions between diesel and green ships, and the algorithm's success in lowering emissions through optimal route planning is demonstrated. The research highlights the significance of switching to more environmentally friendly options whilst providing useful information for the shipping industry. The study concludes with suggestions for more investigation and advancements in carbon emission reduction tactics. By utilizing the A* algorithm, this research enhances the study of ship emissions analysis while developing environmentally responsible behaviour in the marine industry.
C1  - Singapore
C3  - Methods and Applications for Modeling and Simulation of Complex Systems
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-7240-1_14
DP  - Springer Link
SP  - 177
EP  - 193
LA  - en
PB  - Springer Nature
SN  - 978-981-9972-40-1
KW  - A* algorithm
KW  - Decarbonization
KW  - Diesel Engine
KW  - Fuel Consumption
KW  - Sustainability
KW  - Weather-routing
ER  - 

TY  - CONF
TI  - Computational Optimization of Voids on 3D Woven Composites Truss Structures During Infusion
AU  - Koutsonas, Spiridon
AU  - Haroglu, Hasan
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Whole world has undertaken a low carbon emission process due to sustainability and the potential for composites to reduce greenhouse gas (CO2) is clear. Therefore, new composites truss structures materials with 3D woven continuous fibre reinforced composites will start to be used for civil, aerospace, automotive, and marine applications due to their lightweight, water resistance, their internal electrical conductivity and superior mechanical properties. The overall goal and attitude of this paper are to predict the fluid flow behaviour during the liquid infusion processes which are one of the most common manufacturing routes for composites and optimize computationally the high concentration of voids that may arise. Since experimentally this work is presented with high complexity and very expensive. The void formation can compromise the truss structure integrity and the final mechanical properties. The following research work tries to deal with the resin flow behaviour during impregnation affected by the preform properties, which are fibres orientation, and textile volume fractions, that can vary locally. Advanced composites truss structures are made of complex geometry which is made off 3D woven geometrically complex preforms, for better through-thickness properties. Thus making the impregnation process hard to control and potentially causing void defects in the manufacturing of the final component. Therefore, three-dimensional computational optimization scenarios are close realistic and can be used in the final manufacturing process of the truss structure.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_18
DP  - Springer Link
SP  - 326
EP  - 336
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_18.pdf
KW  - Advanced composite materials
KW  - Computational optimization
KW  - Liquid infusion
KW  - Truss structures
KW  - Void formation
ER  - 

TY  - CONF
TI  - Towards AGI: Cognitive Architecture Based on Hybrid and Bionic Principles
AU  - Dushkin, R. V.
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - The article describes the author's proposal on cognitive architecture for the development of a general-level artificial intelligent agent («strong» artificial intelligence). New principles for the development of such an architecture are proposed—a hybrid approach in artificial intelligence and bionics. The architecture diagram of the proposed solution is given and descriptions of possible areas of application are described. Strong artificial intelligence is a technical solution that can solve arbitrary cognitive tasks available to humans (human-level artificial intelligence) and even surpass the capabilities of human intelligence (artificial superintelligence). The fields of application of strong artificial intelligence are limitless—from solving current problems facing the human to completely new problems that are not yet available to human civilization or are still waiting for their discoverer. The novelty of the work lies in the author's approach to the construction of cognitive architecture, which has absorbed the results of many years of research in the field of artificial intelligence and the results of the analysis of cognitive architectures of other researchers. The relevance of the work is based on the indisputable fact that current research in the field of weak artificial intelligence is starting to slow down due to the impossibility of solving general problems, and most national strategies for the development of technologies in the field of artificial intelligence declare the need to develop new artificial intelligence technologies, including Artificial General Intelligence. The work will be of interest to scientists, engineers, and researchers working in the field of artificial intelligence in general, as well as to any interested readers seeking to keep abreast of modern technologies.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_19
DP  - Springer Link
SP  - 337
EP  - 345
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
ST  - Towards AGI
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_19.pdf
KW  - Artificial intelligence
KW  - Artificial intelligent agent
KW  - Bionic approach
KW  - Cognitive architecture
KW  - Explainability
KW  - Goal-setting
KW  - Hybrid artificial intelligence
KW  - Machine learning
KW  - Multisensory integration
KW  - Strong artificial intelligence
ER  - 

TY  - CONF
TI  - DevOps for Open Source Multimedia Frameworks
AU  - Zhao, Juan
AU  - Eoff, Ullysses
AU  - Luo, Focus
AU  - Xu, Guangxin
AU  - Xiang, Haihao
AU  - Zhong, Hongcheng
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - DevOps is well deployed in “Software As A Service”, “Platform As A Service” or a lot of closed-loop software services and products. “DevOps” implies the collaborations between the “Development” and “Operations” team to achieve the same goal of a better development cycle and customer experience. In the closed-loop software, the operations are fully controlled by one party or federation. But in the open source development world, the codes contributed by different individual contributors are maintained by several key maintainers, handling the complexity of the target customers in different domains. One example is the frameworks of the multimedia middleware that provide the media capability to Clouds, Clients and Internet of Things (IoT) products: FFmpeg and GStreamer with a fully open source working model. A better way is required to feed the difference brought by the open source working model. This paper proposed Cartwheel, pre-checkin with DevOps, and the open source tool VAAPI-fits to address these new issues. We introduced the background of Intel’s contributions to the multimedia middleware, as well as the methods engaging with the open source working model and DevOps methodologies.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_13
DP  - Springer Link
SP  - 244
EP  - 254
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_13.pdf
KW  - Automated testing
KW  - Continuous integration
KW  - DevOps
KW  - Multimedia framework
KW  - VAAPI-Fits
ER  - 

TY  - CONF
TI  - Orca: A Software Library for Parallel Computation of Symbolic Expressions via Remote Evaluation on MPI Systems
AU  - Yıldırım, Ahmet Artu
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - This study describes a Scheme library, named Orca, which is used to compute symbolic expressions in parallel via remote evaluation based on the message-passing interface (MPI) standard. Today, MPI is one of the most used standards, in particular high-performance computing systems. However, MPI programmers are explicitly required to deal with many complexities that render MPI programming hard to reason about. We designed and implemented a set of new APIs to alleviate this complexity by taking advantage of the expressive power of Scheme language using remote evaluation techniques on MPI systems. We introduce the application programming interface (API) of the library and evaluate the implemented model on a real-world application of a common parallel algorithm. Our experiments show that it is practical and useful for a variety of applications to exploit multiple processors of a distributed-memory architecture.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_10
DP  - Springer Link
SP  - 204
EP  - 217
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
ST  - Orca
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_10.pdf
KW  - Message-Passing Interface
KW  - MPI
KW  - Parallel computation
KW  - Remote evaluation
KW  - Scheme
KW  - Symbolic expression
ER  - 

TY  - CONF
TI  - Staff Rostering Optimization: Ideal Recommendations vs. Real-World Computing Challenges
AU  - Nurmi, Kimmo
AU  - Kyngäs, Jari
AU  - Kyngäs, Nico
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Staff rostering is a difficult and time-consuming problem that every company or institution that has employees working on shifts or on irregular working days must solve. The Finnish Institute of Occupational Health, which operates under the Ministry of Social Affairs and Health, published their recommendations for shift work in 2019. The recommended values for these individual factors are well justified. However, problems arise when all these recommendations should be satisfied together in real-world staff rostering. This paper shows what can be done to reach the best compromise considering the ideal recommendations, the employer’s point of view and the employees’ point of view. We use the PEAST metaheuristic, a computational intelligence framework, to show how the recommendations and employer requirements compete with each other. We give justification of why we can safely rely on the practical findings given by the metaheuristic.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_15
DP  - Springer Link
SP  - 274
EP  - 291
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
ST  - Staff Rostering Optimization
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_15.pdf
KW  - Computational intelligence
KW  - Nurse rostering
KW  - PEAST metaheuristic
KW  - Real-world computing
KW  - Shift scheduling
KW  - Shift work
KW  - Staff rostering
KW  - Workforce optimization
KW  - Workforce scheduling
ER  - 

TY  - CONF
TI  - Computer Scientist’s and Programmer’s View on Quantum Algorithms: Mapping Functions’ APIs and Inputs to Oracles
AU  - Gheorghe-Pop, Ilie-Daniel
AU  - Tcholtchev, Nikolay
AU  - Ritter, Tom
AU  - Hauswirth, Manfred
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Quantum Computing (QC) is a promising approach which is expected to boost the development of new services and applications. Specific addressable problems can be tackled through acceleration in computational time and advances with respect to the complexity of the problems, for which QC algorithms can support the solution search. However, QC currently remains a domain that is strongly dominated by a physics’ perspective. Indeed, in order to bring QC to industrial grade applications we need to consider multiple perspectives, especially the one of software engineering and software application/service programming. Following this line of thought, the current paper presents our computer scientist’s view on the aspect of black-box oracles, which are a key construct for the majority of currently available QC algorithms. Thereby, we observe the need for the input of API functions from the traditional world of software engineering and (web-)services to be mapped to the above mentioned black-box oracles. Hence, there is a clear requirement for automatically generating oracles for specific types of problems/algorithms based on the concrete input to the belonging APIs. In this paper, we discuss the above aspects and illustrate them on two QC algorithms, namely Deutsch-Jozsa and the Grover’s algorithm.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_9
DP  - Springer Link
SP  - 188
EP  - 203
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
ST  - Computer Scientist’s and Programmer’s View on Quantum Algorithms
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_9.pdf
KW  - API
KW  - Grover’s algorithm
KW  - Oracle
KW  - Quantum computing
ER  - 

TY  - CONF
TI  - A Novel GPU Implementation for Image Stripe Noise Removal
AU  - De Luca, Pasquale
AU  - Galletti, Ardelio
AU  - Marcellino, Livia
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Image processing is a class of procedures very helpful in several research fields. In a general scheme, a starting image generates a output image, or some image features, whose values are composed by using different methods. In particular, among image processing procedures, image restoration represents a current challenge to address. In this context the noise removal plays a central role. Here, we consider the specific problem of stripe noise removal. To this aim, in this paper we propose a novel Gaussian-based method that works in the frequency domain. Due to the large computational cost when using, in general, Gaussian related methods, a suitable parallel algorithm is presented. The parallel implementation is based on a specific strategy which relies the newest powerful of graphic accelerator such as NVIDIA GPUs, by combining CUDA kernels and OpenACC’s routines. The proposed algorithm exhibits good performance in term of quality and execution times. Tests and experiments show the quality of the restored images and the achieved performance.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_12
DP  - Springer Link
SP  - 232
EP  - 243
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_12.pdf
KW  - Gaussian filter
KW  - Image processing
KW  - Noise removing
KW  - Parallel computing
KW  - Stripe noise
ER  - 

TY  - CONF
TI  - The Design of Customizable Distributed Algorithms for InDiGO Framework
AU  - Kolesnikov, Valeriy
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - This paper presents an approach to designing general purpose distributed algorithms customizable to a specific operational context within InDiGO framework. To customize algorithms, they must be expressed in a form amenable to customization. We have developed a mechanism which allows a designer to expose design knowledge related to the communication structure of an algorithm. This involves identifying the interaction sets used for communication in an algorithm, and defining the semantics of these sets in terms of queries supported by the analysis infrastructure of the InDiGO framework.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_17
DP  - Springer Link
SP  - 311
EP  - 325
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_17.pdf
KW  - Customization
KW  - Distributed algorithms
KW  - Frameworks
KW  - InDiGO
ER  - 

TY  - CONF
TI  - Naming Processes in Multichannels with Beeps in the Weak Model
AU  - Aldawsari, Layla S.
AU  - Altman, Tom
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - A system of processes is examined that communicate with beeps in multiple channels. In the beeping model, the processes have limited communication where they can detect the presence of a signal (beep), or its absence (silence). In the weak model, the processes can choose to transmit a beep on one or more channels and can detect beeps and/or silence on all channels. The processes are anonymous and they begin without names to identify themselves. The objective is to develop distributed naming algorithms for two models when n is either known or unknown, where n is the number of processes. The Multichannel Many Beeps Naming algorithm is a Las Vegas algorithm developed for the model when n is known and that has an optimal time complexity of $$\mathcal {O}{(\log {n})}$$O(logn)rounds. When n is unknown, a Monte Carlo algorithm was developed, called the Unknown Multichannel Many Beeps Naming. It has an optimal time complexity of $$\mathcal {O}(\log {n})$$O(logn)rounds and a probability of success that is at least $$1-(n\log {n})^{-1}$$1-(nlogn)-1. These algorithms show an asymptotic improvement when compared to the existing naming algorithms for this model.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_5
DP  - Springer Link
SP  - 118
EP  - 132
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_5.pdf
KW  - Anonymous processes
KW  - Beeping channels
KW  - Distributed naming
KW  - Naming algorithm
ER  - 

TY  - CONF
TI  - Designing a Cost-Efficient Network for a Small Enterprise
AU  - Osemwengie, Lucky
AU  - Jafari, Fahimeh
AU  - Karami, Amin
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Reducing the cost of running a computer internet network in business cannot be over emphases in this current time of rising inflation. This paper assesses the cost of running an existing small enterprise network, called BCT Services Ltd, and suggests ways of reducing them. This will be done by; the introduction of solar panel, change in more scalable and less costly hardware, using more wireless access point in some areas and a different topology that is less costly to run. These changes have been designed in a proposed network scenario with Cisco Packet Tracer software for comparison with the existing one in the enterprise. In this paper, the parameter of interest is to know if the changes in the proposed network scenario will bring about the same amount of throughput in data or more. Our analyses and evaluations show that the proposed network scenario was more cost-efficient, as there was an improvement of over 100% data throughput compared with the current network, a cost savings of over £5,000 for five years period and other benefits like; reduce environmental pollution benefit from the solar panel.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_14
DP  - Springer Link
SP  - 255
EP  - 273
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_14.pdf
KW  - Communication network
KW  - Cost efficiency
KW  - Small enterprise
ER  - 

TY  - CONF
TI  - Distributed Evolution of Deep Autoencoders
AU  - Hajewski, Jeff
AU  - Oliveira, Suely
AU  - Xing, Xiaoyu
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Autoencoders have seen wide success in domains ranging from feature selection to information retrieval. Despite this success, designing an autoencoder for a given task remains a challenging undertaking due to the lack of firm intuition on how the backing neural network architectures of the encoder and decoder impact the overall performance of the autoencoder. In this work we present a distributed system that uses an efficient evolutionary algorithm to design a modular autoencoder. We demonstrate the effectiveness of this system on the tasks of manifold learning and image denoising. The system beats random search by nearly an order of magnitude on both tasks while achieving near linear horizontal scaling as additional worker nodes are added to the system.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_6
DP  - Springer Link
SP  - 133
EP  - 153
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_6.pdf
KW  - Distributed deep learning
KW  - Evolutionary algorithms
KW  - Neural architecture search
ER  - 

TY  - CONF
TI  - Solving High-Dimensional Nonlinear Equations with Infinite Solutions by the SVM Visualization Method
AU  - Lin, Yu-Yuan
AU  - Tzeng, Jeng-Nan
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - There are many standard mathematical methods for solving nonlinear equations. But when it comes to equations with infinite solutions in high dimension, the results from current methods are quite limited. Usually these methods apply to differentiable functions only and have to satisfy some conditions to converge during the iteration. Even if they converge, only one single root is found at a time. However, using the features of SVM, we present a simple fast method which could tell the distribution of these infinite solutions and is capable of finding approximation of the roots with accuracy up to at least $$10^{-12}$$10-12. In the same time, we could also have a visual understanding about these solutions.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_11
DP  - Springer Link
SP  - 218
EP  - 231
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_11.pdf
KW  - High-dimensional nonlinear equations
KW  - Infinite solutions
KW  - SVM
ER  - 

TY  - CONF
TI  - Resolution of the Frobenius Problem with an Adiabatic Quantum Computer
AU  - Ossorio-Castillo, J.
AU  - Tornero, José M.
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - The (Diophantine) Frobenius problem is a well-known NP-hard problem (also called the stamp problem or the chicken nugget problem) whose origins lie in the realm of combinatorial number theory. In this paper we present an algorithm which solves it, via a translation into a QUBO problem of the so-called Apéry set of a numerical semigroup. This algorithm was specifically designed to run in an adiabatic quantum computer (a D-Wave 2X machine), and the performance problems for this precise setting are also discussed.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_16
DP  - Springer Link
SP  - 292
EP  - 310
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_16.pdf
KW  - Adiabatic quantum computation
KW  - Frobenius problem
KW  - Numerical semigroups
KW  - Quantum computation
ER  - 

TY  - CONF
TI  - Multi-population Genetic Algorithm with the Actor Model Approach to Determine Optimal Braking Torques of the Articulated Vehicle
AU  - Warwas, Kornel
AU  - Tengler, Szymon
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - The paper presents an application of message driven optimization to control braking torques on wheels of an articulated vehicle to restore stability during an untripped rollover maneuver. The numerical model of the articulated vehicle and dynamic optimization have been used to calculate appropriate braking torques for each wheel in order to restore stability. The optimization problem requires the equations of motion to be integrated at each optimization step and it is a time-consuming task. Therefore, parallel computing with the use of the Actor Model system has been proposed. The Actor Model has been implemented in the Multi-Population Genetic Algorithm. This paper presents a formulation of Multi-Population Genetic Algorithm with the actor system and results obtained from dynamic optimization.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_2
DP  - Springer Link
SP  - 56
EP  - 74
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_2.pdf
KW  - Actor model
KW  - Articulated vehicle
KW  - Multi-population Genetic Algorithm
KW  - Multibody system
KW  - Optimization
KW  - Parallel computing
ER  - 

TY  - CONF
TI  - Accelerated Quantum Computation based on Quantum Coherent Dynamics of Evanescent Photons in Liquid Water
AU  - Caligiuri, Luigi Maxmilian
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - It has been shown how evanescent photons, produced in highly-coherent excited quantum states of liquid water, could be considered in order to perform quantum computations in a completely novel and still unexplored fashion by considering the formation of excited coherent quantum domains in liquid water, associated to cold vortex of quasi-free electrons, and their interaction through the mutual exchange of virtual evanescent photons, by quantum tunnel effect. Furthermore, the use of metamaterials to enclose water molecules, in order to form suitable waveguide for the evanescent photons generated inside water coherent domains, could allow for the implementation of a superfast network of interacting coherent domains able to represent a basic architecture for a novel kind of quantum hyper-computer based on the coherent dynamics of liquid water. This introduces a new frontier in the field of quantum computation, whose applications to both theoretical and advanced-technology fields (from the simulation of complex quantum systems to biotechnology, artificial intelligence, data encryption and decryption, etc.) would be very deep and nowadays unimaginable.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_8
DP  - Springer Link
SP  - 169
EP  - 187
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_8.pdf
KW  - Evanescent photons
KW  - Excited coherent domains
KW  - Liquid water
KW  - Metamaterials
KW  - Quantum electrodynamics coherence
KW  - Quantum hypercomputing
ER  - 

TY  - CONF
TI  - Scaling Out Transformer Models for Retrosynthesis on Supercomputers
AU  - Mollinga, Joris
AU  - Codreanu, Valeriu
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Retrosynthesis is the task of building a molecule from smaller precursor molecules. As shown in previous work, good results can be achieved on this task with the help of deep learning techniques, for example with the help of Transformer networks. Here the retrosynthesis task is treated as a machine translation problem where the Transformer network predicts the precursor molecules given a string representation of the target molecule. Previous research has focused on performing the training procedure on a single machine but in this article we investigate the effect of scaling the training of the Transformer networks for the retrosynthesis task on supercomputers. We investigate the issues that arise when scaling Transformers to multiple machines such as learning rate scheduling and choice of optimizer, and present strategies that improve results compared to previous research. By training on multiple machines we are able to increase the top-1 accuracy by $$2.5\%$$2.5%to $$43.6\%$$43.6%. In an attempt to improve results further, we experiment with increasing the number of parameters in the Transformer network but find that models are prone to overfitting, which can be attributed to the small dataset used for training the models. On these runs we manage to achieve a scaling efficiency of nearly $$70\%$$70%.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_4
DP  - Springer Link
SP  - 102
EP  - 117
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_4.pdf
KW  - Computer aided retrosynthesis
KW  - Deep learning
KW  - Deep learning on supercomputers
KW  - High performance computing
KW  - Transformer
ER  - 

TY  - CONF
TI  - A Novel Three-Way Merge Algorithm for HTML/XML Documents Using a Hidden Markov Model
AU  - Bakaoukas, Nikolaos G.
AU  - Bakaoukas, Anastasios G.
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Ever since the advent of modern World Wide Web (WWW), collaborative editing of Web Pages at a programming level (via HTML/XML) has been identified as a major programming challenge. Yet surprisingly, relatively little effort has been put into the direction of developing sound algorithms and methodologies for meeting this challenge by automated means. In this paper a novel algorithmic approach to merging HTML/XML code documents is presented that is based on the “Three-way Merge” approach using Hidden Markov Models, the “line-of-code-per-line-of-code” comparison between the documents involved and the “Nested Parenthesis” principle. The algorithm can be easily extended to any level higher than the “Three-way Merge”, with, of course, its computational complexity increasing accordingly.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_3
DP  - Springer Link
SP  - 75
EP  - 101
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_3.pdf
KW  - Algorithms
KW  - Document management
KW  - Hidden Markov models
KW  - HTML/XML diffing
KW  - Version control
ER  - 

TY  - CONF
TI  - Computational Power of a Hybrid Algorithm for Solving the Multiple Knapsack Problem with Setup
AU  - Boukhari, Samah
AU  - Dahmani, Isma
AU  - Hifi, Mhand
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - The Multiple Knapsack Problem with Setups (MKPS) belongs to the well-known NP-hard knapsack family, which represents an extended version of the binary multiple knapsack problem. In this paper, we study MKPS in which a set of families of items and a set of knapsacks are available. Each item is characterized by a knapsack-dependent profit and each family is associated with a knapsack-dependent cost. An item can be selected only if the corresponding family is activated and a family can only be setup in one knapsack. A key feature is that the activation of a family incurs a knapsack-dependent setup cost that should be considered both in the objective function and constraints. The setup cost varies with the knapsack and the goal consists in selecting appropriate items, from different families, to enter a knapsack while maximizing its value with respecting its capacity. We first propose a hybrid algorithm that combines the solution related to the mixed integer linear relaxation and a series of knapsack problems. The mixed linear relaxation can be viewed as the driving problem, where it is solved by using a special black-box solver while the series of knapsack try to build the solutions provided by calling the state-of-the-art Cplex solver. We then propose an enhanced version of the first method, where a series of valid constraints are added for providing a powerful method. The performance of the proposed methods are evaluated on benchmark instances of the literature, where their provided results are compared to those reached by the state-of-the-art Cplex solver and the best methods available in the literature. The computational power of the proposed method shows the importance of hybridization, especially for that type of problems.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_7
DP  - Springer Link
SP  - 154
EP  - 168
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_7.pdf
KW  - Knapsack
KW  - Local branching
KW  - Relaxation
KW  - Setups
ER  - 

TY  - CONF
TI  - Analytical View on Non-invasive Measurement of Moving Charge by Various Topologies of Wannier Qubit
AU  - Pomorski, Krzysztof
A2  - Arai, Kohei
T3  - Lecture Notes in Networks and Systems
AB  - Detection of moving charge in free space is presented in the framework of single electron CMOS devices. It opens the perspective for construction of new type detectors for beam diagnostic in accelerators. General phenomenological model of noise acting on position based qubit implemented in semiconductor quantum dots is given in the framework of simplistic tight-binding model. At first linear position-based qubit also known as Wannier qubit is considered with the situation of being excited by external movement of charged particle in its proximity. Analytical formulas describing the change of qubit state are derived analytically. In the next steps the roton semiconductor qubit representing closed loop of coupled quantum dots is given and the effect of external moving charge on the change of qubit state is determined by analytical formulas. Roton qubit physical state can be controlled by external magnetic and electric field what is the extension of controlling mechanism in comparison with linear Wannier qubit, when we have N quantum dots aligned.
C1  - Cham
C3  - Intelligent Computing
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-80119-9_1
DP  - Springer Link
SP  - 1
EP  - 55
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-80119-9
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-80119-9_1.pdf
KW  - Linear and circular Wannier qubits
KW  - Tight-binding model
KW  - Weak measurement
ER  - 

TY  - CONF
TI  - Personalized Recommendation of English Learning Based on Knowledge Graph and Graph Convolutional Network
AU  - Sun, Yuan
AU  - Liang, Jiaya
AU  - Niu, Pengchao
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of education, a large number of the online learning platforms have emerged. Although they provide the convenience to the students, they cannot provide students with in-depth personalized services. To solve this problem, in this paper, we propose a method to personalize the recommendation of English learning based on knowledge graph and graph convolutional network. Firstly, we construct a knowledge graph containing a large number of Junior High School English exercises, which are classified by the knowledge points. Secondly, a graph convolutional neural network is used to generate a personalized knowledge graph for each student. Finally, it provides students with in-depth personalized services by generating personalized learning path. The experimental results prove the effectiveness of our method.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_13
DP  - Springer Link
SP  - 157
EP  - 166
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_13.pdf
KW  - Graph convolutional network
KW  - Knowledge graph
KW  - Personalized learning path
ER  - 

TY  - CONF
TI  - Design and Implementation of Data Adapter in SWIM
AU  - Sun, Yangfei
AU  - Jiang, Yuanchun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - In the background of the globalized interaction needs of civil aviation information services, the definition of System Wide Information Management (SWIM) was proposed by International Civil Aviation Organization (ICAO). However, the issue of interaction between traditional business systems and heterogeneous systems still exists on the SWIM platform. The data adapter is an important functional component to solve this problem, which can not only solve the problems of high coupling among systems, poor compatibility, low sensitivity, non-standard syntax and poor semantics, but also realize the high sharing of information between systems. Based on the SWIM platform, this article redefines SWIM. First, this article analyzes the concept and architecture of SWIM as well as the role and logical architecture of adapters. Then, according to the requirements of the adapter, a design method of the adapter structure is proposed, and the process design methods of the two main functional modules, data transformation and service encapsulation, are proposed respectively, including data standard and service standard. Extensible Markup Language (XML) technology is a platform independent language, 90% of systems support XML, it is self-descriptive and extensible, suitable for storage and transport on the network, therefore it is the preferred language for software development and is important for the design of SWIM data adapter. Finally, the data adapter is designed and implemented.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_6
DP  - Springer Link
SP  - 70
EP  - 81
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_6.pdf
KW  - Adapter
KW  - Data conversion
KW  - Service encapsulation
KW  - SWIM
ER  - 

TY  - CONF
TI  - Exploring the Informationization of Land Reserve Archives Management
AU  - Zhu, YuXian
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Land Reserve is an innovation of land system reform in China, which plays an important role in promoting urban construction and economic development. The archives, as the historical records of the circulation of the Land tenure, have become an important part of the land reserve work and play an irreplaceable role in verifying it. It is a basic work in the whole land reserve undertaking, and also an important part of the National Archives System. Because the function of the Land Reserve Archives cannot be ignored, the corresponding archives management work needs to be raised to a new height. But in the actual work, there are many problems such as lack and lag, and the rapid development of information technology will also have a great impact on the traditional land reserve file management. The Land Reserve Archives Management Department has to take into account the present situation of its own archives management and actively explore corresponding strategies to meet the various challenges brought about by the information age in the light of the problems existing in the present reserve archives management work, only then can the information technology become the powerful power which promotes the file management to upgrade, promotes the land reserve work quickly and efficiently, realizes the land reserve file management informationization.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_3
DP  - Springer Link
SP  - 27
EP  - 40
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_3.pdf
KW  - File management
KW  - Information
KW  - Land reserve
ER  - 

TY  - CONF
TI  - An Empirical Study on Data Sampling for Just-in-Time Defect Prediction
AU  - Xu, Haitao
AU  - Duan, Ruifeng
AU  - Yang, Shengsong
AU  - Guo, Lei
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - In this paper, the impact of Data Sampling on Just-in-Time defect prediction is explored. We find that there is a significant negative relationship between the class imbalance ratio of the dataset and the performance of the instant software defect prediction model. Secondly although most software defect data are not as unbalanced as expected, a moderate degree of imbalance is sufficient to affect the performance of traditional learning. This means that if the training data for immediate software defects show moderate or more severe imbalances, one need not expect good defect prediction performance and the data sampling approach to balancing the training data can improve the performance of the model. Finally, the empirical approach shows that although the under-sampling method slightly improves model performance, the different sampling methods do not have a substantial impact on the evaluation of immediate software defect prediction models.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_5
DP  - Springer Link
SP  - 54
EP  - 69
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_5.pdf
KW  - Data sampling
KW  - Empirical study
KW  - Just-in-time defect
ER  - 

TY  - CONF
TI  - Research on Optimization of Data Balancing Partition Algorithm Based on Spark Platform
AU  - Wang, Suzhen
AU  - Jia, Zhiting
AU  - Wang, Wenli
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Aiming at the data skew problem in the Spark system caused by the unbalanced distribution of the input data and the default partition algorithm, this paper proposes an optimized partition method to solve the data skew problem. Firstly, the parallel cluster sampling algorithm is used to sample the intermediate data processed by each Map task to predict the data distribution. Then, the frequency of each Key is obtained according to the sampling prediction, and the weight is assigned to each Key. Finally, combining the greedy algorithm to divide the intermediate data to make the amount of data in each partition more balanced. Compared with the Hash and Range partitioning methods of the Spark platform and the SCID algorithm proposed by predecessors, experiments show this method effectively reduces the load deviation and reduces the task execution time.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_1
DP  - Springer Link
SP  - 3
EP  - 13
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_1.pdf
KW  - Data partition
KW  - Data skew
KW  - Load balancing
ER  - 

TY  - CONF
TI  - Efficient Utilization of Cache Resources for Content Delivery Network Based on Blockchain
AU  - Zhang, Hongyan
AU  - Liu, Bo
AU  - Qin, Long
AU  - Zhang, Jing
AU  - Gong, Weichao
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Content delivery network (CDN) has become an important means to alleviate network congestion and improve user service quality. However, with the emergence of new services such as short video and live streaming, traditional CDN has faced some challenges. In order to alleviate the lag problem of passive cache, we propose an active cache delivery scheme based on smart contract. In order to improve the utilization of storage resources in non-core locations of the network, we put forward the CDN-P2P network structure based on blockchain. Furthermore, the model predictive control (MPC) method is adopted to solve the joint optimization problem of bandwidth and delay in replica server selection. A large number of simulation experiments have been done to prove the effectiveness of our proposed scheme.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_11
DP  - Springer Link
SP  - 135
EP  - 146
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_11.pdf
KW  - Blockchain
KW  - Cache
KW  - Content delivery network
ER  - 

TY  - CONF
TI  - Graph Attention Network for Word Embeddings
AU  - Long, Yunfei
AU  - Xu, Huosheng
AU  - Qi, Pengyuan
AU  - Zhang, Liguo
AU  - Li, Jun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - The word embeddings approaches have attracted extensive attention and widely used in many natural language processing (NLP) tasks. Relatedness between words can be reflected in vector space by word embeddings. However, the current word embeddings approaches commonly do not explore the context-specific information of word deeply in the overall corpus. In this paper, we propose to use graph attention network for word embeddings. We build a large single word graph for a corpus based on word order, then learn a word embeddings graph attention network (WEGAT) for the corpus. Our WEGAT is initialized with one-hot representation for word. We propose to use masked language model (MLM) as supervised task. In addition, through the text classification experiment, it is showed that accuracy of the word embeddings represented by WEGAT is higher than the current method for the same classification method.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_16
DP  - Springer Link
SP  - 191
EP  - 201
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_16.pdf
KW  - Graph attention network
KW  - Word embeddings
KW  - Word graph
ER  - 

TY  - CONF
TI  - A Computing Task Offloading Scheme for Mobile Edge Computing
AU  - Ben, Wang
AU  - Tingrui, Li
AU  - Xun, Han
AU  - Huahui, Li
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - The mobile edge computing (MEC) technology sinks the computing and storage resources to the network edge and reaches the goal of improving user service quality by formulating reasonable task offloading strategies. As the number of edge users increases, the energy consumption and energy cost of the MEC are also increasing. Therefore, we investigated the task offloading problem in MEC, and proposed a computational task offloading scheme based on immune clone. Taking the minimization of energy cost as the objective and in consideration of the relationship between number of users unloaded in the computing and energy price. It can be solved by the immune clone algorithm and determined the optimal offloading scheme. Simulation results demonstrate the superiority of the proposed scheme over other the traditional task computing scheme. That this scheme can effectively reduce the system energy cost and improve the solving efficiency as compared to the traditional task computing scheme, in terms of the solving efficiency.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_9
DP  - Springer Link
SP  - 112
EP  - 123
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_9.pdf
KW  - Computing task offloading
KW  - Energy cost
KW  - Hybrid energy supply
KW  - Immune algorithm
KW  - Mobile edge computing
ER  - 

TY  - CONF
TI  - A Container-Oriented Virtual-Machine-Introspection-Based Security Monitor to Secure Containers in Cloud Computing
AU  - Yu, Zhaofeng
AU  - Ye, Lin
AU  - Zhang, Hongli
AU  - Zhan, Dongyang
AU  - Su, Shen
AU  - Tian, Zhihong
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - In recent years, container technology has been widely used in cloud computing, so the security monitoring technology for containers has also received widespread attention. To enhance the isolation of containers, cloud service providers usually run containers in different virtual machines. In this environment, in-container security tools can be detected or attacked by in-container attackers, and in-VM security tools face the risk of container escape attacks. This paper proposes a container-oriented virtual machine introspection technology to secure containers in cloud computing. It runs in cloud hypervisor and analyzes in-VM containers, so it is more secure and transparent. Even though there is container escaping to the operating system of VM, the security monitors are secure. Firstly, our approach automatically identifies the namespace and container processes in the virtual machine from outside by using virtual machine introspection technology. Secondly, security analysis is performed on processes belonging to different containers in the virtual machine, and our system can perform real-time abnormal response based on the analysis results. Finally, our system can monitor container escape behaviors from outside. Experimental results show that the approach proposed in this paper can automatically perform security analysis for different containers, and can monitor container escape behaviors with acceptable overhead.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_8
DP  - Springer Link
SP  - 102
EP  - 111
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_8.pdf
KW  - Container monitoring
KW  - External monitoring
KW  - Virtual machine introspection
ER  - 

TY  - CONF
TI  - Security Transmission Scheme of Sensitive Data for Mobile Terminal
AU  - He, Jicheng
AU  - Gao, Minghui
AU  - Zhang, Zhijun
AU  - Ma, Li
AU  - Ning, Zhiyan
AU  - Cao, Jingyi
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - In response to mobile terminal threats, this work is innovative, and gives practical solutions and prototype systems. The work first analyzes in detail the entire process of the generation, transmission and use of user-sensitive data within the Android system. In order to achieve resource sharing and data transmission between different applications and processes, the Android system provides a mechanism for inter-process communication based on Binder. Sensitive data is transmitted through Binder as a channel in the system. But sensitive data is carried out in the form of clear text during Binder transmission, which allows malware to easily intercept and tamper with sensitive data based on Binder communication, such as SMS content and GPS location information. In response to this problem, based on the above research, this work innovatively proposes and implements an adaptive transparent encryption protection scheme for sensitive data in the Android system from generation to use throughout the life cycle, effectively preventing sensitive data from being. The threat of theft and tampering by malicious third parties guarantees the privacy and integrity of user sensitive data during the internal transmission of the system. In addition, the system provides users with a simple and flexible operating experience, allowing users to independently protect specific types of sensitive data in specified applications, enhancing the ease of use and practicality of the system.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_10
DP  - Springer Link
SP  - 124
EP  - 134
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_10.pdf
KW  - Android
KW  - Mobile terminal
KW  - Security transmission
KW  - Sensitive data
ER  - 

TY  - CONF
TI  - Firewall Filtering Technology and Application Based on Decision Tree
AU  - Jin, Yujie
AU  - Wang, Qun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - In recent years, with the development of computer technology and communication technology, computer networks have developed rapidly to become an indispensable part of people's lives. In the same time, network attacks have been increasing exponentially. Countries around the world have raised network security issues to the height of their national strategies, which shows the importance of network security. Firewall is an important technology for network security at present, and it is a barrier to protect the internal network. However, in the era of information explosion, the data flow of network communication is very large, due to the limitations of memory, CPU, etc., firewalls will become a communication bottleneck. Therefore, this paper introduces the idea of machine learning into the filtering rules of the decision tree, and uses the optimized decision tree C4.5 algorithm to predict the optimal ranking of the firewall filtering rule table attributes, which improves the efficiency of the firewall and thus the throughputs of the firewall.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_17
DP  - Springer Link
SP  - 202
EP  - 215
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_17.pdf
KW  - Decision tree
KW  - Firewall
KW  - Information gain ratio
KW  - Packet Filtering
ER  - 

TY  - CONF
TI  - Detection of Virtual Machines Based on Thread Scheduling
AU  - Lin, Zhi
AU  - Song, Yubo
AU  - Wang, Junbo
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of cloud computing, virtual machines are now attracting more and more attention. Virtual machines used at malicious motivation cause enormous threats to the security of computer systems. Virtual machine detection is crucial for honeypot systems and software that provide free trials. Various strategies based on local register values affected by virtualization have been proposed. However, these strategies have a limited scope of application since they can only run natively. What’s more, the values they depend on can be modified with ease. In this paper, we propose a new remote virtual machine detection strategy applying to different types of virtual machines and different operating systems based on time difference in thread scheduling. Our main contribution is to set up a probability-based thread scheduling analysis model to describe the time difference between physical machines and virtual machines. This paper shows that the probability distribution of execution time of a piece of CPU-bound code in virtual machines has higher variance along with lower kurtosis and skewness, which make up our index system for detection. Results of Numeric simulation and real test show good agreement and provide a clear criterion for detection. In the real test all the virtual machines and 97.2% of the physical machines were identified correctly.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_15
DP  - Springer Link
SP  - 180
EP  - 190
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_15.pdf
KW  - Probability
KW  - Remote detection
KW  - Thread scheduling
KW  - Virtual machine
ER  - 

TY  - CONF
TI  - Research and Implementation of Anomaly Detection Algorithm in Data Mining
AU  - Zhou, Yang
AU  - Liu, Fazhou
AU  - Li, Shan
AU  - Guo, Chao
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - When data mining, there will be a lot of abnormal data, abnormal data refers to data in the data set that is inconsistent with most data or deviates from the normal behavior pattern. In this paper, the KNN (k-Nearest Neighbor) algorithm, the Local Outlier Factor algorithm, and the Isolation Forest algorithm will be used to process the MIT-BIH arrhythmia data set. The KNN algorithm is an Anomaly detection algorithm based on distance but may divide normal data into abnormal data due to the deviation of parameter selection. The improvement proposed in this paper is to add weight to the distance to reduce the probability of division error. The Isolation Forest algorithm divides the data according to the characteristics of the data and then predicts the data to be abnormal or normal data. The improvement proposed in this paper is to first select the features of the data, so that the algorithm can be more accurate when dividing the data, thereby improving the detection. Effect. In terms of visual display of test results, this article selects the Receiver Operating Characteristic Curve graph, which can intuitively show the detection effect of the algorithm.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_4
DP  - Springer Link
SP  - 41
EP  - 53
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_4.pdf
KW  - Anomaly detection algorithm
KW  - MIT-BIH arrhythmia dataset
KW  - Receiver operating characteristic curve
ER  - 

TY  - CONF
TI  - A Dynamic Processing Algorithm for Variable Data in Intranet Security Monitoring
AU  - Zhou, Chunru
AU  - Wu, Guo
AU  - Li, Junhao
AU  - Zhang, Chunrui
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Nowadays corporate Intranet Security Monitoring generally relies on SIEM products or SOC platforms. The data comes from a large number of system logs, application running logs and business data, which are generated by network device, security protection device and application systems, etc., is finally stored as normalized data after word segmentation, field parsing and data type mapping. The Intranet Security Monitoring are extremely sensitive to data quality because of the efficiency and accuracy requirements, but the continuous business changes and system upgrades in the intranet environment make both of the data structure and content variable. The existing automated log parsing algorithms are mainly aimed at system logs with a fixed structure, cannot handle variable data with multiple types and structures, besides, the parsing work only completes word segmentation and field parsing. As for data type identification and mapping, there should be several security experts to wait to write static templates, in case the data is changed. In response to the above problems, an ontology model of data knowledge for Intranet Security Monitoring is constructed, and using the computing power of cloud computing, a dynamic processing algorithm for variable data (DPAVD) based on structural information entropy is proposed, in which the correlation between data fields is used as the core factor, can reduce the interference caused by the difference in character expression and meet the requirements of high-quality data for Intranet Security Monitoring.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_12
DP  - Springer Link
SP  - 147
EP  - 156
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_12.pdf
KW  - Dynamic processing
KW  - Intranet security monitoring
KW  - Ontology model
KW  - Structural information
KW  - Variable data
ER  - 

TY  - CONF
TI  - Optimizing Data Placement in Multi-cloud Environments Considering Data Temperature
AU  - Wang, Pengwei
AU  - Wei, Yi
AU  - Zhang, Zhaohui
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Most data in the real world have spatial and temporal attributes, and some other essential data attributes also have temporal and spatial variability. In the research field of cloud and edge computing, these features always have great impact on data placement and task scheduling. However, these critical spatiotemporal features have been largely ignored by existing studies. To this end, this work firstly synthesizes data popularity, geographical location distribution and other spatiotemporal features to abstract the definition of data temperature, and a temperature calculation model is proposed to reflect the spatiotemporal correlation and variation trend. Then, we put forward a multi-cloud dynamic storage strategy considering data temperature to improve service quality and reflect the value of data temperature. Experiments are performed to evaluate the proposed strategy, which can effectively reduce the total cost and improve data availability.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_14
DP  - Springer Link
SP  - 167
EP  - 179
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_14.pdf
KW  - Data placement
KW  - Data temperature
KW  - Multi-cloud
KW  - Multi-objective optimization
KW  - Spatiotemporal features
ER  - 

TY  - CONF
TI  - Research and Implementation of Dimension Reduction Algorithm in Big Data Analysis
AU  - He, Si Yuan
AU  - Li, Shan
AU  - Guo, Chao
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - With the rapid development of computer and Internet technologies, these data are usually high-dimensional, and the huge amount of data information puts a burden on our calculation and information acquisition. Especially in the fields of data analysis and prediction, it is about that for us to obtain the target data efficiently. Big data analysis is a technique for quickly and efficiently extracting information from multiple types of data. The dimensionality reduction algorithm is an important part of it, which can help us quickly extract valuable parts from a huge amount of data and improve the efficiency of calculation. The core idea of the dimensionality reduction algorithm is to use a mapping method to map the data points in the original dimensional space to the low-dimensional space. This article mainly uses dimensionality reduction algorithms to deal with air quality data sets concept of data classification is introduced into the dimensionality reduction algorithm, which improves the accuracy of data dimensionality reduction. On this basis, a logistic regression algorithm is added, boulevard improving the effect of data visualization.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_2
DP  - Springer Link
SP  - 14
EP  - 26
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_2.pdf
KW  - Air quality
KW  - Big data analysis
KW  - Classification
KW  - Dimensionality reduction
ER  - 

TY  - CONF
TI  - Encrypted Medical Records Search with Supporting of Fuzzy Multi-keyword and Relevance Ranking
AU  - Li, Xiehua
AU  - Long, Gang
AU  - Li, Sijie
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Lecture Notes in Computer Science
AB  - Medical records are highly private and sensitive. To protect the information security of patients and medical institutes, medical records and data should be encrypted before outsourcing to the cloud storage. However, the retrieval of the encrypted data is currently a crucial issue of medical big data security. The existing searchable encryption methods can hardly satisfy the goals of fuzzy multi-keywords search, relevance ranking, access pattern protection and high retrieval efficiency simultaneously. Thus, in this paper, we propose an encrypted medical records searching scheme that can achieve those goals. A new spelling correction algorithm is proposed to support fuzzy multiple input keywords. A new relevance score encryption and calculation algorithm is introduced for ranking medical records with privacy preserving. In addition, a queue-based query procedure is also applied in this scheme to protect the access pattern from statistical attack and file-injection attack. Our proposed scheme achieves fuzzy matching without expending index table or sacrificing computational efficiency, and can support dynamic file updating. The theoretical analysis and experiment results show that our scheme is secure, accurate, error-tolerant and very efficient.
C1  - Cham
C3  - Artificial Intelligence and Security
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78612-0_7
DP  - Springer Link
SP  - 85
EP  - 101
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-78612-0
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-78612-0_7.pdf
KW  - Encrypted medical record
KW  - Fuzzy multi-keyword search
KW  - Relevance ranking
KW  - Searchable encryption
ER  - 

TY  - CONF
TI  - Identification of Experts in the Security Field Based on the Hypernet S-edgeRank Algorithm
AU  - Zhang, Yurui
AU  - Hong, Lei
AU  - Xu, Fan
AU  - Qian, Yiji
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - In recent years, national security has become increasingly important. However, since most security fields are still in their infancy and expert resources are scarce, governments and enterprises often fall into the predicament of not being able to effectively select experts and the evaluation system for experts is not scientific and objective. This paper draws on the PageRank algorithm, improves the transition matrix M and the damping coefficient d, and improves to the S-edgeRank algorithm, which is more suitable for the hypernet, which is a complex network, to calculate various metrics of the hypernet. Crawl CSSCI security-related papers, and build a hypernet with four layers of subnets of citation subnet, domain subnet, and keyword subnet. The S-edgeRank algorithm is used to rank experts and scholars in the thesis database, so as to effectively select experts in related fields, and provide a reference for more accurate and objective evaluation of the ability of experts and scholars in the follow-up.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_6
DP  - Springer Link
SP  - 70
EP  - 79
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_6.pdf
KW  - Expert identification
KW  - Hypernet
KW  - PageRank
KW  - Security field
KW  - Superedge rank
ER  - 

TY  - CONF
TI  - A High-Efficiency Blockchain Sharded Storage Expansion Model
AU  - Guo, Jinliang
AU  - Zhang, Jinquan
AU  - Wan, Wunan
AU  - Qin, Zhi
AU  - Pu, Huailin
AU  - Zhang, Shibin
AU  - Xia, Jinyue
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Blockchain is a new decentralized storage system that combines cryptography, consensus algorithms, distributed storage and other technologies. The full node redundant storage of data on the blockchain provides extremely high security, but while the redundant storage of the blockchain improves the security of the system, it also puts a lot of storage pressure on the nodes. The storage scalability problem of the blockchain has become a shortcoming restricting the development of blockchain technology. Sharded storage is a solution to the scalability of blockchain storage. While the existing sharded storage solution relieves the storage pressure of nodes, it also increases the computing and communication consumption of nodes, and reduces the efficient of blockchain systems. This article proposes a highly efficient fragmented storage model, which classifies blocks according to the frequency and size of the blocks being accessed, and uses different storage schemes for blocks of different classifications, which reduces the storage pressure of the node while controlling the computing and communication consumption of the node.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_15
DP  - Springer Link
SP  - 183
EP  - 193
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_15.pdf
KW  - Blockchain
KW  - Distributed storage
KW  - Sharded storage
ER  - 

TY  - CONF
TI  - A Blockchain-Based Risk Assessment Model for Heterogeneous Identity Alliance
AU  - Yang, Yanbo
AU  - Wan, Wunan
AU  - Zhang, Shibin
AU  - Zhang, Jinquan
AU  - Qin, Zhi
AU  - Xia, Jinyue
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Heterogeneous identity alliance technology solves the identity management problem under heterogeneous networks by building a unified and trusted identity management system, while the risk assessment system of heterogeneous identity alliance can analyze potential security problems in heterogeneous identity alliance in advance, so as to realize timely supervision and maintenance of identity when crossing domains and reduce the proliferation of security problems. A blockchain-based risk assessment model for heterogeneous identity alliance is proposed for existing risk assessment systems that are generally centralized architectures with single point of failure, internal mischief, and loss of control of user data. The model uses attribute encryption to guarantee the secure storage of privacy data, while ensuring that the control of risk assessment-related data is always in the hands of the data owner, and simplifies the three-stage PBFT (Practical Byzantine Fault Tolerance) consensus to two stages to improve the efficiency of risk assessment result processing. Finally, a comparison experiment shows that compared to the three-stage PBFT, the two-stage PBFT reduces the number of communications to reach consensus and improves the throughput by about 7%.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_2
DP  - Springer Link
SP  - 14
EP  - 27
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_2.pdf
KW  - Attribute-based encryption
KW  - Blockchain
KW  - Heterogeneous identity alliance
KW  - PBFT
KW  - Risk assessment
ER  - 

TY  - CONF
TI  - HuntFlow: Search the Arithmetic Vulnerability in Ethereum Smart Contract
AU  - Zhou, Ke
AU  - Cheng, Jieren
AU  - Liu, Le
AU  - Sheng, Victor S.
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the development of blockchain technology, smart contracts have been applied in more and more industries. Smart contracts are immutable once deployed, so unaudited smart contracts can easily cause economic losses. Arithmetic vulnerabilities usually refer to integer overflow vulnerability in smart contracts, and integer calculations in smart contracts are usually related to the transfer of digital assets. However, most of the existing smart contract auditing methods are inefficient and cannot be applied to the rapidly developing blockchain technology. To address these problems mentioned above, we propose a lightweight Ethereum smart contract arithmetic vulnerability detection model called HuntFlow, which can automatically detect the arithmetic vulnerabilities in the smart contract on a lightweight computer without expert knowledge. We first obfuscate 142 original opcodes into a set of 28 vulnerability features based on the characteristics of arithmetic vulnerabilities. And then we use Long-Short-Term-Memory (LSTM) network with attention mechanism for training and testing. The experimental result shows that the vulnerability features is better than original opcode for detecting arithmetic vulnerabilities. Moreover, the detection time of HuntFlow is greatly shortened than traditional tools, it costs only 0.028 s for each smart contract.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_13
DP  - Springer Link
SP  - 158
EP  - 168
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
ST  - HuntFlow
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_13.pdf
KW  - Arithmetic vulnerability
KW  - Blockchain
KW  - Ethereum
KW  - Smart contract
ER  - 

TY  - CONF
TI  - A Blockchain-Based IoT Data Secure Vickery Auction System
AU  - Wang, Haohui
AU  - Chen, Xiubo
AU  - Ahmad, Haseeb
AU  - Xu, Gang
AU  - Yang, Yixian
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Traditional centralized architectures for IoT data suffer from single points of failure in terms of data storage and access control, and IoT data does not fully realize its value as a digital asset. In response to the above challenges, we propose a decentralized storage and lightweight access control method for IoT data based on blockchain technology, and put forward an auction system to commercialize the IoT data. Firstly, a blockchain-based data storage method proposed using Inter Planetary File System (IPFS), which ensures the data is immutable and traceable. Secondly, in this paper, we propose a distributed lightweight Capability-Based Access Control (CapBAC) based on blockchain, in which a time dimension is added so that no additional token revocation operation is required. Thus, lightweight access control is achieved under IoT devices with limited computing power. Finally, we come up with a blockchain-based Vickery auction system to sell the data to the highest bidder in demand. This auction effectively protects the privacy of bidders and does not require third-party intermediary fees. And it can ensure fairness and non-repudiation of the auction. By analyzing the entire system process, we guarantee secure storage of IoT data. Besides, we can achieve lightweight access control and realize the value of the data based on the blockchain technology.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_10
DP  - Springer Link
SP  - 119
EP  - 133
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_10.pdf
KW  - Access control
KW  - Blockchain
KW  - Decentralized storage
KW  - Iot
KW  - Vickery auction
ER  - 

TY  - CONF
TI  - An Efficient Quantum Private Comparison Protocol Based on Cluster State and Bell State
AU  - Li, Chaoyang
AU  - Qing, Hua
AU  - Xu, Gang
AU  - Chen, Xiubo
AU  - Xin, Xiangjun
AU  - Dong, Mianxiong
AU  - Ota, Kaoru
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Quantum private comparison (QPC) is the quantum method that can compare the equality of the distrustful participants’ private information without leaking them. The 4-particle cluster state has a strong violation of local reality and shows to be robust against decoherence than any other 4-particle state. In this paper, a new efficient QPC protocol based on the entanglement swapping between the 4-particle cluster state and Bell state has been proposed. With the pre-shared secret key sequence between the two participants, the semi-honest third party (TP) can only execute the protocol’s processes without obtaining information about the participants’ secrets and the final comparison results. Then, we show that the proposed QPC protocol is secure against outside or participant attacks and more efficient than similar literature.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_8
DP  - Springer Link
SP  - 94
EP  - 105
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_8.pdf
KW  - 4-particle cluster state
KW  - Bell state
KW  - Quantum private comparison
KW  - Semi-honest third party
ER  - 

TY  - CONF
TI  - Deep Edge Defense for Industrial Internet Based on Customized Hardware and UOS Architecture
AU  - Wan, Ming
AU  - Xu, Xinlu
AU  - Zhao, Jianming
AU  - Yao, Jiangyuan
AU  - Lin, Xiu
AU  - Liu, Tingting
AU  - Cao, Xingcan
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the rocketing development of Industrial Internet, the edge control and acquisition networks have become one integral role in determining high-efficiency intelligent manufacturing and flexible production, and the edge security requirements have increasingly drawn widespread attention around the world. In order to strengthen industrial security capabilities, this paper designs a multifunctional deep edge defense system, which is developed on the customized hardware and popular UOS architecture. Furthermore, this system not only supports the basic data routing and forwarding between distinct network boundaries, but also provides some deep content checking and filtering services, which can block malicious attack traffics by setting effective security strategies. Additionally, the multi-scale log audit and authority management can enable the immediate analysis and accurate positioning on abnormal communication behaviors, and further improve the high availability and convenience. The long-term testing shows that this system has fine stability and robust defense capabilities under the comprehensive testing which integrates with different types of data traffics.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_1
DP  - Springer Link
SP  - 3
EP  - 13
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_1.pdf
KW  - Deep content checking and filtering
KW  - Edge defense
KW  - Log audit and authority management
KW  - UOS
ER  - 

TY  - CONF
TI  - Research on Personal Privacy Risks and Countermeasures in the Era of Big Data
AU  - Ye, Naifu
AU  - Yuan, Deyu
AU  - Meng, Yuyan
AU  - Ding, Meng
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Human society has entered the era of big data, and massive amounts of data and information are exchanged between application platforms at high speed. In contrast to the development of technology, the leakage of citizens’ personal privacy information in China has shown a spurt in recent years, and how to protect citizens’ privacy has become an urgent issue in today’s society. This paper uses model analysis and comparative analysis to explore personal privacy risks, analyses the internal and external factors affecting personal privacy risks in the era of big data and establishes a “trinity” personal privacy risk assessment model consisting of network service providers, Internet users and Internet regulators. This article also analyzes the model of federated learning framework, Secure multiparty computation, decentralization and Hawk block chain platform and DNN, model for privacy preservation. Suggestions and countermeasures are given in the article to strengthen personal privacy protection. It also provides recommendations and countermeasures for strengthening personal privacy protection.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_18
DP  - Springer Link
SP  - 222
EP  - 234
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_18.pdf
KW  - Big data
KW  - Personal privacy
KW  - Protection strategy
KW  - Risk assessment
ER  - 

TY  - CONF
TI  - The Principle and Implementation of Sentiment Analysis System
AU  - Xue, Jiani
AU  - Chen, Yuqi
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - The sentiment analysis system is one of the most classic applications in natural language processing and enduring. The development of the mobile Internet has greatly increased people's participation, and everyone can make their own comments on social media platforms such as Weibo. Through public opinion mining and emotional analysis of text information, a rich potential value of information can be obtained. However, in the face of a large number of comment data, how is it more convenient for public opinion workers to see the whole picture and take timely measures? This is the practical problem to be addressed in this article. The main work of this article is to build a public opinion emotional analysis system about Jiangsu Police Institute, to realize the emotional analysis of the comments related to Jiangsu Police Institute in Weibo and post bar. Then related workers are able to screen out the comments of negative emotions. The experimental dataset in this article is a training dataset composed of positive and negative reviews selected from JD commodity reviews, and the test data are random reviews selected from the microblog of Jiangsu Police Institute. This article details the processing of the Chinese comment text dataset. Because Chinese text is involved, the data is first partitioned using the jieba participle. After the data pre-processing, we input the processed data into the Word2Vec model, and set the relevant parameters according to the formatting rules of the word2vec, so that the dataset of text can be quantized to facilitate code learning.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_3
DP  - Springer Link
SP  - 28
EP  - 39
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_3.pdf
KW  - Bi-directional short-term and long-term memory recurrent neural networks
KW  - Natural language processing
KW  - Text emotion analysis
ER  - 

TY  - CONF
TI  - Formal Verification and Testing of Data Plane in Software-Defined Networks: A Survey
AU  - Yao, Jiangyuan
AU  - Jing, Min
AU  - Lin, Shengjun
AU  - Li, Deshun
AU  - Cao, Xingcan
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Software-defined network (SDN) separates the control plane and the data plane, which provides the programmability of the network and is widely deployed in data center networks. As the foundation of SDN, the data plane needs to be fully verified and tested to ensure its correctness and reliability. At present, formal verification and testing methods have been applied to SDN networks. The goals of verification and testing are to find the design defects and the implementation errors of the data plane, respectively. In this paper, we conduct a survey of the state-of-art methods and tools of formal verification and formal testing for SDN data plane. According to support for online verification, the related works of formal verification for the data plane fall into static verification and real-time verification. According to the requirement of source code, the existing works of formal testing for the data plane fall into white-box testing and black-box testing. Based on the state-of-art approaches of verification and testing, we also discuss the research trends of verification and testing for SDN data plane, such as artificial intelligence (AI)-based model construct and property definition, and scalable support for the stateful data plane.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_11
DP  - Springer Link
SP  - 134
EP  - 144
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
ST  - Formal Verification and Testing of Data Plane in Software-Defined Networks
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_11.pdf
KW  - Data plane
KW  - Formal method
KW  - Software-defined network (SDN)
KW  - Testing
KW  - Verification
ER  - 

TY  - CONF
TI  - Linkable Ring Signature Scheme from NTRU Lattice
AU  - Ye, Qing
AU  - Zhao, Nannan
AU  - Wang, Xiaojun
AU  - Pan, Deng
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - There are two serious security problems existing in blockchain: privacy protection problem and quantum attack problem. In order to address them, this paper studied the privacy protection technology of blockchain based on linkable ring signature (LRS) from NTRU lattice, and proposed a new LRS scheme from NTRU lattice whose signature length is $$O(\log M)$$O(logM), where M is the number of members in the ring. Firstly, the GGH standard method is used to construct the homomorphic commitment scheme on NTRU lattice based on the CVP problem of NTRU lattice. Then, based on the homomorphic commitment scheme, the Sigma-protocol on NTRU lattice is constructed. Finally, the protocol is transformed into a LRS scheme through Fiat-Shamir heuristic. The analysis shows that the LRS scheme proposed in this paper not only satisfies the anonymity and unforgeability, but also resists quantum computing attack. In terms of efficiency, since the proposed scheme is constructed based on Sigma-protocol on NTRU lattice, the signature length is $${O}\left( {\log M} \right) $$OlogM.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_4
DP  - Springer Link
SP  - 40
EP  - 53
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_4.pdf
KW  - Blockchain
KW  - Commitment scheme
KW  - NTRU lattice
KW  - Ring signature
ER  - 

TY  - CONF
TI  - Review of Security Choreography Research
AU  - Yu, Jiangping
AU  - Han, Yanyan
AU  - Zhu, Wenyu
AU  - Gao, Yuan
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Security choreography is a process of automatically detecting, preventing, and recovering network attacks without human interference by using a variety of combination technologies. It is the development trend of future network security and the premise of realizing network security automation. How to effectively arrange security resources and tools is an urgent problem to be solved. Security choreography technology, as an efficient means of security, has outstanding advantages such as script automation, reasonable allocation of resources, small cost, and large benefit, and has attracted more and more attention at home and abroad. This paper first introduces the background and basis of security choreography and analyzes the concept and development of security choreography. Secondly, the main quality attributes of long-term average return and stability of security orchestration are given, and the key technologies of security orchestration are summarized according to the quality attributes. Finally, the challenges of security choreography are summarized and the future research trends are pointed out.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_14
DP  - Springer Link
SP  - 169
EP  - 182
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_14.pdf
KW  - Rational allocation of resources
KW  - Security automation
KW  - Security orchestration
KW  - Wireless network virtualization
ER  - 

TY  - CONF
TI  - Reliable Collaboration Mechanism of Side End Resources for Discrete Services of Virtual Power Plants
AU  - Song, Jigao
AU  - Han, Bingyang
AU  - Guo, Jiahui
AU  - Chen, Xiaolu
AU  - Zhao, Baozhu
AU  - Wang, Shi
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - With the substantial increase in the number of participants in virtual power plants and the in-depth popularization of power Internet of Things, a large number of IoT terminals will be deployed on the internal and external networks of the system. Service terminals are connected to the network in different ways, and transmitted to the service system and cloud platform via the backbone network. In the process of data transmission and processing, the communication, computing, and storage resources required by the service terminal are highly heterogeneous and different. The bearing relationship between services and resources, and the connection relationship between resources in different network segments are complex, and it is impossible to Realize the integrated management of end-to-end resources. In response to the above problems, this paper proposes a MEC server collaborative computing model, which combines the computing capabilities of the service terminal itself and edge nodes to coordinate the offload rate between different devices to minimize the system's delay and energy consumption, and proposes A load balancing model that transfers tasks between overloaded and lightly loaded edge nodes to maximize system operating efficiency. Through simulation experiments, the method proposed in this paper effectively reduces the service delay and system energy consumption, and improves the reliability of the system.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_16
DP  - Springer Link
SP  - 194
EP  - 206
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_16.pdf
KW  - Artificial intelligence
KW  - Computation offloading
KW  - Machine learning
KW  - Mobile edge computing
KW  - Virtual power plant
ER  - 

TY  - CONF
TI  - A Blockchain-Assisted Key Generation Electric Health Records Sharing Scheme
AU  - Zhang, Qiao
AU  - Chen, Xiubo
AU  - Ahmad, Haseeb
AU  - Xu, Gang
AU  - Yang, Yixian
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Electronic health records (EHRs) contain a large amount of private data of patients. Once these data are compromised during the process of sharing, it may threaten the patients’ privacy. In this paper, a novel blockchain-assisted electronic health record sharing scheme is proposed, which utilizes attribute-based encryption (ABE) based on the consortium blockchain to realize the privacy protection in the sharing process of EHRs. Firstly, the master key is negotiated by all consensus nodes of consortium blockchain, no one knows the specific value of the master key. Consensus nodes are acted by medical institutions, they also responsible for generating and managing users’ private keys. Secondly, with the help of powerful cloud services, pre-decryption and ciphertext retrieval assignments are outsourced to cloud services for reducing the burden of blockchain. Thirdly, this scheme is also based on searchable encryption, which allows for quick ciphertext lookup from cloud services. Data owners can generate ciphertext indexes for their private data, and data users with retrieval trapdoors can quickly retrieve ciphertexts. Finally, the security and performance of blockchain-assisted electronic health record sharing scheme are analyzed in detail, the results show that our scheme is safe and feasible.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_12
DP  - Springer Link
SP  - 145
EP  - 157
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_12.pdf
KW  - Attribute-based encryption
KW  - Blockchain
KW  - Data sharing
KW  - Electronic health records
ER  - 

TY  - CONF
TI  - Pairing-Free Certificateless Key-Insulated Encryption with Keyword Search
AU  - Miao, Qing
AU  - Lu, Yang
AU  - Guo, Lan
AU  - Sun, Qi
AU  - Wang, Zhongqi
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Public key encryption with keyword search (PEKS) allows a user to make searches on ciphertexts without disclosing the information of encrypted messages and keywords. The certificateless public key encryption with keyword search scheme avoids the problems of public key certificate management and key escrow based on the realization of ciphertext retrieval. But in practice, key leakage is often difficult to avoid, and key leakage will threaten the security of the entire cryptographic system. Considering the key leakage problem in the scheme, we are desirable to incorporate the key insulation mechanism into the certificateless public key encryption with keyword search scheme. In this work, a new scheme named pairing-free certificateless key-insulated encryption with keyword search (KI-CLPEKS) is designed. This scheme realizes two functions of key insulation and ciphertext search at the same time. The security notions for KI-CLPEKS are formally defined and then a concrete KI-CLPEKS scheme is proposed. The security proofs demonstrate that the KI-CLPEKS scheme guarantees the keyword ciphertext indistinguishability against adaptive chosen keyword attacks under the complexity assumption of the computational Diffie-Hellman problem in the random oracle model. The experimental results and comparisons show that the proposed scheme is practicable.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_9
DP  - Springer Link
SP  - 106
EP  - 118
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_9.pdf
KW  - Certificateless public key encryption
KW  - Ciphertext indistinguishability
KW  - Key insulation
KW  - Keyword search
ER  - 

TY  - CONF
TI  - A Fair Blockchain Transaction Based on Commitment
AU  - Jinxia, Yu
AU  - Ruijie, Mu
AU  - Rongxia, Qin
AU  - Jing, Zhang
AU  - Xiaojun, Wang
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Aiming at the problems of the correctness of transaction information and the fairness between participants, a FBT (fair blockchain transaction) scheme based on commitment is proposed. Firstly, a FOC-EC (FO commitment scheme based on elliptic discrete logarithm) scheme is designed to hide the transaction amount to ensure its correctness. At the same time, the scheme improves the computational efficiency and security of the FBT scheme. Secondly, use the FOC-EC and the SM9 signature technology, the new scheme realizes the binding between the commitment value and the participants’ identity information to prevent participants’ denial behaviors. Finally, through the smart contract, the scheme verifies the signatures of both parties and commitment values in order to prevent participants’ cheating behaviors, and punished them in cash. Which ensure fairness between participants in the scheme. The analyses of security and performance show that the scheme not only ensures the correctness of transaction information, but also realizes the punishment of dishonest participants. Moreover, the scheme has better the computational efficiency.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_5
DP  - Springer Link
SP  - 54
EP  - 69
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_5.pdf
KW  - Blockchain
KW  - Commitment
KW  - Punishment mechanism
KW  - Signature
KW  - SM9
KW  - Smart contract
ER  - 

TY  - CONF
TI  - A Search Cryptographically Significant S-Boxes with Improved DPA Resistance Based on Genetic Algorithm
AU  - Qiu, Tingxiu
AU  - Wang, Qichun
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - Finding an S-box that is resistant against DPA attacks is an important research topic in cryptography. Until now, the notion of the transparency order including transparency order (TO) and modified transparency order (MTO) has received considerable attention and is one of the best metrics to measure the resistance of S-boxes against DPA attacks. Recently, Li et al. revisited the concepts of TO and MTO. They spotted a flaw that is overlooked and provided a revised definition (revised transparency order, RTO). There are few works on evolving cryptographically strong S-boxes with good RTO values. In fact, generating high nonlinear balanced S-boxes with low differential uniformity and improved DPA resistance is an extremely challenging problem. In this paper, we propose to use the genetic algorithm to search cryptographically significant S-boxes. Particularly, we generate an 8 $$\times $$×8 balanced S-box, with algebraic degree of 7, nonlinearity of 112 and differential uniformity of 4, absolute indicator 32, RTO 7.5222, SNR 8.8869 (the RTO of the S-box of AES is 7.5402 and SNR is 9.6000), which improves the resistance to DPA attack.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_7
DP  - Springer Link
SP  - 80
EP  - 93
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_7.pdf
KW  - Differential power analysis
KW  - Differential uniformity
KW  - Nonlinearity
KW  - Revised transparency order
KW  - S-box
ER  - 

TY  - CONF
TI  - An Improved Certificateless Partial Blind Signature Scheme Based on Homomorphic Encryption
AU  - Tan, Pengfei
AU  - Qin, Zhi
AU  - Wan, Wunan
AU  - Zhang, Shibin
AU  - Zhang, Jinquan
AU  - Xia, Jinyue
A2  - Sun, Xingming
A2  - Zhang, Xiaorui
A2  - Xia, Zhihua
A2  - Bertino, Elisa
T3  - Communications in Computer and Information Science
AB  - A modified Paillier homomorphic cryptography-based partial blind signature scheme is proposed to address the problems of centralized key generation in traditional blind signature schemes and the fact that the current tamper-proof protection scheme for public messages only protects them after they have been attacked or does not protect public messages. In this scheme, the certificateless idea allows the distribution of keys to be decentralized to the KGC (Public Key Generation) and the user’s personal key to be protected, while the partial blind signature idea ensures that the signer’s signature is not misused and protects the signed message. The experimental results show that the use of the Paillier homomorphic encryption algorithm not only satisfies the feasible operational efficiency, but also demonstrates that the scheme can be resisted before the public message is tampered with, improving the security of the scheme in terms of security and feasibility.
C1  - Cham
C3  - Advances in Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06764-8_17
DP  - Springer Link
SP  - 207
EP  - 221
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-06764-8
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-06764-8_17.pdf
KW  - Cryptography
KW  - Homomorphic encryption
KW  - Partially blind signature
KW  - Privacy
ER  - 

TY  - CONF
TI  - Automatic Reading Order Detection of Comic Panels
AU  - Zhang, Yunlong
AU  - Hotta, Seiji
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Tasks such as object detection for comic content are attracting more and more attention from the public. A lot of work focuses on character detection, text recognition, or other tasks. However, only a few of them focus on the reading order detection of panels. In this paper, we review several existing sorting methods and propose a novel method based on these existing methods. Experiment results show that the proposed method outperforms the baseline methods. The proposed method can deal with pages with basic layouts easily. And sometimes has the ability to deal with some pages with complex layouts.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_6
DP  - Springer Link
SP  - 76
EP  - 90
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_6.pdf
KW  - Comic
KW  - Layout
KW  - Reading order
ER  - 

TY  - CONF
TI  - Towards the Automation of Wildfire Monitoring with Aerial Vehicles: The FIREFRONT Project
AU  - Ribeiro, Ricardo
AU  - Bernardino, Alexandre
AU  - Cruz, Gonçalo
AU  - Silva, Diogo
AU  - Felix, Luís
AU  - Caetano, João
AU  - Folgado, Duarte
AU  - Francisco, João
AU  - Simões, Nuno
AU  - Viegas, Carlos Xavier
AU  - Viegas, Domingos Xavier
AU  - Harkat, Houda
AU  - Nascimento, Jose
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - This paper describes an integrated system for wildfire monitoring with aerial vehicles. The system is composed of an airborne payload compatible with UAVs and manned aircraft and associated communication and software infrastructure. The system is able to detect fire and smoke in the payload thermal and RGB images, georeference their location in ground coordinates using telemetry (GPS, IMU), and forecast the fire front spread. We describe the progress made in the payload system, acquired datasets, fire/smoke segmentation methods, fire georeferencing, and wildfire spread modeling, providing the reader with a overview of the project and related technical publications.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_15
DP  - Springer Link
SP  - 183
EP  - 193
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
ST  - Towards the Automation of Wildfire Monitoring with Aerial Vehicles
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_15.pdf
KW  - Fire and Smoke Detection
KW  - Fire Prediction
KW  - Forest Fires
KW  - Georeferencing
KW  - Manned and Unmanned Air Vehicles
ER  - 

TY  - CONF
TI  - A Method to Annotate Who Speaks a Text Line in Manga and Speaker-Line Dataset for Manga109
AU  - Sakurai, Tsubasa
AU  - Ito, Risa
AU  - Abe, Kazuki
AU  - Nakamura, Satoshi
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Speaker estimation in a manga is one component that needs to be recognized in conducting research using manga. To identify the speaker of a text line in a manga, a dataset of who speaks the lines is needed. In order to construct such a dataset easily, we proposed a method to annotate who speaks a text line based on characteristics of information design and the human factor. Then, we developed a prototype system, constructed a dataset that mapped between text lines and speakers in the Manga109 dataset, and distributed the dataset on the Web. Then, we analyzed the dataset and showed that the perfect match rate was about 80% when there were five annotators. In addition, we found that variation in annotation occurred even with human judgment and that this was partly due to lines requiring reference to other frames. We also found that it was difficult for annotators to map speakers in scenes involving science fiction and battles by calculating the Evaluation Consistency Indicators.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_2
DP  - Springer Link
SP  - 22
EP  - 33
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_2.pdf
KW  - Comic
KW  - Manga
KW  - Speaker-Line Dataset
KW  - Text Line
ER  - 

TY  - CONF
TI  - Automated Emotion Recognition Through Graphical Cues on Comics at Character Scale
AU  - Ruddy, Théodose
AU  - Jean-Christophe, Burie
AU  - Arnaud, Revel
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Emotions are psychological reactions to external events. Characters represented in artistic works may manifest emotions in order to replicate credible and human-like behaviors in specific situations. They also provides important hints to better understand the stakes and the tone of story. In comics, markers of emotions can be found in the dialogues or through visual cues specifically drawn by the artists. While automated emotion extraction on textual information is an active research field, few works have addressed this topic through the graphical grammar of comics (and more generally on drawings). In this paper, we propose to review the different visual tools used by artists to convey expressiveness to their characters and how they can be exploited for automated processing. Some of those cues are strongly related to the human body, its representation and mechanisms. Consequently, we propose to study developed methods for those topics on photography or captured videos. Then, we suggest contributions that aimed at facilitating the transition between real and drawn domains.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_5
DP  - Springer Link
SP  - 61
EP  - 75
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_5.pdf
KW  - Comic Analysis
KW  - Document Analysis
KW  - Emotion Recognition
KW  - Machine Learning
ER  - 

TY  - CONF
TI  - Can Deep Learning Approaches Detect Complex Text? Case of Onomatopoeia in Comics Albums
AU  - Louis, John Benson
AU  - Burie, Jean-Christophe
AU  - Revel, Arnaud
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - In recent years, the use of deep learning has contributed to the development of new approaches that outperform traditional methods for many computer vision and document analysis tasks. Many text detection approaches have been proposed and target historical documents, newspapers, administrative documents but also texts in the wild.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_4
DP  - Springer Link
SP  - 48
EP  - 60
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
ST  - Can Deep Learning Approaches Detect Complex Text?
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_4.pdf
KW  - Comics album
KW  - Deep Learning
KW  - Onomatopoeia
KW  - Text detection
ER  - 

TY  - CONF
TI  - Real-Time Georeferencing of Fire Front Aerial Images Using Structure from Motion and Iterative Closest Point
AU  - Sargento, Francisco
AU  - Ribeiro, Ricardo
AU  - Cherif, El Khalil
AU  - Bernardino, Alexandre
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - This work proposes the use of Structure-from-motion (Sfm) and Iterative Closest Point (ICP) as a forest fire georeferencing algorithm to be used with footage captured by an aerial vehicle. Sfm+ICP uses the real time video captured by an aircraft’s camera, as well as its Inertial Measurement Unit (IMU) and Global Positioning System (GPS) measurements, to reconstruct a dense three dimensional (3D) point cloud of the disaster area. The Sfm reconstruction is divided in two steps to improve computational efficiency: a sparse reconstruction step using Speeded-up robust features (SURF) for camera pose estimation, and a dense reconstruction step relying on a Kanade-Lucas-Tomasi (KLT) feature tracker initialized using the minimum eigenvalue algorithm. In addition, the dense 3D reconstruction is registered to a real Digital Elevation Model (DEM) of the surrounding area, and used as the basis of the georeferencing estimates. Indeed, the algorithm was validated with a real forest fire video and compares favourably with a direct georeferencing method evaluated in the same scenario. The results demonstrate that Sfm+ICP can perform accurate 3D reconstructions while also real-time georeferencing several targets in a forest fire scenario. Furthermore, the algorithm is robust to high IMU and GPS errors, making it a far better option than optic-ray-based georeferencing for UAVs with unreliable telemetry.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_16
DP  - Springer Link
SP  - 194
EP  - 202
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_16.pdf
KW  - Fire Front
KW  - Real-time Georeferencing
KW  - UAV
ER  - 

TY  - CONF
TI  - Considering Meanings and Effects of Frames Without Onomatopoeias in Japanese Comics
AU  - Sugita, Riko
AU  - Okajima, Minami
AU  - Komatsu, Takanori
AU  - Nakamura, Satoshi
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Onomatopoeias - echoic, imitative, or mimetic words - are good for describing intuitive, sensitive, and ambiguous feelings that are difficult to express literally. They are often used in Japanese comics as an effective means of expression. In this study, we hypothesize that there are expressive techniques in comics such as “purposely not using onomatopoeia” and discuss the meanings and effects of frames without onomatopoeias. As a result, we confirm that frames without onomatopoeias frequently appear in significant scenes even though onomatopoeias are generally highly expressive in comics.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_3
DP  - Springer Link
SP  - 34
EP  - 47
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_3.pdf
KW  - Background music (BGM)
KW  - Depiction in great detail
KW  - Enlargement of the body parts
KW  - Japanese comics
KW  - Large sized frame
KW  - Onomatopoeias
ER  - 

TY  - CONF
TI  - An Overview of Tools and Algorithms Used to Classify, Detect, and Monitor Forest Area Using LiDAR Data
AU  - Amakhchan, Wijdan
AU  - El Kharki, Omar
AU  - Cherif, El Khalil
AU  - Wahbi, Miriam
AU  - Yazidi Alaoui, Otmane
AU  - Maatouk, Mustapha
AU  - Boulaassal, Hakim
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - LIght Detection and Ranging (LIDAR) is gaining popularity more and more among scientists for developing predictive models in forest areas. Lidar point cloud data has a strong potential for application to manage forest resources thanks to its high accuracy. Obviously, the forest should be given more concern, to not be destroyed, causing economic and ecological damage which affects human lives as well. Therefore, using the developed technologies to protect it is crucial. The Lidar technology is one of the most used recently to meet this requirement. To highlight the big interest of Lidar data in the forest monitoring issue, this article introduces a summary of Lidar data sources Airborne Laser scanning (ALS), Terrestrial Laser scanning (TLS) and mobile mapping system (MMS) algorithms and methods used to classify and filter the point cloud lidar data in forest areas.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_14
DP  - Springer Link
SP  - 171
EP  - 182
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_14.pdf
KW  - ALS
KW  - Fire Forest
KW  - LiDAR data processing
KW  - MMS
KW  - TLS
ER  - 

TY  - CONF
TI  - Towards Content-Aware Pixel-Wise Comic Panel Segmentation
AU  - Ikuta, Hikaru
AU  - Yu, Runtian
AU  - Matsui, Yusuke
AU  - Aizawa, Kiyoharu
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Comic panel detection is the task of identifying panel regions from a given comic image. Many comic datasets provide the borders of the panel lines as its panel region annotations, expressed in formats such as bounding boxes. However, since such panel annotations are usually not aware of the contents of the panel, they do not capture objects that extend outside of the panels, causing such objects to be partially discarded when panels are cropped along the annotations. In such applications, a content-aware annotation that contains all of the contents in each panel is suitable. In this paper, we assess the problem of content-aware comic panel detection using two types of annotations. We first create a small dataset with bounding box annotations where each region contains the entire contents of each panel, and train a detection model. We also explore training a pixel-wise instance segmentation model using synthetic data.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_1
DP  - Springer Link
SP  - 7
EP  - 21
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_1.pdf
KW  - Comic panel detection
KW  - Instance segmentation
KW  - Object detection
ER  - 

TY  - CONF
TI  - Estimation of Unknown Words Using Speech and Eye Gaze When Reading Aloud Comics
AU  - Takaike, Taro
AU  - Iwata, Motoi
AU  - Kise, Koichi
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - This paper proposes a method for estimating speech balloons with unknown words for English learners based on speech and eye gaze information during reading aloud Japanese comics translated into English. In this method, a headset and eye tracker are used to record speech and eye gaze information. Then we extract 47 features from them together with text information. The features are used to train a support vector machine to estimate unknown words for each speech balloon. We evaluated the proposed method by measuring data from 20 Japanese university students. As a result, we confirmed that the proposed method performs better than the estimation using only text information and that the speech and eye gaze information are effective for estimating unknown words.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_7
DP  - Springer Link
SP  - 91
EP  - 106
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_7.pdf
KW  - Comic computing
KW  - Education
KW  - Estimation
KW  - Eye gaze
KW  - Learning Support
KW  - Speech
KW  - Unknown words
ER  - 

TY  - CONF
TI  - Land Cover Classification for Fires Using Sentinel-2 Satellite RGB Images and Deep Transfer Learning
AU  - Taha, Ait Tchakoucht
AU  - Cherif, El Khalil
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Land cover classification is referred to as the process of identifying different types of land cover in images, generally acquired through remote sensing. It is a crucial practice to various areas such as precision agriculture, ecology, natural disaster risk assessment, urban planning and so on. The paper describes a pipeline for terrain classification for Forest Fire risk assessment using Convolutional Neural Network models and transfer learning and compares their performances on Sentinel-2 satellite Red, Blue, Green (RGB) images. The results prove the ability of transfer learning to accurately identify land cover types.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_11
DP  - Springer Link
SP  - 142
EP  - 150
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_11.pdf
KW  - Deep Transfer Learning
KW  - Land cover
KW  - Remote sensing
ER  - 

TY  - CONF
TI  - Analyzing Textual Sources Attributes of Comics Based on Word Frequency and Meaning
AU  - Higuchi, Ryota
AU  - Yamanishi, Ryosuke
AU  - Matsushita, Mitsunori
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - The purpose of this research is to analyze the textual source attributes of explanations and reviews about comics. Comics are difficult to process in terms of the intended story because they are primarily composed of pictures and text. One of the processing methods is to analyze comics text on the Web, particularly the description of characters and reviews including the reader’s impression about the comic. Sources of textual information, such as explanations or reviews, are selected according to the application of the study. However, differences among textual sources regarding comics are not taken into consideration in the analysis. This paper classifies words appearing frequently in the text semantically, with results showing that explanations include words that express the story, for example, the family structure, physical information, and sex of the characters for describing the characters. Conversely, the review frequently uses words that provide meta-information about comics, such as illustrations and style. The proposed method revealed that explanations of comics are more useful as textual sources for analyzing story information than reviews.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_8
DP  - Springer Link
SP  - 107
EP  - 118
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_8.pdf
KW  - Characteristics of Comic Story
KW  - Differences in Data Sources
KW  - Explanation Texts of Characters
KW  - Review Sentences of Comics
ER  - 

TY  - CONF
TI  - Data-Driven Transform Based Adaptive Compressive Sensing Framework for 3D Reconstruction of Forests
AU  - Shinde, Rajat C.
AU  - Durbha, Surya S.
AU  - Talreja, Pratyush V.
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Forests comprise a key natural resource of our natural ecosystem and play a significant role in the sustenance of living beings. LiDAR enables accurate x, y, and z measurements of the 3D surrounding. In our work, we propose a novel framework (called MEMD-CS) based on the multivariate Empirical Mode Decomposition (EMD) inspired by a Compressive Sensing (CS) framework. EMD is a data-driven transform in which the transformation basis is learned, unlike Fourier transform or wavelets having “rigid” transformation functions. We propose using the EMD-derived components as a transformation basis for the CS framework, which usually uses predefined probability distributions as priors. Our novel approach is data-agnostic and focuses on the adaptive decomposition of the input signal. We test our approach on multiple samples chosen from different forest LiDAR datasets available in the public domain. To the best of our knowledge, multivariate EMD within a compressive sensing framework is the first attempt for the LiDAR point clouds of forests. We compare our results based on the Canopy Height Model (CHM) derived from the reconstructed LiDAR point clouds.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_10
DP  - Springer Link
SP  - 133
EP  - 141
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_10.pdf
KW  - Canopy Height Model
KW  - Compressive Sensing
KW  - Data-driven transform
KW  - LiDAR for forests
KW  - Multivariate Empirical Mode Decomposition
KW  - Sparse Representation
ER  - 

TY  - CONF
TI  - An Adversarial Method for Semi-supervised Segmentation of Smoke and Fire in Images
AU  - Kuhlmann, Lisa
AU  - Niknejad, Milad
AU  - Barata, Catarina
AU  - Bernardino, Alexandre
AU  - Zhang, Gefei
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Detecting and segmenting fire and smoke on images and videos is an essential tool for autonomous systems to battle fire incidents. State-of-the-art methods based on Convolutional Neural Networks (CNNs) require large numbers of annotated images, which are time-consuming to obtain and need lots of human efforts. In this paper, we propose a semi-supervised method for fire and smoke segmentation using an adversarial approach which uses a fully-supervised pretraining stage. A dataset is also introduced containing pixel labeled and unlabeled images of fire and smoke that can be used in semi-supervised fire and smoke segmentation methods. Our proposed method shows improvement over a fully-supervised segmentation method in different percentages of available labeled images for fire and smoke segmentation.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_9
DP  - Springer Link
SP  - 123
EP  - 132
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_9.pdf
ER  - 

TY  - CONF
TI  - Landsat 8 data for forest fire monitoring: case of Mediouna forest in Tangier, Morocco
AU  - Badda, Houda
AU  - Boulaassal, Hakim
AU  - Cherif, El Khalil
AU  - Wahbi, Miriam
AU  - El Kharki, Omar
AU  - Maatouk, Mustapha
AU  - Yazidi Alaoui, Otmane
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - During the last years, many regions in North of Morocco have suffered from the spread of wildfires in summer such as Mediouna forest. Indeed, the need for Remote sensing data became more and more evident, since it provides huge regional scale data in short window time and with less cost and human resources. The challenge of this paper is to study the behavior of the Normalized Burn Ratio (NBR) index over time to determine the relationship between its variation and the Mediouna forest biomass evolution using Landsat 8 images. Moreover, we classify the burned areas, and estimate the burn severity based on spectral signatures. The monitoring of the burned areas was performed using the NBR and Burn area severity is performed using Differential Normalized Burn Ratio (dNBR). The correction of the satellite images, the calculation of the NBR index, the analysis and the mapping of the results were carried out using QGIS software. We deduced that NBR and dNBR indices are effective in monitoring Mediouna forest fires.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_12
DP  - Springer Link
SP  - 151
EP  - 159
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
ST  - Landsat 8 data for forest fire monitoring
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_12.pdf
KW  - Burn severity
KW  - Forest fire
KW  - Forest monitoring
KW  - Remote sensing
ER  - 

TY  - CONF
TI  - Forest Fires Identification Using Self-Supervised Learning
AU  - Fernandes, Sara
AU  - Niknejad, Milad
AU  - Barata, Catarina
AU  - Bernardino, Alexandre
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - Forest fires are responsible for the destruction of thousands of hectares and infrastructures every year. To minimize their disastrous effects, it is necessary to i) accomplish and early detection and ii) ensure an efficient monitoring of the event. Automatic methods based on image analysis (acquired from surveillance towers and/or UAVs) are a useful tool to support the firefighting teams. The development of robust methods requires the acquisition of extensively labelled datasets. However, the number of publicly available images with associated annotations is low and generating labels for new data can be time-consuming. On the other hand, there are thousands of images available online, but without annotations. We propose to take advantage of these images, adopting a two phase methodology. First, a deep neural network is trained to solve a pretext task using an unlabelled dataset (self-supervised learning). Afterwards, by combining part of the learned model with a much smaller labelled dataset, the final classifier is achieved. When comparing the models only trained with the smaller dataset, the proposed methodology achieved a better performance, demonstrating the importance of a self-supervised pre-training.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_17
DP  - Springer Link
SP  - 203
EP  - 212
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_17.pdf
KW  - deep learning
KW  - fire detection
KW  - self-supervised learning
ER  - 

TY  - CONF
TI  - Flying Wing Wildfire Tracking Using Visual Servoing and Gimbal Control
AU  - Nunes, António Peres
AU  - Moutinho, Alexandra
AU  - Azinheira, José Raul
A2  - Rousseau, Jean-Jacques
A2  - Kapralos, Bill
T3  - Lecture Notes in Computer Science
AB  - This paper describes a vision control algorithm for flying wing wildfire tracking. The aircraft, equipped with a camera attached to a gimbal, is dropped at a given altitude by a high-altitude balloon, and then performs a gliding descent while surveying the region of interest.
C1  - Cham
C3  - Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-37742-6_13
DP  - Springer Link
SP  - 160
EP  - 170
LA  - en
PB  - Springer Nature Switzerland
SN  - 978-3-031-37742-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-37742-6_13.pdf
KW  - Flying wing
KW  - Target tracking
KW  - Visual-servoing control
KW  - Wildfire monitoring
ER  - 

TY  - CONF
TI  - Active Control of Chatter for Five-Axis Milling Based on Piezoelectric Actuator
AU  - Gao, Shun
AU  - Peng, Fangyu
AU  - Tang, Xiaowei
AU  - Yan, Rong
AU  - Wu, Jiawei
AU  - Xin, Shihao
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Five-axis milling is an important machining method for complex surface parts, and chatter is an important factor affecting its machining efficiency and quality. Stability boundary prediction can effectively optimize process parameters and avoid chattering, but it is difficult to actively improve the stability boundary. Therefore, in this paper, a research on active control of five-axis milling chatter based on piezoelectric actuators is carried out. A device for active control of chatter is designed, and a dynamic model of five-axis milling machining considering active vibration suppression is established. The fuzzy PD control method is used to simulate the chatter active control, and the effect of chatter suppression is analyzed by simulation, and the active control experiment is carried out to verify the effectiveness of the active chatter control device and method.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_1
DP  - Springer Link
SP  - 3
EP  - 14
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_1.pdf
KW  - Active control
KW  - Chatter
KW  - Five-axis milling
KW  - Fuzzy PD
ER  - 

TY  - CONF
TI  - Effect of Foot Shape on Walking Performance of a Biped Robot Controlled by State Machine
AU  - Zhou, Zhihao
AU  - Ye, Linqi
AU  - Liu, Houde
AU  - Liang, Bin
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Bipedal robot is a multi-degree-of-freedom, high-dimensional, naturally unstable system. The control method based on kinematics and dynamics is complex in theory and implementation, and the control algorithm usually involves many parameters, which is difficult to design. In this paper, a control framework based on a state machine is designed to achieve stable walking of a 3D bipedal robot, which only involves 6 parameters to be designed. In terms of the structural design of biped robots, researcher’s interests are mostly focused on legs, knees, and ankles, and there are few studies on the shape of the robot foot. In this paper, we build a three-dimensional biped robot model in Webots and use random searching method to find the control parameters that lead to stable walking. For the stable walking gaits, we compare the performance of five foot shapes in terms of the walking style, control efficiency, and stability. We found that the yaw angle is a key factor affecting the diversity of the robot’s gait. In addition, it is found that the overall performance of the flat foot is most satisfying. The research in this paper can be helpful for the bipedal robot walking algorithm and the design of the foot shape.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_14
DP  - Springer Link
SP  - 150
EP  - 160
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_14.pdf
KW  - Biped robot
KW  - Foot shape
KW  - State machine
ER  - 

TY  - CONF
TI  - 3D Visual Servo Control of a Flexible Endoscope with RCM Constraint
AU  - Li, Jian
AU  - Zhang, Xue
AU  - Huang, Yisen
AU  - Luo, Xiao
AU  - Xie, Ke
AU  - Xian, Yitian
AU  - Chiu, Philip Waiyan
AU  - Li, Zheng
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - In minimally invasive surgery, endoscopes provide visual guidance to surgical operations. To tackle the problems caused by traditional hand-held endoscope, robots are introduced to steer the endoscope.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_5
DP  - Springer Link
SP  - 53
EP  - 63
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_5.pdf
KW  - 3D visual servo control
KW  - Remote center of motion
KW  - Robotic flexible endoscope
ER  - 

TY  - CONF
TI  - Multiple Object Tracking by Joint Head, Body Detection and Re-Identification
AU  - Liu, Zuode
AU  - Liu, Honghai
AU  - Ren, Weihong
AU  - Chang, Hui
AU  - Shi, Yuhang
AU  - Lin, Ruihan
AU  - Wu, Wenhao
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Multi-object tracking (MOT) is an important problem in computer vision which has a wide range of applications. Formulating MOT as multi-task learning of object detection and re-Identification (re-ID) in a single network is appealing since it achieves real-time but effective inference on detection and tracking. However, in crowd scenes, the existing MOT methods usually fail to locate occluded objects, which also results in bad effects on the re-ID task. To solve people tracking in crowd scenes, we present a model called HBR (Head-Body-ReID Joint Tracking) to jointly formulates head detection, body detection and re-ID tasks into an uniform framework. Human heads are hardly affected by occlusions in crowd scenes, and they can provide informative clues for whole body detection. The experimental results on MOT17 and MOT20 show that our proposed model performs better than the state-of-the-arts.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_16
DP  - Springer Link
SP  - 171
EP  - 180
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_16.pdf
KW  - Head detection
KW  - Multiple Object Tracking
KW  - Person re-Identification
ER  - 

TY  - CONF
TI  - A Novel Cable-Driven Manipulator with Constant-Curvature Deflections and Equal Displacements of the Antagonistic Cables
AU  - Dai, Yicheng
AU  - Li, Xiran
AU  - Wang, Xin
AU  - Yuan, Han
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - The constant-curvature method can effectively reduce the complexity in kinematic modeling of the cable-driven manipulator and make the dynamic control easier. However, existing research has encountered some difficulties in modeling using this method. Due to the external load, the bending shape is not a constant-curvature arc. In this paper, a novel cable-driven serpentine manipulator is proposed, which can bend in accurate constant curvature under situations with or without external load. This manipulator is mainly composed of two parts, including arm segments and links. Both are with gear teeth. Two adjacent segments have a rolling motion by gear meshing, connected by an auxiliary link. The accurate constant curvature is realized by gear meshing of the links. Moreover, through the delicate position distribution of the gear center, the driving cables have equal antagonistic displacements, which means that a single pulley can control both cables. This feature can reduce the number of actuators significantly. Besides, the mapping between driving cable space and joint space can be linearized with a relatively small error, thanks to the special structure. Experiments in different conditions are carried out and the results show that the maximum tracking error and repeat positioning error are 4.9 mm and 4.87 mm while the average values are 1.52 mm and 1.04 mm, which are very small compared to the 272 mm long manipulators.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_8
DP  - Springer Link
SP  - 76
EP  - 87
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_8.pdf
KW  - Cable-driven manipulator
KW  - Constant curvature
KW  - Equal antagonistic displacements
KW  - Linearization
ER  - 

TY  - CONF
TI  - Group Sparsity Regularized High Order Tensor for HSIs Super-Resolution
AU  - Chen, Xi’ai
AU  - Guo, Siyu
AU  - Jia, Huidi
AU  - Liu, Baichen
AU  - Li, Zhenyu
AU  - Han, Zhi
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Super-resolution of hyperspectral images is a crucial task in remote sensing applications. In this paper, we propose a group sparsity regularized high order tensor model for hyperspectral images super-resolution. In our model, a relaxed low tensor train rank estimation strategy is applied to exploit the correlations of local spatial structure along the spectral mode. Weighted group sparsity regularization is used to model the local group sparsity. An efficient algorithm is derived under the framework of alternative direction multiplier method. Extensive experimental results on public datasets have proved that the proposed method is effective compared with the state-of-art methods.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_12
DP  - Springer Link
SP  - 125
EP  - 137
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_12.pdf
KW  - Group sparsity
KW  - High order tensor
KW  - HSI super-resolution
KW  - Relaxed tensor train rank
ER  - 

TY  - CONF
TI  - Bearing Fault Diagnosis Method Based on Multi-sensor Feature Fusion Convolutional Neural Network
AU  - Zhong, Xiaoyong
AU  - Song, Xiangjin
AU  - Wang, Zhaowei
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Most existing deep learning models use a single sensor signal as input data, which makes them susceptible to external variables and cannot represent the operating state of a certain component. To achieve intelligent fault diagnosis of the rolling bearing in permanent magnet synchronous motors (PMSM) under cross-working conditions, a novel method based on a multi-sensor feature fusion convolutional neural network (MFFCN) is presented. The proposed model consists of a core network and two sub-networks to achieve information sharing and exchange. The deep features in multi-sensor signals are extracted by using dilated convolution blocks in the subnetwork. An attention mechanism is introduced in the core network to flexibly extract and fuse more effective features. The proposed model is verified by a fusion of vibration and current signal for bearing fault diagnosis of the PMSM. Experimental results show that the proposed model has higher diagnostic accuracy in fault diagnosis under various working conditions. In addition, the interpretability of the network model is improved through network visualization.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_13
DP  - Springer Link
SP  - 138
EP  - 149
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_13.pdf
KW  - Attention mechanism
KW  - Bearing fault diagnosis
KW  - Feature fusion
ER  - 

TY  - CONF
TI  - The Geometric Transformation Model of Two Views Based on the Line-Scan Camera Imaging Model
AU  - Fang, Lei
AU  - Shi, Zelin
AU  - Liu, Yunpeng
AU  - Li, Chenxi
AU  - Zhao, Enbo
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - With the increasing use of line-scan camera, it is difficult to ensure that its sensor is parallel to the target in imaging. This will make the target present a different appearance in linear array images. When two linear array images are registered, it is crucial to choose a suitable geometric transformation model. However, the imaging model of line-scan camera is different from that of frame camera, and the classical geometric transformation model of frame image, namely perspective transformation model, does not conform to geometric transformation of linear array image. Therefore, according to the imaging model of line-scan camera, the geometric transformation model of linear array image is derived in this paper. To obtain linear array images, an acquisition system is built. The geometric transformation model established in this paper and perspective transformation model are used to register the linear array images respectively. The registration results based on the geometric transformation model of linear array image show that the two linear array images can be completely aligned and the root mean square error of feature points is smaller. On the contrary, the registration results based on perspective transformation model show that the two images are not alignment, and the root mean square error of feature points is larger, which also indicates that it is not suitable for geometric transformation of linear array images.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_11
DP  - Springer Link
SP  - 113
EP  - 124
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_11.pdf
KW  - Geometric transformation model
KW  - Imaging model
KW  - Line-scan camera
KW  - Linear array image
ER  - 

TY  - CONF
TI  - Model Predictive 6D Image-Based Visual Servoing for 3C Products Assembly
AU  - Qu, Ying
AU  - Yang, Xiansheng
AU  - Xie, Yixin
AU  - Lou, Yunjiang
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - The application of visual servoing in robot assembly is very promising. In this paper, the 6-degree-of-freedom (DOF) image-based visual servoing (IBVS) control based on model predictive control (MPC) is implemented for 3C products assembly. Since the classical IBVS is calculated by multiplying the error times the pseudoinverse of an interaction matrix, it cannot handle constraints. Hence, the collision encountered in the process and the feature points out of the visual range cannot be solved well. Therefore, based on MPC, which can solve the servoing problems by transforming them into constrained optimization, this paper proposes a new MPC for the 3C products assembly system. In the new MPC, we estimate the depth information through image information, to solve the problem of deep collision, and propose a new cost function, which can better solve the problem of the system falling into a local optimal solution. Finally, the simulation verified in the ROS-Gazebo simulation results shows that the new control method is feasible and the control performance is more satisfactory.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_4
DP  - Springer Link
SP  - 41
EP  - 52
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_4.pdf
KW  - Assembly
KW  - Image-based visual servoing (IBVS)
KW  - Model predictive control (MPC)
KW  - Robot control
ER  - 

TY  - CONF
TI  - Automated Vein Segmentation from NIR Images Using a Mixer-UNet Model
AU  - Ji, Jiarui
AU  - Zhao, Yibo
AU  - Xie, Tenghui
AU  - Du, Fuxin
AU  - Qi, Peng
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Accessing the venous bloodstream to obtain a blood sample is the most common clinical routine. Nevertheless, due to the reliance of venipuncture on manual technique, first-stick accuracy of venipuncture falls below 50% in difficult cases. A surge of research on robotic guidance for autonomous vascular access have been conducted. With regard to robotic venipuncture, efficiency and accuracy of vein segmentation is of much importance. This paper describes a method to accurately and efficiently segment, localize and track the topology of human veins from near-infrared (NIR) images. Both spatial and color augmentation are implemented on the dataset at first. Next, Mixer-UNet is used for identifying veins that would be hard to find in clinical visual assessment. The Mixer-UNet is developed on the basis of UNet and MLP-Mixer. Through the flexible information exchange through Token-mixing layer and Channel-mixing layer, Mixer-UNet can extract features from NIR images accurately. The performance of Mixer-UNet is validated on 270 NIR images, which are collected from 30 volunteers. Mixer-UNet reaches 93.07% on Accuracy indicator. Compared with the best-performing baseline, the F1-score indicator increases by 2.82%, reaching 78.37% in testing sample. The high accuracy and robustness of Mixer-UNet is expected to improve the vein segmentation of NIR images, and further contributes to the goal of an improved automated venipuncture robot.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_6
DP  - Springer Link
SP  - 64
EP  - 75
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_6.pdf
KW  - Medical robotics
KW  - MLP-Mixer
KW  - UNet
KW  - Vein segmentation model
KW  - Venipuncture robot
ER  - 

TY  - CONF
TI  - Tri-axial Motion Sensing with Mechanomagnetic Effect for Human-Machine Interface
AU  - Liu, Zijie
AU  - Guo, Chuxuan
AU  - Xue, Hongwei
AU  - Guo, Jiajie
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Haptic sensing has been critical to human-machine interaction for wearable robotics, where interaction force sensing in the three-dimensional (3D) space play a key role in stimulating environmental proprioception, predicting human-motion intent and modulating robotic fine-motions. While normal pressure sensing has been widely explored in the uniaxial way, it is still a challenging task to capture shear forces along the tangential directions where typical capacitive or resistive sensing is difficult to implement. Moreover, integration of uniaxial force sensing modules in one unit would produce a bulky system that is impractical for wearable applications. Herein, this paper proposes a tri-axial motion sensing method based on mechanomagnetic effect, where both normal and shear forces can be captured through the magnetic field monitoring in the 3D space. A soft magnetic film was designed and fabricated to induce compliant deformations under tri-axial loads, and the flexible deformations can be captured through the magnetic flux changes via the hall-effect. Both simulation and experimental results are provided to justify the sensor performance and validate its potential applications to human-machine interaction.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_3
DP  - Springer Link
SP  - 29
EP  - 38
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_3.pdf
KW  - Flexible sensor
KW  - Human-machine interface (HMI)
KW  - Mechanomagnetic effect
KW  - Tri-axial motion sensing
KW  - Wearable robotics
ER  - 

TY  - CONF
TI  - A Robot-Assisted System for Dental Implantation
AU  - Wu, Xianglong
AU  - Tang, Qirong
AU  - Wang, Fang
AU  - Guo, Ruiqin
AU  - Zhu, Qing
AU  - Li, Shujun
AU  - Tu, Deyu
AU  - Liu, Qingyun
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - For treating tooth defects or loss, dental implant technology is the main treatment method because of its comfort, beauty, durability and no damage to the adjacent teeth. Free-hand operation for dental implant surgery highly depends on the clinical experience of the doctors and their state during the operation. Moreover, the training period is long. Additionally, dental implant surgery guided by an implant guide plate also has some limitations, such as poor cooling effect, high chance of thermal burn injury to the bone, blind operation, inability to make real-time adjustments during the operation, etc. In this study, a robot-assisted dental implant implantation system guided by the NOKOV optical motion capture system is presented, and the functions of each component of the system is introduced. The kinematics of the system was analyzed, and the coordinate transformation between the optical motion capture system and the manipulator was completed. Finally, the motion planning of the manipulator was simulated according to the pose recognized by the optical motion capture system. The results of the simulation confirmed the effectiveness of the proposed robot-assisted system. Our findings suggested that the system should be further investigated for practical applications in the future.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_2
DP  - Springer Link
SP  - 15
EP  - 28
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_2.pdf
KW  - Anodontism
KW  - Dental implant surgery
KW  - Kinematic analysis
KW  - Robot-assisted implantation
ER  - 

TY  - CONF
TI  - Open-Set Fault Diagnosis Method for Industrial Process Based on Semi-supervised Learning
AU  - Liu, Jiaren
AU  - Song, Hong
AU  - Wang, Jianguo
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Aiming at the inconsistent distribution of labeled and unlabeled data categories in the actual industrial production process, this paper proposes an open-set semi-supervised process fault diagnosis method based on uncertainty distribution alignment. Firstly, the proposed method forces the matching of the distribution of labeled data and unlabeled data. Then it combines a semi-supervised fault diagnosis model with the anomaly detection of one-vs-all classifier. The interior point (unlabeled samples in known class) is correctly classified while rejecting outliers to realize the fault diagnosis of open-set industrial process data. Finally, fault diagnosis experiments are carried out through numerical simulation and Tennessee-Eastman chemical process to verify the effectiveness and feasibility of the proposed method. Compared with temporal ensembling-dual student (TE-DS) and other semi-supervised fault diagnosis methods, it is proved that the proposed method is suitable for open-set fault diagnosis.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_10
DP  - Springer Link
SP  - 103
EP  - 112
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_10.pdf
KW  - Fault diagnosis
KW  - Industrial process
KW  - Open-set
KW  - Semi-supervised learning
KW  - Uncertainty distribution alignment
ER  - 

TY  - CONF
TI  - Research on Part Image Segmentation Algorithm Based on Improved DeepLabV3+
AU  - Hou, Weiguang
AU  - Fu, Shengpeng
AU  - Xia, Xin
AU  - Xia, Renbo
AU  - Zhao, Jibin
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Aiming at the problem of fuzzy edge segmentation and incomplete division in DeepLabV3+ segmentation results of parts, we propose an improved DeepLabV3+ semantic segmentation algorithm. Firstly, We replace Xception in the original network with lightweight MobileNet_V2 on the backbone network, improving the lightness of the network model. Then, channel attention is introduced into the backbone network to enhance the importance of effective feature information and enhance the learning ability of parts objective. After that, using feature fusion branches to adaptively learn spatial information of low-level features at different levels to obtain richer semantic information. Finally, the asymmetric convolution is used to replace the $$3\times 3$$3×3convolution in the Decode-part to improve the processing ability of the convolution kernel and verify on the self-built mechanical parts dataset. The experimental results show that our method can achieve more precise semantic segmentation effect compared with the traditional deeplabv3+ and other segmentation methods.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_15
DP  - Springer Link
SP  - 161
EP  - 170
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_15.pdf
KW  - Adaptive spatial feature fusion
KW  - Asymmetric convolution
KW  - Channel attention
KW  - DeepLabV3+
ER  - 

TY  - CONF
TI  - Recognition of Blinding Diseases from Ocular OCT Images Based on Deep Learning
AU  - Wang, Rong
AU  - Wang, Yaqi
AU  - Yu, Weiquan
AU  - Zhang, Suiyu
AU  - Wang, Jiaojiao
AU  - Yu, Dingguo
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Age-Related Macular Degeneration (AMD) and Diabetes Macular Edema (DME) are eye diseases with the highest blinding rate. Optical Coherence Tomography (OCT) is widely used to diagnose different eye diseases. However, the lack of automatic image analysis tools to support disease diagnosis remains a problem. At present, the high-dimensional analysis of OCT medical images using Convolutional Neural Networks (CNN) has been widely used in the fields of visual field assessment of glaucoma and diabetes retinopathy. The method we proposed involves the transfer learning of Inception V3. The experiment includes two stages: (1) Firstly, using SinGAN to generate high-quality image samples and enhance the data; (2) Fine-tune and validate the Xception model generated using transfer learning. The research shows that the Xception model achieves 98.8% classification accuracy on the OCT2017 data set under the condition that the Xception model has the same parameter quantity as the Inception model, to realize a more accurate classification of OCT images of blinding diseases.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_17
DP  - Springer Link
SP  - 181
EP  - 190
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_17.pdf
KW  - Deep learning
KW  - Image classification
KW  - OCT
KW  - SinGAN
KW  - Xception
ER  - 

TY  - CONF
TI  - Vessel Site Selection for Autonomous Cannulation Under NIR Image Guidance
AU  - Zhao, Yibo
AU  - Ji, Jiarui
AU  - Xie, Tenghui
AU  - Du, Fuxin
AU  - Qi, Peng
A2  - Liu, Honghai
A2  - Yin, Zhouping
A2  - Liu, Lianqing
A2  - Jiang, Li
A2  - Gu, Guoying
A2  - Wu, Xinyu
A2  - Ren, Weihong
T3  - Lecture Notes in Computer Science
AB  - Venipuncture is a nearly ubiquitous part of modern clinical practice. However, currently venipuncture procedures are mainly applied by manual operation, whose the success rate might decrease below 50% in some situations, including pediatric, and geriatric patients. Thus, robotic technologies to guide autonomous vascular access attracts research attention. For venipuncture robots, near-infrared (NIR) images are widely used for real-time servoing and further to segment subcutaneous vessels for puncture with a series of deep convolutional neural networks. It has been realized that the success rate of puncture largely relies on the performance of segmentation models. However, the small size and low quality of NIR image dataset severely limit the accuracy and efficiency of segmentation models. This paper aims to address this issue by proposing a novel data processing method to improve the performance of segmentation models. With those novel image processing strategies, the segmentation results are improved. The Dice-mean value has increased by an average of 1.12%. Additionally, an algorithm of vessel site selection for puncture is proposed in this paper. Such data processing methods and the puncture site selection algorithm are expected to finally improve the performance of venipuncture robots.
C1  - Cham
C3  - Intelligent Robotics and Applications
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_9
DP  - Springer Link
SP  - 88
EP  - 99
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-13841-6
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-13841-6_9.pdf
KW  - Data augmentation
KW  - Gaussian blur
KW  - Image processing
KW  - The Bézier curve
KW  - Venipuncture robot
ER  - 

TY  - CONF
TI  - Partially Occluded Skeleton Action Recognition Based on Multi-stream Fusion Graph Convolutional Networks
AU  - Li, Dan
AU  - Shi, Wuzhen
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Skeleton-based action recognition methods have been widely developed in recent years. However, the occlusion problem is still a difficult problem at present. Existing skeleton action recognition methods are usually based on complete skeleton data, and their performance is greatly reduced in occluded skeleton action recognition tasks. In order to improve the recognition accuracy on occluded skeleton data, a multi-stream fusion graph convolutional network (MSFGCN) is proposed. The proposed multi-stream fusion network consists of multiple streams, and different streams can handle different occlusion cases. In addition, joint coordinates, relative coordinates, small-scale temporal differences and large-scale temporal differences are extracted simultaneously to construct more discriminative multimodal features. In particular, to the best of our knowledge, we are the first to propose the simultaneous extraction of temporal difference features at different scales, which can more effectively distinguish between actions with different motion amplitude. Experimental results show that the proposed MSFGCN obtains state-of-the-art performance on occluded skeleton datasets.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_14
DP  - Springer Link
SP  - 178
EP  - 189
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_14.pdf
KW  - Graph convolutional network
KW  - Multi-stream fusion network
KW  - Multimodal features
KW  - Occluded skeleton action recognition
ER  - 

TY  - CONF
TI  - Monocular Dense SLAM with Consistent Deep Depth Prediction
AU  - Yan, Feihu
AU  - Wen, Jiawei
AU  - Li, Zhaoxin
AU  - Zhou, Zhong
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Monocular simultaneous localization and mapping (SLAM) that using a single moving camera for motion tracking and 3D scene structure reconstruction, is an essential task for many applications, such as vision-based robotic navigation and augmented reality (AR). However, most existing methods can only recover sparse or semi-dense point clouds, which are not adequate for many high-level tasks like obstacle avoidance. Meanwhile, the state-of-the-art methods use multi-view stereo to recover the depth, which is sensitive to the low-textured and non-Lambertian surface. In this work, we propose a novel dense mapping method for monocular SLAM by integrating deep depth prediction. More specifically, a classic feature-based SLAM framework is first used to track camera poses in real-time. Then an unsupervised deep neural network for monocular depth prediction is introduced to estimate dense depth maps for selected keyframes. By incorporating a joint optimization method, predicted depth maps are refined and used to generate local dense submaps. Finally, contiguous submaps are fused with the ego-motion constraint to construct the globally consistent dense map. Extensive experiments on the KITTI dataset demonstrate that the proposed method can remarkably improve the completeness of dense reconstruction in near real-time.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_9
DP  - Springer Link
SP  - 113
EP  - 124
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_9.pdf
KW  - Dense mapping
KW  - Monocular depth prediction
KW  - Visual SLAM
ER  - 

TY  - CONF
TI  - Stable Depth Estimation Within Consecutive Video Frames
AU  - Luo, Fei
AU  - Wei, Lin
AU  - Xiao, Chunxia
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Deep learning based depth estimation methods have been proven effective and promising, especially learning depth from monocular video. Depth-from-video is the real sense of unsupervised depth estimation, as it doesn’t need depth ground truth or stereo image pairs as supervision. However, most of existing depth-from-video methods did not think of frame-to-frame depth estimation stability. We found depths within temporally consecutive frames exist instability although single image depth can be estimated well by recent works. Thus, this work aims to solve this problem. Specifically, we define a temporal smoothness term for the depth map and propose a temporal stability loss to constrain depths of the same objects within consecutive frames to keep their stability. We also propose an inconsistency check processing according to the differences between synthetic view frames and their original RGB frame. Based on the inconsistency check, we propose a self-discovered mask to handle the moving and occluded objects. Experiments show that the proposed method is effective and can estimate stable depth results within temporally consecutive frames. Meanwhile, it achieves competitive performance on the KITTI dataset.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_4
DP  - Springer Link
SP  - 54
EP  - 66
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_4.pdf
KW  - Depth estimation
KW  - Depth stability
KW  - Monocular video
ER  - 

TY  - CONF
TI  - Reinforcement Learning for Quadruped Locomotion
AU  - Zhao, Kangqiao
AU  - Lin, Feng
AU  - Seah, Hock Soon
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - In adversarial games like VR hunting which involves predators and preys, locomotive behaviour of the non-player character (NPC) is crucial. For effective and realistic quadruped locomotion, major technical contributions of this paper are made to inverse kinematics embedded motion control, quadruped locomotion behaviour adaptation and dynamic environment informed reinforcement learning (RL) of the NPC agent. Behaviour of each NPC can be improved from the top-level decision making such as pursuit and escape down to the actual skeletal motion of bones and joints. The new concepts and techniques are illustrated by a specific use case of predator and prey interaction, in which the objective is to create an intelligent locomotive predator to reach its autonomous steering locomotive prey as fast as possible in all the circumstances. Experiments and comparisons are conducted against the Vanilla dynamic target training; and the RL agent of the quadruped displays more realistic limb movements and produces faster locomotion towards the autonomous steering target.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_13
DP  - Springer Link
SP  - 167
EP  - 177
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_13.pdf
KW  - Adversarial game
KW  - Locomotive behaviour
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - PointCNN-Based Individual Tree Detection Using LiDAR Point Clouds
AU  - Ying, Wenyuan
AU  - Dong, Tianyang
AU  - Ding, Zhanfeng
AU  - Zhang, Xinpeng
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Due to the rapid development of deep learning technology in recent years, many scholars have applied deep learning technology to the field of remote sensing imagery. But few have directly applied LiDAR point clouds to 3D neural networks for tree detection. And the existing methods usually have better detection results in a specific single scene, but in some complex scenes, such as containing diverse types of trees, urban forests and high forest density, the detection results are not satisfactory. Therefore, this paper presents a PointCNN-based method of 3D tree detection using LiDAR point clouds, which aims to improve the detection accuracy of trees in complex scenes and versatility. This method first builds a canopy height model (CHM) using raw LiDAR point clouds and obtains rough seed points on CHM. Then it extracts the detection samples consisting of single tree's point cloud data based on the rough seed points. Next, the 3D-CNN classifier based on PointCNN is adopted to classify detection samples, and the classification results are used for filtering seed points. Finally, our method performs the tree stagger analysis on those close seed points. This study selected twelve experimental plots from study areas in Bend, Central Oregon, USA. Based on the results of our experiments, the highest matching score and average score reached 91.0 and 88.3. Experimental results show that our method can effectively extract tree information in complex scenes.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_7
DP  - Springer Link
SP  - 89
EP  - 100
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_7.pdf
KW  - CHM
KW  - LiDAR
KW  - PointCNN
KW  - Single tree detection
KW  - Tree stagger
ER  - 

TY  - CONF
TI  - The Impact of Animations in the Perception of a Simulated Crowd
AU  - Molina, Elena
AU  - Ríos, Alejandro
AU  - Pelechano, Nuria
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Simulating virtual crowds is an important challenge in many areas such as games and virtual reality applications. A lot of effort has been dedicated to improving pathfinding, collision avoidance, or decision making, to achieve more realistic human-like behavior. However, crowd simulation will be far from appearing realistic as long as virtual humans are limited to walking animations. Including animation variety could greatly enhance the plausibility of the populated environment. In this paper, we evaluated to what extend animation variety can affect the perceived level of realism of a crowd, regardless of the appearance of the virtual agents (bots vs. humanoids). The goal of this study is to provide recommendations for crowd animation and rendering when simulating crowds. Our results show that the perceived realism of the crowd trajectories and animations is significantly higher when using a variety of animations as opposed to simply having locomotion animations, but only if we render realistic humanoids. If we can only render agents as bots, then there is no much gain from having animation variety, in fact, it could potentially lower the perceived quality of the trajectories.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_2
DP  - Springer Link
SP  - 25
EP  - 38
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_2.pdf
KW  - Character animation
KW  - Crowd simulation
KW  - Perception
ER  - 

TY  - CONF
TI  - Social-Scene-Aware Generative Adversarial Networks for Pedestrian Trajectory Prediction
AU  - Huang, Binhao
AU  - Ma, Zhenwei
AU  - Chen, Lianggangxu
AU  - He, Gaoqi
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Pedestrian trajectory prediction is crucial across a wide range of applications like self-driving vehicles and social robots. Such prediction is challenging because crowd behavior is inherently determined by various factors, such as obstacles, stationary crowd groups and destinations which were difficult to effectively represent. Especially pedestrians tend to be greatly affected by the pedestrians in front of them more than those behind them, which were often ignored in literature. In this paper, we propose a novel framework of Social-Scene-Aware Generative Adversarial Networks (SSA-GAN), which includes three modules, to predict the future trajectory of pedestrians in dynamic scene. Specifically, in the Scene module, we model the original scene image into a scene energy map by combining various scene factors and calculating the probability of pedestrians passing at each location. And the modeling formula is inspired by the distance relationship between pedestrians and scene factors. Moreover, the Social module is used to aggregate neighbors’ interactions on the basis of the correlation between the motion history of pedestrians. This correlation is captured by the self-attention pooling module and limited by the field of view. And then the Generative Adversarial module with variety loss can solve the multimodal problem of pedestrian trajectory. Extensive experiments on publicly available datasets validate the effectiveness of our method for crowd behavior understanding and trajectory prediction.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_15
DP  - Springer Link
SP  - 190
EP  - 201
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_15.pdf
KW  - Crowd behavior
KW  - Energy map
KW  - Pedestrian trajectory prediction
KW  - Self-attention
KW  - Social interaction
ER  - 

TY  - CONF
TI  - Temporal Parameter-Free Deep Skinning of Animated Meshes
AU  - Moutafidou, Anastasia
AU  - Toulatzis, Vasileios
AU  - Fudos, Ioannis
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - In computer graphics, animation compression is essential for efficient storage, streaming and reproduction of animated meshes. Previous work has presented efficient techniques for compression by deriving skinning transformations and weights using clustering of vertices based on geometric features of vertices over time. In this work we present a novel approach that assigns vertices to bone-influenced clusters and derives weights using deep learning through a training set that consists of pairs of vertex trajectories (temporal vertex sequences) and the corresponding weights drawn from fully rigged animated characters. The approximation error of the resulting linear blend skinning scheme is significantly lower than the error of competent previous methods by producing at the same time a minimal number of bones. Furthermore, the optimal set of transformation and vertices is derived in fewer iterations due to the better initial positioning in the multidimensional variable space. Our method requires no parameters to be determined or tuned by the user during the entire process of compressing a mesh animation sequence.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_1
DP  - Springer Link
SP  - 3
EP  - 24
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_1.pdf
KW  - Animation
KW  - Deep learning
KW  - Skinning
ER  - 

TY  - CONF
TI  - Virtual Haptic System for Shape Recognition Based on Local Curvatures
AU  - Garrofé, Guillem
AU  - Parés, Carlota
AU  - Gutiérrez, Anna
AU  - Ruiz, Conrado
AU  - Serra, Gerard
AU  - Miralles, David
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Haptic object recognition is widely used in various robotic manipulation tasks. Using the shape features obtained at either a local or global scale, robotic systems can identify objects solely by touch. Most of the existing work on haptic systems either utilizes a robotic arm with end-effectors to identify the shape of an object based on contact points, or uses a surface capable of recording pressure patterns. In this work, we introduce a novel haptic capture system based on the local curvature of an object. We present a haptic sensor system comprising of three aligned and equally spaced fingers that move towards the surface of an object at the same speed. When an object is touched, our system records the relative times between each contact sensor. Simulating our approach in a virtual environment, we show that this new local and low-dimensional geometrical feature can be effectively used for shape recognition. Even with 10 samples, our system achieves an accuracy of over $$90\%$$90%without using any sampling strategy or any associated spatial information.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_3
DP  - Springer Link
SP  - 41
EP  - 53
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_3.pdf
KW  - Haptic capture
KW  - Haptic perception
KW  - Robotic simulation
KW  - Shape recognition
KW  - Tactile recognition
ER  - 

TY  - CONF
TI  - Real-Time Fluid Simulation with Atmospheric Pressure Using Weak Air Particles
AU  - Sang, Tian
AU  - Chen, Wentao
AU  - Ma, Yitian
AU  - Wang, Hui
AU  - Yang, Xubo
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Atmospheric pressure is important yet often ignored in fluid simulation, resulting in many phenomena being overlooked. This paper presents a particle-based approach to simulate versatile liquid effects under atmospheric pressure in real time. We introduce weak air particles as a sparse sampling of air. The weak air particles can be used to efficiently track liquid surfaces under atmospheric pressure, and are weakly coupled with the liquid. We allow the large-mass liquid particles to contribute to the density estimation of small-mass air particles and neglect the air’s influence on liquid density, leaving only the surface forces of air on the liquid to guarantee the stability of the two-phase flow with a large density ratio. The proposed surface force model is composed of density-related atmospheric pressure force and surface tension force. By correlating the pressure and the density, we ensure that the atmospheric pressure increases as the air is compressed in a confined space. Experimental results demonstrate the efficiency and effectiveness of our methods in simulating the interplay between air and liquid in real time.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_12
DP  - Springer Link
SP  - 151
EP  - 164
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_12.pdf
KW  - Air-liquid interaction
KW  - Atmospheric pressure
KW  - Fluid simulation
KW  - Position based fluids
KW  - Real-time simulation
KW  - Surface tension
ER  - 

TY  - CONF
TI  - Progressive Multi-scale Reconstruction for Guided Depth Map Super-Resolution via Deep Residual Gate Fusion Network
AU  - Wen, Yang
AU  - Wang, Jihong
AU  - Li, Zhen
AU  - Sheng, Bin
AU  - Li, Ping
AU  - Chi, Xiaoyu
AU  - Mao, Lijuan
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Depth maps obtained by consumer depth sensors are often accompanied by two challenging problems: low spatial resolution and insufficient quality, which greatly limit the potential applications of depth images. To overcome these shortcomings, some depth map super-resolution (DSR) methods tend to extrapolate a high-resolution depth map from a low-resolution depth map with the additional guidance of the corresponding high-resolution intensity image. However, these methods are still prone to texture copying and boundary discontinuities due to improper guidance. In this paper, we propose a deep residual gate fusion network (DRGFN) for guided depth map super-resolution with progressive multi-scale reconstruction. To alleviate the misalignment between color images and depth maps, DRGFN applies a color-guided gate fusion module to acquire content-adaptive attention for better fusing the color and depth features. To focus on restoring details such as boundaries, DRGFN applies a residual attention module to highlight the different importance of different channels. Furthermore, DRGFN applies a multi-scale fusion reconstruction module to make use of multi-scale information for better image reconstruction. Quantitative and qualitative experiments on several benchmarks fully show that DRGFN obtains the state-of-the-art performance for depth map super-resolution.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_5
DP  - Springer Link
SP  - 67
EP  - 79
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_5.pdf
KW  - Attention mechanism
KW  - Color image guidance
KW  - Depth map super-resolution
KW  - Gate fusion network
KW  - Multi-scale
ER  - 

TY  - CONF
TI  - Light-Weight Multi-view Topology Consistent Facial Geometry and Reflectance Capture
AU  - Ji, Penglei
AU  - Li, Hanchao
AU  - Jiang, Luyan
AU  - Liu, Xinguo
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - We present a light-weight multi-view capture system with different lighting conditions to generate a topology consistent facial geometry and high-resolution reflectance texture maps. Firstly, we construct the base mesh from multi-view images using the stereo reconstruction algorithms. Then we leverage the mesh deformation technique to register a template mesh to the reconstructed geometry for topology consistency. The facial and ear landmarks are also utilized to guide the deformation. We adopt the photometric stereo and BRDF fitting methods to recover the facial reflectance field. The specular normal which contains high-frequency information is finally utilized to refine the coarse geometry for sub-millimeter details. The captured topology consistent finer geometry and high-quality reflectance information can be used to produce a lifelike personalized digital avatar.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_11
DP  - Springer Link
SP  - 139
EP  - 150
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_11.pdf
ER  - 

TY  - CONF
TI  - Variance Weight Distribution Network Based Noise Sample Learning for Robust Person Re-identification
AU  - Long, Xiaoyi
AU  - Hu, Ruimin
AU  - Xu, Xin
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Person re-identification (re-ID) usually requires a large amount of well-labeled training data to learn generalized discriminative person feature representations. Most of current deep learning models assume that all training data are correctly labeled. However, noisy data commonly exists due to incorrect labeling and person detector errors or occlusions in large scale practical applications. Both types of noisy data can influence model training, while they are ignored by most re-ID models so far. In this paper, we propose a robust deep re-ID model, called variance weight distribution network (VWD-Net), to address this problem. Different from the traditional representations of each person image as a feature vector, the variance weight distribution network focuses on the following three aspects. 1) An improved Gaussian distribution and its variance are used to represent the uncertainty of person features. 2) A well-designed loss in the variance weight distribution network is used to delegate the distribution uncertainty with respect to the training data. 3) The noisy labels are rectified for further optimization on the model training performance. The large scale variance/uncertainty has been assigned to noisy samples and then rectifies their labels, in order to mitigate their negative impact on the training process. Extensive experiments on two benchmarks demonstrate the robustness and effectiveness of VWD-Net.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_8
DP  - Springer Link
SP  - 101
EP  - 112
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_8.pdf
KW  - Feature distribution
KW  - Noise sample learning
KW  - Person re-identification
ER  - 

TY  - CONF
TI  - 3D Shape-Adapted Garment Generation with Sketches
AU  - Chen, Yijing
AU  - Xian, Chuhua
AU  - Jin, Shuo
AU  - Li, Guiqing
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Garment generation or reconstruction is becoming extremely demanding for many digital applications, and the traditional process is time-consuming. In recent years, garment reconstruction from sketch leveraging deep learning and principal component analysis (PCA) has made great progress. In this paper, we present a data-driven approach wherein 3D garments are directly generated from sketches combining given body shape parameters. Our framework is an encoder-decoder architecture. In our network, sketch features extracted by DenseNet and body shape parameters were encoded to latent code respectively. Then, the new latent code obtained by adding two latent codes of the sketch and human body shape is decoded by a fully convolutional mesh decoder. Our network enables the body shape adapted detailed 3D garment generation by leveraging garment sketch and body shape parameters. With the fully convolutional mesh decoder, the network can show the effect of body shape and sketch on the generated garment. Experimental results show that the fully convolutional mesh decoder we used to reconstruct the garment performs higher accuracy and maintains lots of detail compared with the PCA-based method.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_10
DP  - Springer Link
SP  - 125
EP  - 136
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_10.pdf
KW  - 3D Garment Reconstruction
KW  - Body shape adapted
KW  - Mesh decoder
KW  - Sketch-based modeling
ER  - 

TY  - CONF
TI  - SE_EDNet: A Robust Manipulated Faces Detection Algorithm
AU  - Peng, Chaoyang
AU  - Yao, Lihong
AU  - Sun, Tanfeng
AU  - Jiang, Xinghao
AU  - Mi, Zhongjie
A2  - Magnenat-Thalmann, Nadia
A2  - Interrante, Victoria
A2  - Thalmann, Daniel
A2  - Papagiannakis, George
A2  - Sheng, Bin
A2  - Kim, Jinman
A2  - Gavrilova, Marina
T3  - Lecture Notes in Computer Science
AB  - Face manipulation techniques have raised concern over potential threats, which demand effective images forensic methods. Various approaches have been proposed, but when detecting higher-quality manipulated faces, the performance of previous method is not good enough. To prevent the abuse of these techniques and improve the detection ability, this paper proposes a new algorithm named Squeeze-Excitation Euclidean Distance Network (SE_EDNet) to detect manipulated faces, which is suitable for Deepfakes and GANs detection. SE_EDNet use Euclidean distance to describe similaity of vectors, which gives higher weights to important areas than traditional self-attention mechanism. Further, we take frequency into account and extract residuals information, which are obtained by a second-order filter. Then residuals are combined with original images as the input features for the network. Comparison experiment shows SE_EDNet performs better than existing algorithms. Extensive robustness experiments on Celeb-DF and DFFD demonstrate that proposed algorithm is robust against attacking on AUC scores and Recalls.
C1  - Cham
C3  - Advances in Computer Graphics
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-89029-2_6
DP  - Springer Link
SP  - 80
EP  - 88
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-89029-2
ST  - SE_EDNet
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-89029-2_6.pdf
KW  - Image forensics
KW  - Image residuals
KW  - Manipulated faces
KW  - SE_EDNet
ER  - 

TY  - CONF
TI  - A Hybrid Method for Window Detection on High Resolution Facade Images
AU  - Rahmani, Kujtim
AU  - Mayer, Helmut
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - In this paper we present a hybrid method for detecting windows on high-resolution rectified images of building facades combining deep learning with traditional geometric processing. As initial step we use a deep learning object detection method. As we observed that in most cases the detector outputs a larger object than the ground truth. We employ geometric processing based on image gradients to precisely delineate the window edges. For the evaluation of the algorithm we have created a high resolution dataset with more than 2000 annotated windows. The obtained results show that the detector’s bounding box differs from ground truth mostly by less than six pixels. The Intersection over Union IoU of the objects is 96.9%. Geometric processing improves IoU by 1.7% leading to an IoU score of 98.6%.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_4
DP  - Springer Link
SP  - 43
EP  - 50
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_4.pdf
KW  - Facade interpretation
KW  - Object detection
KW  - Optimization
KW  - Window detection
ER  - 

TY  - CONF
TI  - Recursive Feature Elimination Technique for Technical Indicators Selection
AU  - Nagaraj, Naik
AU  - Vikranth, B. M.
AU  - Yogesh, N.
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Stock price movements are determined by several factors such as demand and supply, political stability, company earnings, and foreign portfolio investments. These factors are reflected in stock price, and the market becomes volatile. Most of the studies related to stock price classification are considered limited technical indicators. However, there are more than 100 technical indicators are available. Therefore in this paper, we explored 35 technical indicators. We have considered the recursive feature elimination (RFE) feature selection method to find relevant technical indicators. Final selected feature by the RFE method are given input to a random forest classifier to classify the stock price movements. We have considered Infosys and Reliance stock for the experiments. We found the 0.90 Area Under Curve (AUC) for Infosys stock and the 0.93 AUC for Reliance stock. The experimental results using random forest outperformed compared to Artificial Neural Network (ANN) method.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_12
DP  - Springer Link
SP  - 139
EP  - 145
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_12.pdf
KW  - Random forest classification
KW  - Recursive feature elimination (RFE)
KW  - Technical indicators
ER  - 

TY  - CONF
TI  - Building a Multilingual Corpus of Tweets Relating to Algerian Higher Education
AU  - Siagh, Asma
AU  - Laallam, Fatima Zohra
AU  - Kazar, Okba
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Nowadays, sentiment analysis on user-generated content on social media platforms has shown outstanding benefits in various fields such as marketing, politics, and medicine. Likewise, higher education institutions can draw advantages from the knowledge gained by sentiment analysis of student-generated content on social media to improve their policies and services. However, there has been no available social media corpus concerning Algerian higher education. In light of this, we provide Algerian higher education institutions with the first multilingual tweets corpus. This paper describes the undertaken steps for the corpus-building involving data collection, data preprocessing, and data annotation.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_11
DP  - Springer Link
SP  - 132
EP  - 138
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_11.pdf
KW  - Corpus annotation
KW  - Higher education
KW  - Sentiment analysis
KW  - Social media
ER  - 

TY  - CONF
TI  - 3D Dense & Scaled Reconstruction Pipeline with Smartphone Acquisition
AU  - Thisse, Quentin
AU  - Houzet, Dominique
AU  - Adoux, Jérémy
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Computer vision tackles the hard problems of understanding images and videos. It is a challenge widely discussed in many recent works. Mobile devices such as smartphones or tablets are equipped with sensors more and more precise. They have powerful processing units to collect information about their environment, making them the perfect tool to understand surroundings. Humans understand their world in 3D and have no problems estimating the approximate scale of an object placed in front of them. We tackle this problematic by using a smartphone to acquire visual data and inertial data to reproduce human vision. In that sense, we propose a pipeline for 3D reconstruction that generates dense, scaled and textured 3D model from a series of images acquired with a monocular smartphone. We present a solution of high quality 3D scan within everyone’s reach thanks to data acquisition on a smartphone. We propose a new keyframe selection algorithm that includes an augmented reality object during the scan in order to improve both data quality and ease of use during a scan. Finally, we produce a high quality, dense, textured, scaled 3D model without artifacts thanks to our optimized 3D reconstruction pipeline.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_1
DP  - Springer Link
SP  - 3
EP  - 18
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_1.pdf
KW  - 3D reconstruction
KW  - Automated
KW  - Dense reconstruction
KW  - Scaled
KW  - Smartphone acquisition
ER  - 

TY  - CONF
TI  - Improved Cerebral Images Semantic Segmentation Using Advanced Approaches of Deep Learning
AU  - Zoghbi, Abderraouf
AU  - Benleulmi, Maroua
AU  - Cheriguene, Soraya
AU  - Azizi, Nabiha
AU  - Lagrini, Samira
AU  - Layeb, S. Nadine
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Reliable detection of brain tumors is a challenging task, even with the proper acquisition of Magnetic resonance imaging (MRI) images. Computer-aided detection (CADe) systems can reduce the workload of physicians and minimize the time required for accurate segmentation of illnesses. CADe systems for brain tumors comprises two principles stages: pre-processing of MRI images, and segmentation to define the region of interest (ROI). This paper describes the application of deep learning to detect tumors on brain MRI images where the number of defective samples available is small, which is fairly common in many real practical applications and can negatively affect the model performance. In the presented study, the Generative Adversarial Networks (GANs) learned how to synthesize realistic images to improve the training of DL models. We also explored CyclaGAN architecture via hyperparameter tuning and performed image segmentation for brain tumor. The proposed CADe system was validated on Figshare dataset of brain MRI images. Experimental results show that, the data augmentation method can increase the segmentation performance efficiently and effectively.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_6
DP  - Springer Link
SP  - 65
EP  - 77
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_6.pdf
KW  - Brain tumor
KW  - Computer-Aided Detection
KW  - Data augmentation
KW  - Deep learning
KW  - Generative Adversarial Networks
KW  - Imbalanced data
KW  - Medical image
KW  - MRI
KW  - Segmentation
KW  - Synthesis image
ER  - 

TY  - CONF
TI  - Neuro-Fuzzy Predictive Approach for Visual Analytics Evaluation of Medical Data
AU  - Amri, Saber
AU  - Kaddachi, Med Lassaad
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - In Visual analytics evaluation field we still do not know what would look like an efficient application. We then aim to develop guidelines (design then development), in order to obtain a coherent information base. This paper introduces a new intelligent approach based on neural network and fuzzy logic techniques allowing an automated visual analytics evaluation. This novel approach executes a Self-Organizing Feature Map (SOFM) neural network model that communicates with human environment using natural language, interacts with users, understands the context of conversations, and detects each sentence meaning. Then, we use fuzzy logic to process participant responses. By this way, an intelligent evaluation procedure is generated. After executing a learning algorithm, our application becomes capable to automatically capture new knowledge and reorganize it in visualization evaluation procedures. This enables an efficient visualizations evaluations taking into account different criteria and measures of visualization characteristics. This feature cancels required limitations imposed on users using other evaluations methods. It allows them to freely evaluate visualizations and discovering each time new criteria evaluations. Moreover this method allows an automatic learning of evaluation procedure following sentence given by users.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_5
DP  - Springer Link
SP  - 51
EP  - 64
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_5.pdf
KW  - Artificial neural networks (ANNs)
KW  - Evaluation
KW  - Fuzzy logic
KW  - Self-Organizing Feature Map (SOFM)
KW  - Visualization
ER  - 

TY  - CONF
TI  - Self-supervised Learning for COVID-19 Detection from Chest X-ray Images
AU  - Feki, Ines
AU  - Ammar, Sourour
AU  - Kessentini, Yousri
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Most of existing computer vision applications rely on models trained on supervised corpora, this is contradictory to what the world is seeing with the explosion of massive sets of unlabeled data. In the field of medical imaging for example, creating labels is extremely time-consuming because professionals should spend countless hours looking at images to manually annotate, segment, etc. Recently, several works are looking for solutions to the challenge of learning effective visual representations with no human supervision. In this work, we investigate the potential of using a self-supervised learning as a pretraining phase in improving the classification of radiographic images when the amount of available annotated data is small. To do that, we propose to use a self-supervised framework by pretraining a deep encoder with contrastive learning on a chest X-ray dataset using no labels at all, and then fine-tuning it using only few labeled data samples.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_7
DP  - Springer Link
SP  - 78
EP  - 89
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_7.pdf
KW  - COVID-19 detection
KW  - Deep learning
KW  - Self-supervised learning
KW  - X-ray images
ER  - 

TY  - CONF
TI  - Exploratory Analysis of Driver and Vehicle Factors Associated with Traffic Accidents in Morocco
AU  - Khyara, Hamza
AU  - Amine, Aouatif
AU  - Nassih, Bouchra
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - In Morocco, road safety corresponds to a major public health and personal protection issue. According to statistics from the Ministry of Equipment, Transport, Logistics, and Water (METLW), the number of personal injuries reached 89,375 with an average of 10 deaths and 361 injured per day in 2017. This study tends to analyze Moroccan road traffic accidents and reveal the most influencing driver and vehicle factors on them. We implement a statistical analysis based on descriptive and exploratory analysis on the Moroccan accident database between 2013 and 2017. The database is provided by METLW and includes information about the driver and motor vehicle characteristics. Drivers between the ages of 18 and 53 are the most vulnerable to road accidents, accounting for 76% of all drivers. Male drivers represent a high percentage, around 95.2%. Most of the victims drivers were uninjured or slightly injured, which means that accidents are more likely to occur at intersections. Vehicle type and usage do not have a significant effect on Moroccan accident casualties and fatalities.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_10
DP  - Springer Link
SP  - 119
EP  - 131
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_10.pdf
KW  - Descriptive analysis
KW  - Exploratory data analysis
KW  - Road safety
KW  - Road traffic accident
KW  - Statistical analysis
ER  - 

TY  - CONF
TI  - Bat Echolocation Call Detection and Species Recognition by Transformers with Self-attention
AU  - Bellafkir, Hicham
AU  - Vogelbacher, Markus
AU  - Gottwald, Jannis
AU  - Mühling, Markus
AU  - Korfhage, Nikolaus
AU  - Lampe, Patrick
AU  - Frieß, Nicolas
AU  - Nauss, Thomas
AU  - Freisleben, Bernd
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Biodiversity is important for several ecosystem services that provide the existential basis for human life. The current decline in biodiversity requires a transformation from manual, periodic assessment to automatic real-time biodiversity monitoring. Bats as one of the most widespread species among terrestrial mammals serve as important bioindicators for the health of ecosystems. Typically, bats are monitored by recording and analyzing their echolocation calls. In this paper, we present a novel approach for detecting bat echolocation calls and recognizing bat species in audio spectrograms. It is based on a transformer neural network architecture and relies on self-attention. Our experiments show that our approach outperforms state-of-the-art approaches for bat echolocation call detection and species recognition on several publicly available data sets. While our bat echolocation call detection approach achieves a performance of up to 90.2% in terms of average precision, our bat species recognition model obtains up to 88.7% accuracy for 14 bat classes occurring in Germany, some of which are difficult to distinguish even for human experts.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_16
DP  - Springer Link
SP  - 189
EP  - 203
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_16.pdf
KW  - Bat echolocation call detection
KW  - Bat species recognition
KW  - Self-attention
KW  - Transformer architectures
ER  - 

TY  - CONF
TI  - Deep Learning-Based Segmentation of Connected Components in Arabic Handwritten Documents
AU  - Gader, Takwa Ben Aïcha
AU  - Echi, Afef Kacem
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - This work proposes a practical and powerful segmentation approach that allows touching or overlapping characters in adjacent text lines or words within Arabic manuscripts to be segmented correctly. It is the first deep learning-based method proposed to solve this problem. It is based on a modified U-Net named AR2U-net: an Attention-based Recurrent Residual U-net model trained to separate touching characters. It is trained on the LTP (Local Touching Patches) database to segment touching characters in a pixel-wise classification. The network labels pixels of the touching characters’ images in four classes: pixels of background, pixels of the first character, pixels of the second character, and those where characters touch. Once the segmentation is done, the separation of touching text lines or words can be done efficiently and speedily. We also propose a post-treatment to segment successive touching text lines in this work. Experimental results on the LTP database show that our proposed method is practical in copes with touching and overlapped characters separation. It achieves higher accuracy of 94.6% than those reported in the state-of-the-art.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_8
DP  - Springer Link
SP  - 93
EP  - 106
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_8.pdf
KW  - Attention mechanism
KW  - Deep learning
KW  - Handwritten characters
KW  - Segmentation
KW  - Touching characters
ER  - 

TY  - CONF
TI  - A New Study of Needs and Motivations Generated by Virtual Reality Games and Factor Products for Generation Z in Bangkok
AU  - Meksumphun, Kawin
AU  - Kerdvibulvech, Chutisant
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Metaverse has recently been an emerging field in computer science, especially virtual reality games. Therefore, this paper aims to find the need and motivation for virtual reality games and the factor products via correlational research. The target group is framed from the demographic data in Bangkok in 2019 by the National Statistical Office of Thailand. 40 people around 18–24 years old are selected. We then develop new virtual reality games from free assets on Unity for testing and gathering information. Findings from the study showed that the product motives affecting Generation Z in Bangkok differ according to demographic characteristics. The results found that the highest average of need and motivation of Generation Z is convenience (4.25%), product appearance (4.20%), game effects (4.18%), pictures and graphics (4.05%), sound effects (3.93%), and game challenge (3.93%). However, the most negligible impact shows that the needs and motivations of Generation Z are branding (3.93%).
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_3
DP  - Springer Link
SP  - 29
EP  - 42
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_3.pdf
KW  - Augmented reality
KW  - Correlational research
KW  - Games
KW  - Generation Z
KW  - Metaverse
KW  - Motivation
KW  - Virtual world
ER  - 

TY  - CONF
TI  - A Genetic Model for Medical Images Reproduction
AU  - Benhamza, Karima
AU  - Guerziz, Ines
AU  - Bentagine, Amel
AU  - Seridi, Hamid
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Reproducing images arise in many applications such as image compression, Image optimization, graphic art, and medical image processing. For medical images, image quality is crucial for proper diagnosis from an imaging study. The challenges in medical image processing occur due to poor image contrast and artifacts that outcome from missing organ boundaries. In this paper, a new variant of the Genetic Algorithm (GA) is proposed to provide an optimal solution to the medical image reproduction problem. The genetic operators have been adapted and the fitness function has been adjusted to produce good solutions. The implemented method, tested with different medical images, offers good results and agrees well with the complex medical images and even with low-quality images.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_2
DP  - Springer Link
SP  - 19
EP  - 28
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_2.pdf
KW  - Fitness function
KW  - Genetic algorithm
KW  - Medical image
KW  - Reproducing image
KW  - Similarity
ER  - 

TY  - CONF
TI  - Document-Based Knowledge Discovery with Microservices Architecture
AU  - Gidey, Habtom Kahsay
AU  - Kesseler, Mario
AU  - Stangl, Patrick
AU  - Hillmann, Peter
AU  - Karcher, Andreas
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - The first step towards digitalization within organizations lies in digitization - the conversion of analog data into digitally stored data. This basic step is the prerequisite for all following activities like the digitalization of processes or the servitization of products or offerings. However, digitization itself often leads to “data-rich” but “knowledge-poor” material. Knowledge discovery and knowledge extraction as approaches try to increase the usefulness of digitized data.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_13
DP  - Springer Link
SP  - 146
EP  - 161
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_13.pdf
KW  - Knowledge discovery
KW  - Microservices
KW  - Ontology
KW  - Servitization
ER  - 

TY  - CONF
TI  - Parameter Identification and Validation of Multi-innovation Least Squares Lithium Battery for Second-Order Battery Model
AU  - Wu, Jie
AU  - Xu, Huigang
AU  - Zhu, Peiyi
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Accurate lithium-ion battery models are important for the accurate estimation of battery states as well as the simulation, design, and optimization of new energy electric vehicles. However, the traditional recursive least squares method exhibits disadvantages such as low accuracy and long convergence time when applied to the identification of battery model parameters. In this paper, the second-order RC equivalent circuit model of lithium-ion battery is studied, and the online identification of model parameters by Multi-innovation least squares method is presented, data collected through HPPC cycle conditions and NEDC conditions experiments. The accuracy and convergence speed of the conventional recursive least squares estimation algorithm is described, to compare the absolute error between the estimated battery port voltage and the real value of the battery with different new interest lengths of the new interest least squares algorithm. The experimental results show that the multi-new interest least squares algorithm with longer new interest length has higher accuracy and convergence speed, which verifies the effectiveness and feasibility of the proposed method.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_15
DP  - Springer Link
SP  - 180
EP  - 188
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_15.pdf
KW  - Estimation of battery states
KW  - Lithium-ion battery
KW  - Multi-innovation least squares
ER  - 

TY  - CONF
TI  - Classifying the Human Activities of Sensor Data Using Deep Neural Network
AU  - Al-Khamees, Hussein A. A.
AU  - Al-A’araji, Nabeel
AU  - Al-Shamery, Eman S.
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - Today sensors represent one of the most important applications for generating data stream. This data has a number of unique characteristics, including fast data access, huge volume, as well as the most prominent feature, the concept drift. Machine learning in general and deep learning technique in particular is among the predominant and successful selections to classify the human activities. This is due to several reasons such as results quality and processing time. The recognition of human activities that produced from sensors considers is an effective and vital task in the healthcare field, meanwhile, it is an attractive to researchers. This paper presents a DNN model to classify the human activities of the HuGaDB sensor dataset by implementing multilayer perceptron (MLP) structure. The current model achieved results, 91.7% of accuracy, 92.5% precision, 92.0% recall, and 92.0% of F1-score, using a tiny time. The model results were compared with the previous models and it has proven its efficiency by outperforming those models.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_9
DP  - Springer Link
SP  - 107
EP  - 118
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_9.pdf
KW  - Deep neural network
KW  - HuGaDB dataset
KW  - Human activities classification
KW  - MultiLayer Perceptron (MLP)
KW  - Sensor data stream
ER  - 

TY  - CONF
TI  - Feature Selection for Credit Risk Classification
AU  - Atif, Dalia
AU  - Salmi, Mabrouka
A2  - Bennour, Akram
A2  - Ensari, Tolga
A2  - Kessentini, Yousri
A2  - Eom, Sean
T3  - Communications in Computer and Information Science
AB  - With the advancement of storage methods, feature selection has become increasingly important in many fields of study, including credit risk classification. To improve model robustness, feature screening has predominated, but it suffers from being trapped at the local optimum. Among the various proposed strategies to deal with this issue is integrating feature selection into the training phase. We compare two of the most commonly used methods in the related field, one parametric (logistic regression) with regularization of the L1 norm and the second non-parametric (random forests) with wrapper-based strategy; while integrating feature selection into the training process. We used the German credit dataset and employed preprocessing steps such as class merging, data standardization, and dummy coding. The results formulated on classification based-measures built on a 70:30 split revealed that logistic regression outperformed with Accuracy = 0.75, Sensitivity (Recall) = 0.9825, Precision = 0.742, F1-score = 0.845, AUC = 0.8, and PR-AUC = 0.877.
C1  - Cham
C3  - Intelligent Systems and Pattern Recognition
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-08277-1_14
DP  - Springer Link
SP  - 165
EP  - 179
LA  - en
PB  - Springer International Publishing
SN  - 978-3-031-08277-1
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-031-08277-1_14.pdf
KW  - Credit risk classification
KW  - Embedded
KW  - Feature selection
KW  - Lasso
KW  - Random forests
KW  - Wrapper
ER  - 

TY  - CONF
TI  - CySpider: A Neural Semantic Parsing Corpus with Baseline Models for Property Graphs
AU  - Zhao, Ziyu
AU  - Liu, Wei
AU  - French, Tim
AU  - Stewart, Michael
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Enterprise knowledge graphs are gaining increasing popularity in industrial applications, with a pressing demand for natural language interfaces to support non-technical end-users. For natural language queries to relational databases, the neural semantic parsing task Text-to-SQL achieves strong performance in translating text inputs to SQL queries. However, very few public corpora are available for the training of neural semantic parsing models that convert textual queries to graph query languages. In this research, we develop a generic SQL2Cypher algorithm that can map a SQL query to a set of Cypher clauses, where Cypher is a query language used by a popular property graph database Neo4j. The converted Cypher statement is then combined with the original natural language query to create a parallel corpus that enables end-to-end training of neural semantic parsing models for Text-to-Cypher. To evaluate the dataset quality, we construct a corresponding graph database to obtain execution accuracy. In addition, the Text-to-Cypher corpus features four transformer-based baseline models. The availability of such corpus and baseline models is critical in developing and benchmarking new machine learning methods in advancing natural language interfaces for fact retrieval from large graph-based knowledge repositories. The source code and dataset are available at github(https://github.com/22842219/SemanticParser4Graph).
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_10
DP  - Springer Link
SP  - 120
EP  - 132
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
ST  - CySpider
KW  - Semantic Parsing
KW  - Text-to-Cypher
KW  - Text/Data Mining
ER  - 

TY  - CONF
TI  - Epistemic Reasoning in Computational Machine Ethics
AU  - Limarga, Raynaldio
AU  - Song, Yang
AU  - Pagnucco, Maurice
AU  - Rajaratnam, David
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Recent developments in computational machine ethics have adopted the assumption of a fully observable environment. However, such an assumption is not realistic for the ethical decision-making process. Epistemic reasoning is one approach to deal with a non-fully observable environment and non-determinism. Current approaches to computational machine ethics require careful designs of aggregation functions (strategies). Different strategies to consolidate non-deterministic knowledge will result in different actions determined to be ethically permissible. However, recent studies have not tried to formalise a proper evaluation of these strategies. On the other hand, strategies for a partially observable universe are also studied in the game theory literature, with studies providing axioms, such as Linearity and Symmetry, to evaluate strategies in situations where agents need to interact with the uncertainty of nature. Regardless of the resemblance, strategies in game theory have not been applied to machine ethics. Therefore, in this study, we propose to adopt four game theoretic strategies to three approaches of machine ethics with epistemic reasoning so that machines can navigate complex ethical dilemmas. With our formalisation, we can also evaluate these strategies using the proposed axioms and show that a particular aggregation function is more volatile in a specific situation but more robust in others.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_7
DP  - Springer Link
SP  - 82
EP  - 94
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Epistemic Reasoning
KW  - Game Theory
KW  - Machine Ethics
ER  - 

TY  - CONF
TI  - Using Social Sensing to Validate Flood Risk Modelling in England
AU  - Joyce, Joshua
AU  - Arthur, Rudy
AU  - Fu, Guangtao
AU  - Bialkowski, Alina
AU  - Williams, Hywel
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Floods are amongst the most severe natural disasters. Accurate flood risk maps are vital for emergency response operations and long-term flood defence planning. Currently the validation of such maps is often neglected and suffers from a lack of high-quality data. The proliferation of social media usage worldwide in recent years has supplied access to large amounts of data linked to flooding, and the detection of real-world events using such data is termed ‘social sensing’. In this paper we investigate the use of social sensing for the validation of flood risk maps. We apply this methodology to 7 years’ worth of flood related Tweets in order to perform a comparison to long term planning flood risk maps in England. The results show that there is a low level of correlation between the collection of socially sensed floods and high-risk flood areas as well as highlighting areas with high levels of socially sensed flooding that have low levels of flood risk, showcasing the potential importance of social media data for use in flood risk validation and planning policy.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_8
DP  - Springer Link
SP  - 95
EP  - 106
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Flooding
KW  - Social media
KW  - Twitter
ER  - 

TY  - CONF
TI  - Lateral AI: Simulating Diversity in Virtual Communities
AU  - Hadzic, Fedja
AU  - Krayneva, Maya
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - In this paper, we present Lateral AI that offers a diverse and multi-dimensional world experience. It makes use of semi-automated prompt engineering on top of GPT3.5. The coupling with named entity recognition and text summarization enables creation of a diversity of AI personas and a multiplicity of requests. The features of Lateral AI, such as creation of custom AI personas, prioritisation of user-embedded knowledge in those personas and follow-up requests, enable users to co-create with AI. Users can contribute certain information and perspectives to the application if a Large Language Model does not have access to it. Lateral AI makes the user an active component of the integrated system rather than a mere AI consumer. We demonstrate use of Lateral AI to generate a range of diverse responses and illustrate the ability of AI to predict beyond its factual knowledge. Lateral AI is a unique and alternative option to other AI models, contributing to the diverse and creative pool of emerging AI technologies and applications. The principles behind Lateral AI can be used to simulate diverse communities in a variety of settings such as online virtual communities and human robotics.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_4
DP  - Springer Link
SP  - 41
EP  - 53
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
ST  - Lateral AI
KW  - Knowledge Prioritization in LLMs
KW  - Lateral AI
KW  - Lateral Thinking
KW  - LLM Predictions
KW  - Virtual Communities
ER  - 

TY  - CONF
TI  - A Prompting Framework to Enhance Language Model Output
AU  - Ratnayake, Himath
AU  - Wang, Can
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - This research investigates the role of prompt engineering in enhancing the performance and generalisation of large-scale language models (LLMs) across a wide range of Natural Language Processing (NLP) tasks. The study introduces a comprehensive framework for prompt engineering, titled the “PERFECT” framework, and evaluates its effectiveness across different tasks and domains. The research findings underscore the pivotal role of advanced prompting techniques in eliciting more nuanced and flexible responses from AI models. The study also explores the future implications of prompt engineering, including the integration of reinforcement learning with human feedback, the emergence of prompt engineering as a new job market, and the rise of context-aware and interactive prompts. The research contributes to a deeper understanding of the principles, mechanisms, and best practices in prompt engineering, with practical implications for improving LLM performance and reducing the barrier to entry for new adoptees through using prompting frameworks. The research aims have been largely achieved, providing a new framework for prompting while also exploring future advancements. However, the study also highlights the need for further exploration of the constraints placed on current prompting techniques, such as token size and context window.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_6
DP  - Springer Link
SP  - 66
EP  - 81
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Large-Scale Language Models
KW  - Natural Language Processing
KW  - Prompt Engineering
KW  - Prompting Framework
ER  - 

TY  - CONF
TI  - Impact of Fidelity and Robustness of Machine Learning Explanations on User Trust
AU  - Wang, Bo
AU  - Zhou, Jianlong
AU  - Li, Yiqiao
AU  - Chen, Fang
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - EXplainable machine learning (XML) has recently emerged as a promising approach to address the inherent opacity of machine learning (ML) systems by providing insights into their reasoning processes. This paper explores the relationships among user trust, fidelity, and robustness within the context of ML explanations. To investigate these relationships, a user study is implemented within the context of predicting students’ performance. The study is designed to focus on two scenarios: (1) fidelity-based scenario—exploring dynamics of user trust across different explanations at varying fidelity levels and (2) robustness-based scenario—examining dynamics of in user trust concerning robustness. For each scenario, we conduct experiments based on two different metrics, including self-reported trust and behaviour-based trust metrics. For the fidelity-based scenario, we find that users trust both high and low-fidelity explanations compared to without-fidelity explanations (no explanations) based on the behaviour-based trust results, rather than relying on the self-reported trust results. We also obtain consistent findings based on different metrics, indicating no significant differences in user trust when comparing different explanations across fidelity levels. Additionally, for the robustness-based scenario, we get contrasting results from the two metrics. The self-reported trust metric does not demonstrate any variations in user trust concerning robustness levels, whereas the behaviour-based trust metric suggests that user trust tends to be higher when robustness levels are higher.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_17
DP  - Springer Link
SP  - 209
EP  - 220
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Fidelity
KW  - Human computer interaction
KW  - Machine learning explanation
KW  - Robustness
KW  - User trust
ER  - 

TY  - CONF
TI  - S5TR: Simple Single Stage Sequencer for Scene Text Recognition
AU  - Wu, Zhijian
AU  - Li, Jun
AU  - Xu, Jianhua
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - As an active research topic in computer vision, scene text recognition (STR) aims to recognize character sequences in natural scenes. Currently, mainstream STR approaches consist of two main modules: a visual model for feature extraction and a sequence model for text translation. The two modules function separately and sequentially, which increases the complexity of the STR model. In this study, we propose a novel Simple Single Stage Sequencer for Scene Text Recognition (S5TR), which allows to transform text instance images into string sequences directly. Specifically, our S5TR contains stacks of Sequencers made of horizontal and vertical Long Short Term Memory Networks (LSTMs). On the one hand, S5TR extracts visual representations of images by modeling long-range dependencies via LSTM, which is similar to self-attention in Vision Transformer (ViT). On the other hand, LSTM serving as a sequence modeling module is able to capture contextual information within the character sequence for predicting the character. Experimental results demonstrate that our S5TR achieves highly competitive performance compared to existing STR methods.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_11
DP  - Springer Link
SP  - 133
EP  - 143
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
ST  - S5TR
KW  - LSTM
KW  - Neural network
KW  - Scene text recognition
KW  - Text transcription
ER  - 

TY  - CONF
TI  - Systematic Analysis of the Impact of Label Noise Correction on ML Fairness
AU  - Silva, Inês Oliveira e.
AU  - Soares, Carlos
AU  - Sousa, Inês
AU  - Ghani, Rayid
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply the methodology to analyze six label noise correction methods according to several fairness metrics on standard OpenML datasets. Our results suggest that the Hybrid Label Noise Correction [20] method achieves the best trade-off between predictive performance and fairness. Clustering-Based Correction [14] can reduce discrimination the most, however, at the cost of lower predictive performance.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_14
DP  - Springer Link
SP  - 173
EP  - 184
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
L4  - https://arxiv.org/pdf/2306.15994
KW  - Bias mitigation
KW  - Label noise correction
KW  - ML fairness
KW  - Semi-synthetic data
ER  - 

TY  - CONF
TI  - Coping with Data Distribution Shifts: XAI-Based Adaptive Learning with SHAP Clustering for Energy Consumption Prediction
AU  - Clement, Tobias
AU  - Nguyen, Hung Truong Thanh
AU  - Kemmerzell, Nils
AU  - Abdelaal, Mohamed
AU  - Stjelja, Davor
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Adapting to data distribution shifts after training remains a significant challenge within the realm of Artificial Intelligence. This paper presents a refined approach, superior to Automated Hyper Parameter Tuning methods, that effectively detects and learns from such shifts to improve the efficacy of prediction models. By integrating Explainable AI (XAI) techniques into adaptive learning with SHAP clustering, we generate interpretable model explanations and use these insights for adaptive refinement. Our three-stage process: (1) SHAP value generation for the model explanation, (2) clustering these values for pattern identification, and (3) model refinement based on the derived SHAP cluster characteristics, mitigates overfitting and ensures robust data shift handling. We evaluate our method on a comprehensive dataset comprising energy consumption records of buildings, as well as two additional datasets, to assess the transferability of our approach to other domains, regression, and classification problems. Our experiments highlight that our method not only improves predictive performance in both task types but also delivers interpretable model explanations, offering significant value in dealing with the challenges of data distribution shifts in AI.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_12
DP  - Springer Link
SP  - 147
EP  - 159
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
ST  - Coping with Data Distribution Shifts
KW  - Adaptive Learning
KW  - Data Distribution Shifts
KW  - Explainable AI
ER  - 

TY  - CONF
TI  - The Difficulty of Novelty Detection and Adaptation in Physical Environments
AU  - Pinto, Vimukthini
AU  - Gamage, Chathura
AU  - Stephenson, Matthew
AU  - Renz, Jochen
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Detecting and adapting to novel situations is a major challenge for AI systems that operate in open-world environments. One reason for this challenge is due to the diverse range of forms that novelties can take. To accurately evaluate an AI system’s ability to detect and adapt to novelties, it is crucial to investigate and formalize the difficulty of different novelty types. In this paper, we propose a method for quantifying the difficulty of novelty detection and novelty adaptation in open-world physical environments, considering factors such as the appearance and location of objects, as well as the actions required by the agent. We implement several difficulty measures using a combination of qualitative spatial relations, learning algorithms, and statistical distance measures. To demonstrate an application of our approach, we apply our difficulty measures to novelties in the popular physics simulation game Angry Birds. We invite researchers to incorporate the proposed novelty difficulty measures when evaluating AI systems to gain a better understanding of their limitations and identify areas for future improvement.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_3
DP  - Springer Link
SP  - 28
EP  - 40
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - AI Evaluation
KW  - Difficulty
KW  - Novelty
KW  - Open-world Learning
ER  - 

TY  - CONF
TI  - Towards Learning Action Models from Narrative Text Through Extraction and Ordering of Structured Events
AU  - Li, Ruiqi
AU  - Haslum, Patrik
AU  - Cui, Leyang
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Event models, in the form of scripts, frames, or precondition/effect axioms, allow for reasoning about the causal and motivational connections between events in a story, and thus are central to AI understanding and generating narratives. However, previous efforts to learn general structured event models from text have overlooked important challenges raised by the narrative text, such as the complex (nested) event arguments and inferring the order and actuality of mentioned events. We present an NLP pipeline for extracting (partially) ordered, structured event representations for use in learning general event models from three large text corpora. We address each of the challenges that we identify to some degree, but also conclude that they raise open problems for future research.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_2
DP  - Springer Link
SP  - 16
EP  - 27
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - event extraction
KW  - event model acquisition
KW  - event ordering
ER  - 

TY  - CONF
TI  - Part-Aware Prototype-Aligned Interpretable Image Classification with Basic Feature Domain
AU  - Li, Liangping
AU  - Gong, Xun
AU  - Wang, Chenzhong
AU  - Kong, Weiji
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - In recent years, the interpretive this looks like that structure has gained significant attention. It refers to the human tendency to break down images into key parts and make classification decisions by comparing them to pre-existing concepts in their minds. However, most existing prototypical-based models assign prototypes directly to each category without considering that key parts with the same meaning may appear in images from different categories. To address this issue, we propose dividing prototypes with the same meaning into the same latent space (referred to as Basic Feature Domain) since different category parts only slightly affect the corresponding prototype vectors. This process of integrating prototypes based on the feature domain is referred to as prototype alignment. Additionally, we introduce the concept of part-aware optimization, which prioritizes prototypical parts of images over simple category labels during optimizing prototypes. Moreover, we present two feature aggregation methods, by row and by cluster, for the basic feature domain. We demonstrate competitive results compared to other state-of-the-art prototypical part methods on the CUB-2011-200 dataset and Stanford Cars dataset using our proposed self-explanatory part-aware proto-aligned network (PaProtoPNet).
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_15
DP  - Springer Link
SP  - 185
EP  - 196
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Interpretable image classification
KW  - Prototype alignment
KW  - Reasoning process
ER  - 

TY  - CONF
TI  - Collaborative Qualitative Environment Mapping
AU  - Secolo, Adeline
AU  - Santos, Paulo E.
AU  - Doherty, Patrick
AU  - Sjanic, Zoran
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - This paper explores the use of LH Interval Calculus, a novel qualitative spatial reasoning formalism, to create a human-readable representation of environments observed by UAVs. The system simplifies data from multiple UAVs collaborating on environment mapping. Real UAV-captured data was used for evaluation. In tests involving two UAVs mapping an outdoor area, LH Calculus proved effective in generating a cohesive high-level description of the environment, contingent on consistent input data.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_1
DP  - Springer Link
SP  - 3
EP  - 15
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Knowledge representation
KW  - mapping
KW  - multi-robot systems
ER  - 

TY  - CONF
TI  - Concept-Guided Interpretable Federated Learning
AU  - Yang, Jianan
AU  - Long, Guodong
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Interpretable federated learning is an emerging challenge to identify explainable characteristics of each client-specific personalized model in a federated learning system. This paper proposes a novel federated concept bottleneck (FedCBM) method by introducing human-friendly concepts for client-wise model interpretation. Specifically, given a set of pre-defined concepts, all clients will collaboratively train shared Concept Activation Vectors (CAVs) in federated settings. The shared concepts will be the information carrier to align client-specific representations, and also be applied to enhance the model’s accuracy under a supervised learning loss. The effectiveness of our method and concept-level reasoning is demonstrated in our experimental analysis.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_13
DP  - Springer Link
SP  - 160
EP  - 172
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Concept Reasoning
KW  - Federated Learning
KW  - Interpretability
ER  - 

TY  - CONF
TI  - Reports, Observations, and Belief Change
AU  - Hunter, Aaron
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - We consider belief change in a context where information comes from reports, and the reporting agents may not be honest. In order to capture this process, we introduce an extended class of epistemic states that includes a history of past reports received. We present a set of postulates that describe how new reports should be incorporated. The postulates describe a new kind of belief change operator, where reported information can either be believed or ignored. We then provide a representation result for these postulates, which characterizes report revision in terms of an underlying set of agents that are perceived to be honest. We then extend our framework by adding observations. In this framework, observations are understood to be highly reliable. As such, when an observation conflicts with a report, we must question the honesty of the agent that provided the report. We introduce a flexible framework where we can set a threshold for the number of false reports an agent can send before they are labelled dishonest. Fundamental results are provided, along with a discussion on key future problems to be addressed in trust and belief revision.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_5
DP  - Springer Link
SP  - 54
EP  - 65
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - Belief Revision
KW  - Knowledge Representation
KW  - Trust
ER  - 

TY  - CONF
TI  - Hybrid CNN-Interpreter: Interprete Local and Global Contexts for CNN-Based Models
AU  - Yang, Wenli
AU  - Huang, Guan
AU  - Li, Renjie
AU  - Yu, Jiahao
AU  - Chen, Yanyu
AU  - Bai, Quan
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - Convolutional neural network (CNN) models have seen advanced improvements in performance in various domains, but lack of interpretability is a major barrier to assurance and regulation during operation for acceptance and deployment of AI-assisted applications. There have been many works on input interpretability focusing on analyzing the input-output relations, but the internal logic of models has not been clarified in the current mainstream interpretability methods. In this study, we propose a novel hybrid CNN-interpreter through: (1) An original forward propagation mechanism to examine the layer-specific prediction results for local interpretability. (2) A new global interpretability that indicates the feature correlation and filter importance effects. By combining the local and global interpretabilities, hybrid CNN-interpreter enables us to have a solid understanding and monitoring of model context during the whole learning process with detailed and consistent representations. Finally, the proposed interpretabilities have been demonstrated to adapt to various CNN-based model structures.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_16
DP  - Springer Link
SP  - 197
EP  - 208
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
ST  - Hybrid CNN-Interpreter
KW  - correlation
KW  - filter importance
KW  - global context
KW  - Hybrid interpreter
KW  - Local context
ER  - 

TY  - CONF
TI  - Symbolic Data Analysis to Improve Completeness of Model Combination Methods
AU  - Strecht, Pedro
AU  - Mendes-Moreira, João
AU  - Soares, Carlos
A2  - Liu, Tongliang
A2  - Webb, Geoff
A2  - Yue, Lin
A2  - Wang, Dadong
T3  - Lecture Notes in Computer Science
AB  - A growing number of organizations are adopting a strategy of breaking down large data analysis problems into specific sub-problems, tailoring models for each. However, handling a large number of individual models can pose challenges in understanding organization-wide phenomena. Recent studies focus on using decision trees to create a consensus model by aggregating local decision trees into sets of rules. Despite efforts, the resulting models may still be incomplete, i.e., not able to cover the entire decision space. This paper explores methodologies to tackle this issue by generating complete consensus models from incomplete rule sets, relying on rough estimates of the distribution of independent variables. Two approaches are introduced: synthetic dataset creation followed by decision tree training and a specialized algorithm for creating a decision tree from symbolic data. The feasibility of generating complete decision trees is demonstrated, along with an empirical evaluation on a number of datasets.
C1  - Singapore
C3  - AI 2023: Advances in Artificial Intelligence
DA  - 2024///
PY  - 2024
DO  - 10.1007/978-981-99-8391-9_9
DP  - Springer Link
SP  - 107
EP  - 119
LA  - en
PB  - Springer Nature
SN  - 978-981-9983-91-9
KW  - consensus models
KW  - model completeness
KW  - symbolic data
ER  - 

TY  - CONF
TI  - Emulation of Multipath Solutions in Heterogeneous Wireless Networks Over Ns-3 Platform
AU  - Hapanchak, Vadym S.
AU  - Costa, António D.
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - The increased availability of devices equipped with multiple wireless interfaces leads to consider multihoming as one of the key features of the next generation 5G networks. This paper discusses the emulation technique that integrates Linux Container and ns-3 network simulator to evaluate emerging multipath applications and protocols. The presented solution was utilized as an experimental platform to analyze the performance of Multipath TCP (MPTCP) protocol in heterogeneous network environments, particularly wireless ones, such as WLAN and cellular networks. We tested the MPTCP in fixed and mobility scenarios, exploiting the ns-3 to provide multipath wireless connectivity. The obtained results show the protocol behaviour that might have been expected from the system under investigation. Thus, one could use the presented scheme to get emulation results with reasonable accuracy, as long as ns-3 follows up with external real-time events. We further discuss the main limitations of the described method, observed in large-scale scenarios.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_1
DP  - Springer Link
SP  - 3
EP  - 18
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_1.pdf
KW  - Heterogeneous
KW  - LXC
KW  - MPTCP
KW  - Multipath
KW  - Network emulation
KW  - Ns-3
KW  - Simulation
KW  - Wireless networks
ER  - 

TY  - CONF
TI  - A Video Parallel Retrieval Method Based on Deep Hash
AU  - Li, Jiayi
AU  - Bei, Lulu
AU  - Li, Dan
AU  - Cui, Ping
AU  - Huang, Kai
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - This paper designs a parallel video retrieval based on Spark and deep hash. The method comprises deep feature extraction using a convolution neural network based on partial semantic weighted aggregation; filtering features of image information in deep networks; the extraction and distributed storage of video summary keys; the establishment of distributed product quantitative hash coding model of image, realizing the distributed coding compression of high-dimensional features. The video parallel retrieval method proposed in this design has the advantages of high retrieval accuracy and good retrieval efficiency.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_12
DP  - Springer Link
SP  - 135
EP  - 141
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_12.pdf
KW  - Convolution neural network
KW  - Deep hash
KW  - High precision
ER  - 

TY  - CONF
TI  - Feature Filtering Spectral Clustering Method Based on High Dimensional Online Clustering Method
AU  - Feng, Zizhou
AU  - Gu, Yujian
AU  - Yang, Bin
AU  - Chen, Baitong
AU  - Bao, Wenzheng
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Golgi is an important eukaryotic organelle. Golgi plays a key role in protein synthesis in eukaryotic cells, and its dysfunction will lead to various genetic and neurodegenerative diseases. In order to better develop drugs to treat diseases, one of the key problems is to identify the protein category of Golgi apparatus. In the past, the physical and chemical properties of Golgi proteins have often been used as feature extraction methods, but more accurate sub-Golgi protein identification is still challenged by existing methods. In this paper, we use the tape-bert model to extract the features of Golgi body. To create a balanced dataset from an unbalanced Golgi dataset, we used the SMOTE oversampling method. In addition, we screened out the important eigenvalues of 300 dimensions to identify the types of Golgi proteins. In 10-fold cross validation and independent test set test, the accuracy rate reached 90.6% and 95.31%.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_14
DP  - Springer Link
SP  - 157
EP  - 164
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_14.pdf
KW  - Golgi appratus
KW  - Malonylation
KW  - Protein
KW  - SMOTE
ER  - 

TY  - CONF
TI  - Research on CRM Boost PFC Converter Based on GaN Device
AU  - Ding, Yao
AU  - Fang, En
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - There is a need for Power Factor Correction (PFC) converters to improve performance and reduce device size while maintaining a high power factor in the consumer electronics arena. Increasing the switching frequency is the essential way to increase the power density of the PFC converter. When the switching frequency of the converter is close to the MHz level, the switching loss of the conventional Si MOSFET increases sharply, resulting in a decrease in the overall efficiency of the converter. The dual-pulse test platform based on the cascode GaN transistor TPH3206PD and the experimental platform of 200 W single-phase CRM boost PFC converter is introduced. Then, the stability of the high-frequency driving circuit of the GaN device is verified by the dual-pulse test platform, which effectively avoids the false turn-off phenomenon in the turn-on process. The switching loss of TPH3206PD is measured experimentally, and the accuracy of theoretical calculation is verified. The experimental results show that when the operating frequency of the CRM boost PFC converter is close to 1 MHz. GaN devices can effectively reduce switching loss and improve overall efficiency.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_15
DP  - Springer Link
SP  - 165
EP  - 177
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_15.pdf
KW  - Boost PFC converter
KW  - Critical current mode
KW  - GaN devices
ER  - 

TY  - CONF
TI  - Application of Cascode GaN HEMT in LLC Soft Switching Converter
AU  - Qin, Kaiyuan
AU  - Fang, En
AU  - Zhang, Yuan-ming
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - After decades of development, the performance of Si-based power switching devices is approaching its material limits. The power electronic converter is limited to further growth in the direction of high frequency, high efficiency, and high power density. As an outstanding representative of the third generation of wide bandgap semiconductor devices, the cascode GaN HEMT utilizes a cascode structure to achieve the normally-off nature of GaN devices, with unmatched steady-state and dynamic performance of Si-based devices. In order to promote its replacement of Si devices and give full play to the performance advantages, the cascode GaN HEMT is applied to the soft-switching topology of the LLC resonant converter in this paper. The relationship between the output capacitance and the dead-time of the switching device is analyzed. The effects with root mean square values of the first and second side currents are also considered. Taking advantage of the small output capacitance of the cascode GaN HEMT, the circulating current of the converter is reduced, which leads to further reduction of the conduction and transformer loss. Thus, the efficiency of the converter is improved. An LLC converter with 97% maximum efficiency and 96.2% total load efficiency was built to prove the correctness and effectiveness of the analysis.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_16
DP  - Springer Link
SP  - 178
EP  - 193
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_16.pdf
KW  - Application research
KW  - Cascode GaN device
KW  - Hard switch
KW  - Soft switch
ER  - 

TY  - CONF
TI  - A Network Traffic Measurement Approach for Edge Computing Networks
AU  - Song, Xi
AU  - Cai, Wansheng
AU  - Liu, Chuan
AU  - Jiang, Dingde
AU  - Huo, Liuwei
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Edge computing is one of the key technologies in 5G networks, it can collect and process data on the access network and decrease the transmission load of the network. The data exchange in the Edge computing network Software Defined Networking (SDN) decouples the control plane and forwarding plane in traditional switches and plans to route in the global view, making network management more flexible and efficient. The accurate and comprehensive network traffic measurement is the key to traffic management of edge computing networks. Then, we propose a novel edge computing network traffic measurement approach to SDN. The proposed measurement methods use the in SDN by collecting statistics in OpenFlow-based switch and utilize the LSTM model and GNN method to infer the fine-grained measurement. Then, we construct an objective function to optimize the estimation results. Finally, we conduct a series of simulations to evaluate the performance of the proposed scheme. Simulation results show that our approach is feasible and has low measurement cost.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_3
DP  - Springer Link
SP  - 29
EP  - 37
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_3.pdf
KW  - Edge computing
KW  - Internet of things
KW  - Software defined networking
ER  - 

TY  - CONF
TI  - An Adaptive and Efficient Network Traffic Measurement Method Based on SDN in IoT
AU  - Cai, Wansheng
AU  - Song, Xi
AU  - Liu, Chuan
AU  - Jiang, Dingde
AU  - Huo, Liuwei
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - The Internet of Things (IoT) is a worldwide information network that connects thousands of technological gadgets. We incorporate the SDN network architecture into IoT networks and investigate the characteristics of SDN-based IoT networks in order to make the IoT more flexible and extendable. SDN (Software Defined Networking) is a logical control center with a centralized control plane that makes network management more flexible and efficient. For IoT network management, fine-grained and reliable traffic information is critical. Then, in SDN-based IoT networks, we construct a network traffic model by analyzing the self-similarity of network traffic in IoT network. Then, we collect some traffic statistics in OpenFlow-based switches as the source data and use it to train the proposed network traffic estimation model. Using the measured network traffic in the IoT network, we use the Kalman Filtering to measure and estimate each flow, this scheme just increases a little overhead. Then, we propose to an algorithm to search the more accuracy of traffic. Finally, we run additional simulations to ensure that the suggested measuring system is accurate. Simulation findings suggest that using intelligent optimization approaches, we can improve the granularity and accuracy of traffic data.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_6
DP  - Springer Link
SP  - 64
EP  - 74
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_6.pdf
KW  - Internet of Things
KW  - Network measurement
KW  - Optimization algorithm
KW  - Software Defined Network
ER  - 

TY  - CONF
TI  - Cosmetics Sales Data Classification Method of Japanese Cross-Border E-Commerce Platform Based on Big Data
AU  - Huang, Jingxian
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Data analysis is playing an increasingly important role in the cross-border e-commerce platform in the cosmetics industry. Therefore, this paper proposes a cosmetics sales data classification method for the Japanese cross-border e-commerce platform based on big data. Taking the cosmetics sales data on the Japanese cross-border e-commerce platform as the research object, the development model of Japanese cross-border e-commerce and the connotation of cosmetics are expounded. Take targeted methods and measures; extract consumer purchase behavior characteristics on Japanese cross-border e-commerce platform, conduct in-depth analysis of customer relationship from three aspects: customer analysis, sales analysis and e-commerce platform analysis, and guide the behavior of maintaining customer relationship; Big data technology is used to predict the sales potential of cosmetics, determine the output according to the actual sales volume, and design the sales data classification model according to the characteristics of the data samples. Experimental results have classify the sales data, it is of great significance to the cosmetics sales of the e-commerce platform.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_13
DP  - Springer Link
SP  - 142
EP  - 153
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_13.pdf
KW  - Big data
KW  - Consumer
KW  - Cosmetics sales
KW  - Data classification
KW  - Japanese cross-border e-commerce platform
KW  - Sales potential
ER  - 

TY  - CONF
TI  - Mobility-Aware Resource Allocation Based on Matching Theory in MEC
AU  - Niu, Bin
AU  - Liu, Wei
AU  - Ma, Yinghong
AU  - Han, Yue
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Mobile Edge Computing (MEC) is a technology that provides communication, computing, and storage resources at the edge of a mobile network to improve the Quality of service (Qos) for mobile users. However, the conflict between the mobility of the user and the limited coverage of the edge server may interrupt the ongoing service and cause a decrease in the quality of the service. In this context, we jointly formulate service migration and resource allocation in MEC by considering user mobility, service migration, communication and computing resources in the edge server to minimize the total service delay. Then we propose a matching algorithm that takes into account the selection preferences of users and Edge servers, and effectively solves the integer nonlinear programming problem we formulated. Finally, the simulation results prove the effectiveness of the proposed algorithm.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_7
DP  - Springer Link
SP  - 75
EP  - 88
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_7.pdf
KW  - Matching theory
KW  - MEC
KW  - Mobility
KW  - Resource allocation
ER  - 

TY  - CONF
TI  - An Energy-Efficient Dynamic Spectrum Access Approach for Internet of Things Applications
AU  - Chen, Jianguang
AU  - Jiang, Dingde
AU  - Yang, Wei
AU  - Fan, Xiaoqian
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Energy efficiency has become the main problem of the communication network for sustainable development. The highly energy-efficient communication has become research focus and hotspot. Traditional network designs only consider network efficiency or network minimum energy consumption, but rarely consider maximum energy efficiency of networks. This paper presents an energy-efficient dynamic spectrum access approach for internet of things applications. We consider that communications between secondary users does not affect normal communications of primary users. The minimum interference problem between secondary users and primary users is discussed. By taking maximal energy efficiency as the optimal goal, we propose the energy efficient channel allocation strategy and sleeping mechanism. Then by minimizing the interference between secondary users and primary users, we can improve system throughput. The sleeping mechanism is utilized to minimize network energy consumption and establish the end-to-end cognitive multi-hop routing. Simulation results show that our algorithm is effective and feasible.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_9
DP  - Springer Link
SP  - 101
EP  - 110
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_9.pdf
KW  - Channel allocation
KW  - Cognitive networks
KW  - Energy efficiency
KW  - Sleeping mechanism
KW  - Spectrum access
ER  - 

TY  - CONF
TI  - A Dynamic Migration Strategy of SDN Controllers in LEO Networks
AU  - Huo, Liuwei
AU  - Jiang, Dingde
AU  - Yang, Wei
AU  - Chen, Jianguang
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Multiple low earth orbit (LEO) satellites form a constellation that can construct the network to achieve full coverage of the ground. However, the topology of the LEO satellite network is highly dynamic, and end-to-end transmission is a huge challenge for the LEO satellite network. As an important technology to solve the network dynamic management, the software defined network (SDN) has been introduced into the LEO satellite network. To manage the LEO network efficiently, the controllers of the SDN-based LEO satellite network can be deployed on some satellites and directly controlled by the ground base stations (GBSs). Since GBSs are static, so the controller should be migrated from one LEO satellite to another LEO satellite. Controller migration as an elastic control method plays an important role in the SDN-based LEO satellite network. Aiming at the problems of low migration efficiency and high migration cost in existing migration schemes, we propose a dynamic migration strategy of the controller. First, we analyze the load composition of the controller, and construct a load function, set the trigger factor to determine the load imbalance. Then, we determine the migration target and establish a migration efficiency model, and consider the load balancing rate and migration cost to determine the migration switch and the migration controller. Finally, by setting migration triplets to complete the migration mapping, to achieve efficient controller migration in the LEO satellite network. Simulation results show that this strategy can effectively reduce the controller response time, reduce the migration cost, and improve the controller throughput.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_2
DP  - Springer Link
SP  - 19
EP  - 28
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_2.pdf
KW  - Controller
KW  - Dynamic migration
KW  - Low earth orbit satellite
KW  - Software-defined network
ER  - 

TY  - CONF
TI  - Native Versus Overlay-Based NDN over Wi-Fi 6 for the Internet of Vehicles
AU  - de Sena, Ygor Amaral B. L.
AU  - Dias, Kelvin Lopes
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Internet of Vehicles (IoV) is a cornerstone building block of smart cities to provide better traffic safety and mobile infotainment. Recently, improved efficiency in WLAN-based dense scenarios has become widespread through Wi-Fi 6, a license-free spectrum technology that can complement the cellular-based infrastructure for IoV. In addition, Named Data Networking (NDN) is a promising Internet architecture to accomplish content distribution in dynamic IoV scenarios. However, NDN deployments, i.e., native (clean-slate) and overlay (running on top of IP stack), require further investigation of their performance over wireless networks, particularly regarding the IoV scenario. This paper performs a comparative simulation-based study of these NDN deployments over Wi-Fi 6 for IoV using real vehicular traces. To the best of our knowledge, this is the first effort that extends ndnSIM 2 with an overlay-based NDN implementation and that compares it with the native approach. Results show that the overlay-based NDN consistently outperforms the native one, reaching around 99% of requests satisfied, against only 42.35% in the best case of native deployment.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_5
DP  - Springer Link
SP  - 51
EP  - 63
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_5.pdf
KW  - Internet of Vehicles
KW  - Named Data Networking
KW  - NDN deployments
KW  - Wi-Fi 6
ER  - 

TY  - CONF
TI  - A Botnet Detection Method Based on SCBRNN
AU  - Xu, Yafeng
AU  - Zhang, Kailiang
AU  - Zhou, Qi
AU  - Cui, Ping
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - With the rapid development of the social network and Internet of things, the complex network environment has led to more serious network security issues. Botnets have always been one of the most important issues in network security. The continuous update of botnet technology has severely influence the network operation of Internet service providers, posing a huge threat to security. Effective detection of botnets is the focus of related security solutions. In the new environment, traditional solutions have become inefficient. In recent years, botnet detection results based on machine learning technology continue to emerge. From the perspective of small batch gradient sample collection, this article optimizes the two-way neural network model and adopts approximate entropy to determine the abnormality of the data, thereby effectively detecting botnets. Research data shows that the model has good performance and can accurately identify botnets. Compared with the traditional model method, when the small batch sampling range is reduced, the accuracy is significantly improved, which provides effective help for Internet service providers to accurately detect botnets, improves service security mechanisms, and improves core competition force.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_11
DP  - Springer Link
SP  - 123
EP  - 131
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_11.pdf
KW  - ApEn
KW  - Botnet
KW  - SCBRNN
KW  - Small batch
ER  - 

TY  - CONF
TI  - On Jamming Game in Multi-user MIMO Downlink AF Relay System
AU  - Shi, Bai
AU  - Cui, Kai
AU  - Jiang, Jihong
AU  - Shao, Huaizong
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - Wireless devices may threaten urban security if they are maliciously used. Some Internet-of-things (IoT) devices have already troubled the city management even hurt citizens. Jamming technique is one of the effective approaches to prevent these malicious activities. In addition, some IoT devices may locate far from base station and the power of received signals may be low. In this paper, we discuss a jamming power allocation problem in a multi-user multiple-input multiple-output (MU-MIMO) downlink relay system when the communication and jamming signals are relatively low due to the long distance between them, in which jammer tries to minimize the sum rate of IoT devices while these devices try to communicate at the fastest rate. Besides, jammer transmits jamming signals after detecting the communication request of devices so base station should decide how to transmit first, which is modeled by a two-person zero-sum Stackelberg game. However, the sum rate in such a scenario is non-convex. Finding the equilibrium strategy is general N-P hard. To address this complex problem, we decompose it into several easy-solved sub-problems and adopt an alternating optimization over them. Further, we simulate the proposed method numerically and results suggest the superiority.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_8
DP  - Springer Link
SP  - 89
EP  - 100
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_8.pdf
KW  - Jamming
KW  - MIMO
KW  - Relay
KW  - Stackelberg game
KW  - Sum rate
KW  - Urban security
KW  - Zero-sum game
ER  - 

TY  - CONF
TI  - A New End-To-End Network Traffic Reconstruction Approach Based on Different Time Granularities
AU  - Yang, Wei
AU  - Jiang, Dingde
AU  - Chen, Jianguang
AU  - Wang, Zhihao
AU  - Huo, Liuwei
AU  - Zhao, Wenhui
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - End-to-end network traffic is an important input parameter for network planning and network monitoring, which plays an important role in network management and design. This paper proposes a new end-to-end network traffic reconstruction algorithm based on different time granularity. This algorithm reconstructs the end-to-end network traffic with fine time granularity by taking advantage of the characteristics of the link traffic which is easy to be measured directly in the network with coarse time granularity. According to the fractal and self-similar characteristics of network traffic found in existing studies, we first carry out fractal interpolation for link traffic measurement under coarse time granularity to obtain link traffic under fine time granularity. Then, by using the compressive sensing theory, an appropriate sparse transformation matrix and measurement matrix are constructed to reconstruct the end-to-end network traffic with fine time granularity. Simulation results show that the proposed algorithm is effective and feasible.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_10
DP  - Springer Link
SP  - 111
EP  - 122
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_10.pdf
KW  - Compression sense
KW  - Dictionary Learning Algorithm
KW  - End-to-end network traffic reconstruction
KW  - Fractal interpolation
ER  - 

TY  - CONF
TI  - End User Experience Evaluation of Map Navigation and Location Service
AU  - Chen, Kai
AU  - Chen, Lei
AU  - Tang, Zichen
AU  - Zhang, Qimeng
AU  - Jiang, Yulong
AU  - Yin, Jun
AU  - Tao, Jian
AU  - Cui, Ping
A2  - Jiang, Dingde
A2  - Song, Houbing
T3  - Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering
AB  - The Map Navigation and Location Service is one of the most popular service types. To analyze the quality of the end-user experience, we identify the key indicators of quality of experience (QoE) for these services, and estimate the weights of these indicators. Based on the SERVPERF model, we collect the feedback data of college students and workers to build an index system of map navigation and location service. Using this index system, we can help users choose high-quality map navigation and location service, and to improve the end user experience for these services.
C1  - Cham
C3  - Simulation Tools and Techniques
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-97124-3_4
DP  - Springer Link
SP  - 38
EP  - 50
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-97124-3
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-97124-3_4.pdf
KW  - Location service
KW  - Navigation service
KW  - Quality of experience
ER  - 

TY  - CHAP
TI  - The Early Days of Synthetic Data
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - It may appear that synthetic data has become instrumental only very recently, with the rise of modern computer graphics that allows for near-photorealistic imagery. But in fact, synthetic data has been used throughout the history of computer vision, starting from its very inception in the 1960s. In this chapter, we begin with the early days of synthetic data, show some of the earliest models and applications of computer vision, and discuss aspects of computer vision that have always been very hard or even impossible to do without synthetic data.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 139
EP  - 159
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_5
Y2  - 2024/01/31/07:36:01
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_5.pdf
ER  - 

TY  - CHAP
TI  - Synthetic Data for Basic Computer Vision Problems
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - It is time to put the pedal to the metal: starting from this chapter, we will discuss the current state of the art in various aspects of synthetic data. This chapter is devoted to basic computer vision problems: we begin with low-level problems such as optical flow estimation and stereo image matching, proceed to datasets of basic objects that can be used to train computer vision models, discuss in detail the case study of synthetic data for object detection, and finish with several different use cases such as synthetic datasets of humans, OCR, and visual reasoning.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 161
EP  - 194
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_6
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_6.pdf
ER  - 

TY  - CHAP
TI  - Directions in Synthetic Data Development
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - In this chapter, we outline the main directions that we believe to represent promising ways to further improve synthetic data, making it more useful for a wide variety of applications in computer vision and other fields. In particular, we discuss the idea of domain randomization (Section 9.1) intended to improve the applications of synthetic datasets, methods to improve CGI-based synthetic data generation itself (Section 9.2), ways to create synthetic data from real images by cutting and pasting (Section 9.3), and finally possibilities to produce synthetic data by generative models (Section 9.4). The latter means generating useful synthetic data from scratch rather than domain adaptation and refinement, which we consider in a separate Chapter 10.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 227
EP  - 234
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_9
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_9.pdf
ER  - 

TY  - CHAP
TI  - Introduction: The Data Problem
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - Machine learning has been growing in scale, breadth of applications, and the amounts of required data. This presents an important problem, as the requirements of state-of-the-art machine learning models, especially data-hungry deep neural networks, are pushing the boundaries of what is economically feasible and physically possible. In this introductory chapter, we show and illustrate this phenomenon, discuss several approaches to solving the data problem, introduce the main topic of this book, synthetic data, and outline a plan for the rest of the book.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 1
EP  - 17
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
ST  - Introduction
UR  - https://doi.org/10.1007/978-3-030-75178-4_1
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_1.pdf
ER  - 

TY  - CHAP
TI  - Synthetic Data Outside Computer Vision
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - While computer vision remains the main focus of synthetic data applications, other fields also begin to use synthetic datasets, with some directions entirely dependent on synthetic data. In this chapter, we survey some of these fields. Specifically, Section 8.1 discusses how structured synthetic data is used for fraud and intrusion detection and other applications in the form of network and/or system logs; in Section 8.2, we consider neural programming; Section 8.3 discusses synthetic data generation and use in bioinformatics, and Section 8.4 reviews the (admittedly limited) applications of synthetic data in natural language processing.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 217
EP  - 226
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_8
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_8.pdf
ER  - 

TY  - CHAP
TI  - Promising Directions for Future Work
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - In this concluding chapter, we discuss the next steps that we can expect from the field of synthetic data for deep learning. We consider four different ideas that are starting to gain traction in this field. First, procedural generation of synthetic data can allow for much larger synthetic datasets or datasets generated on the fly. Second, recent works try to make the shift from domain randomization to the generation feedback loop, adapting synthetic data generation to the model and problem at hand. Third, we discuss how to best incorporate additional knowledge into the domain adaptation architectures, and fourth, show examples of introducing extra modalities into synthetic datasets with the purpose to improve downstream tasks that formally might not even use these modalities.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 285
EP  - 294
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_12
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_12.pdf
ER  - 

TY  - CHAP
TI  - Privacy Guarantees in Synthetic Data
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - In this chapter, we discuss another important field of applications for synthetic data: ensuring privacy. In many real-world problems, real data is sensitive enough that it is impossible to release. One possible solution could be to train generative models that would produce new synthetic datasets based on real data, while the real data itself would remain secret. But how can we be sure that real data will not be inadvertently leaked? Guarantees in this regard can be provided by the framework of differential privacy. We give a brief introduction to differential privacy, its relation to machine learning, and the guarantees that it can provide for synthetic data generation.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 269
EP  - 283
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_11
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_11.pdf
ER  - 

TY  - CHAP
TI  - Synthetic Simulated Environments
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - In this chapter, we proceed from datasets of static synthetic images, either prerendered or procedurally generated, to entire simulated environments that can be used either to generate synthetic datasets on the fly or provide learning environments for reinforcement learning agents. We discuss datasets and simulations for outdoor environments (mostly for autonomous driving), indoor environments, and physics-based simulations for robotics. We also make a special case study of datasets for unmanned aerial vehicles and the use of computer games as simulated environments.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 195
EP  - 215
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_7
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_7.pdf
ER  - 

TY  - CHAP
TI  - Deep Neural Networks for Computer Vision
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - Computer vision problems are related to the understanding of digital images, video, or similar inputs such as 3D point clouds, solving problems such as image classification, object detection, segmentation, 3D scene understanding, object tracking in videos, and many more. Neural approaches to computer vision were originally modeled after the visual cortex of mammals, but soon became a science of their own, with many architectures already developed and new ones appearing up to this day. In this chapter, we discuss the most popular architectures for computer vision, concentrating mainly on ideas rather than specific models. We also discuss the first step towards synthetic data for computer vision: data augmentation.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 59
EP  - 95
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_3
Y2  - 2024/01/31/07:36:02
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_3.pdf
ER  - 

TY  - CHAP
TI  - Deep Learning and Optimization
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - Deep learning is currently one of the hottest fields not only in machine learning but in the whole of science. Since the mid-2000s, deep learning models have been revolutionizing artificial intelligence, significantly advancing state of the art across all fields of machine learning: computer vision, natural language processing, speech and sound processing, generative models, and much more. This book concentrates on synthetic data applications; we cannot hope to paint a comprehensive picture of the entire field and refer the reader to other books for a more detailed overview of deep learning [153, 289, 630, 631]. Nevertheless, in this chapter, we begin with an introduction to deep neural networks, describing the main ideas in the field. We especially concentrate on approaches to optimization in deep learning, starting from regular gradient descent and working our way towards adaptive gradient descent variations and state-of-the-art ideas.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 19
EP  - 58
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_2
Y2  - 2024/01/31/07:36:03
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_2.pdf
ER  - 

TY  - CHAP
TI  - Generative Models in Deep Learning
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - So far, we have mostly discussed discriminative machine learning models that aim to solve a supervised problem, i.e., learn a conditional distribution of the target variable conditioned on the input. In this chapter, we consider generative models whose purpose is to learn the entire distribution of inputs and be able to sample new inputs from this distribution. We will go through a general introduction to generative models and then proceed to generative models in deep learning. First, we will discuss explicit density models that model distribution factors with deep neural networks and their important special case, normalizing flows, and explicit density models that approximate the distribution in question, represented by variational autoencoders. Then we will proceed to the main content, generative adversarial networks, discuss various adversarial architectures and loss functions, and give a case study of style transfer with GANs that is directly relevant to synthetic-to-real transfer.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 97
EP  - 137
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_4
Y2  - 2024/01/31/07:36:03
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_4.pdf
ER  - 

TY  - CHAP
TI  - Synthetic-to-Real Domain Adaptation and Refinement
AU  - Nikolenko, Sergey I.
T2  - Synthetic Data for Deep Learning
A2  - Nikolenko, Sergey I.
T3  - Springer Optimization and Its Applications
AB  - Domain adaptation is a set of techniques aimed to make a model trained on one domain of data to work well on a different target domain. In this chapter, we give a survey of domain adaptation approaches that have been used for synthetic-to-real adaptation, that is, methods for making models trained on synthetic data work well on real data, which is almost always the end goal. We distinguish two main approaches. In synthetic-to-real refinement input synthetic data is modified, usually to be made more realistic, and we can actually see the modified data. In model-based domain adaptation, it is the training process or the model structure that changes to ensure domain adaptation, while the data remains as synthetic as it has been. We will discuss neural architectures for both approaches, including many models based on generative adversarial networks.
CY  - Cham
DA  - 2021///
PY  - 2021
DP  - Springer Link
SP  - 235
EP  - 268
LA  - en
PB  - Springer International Publishing
SN  - 978-3-030-75178-4
UR  - https://doi.org/10.1007/978-3-030-75178-4_10
Y2  - 2024/01/31/07:36:03
L4  - https://link.springer.com/content/pdf/10.1007%2F978-3-030-75178-4_10.pdf
ER  - 

TY  - CONF
TI  - Research on the construction of visual intelligent park management system
AU  - Zhang, Chengting
AU  - Ye, Zhihui
AU  - Jin, Wenlong
AU  - Shi, Dingke
T3  - EITCE '22
AB  - With the continuous deepening and development of smart city construction, the concept of smart parks has gradually entered the public's field of vision. The construction of smart parks is an important way to realize the modernization and intelligence of park management. Through the construction of smart parks, various resources can not only be utilized and integrated, but also the operation efficiency of the parks can be comprehensively improved. The so-called wisdom not only means to increase the construction of infrastructure, but also to strengthen the construction of informatization. By establishing a set of visual intelligent park management and control platform, the originally independent subsystems can be linked according to the management characteristics of the park, so as to improve The overall management service level of the park. Based on this, the construction plan of the visualized smart park management system is proposed.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573601
SP  - 957
EP  - 960
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573601
KW  - Internet of things
KW  - Microservice architecture
KW  - Visualization
ER  - 

TY  - CONF
TI  - Optimal Beacons Selection Strategy In TOA Localization
AU  - Wei, Liang
AU  - Yin, Kangyong
AU  - Lin, Yuandi
AU  - Zhang, Yu
AU  - Zhu, Rui
T3  - EITCE '22
AB  - The localization technology based on time of arrival (TOA) plays an essential role in many fields such as positioning and navigation, sensor localization, and radar. The TOA technology attaches attention because it is easy to use and with high accuracy. In the real world, limited by computing and communication resources, not all the TOA signals can be used for localization. Towards optimal beacons’ selection problem, two strategies are proposed. The first one uses Cramer-Rao Lower Bound (CRLB) as the criterion. The other is based on the linearization process of a two-step weighted least squares TOA algorithm, which utilizes convex optimization to select an optimal combination. Simulations reveal the proposed methods achieve the performance of the exhaustive search method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573600
SP  - 951
EP  - 956
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573600
KW  - Beacon selection
KW  - Cranmer_Rao lower bound
KW  - Localization
ER  - 

TY  - CONF
TI  - A Prompt-based Few-shot Machine Reading Comprehension Model for Intelligent Bridge Management
AU  - Zhang, Luyi
AU  - Li, Ren
AU  - Xiao, Qiao
T3  - EITCE '22
AB  - Bridge inspection reports are an important data source in the bridge management process, and they contain a large amount of fine-grained information. However, the research on machine reading comprehension (MRC) methods for this field is insufficient, and annotating large scale domain-specific corpus is time-consuming. This paper presented a novel prompt-based few-shot MRC approach for intelligent bridge management. The proposed model uses the pretrained model MacBERT as backbone. The prompt templates are designed based on some domain-specific heuristic rules. The experimental results show that our model outperforms the baseline models in different few-shot settings. The proposed model can provide technical support for the construction of automatic question answering system in the field of bridge management.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573599
SP  - 946
EP  - 950
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573599
KW  - Bridge inspection
KW  - Few-shot
KW  - Machine reading comprehension
KW  - Prompt
ER  - 

TY  - CONF
TI  - Key Phrase Extraction based on Pre-trained Language Models
AU  - Yao, Shunyu
AU  - Hu, Jie
AU  - Sun, Chuxiong
AU  - Gao, Zhiqiao
AU  - Liu, Ning
T3  - EITCE '22
AB  - With the explosion of information and a large amount of data appearing every moment, it is a meaningful task to quickly find the information people want to know in a large amount of text and to present long texts in a streamlined form. Key phrase extraction, which aims to extract from documents a collection of key phrases that express the topic and content of the document, is important for text processing tasks such as information retrieval and document classification and can provide readers with a more comprehensive overview of the topic. We use two types of pre-trained language models for key phrase extraction, namely DeBERTa and RoBERTa, which are first pre-trained on the dataset and then fine-tuned, and the experimental results of these models proved that DeBERTa-V3-Large has reached an F1 score of 0.8925, which is the best result among these models.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573598
SP  - 941
EP  - 945
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573598
KW  - Artificial Intelligence
KW  - Key Phrase Extraction
KW  - Natural Language Processing
KW  - Neural Network
ER  - 

TY  - CONF
TI  - A database search optimization method for maritime emergency rescue under the condition of limited bandwidth
AU  - Chen, Chunxu
AU  - Yang, Lichun
AU  - Su, Yun
T3  - EITCE '22
AB  - With the rapid development of my country's marine activities, the importance of marine emergency rescue is becoming more and more significant. This article is aimed at that the rescue environment is far away from the shore base station in the marine emergency rescue information system the communication bandwidth is limited, which affects the data retrieval efficiency, A database search optimization method for maritime emergency rescue under the condition of limited bandwidth is proposed. Categorized search by keyword technology, the retrieval results are prioritized and compressed, and only summary information is returned to reduce the delay in returning retrieval results. And use the retrieval personalization technology to highlight the keywords in the abstract content to highlight to users. Finally, using the data of the marine database to the query performance of the database search optimization method proposed in this paper. The experimental results show that the method in this paper can realize the rapid retrieval of marine emergency rescue database, has strong stability, and has a wide range of application prospects in marine emergency rescue and other fields.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573596
SP  - 932
EP  - 935
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573596
ER  - 

TY  - CONF
TI  - Design of Enterprise Inventory Management Program Based on Java EE Programming
AU  - Wang, Juan
AU  - Chen, Shumei
T3  - EITCE '22
AB  - Since the outbreak of the novel coronavirus at the end of 19, the competition among SMEs has become increasingly fierce. Based on their traditional management model and low level of informatization, SMEs have poor ability to cope with the impact of the epidemic and cannot quickly meet the new needs of target customers and new market opportunities. In the context of the impact of the epidemic situation, small and medium-sized enterprises need to optimize the inventory management system by introducing computer technology, use big data analysis technology to adapt to market demand, reduce the problem of enterprise inventory backlog, improve the efficiency of enterprise resource allocation, and maximize the avoidance of resource mismatch. This paper uses Java EE programming technology and the Spring Boot framework to design an enterprise inventory management system, which can comprehensively and directly display the enterprise inventory management situation, achieve data recording, storage, and modification. At the same time, it uses enterprise inventory management data to achieve the portrait analysis of target users, improve the efficiency of enterprise inventory management, optimize the enterprise management system, and quickly meet the new needs of customers.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573597
SP  - 936
EP  - 940
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573597
KW  - database
KW  - inventory management
KW  - Java EE
KW  - system design
ER  - 

TY  - CONF
TI  - A High-Reliability On-line: Update method for DSP Software
AU  - Tian, Yuzhao
AU  - Wang, Yunhui
AU  - Zhou, Li
AU  - Feng, Yi
T3  - EITCE '22
AB  - With the continuous progress of IC technology, DSP has been widely used in the product application of various digital signal processing algorithms. For some special applications, in order to avoid the disassembly of products, a high-reliability on-line update method for DSP software is implemented. This paper brings a design procedure and software implementation, describing the DSP software upgrade, loading and the self-repair process. With the purpose of avoid the risk of program jump and software upgrade failure caused by abnormal operation, then the reliability and security of DSP software online upgrade will be improved.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573781
SP  - 928
EP  - 931
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573781
KW  - DSP (Digital Signal Processing) software
KW  - High-Reliability
KW  - On-line update
KW  - Self-Repair
ER  - 

TY  - CONF
TI  - Research and application of feature-based product process review software DFM
AU  - Zeng, Fenfang
AU  - Zheng, Wei
AU  - Wang, Huachang
T3  - EITCE '22
AB  - The traditional process review is done manually, and the review result is closely related to personal experience with low review efficiency and long review period. Through the analysis of product process review knowledge, this paper studies feature-based review knowledge modeling and feature parameter-based process review, and develops feature-based process review system 3DDFM, which intelligently reports design defects in product models with one-click operation and details the causes of defects and modification suggestions for designers to make modifications. The 3DDFM system has been proven to meet the requirements of intelligent process review of manufacturing enterprises, and has a very obvious effect on improving the efficiency of process review, reducing process error rate, improving product design quality and shortening the development cycle.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573594
SP  - 922
EP  - 927
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573594
ER  - 

TY  - CONF
TI  - Design and implementation of a semantic retrieval system based on document understanding
AU  - Chen, Zongchao
AU  - Tang, Gongzheng
AU  - Fu, Lijun
T3  - EITCE '22
AB  - In the urrent information environment, unstructured text is an important part of all kinds of information, and it has become an urgent problem in the current information service field to extract the required information from text data for user information needs. Based on semantic retrieval and an extractive document reading comprehension model, this paper investigates how to quickly and effectively extract the required answer information from a large document library based on user questions, and constructs a semantic retrieval system based on document comprehension. It is important to help users get the required information quickly and effectively and improve the efficiency of information services in the current massive information environment. The experiments show that the system can quickly and precisely locate the answers to the user's questions and help the user to obtain the required information quickly and effectively.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573593
SP  - 917
EP  - 921
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573593
ER  - 

TY  - CONF
TI  - A Secure Data Aggregation Scheme Enabling Abnormal Smart Meters Traceback for Smart Grid
AU  - Yao, Shiying
AU  - Zeng, Jian
AU  - Wang, Shuangxing
AU  - Yang, Xiaolong
AU  - Luo, Jingtang
AU  - Wang, Ziqi
T3  - EITCE '22
AB  - In order to prevent smart meter data from being stolen by attackers during transmission, it is common practice to securely aggregate the data and report it to the power company. Although the existing aggregation scheme can protect users' electricity consumption privacy, it cannot distinguish the data that has been attacked by false data injection (FDI), meaning it is difficult to trace and exclude abnormal data sources. To solve this problem, the study proposes a smart meter data aggregation scheme that can trace abnormal nodes. The aggregation center (AC) divides the smart meter (SM) into multiple groups, and the SM in the same group detect the abnormal behavior with each other by calculating whether the Hellinger distance of the power consumption of two adjacent timespan of their counterparts exceeds the set threshold, then feedback to the AC. Through multiple “grouping-detection” iterations, AC locates the groups which contains abnormal SMs. Then AC excludes the abnormal nodes and calculates the normal SMs’ power consumption aggregate value in the group by employing EC-EIGamal homomorphic encryption. Experimental results show that the detection accuracy is 73.3%∼100% under multiple FDI attacks, and attacked SMs can be effectively traced and excluded.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573780
SP  - 911
EP  - 916
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573780
KW  - Abnormal node tracing
KW  - Data aggregation
KW  - Grouping supervision
KW  - Homomorphic encryption
KW  - Smart meter
ER  - 

TY  - CONF
TI  - A high-resolution spaceborne SAR wave potential design method for large scene
AU  - Liu, Bin
T3  - EITCE '22
AB  - For high resolution spaceborne SAR, high resolution needs large rotation of azimuthal angle, so range cell migration is larger. In order to solve this problem, this paper proposes a design method of wave location for high resolution spaceborne SAR. During the working process, the echo receiving window is sliding by changing system repeat frequency, so the echo of scene can be received completely. This method includes two kinds of wave level design: piecewise variable repetition frequency and group variable repetition frequency. The method can meet different scene application. The method is simple, reliable and practical. It can be widely used in high resolution spaceborne SAR.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573591
SP  - 907
EP  - 910
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573591
KW  - group variable repetition frequency
KW  - piecewise variable repetition frequency
KW  - wave level
ER  - 

TY  - CONF
TI  - Research and Development of GNSS Wearable Device for Sports Performance Monitoring by Example of Soccer Player Analysis∗
AU  - Liu, Yongqing
T3  - EITCE '22
AB  - With the continuous progress in measurement accuracy and algorithm maturity, wearable devices have been used more widely in competitive sports, and even some wearable devices have obtained the qualification for application on the competition scene. Taking soccer as an example, this research developed a wearable device for sports performance analysis of soccer players, realized the acquisition of sports position, distance and speed information and carried out the analysis of sports performance, explored the motion mode of soccer and built a sports performance model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573590
SP  - 901
EP  - 906
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573590
KW  - GNSS
KW  - Sports Performance
KW  - Wearable Device
ER  - 

TY  - CONF
TI  - Interaction-aware Pedestrian Trajectory Prediction Considering Vision and Background Information
AU  - Wang, Xikai
AU  - Wang, Xinyu
AU  - Guo, Sijing
T3  - EITCE '22
AB  - Recently, a large number of models have been proposed for predicing pedestrians’ trajectories, but most of the models infer the pedestrians’ trajectories only based on their historical motion data, resulting in an overlap of a pedestrian's trajectory with a roadside flower bed, for example. This paper aims at buidling a trajectory prediciton model, considering the influences of the surroundings on the pedestrians. Specifically, a graph convolutional network was built, using adaptive relational aggregation to encode the relationship between pedestrians and their background information. Additionally, a pedestrian vision module was added to mimic the pedestrians’ perception of other pedestrians and the surrounding environment, which eliminated the unrelated information and reduced the comuplational complexity. An existing datase was enriched by extracting the environmental information. The proposed model was tested on the dataset, and results showed that the proposed model with background and vision information outperformed state-of-the-art RNN-based models in terms of prediction accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573589
SP  - 895
EP  - 900
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573589
KW  - environmental background
KW  - Graph neural networks
KW  - pedestrian trajectory prediction
KW  - pedestrian vision
ER  - 

TY  - CONF
TI  - Research on Underground Road Vehicle Location and Mapping Using MMW Radar
AU  - Wei, Yonghui
AU  - Li, Yang
AU  - Wang, Yanping
AU  - Lin, Yun
AU  - Shen, Wenjie
T3  - EITCE '22
AB  - Millimeter-wave (MMW) radar Simultaneous Localization and Mapping (SLAM) technology is a powerful tool for vehicle detection with limited vision in fire scenario caused by underground road vehicle accident. Current approaches based on the maximum likelihood radar movement locus estimation showed promising results. However, the random error of radar azimuth angle measurement is accumulated and took into radar movement locus estimation due to coordinate transformation and a regular radar scattering pattern distribution caused by a regular radar movement pattern. It also makes an anamorphic occupancy grid map leading to a worse target detection performance. This paper attempts to integrate a prior rail-motion model into the current approach for reducing the accumulated error. This algorithm is validated by the test data measured by a MMW radar mounted on a rail-guided robot in a tunnel. Two cars on fire were set as the targets. The experiment proves the effectiveness of the approach and the error of radar movement locus estimation is less than 0.1m (radar LOS direction) and 1.8m (radar movement direction) respectively.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573588
SP  - 890
EP  - 894
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573588
KW  - Millimeter Wave Radar
KW  - SLAM
KW  - Underground road
ER  - 

TY  - CONF
TI  - A Path Utilization-Based Congestion-Aware Deadlock-Free Routing for Network-on-Chip
AU  - Liu, Jungan
AU  - Li, Chang
AU  - Ye, Yaoyao
T3  - EITCE '22
AB  - Routing algorithm determines how to select a path for each packet transmission in network-on-chip (NoC). In this work, we propose a path utilization-based congestion-aware deadlock-free routing to enhance the communication efficiency for typical traffic patterns or real applications. Firstly, a path utilization model is proposed to indicate the congested paths in NoC under typical traffic patterns or real applications. Secondly, a greedy congestion-aware deadlock-free adaptive routing algorithm is proposed, which would bypass congested regions adaptively with no deadlock. Simulation results under a set of traffic patterns demonstrate the optimization effect of the proposed routing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573587
SP  - 883
EP  - 889
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573587
KW  - application-specific
KW  - congestion-aware
KW  - network-on-chip
KW  - Routing
ER  - 

TY  - CONF
TI  - Traffic Classification Method Based on Federated Semi-Supervised Learning
AU  - Sun, Chongxin
AU  - Chen, Bo
AU  - Bu, Youjun
AU  - Zhang, Desheng
T3  - EITCE '22
AB  - In order to protect the data privacy of network users and solve the training difficulties caused by traffic distribution, this paper based on federal semi-supervised learning presents a traffic classification method to solve the problem of a small number of labeled traffic distributed in server, and a large number of non-labeled traffic distributed independently and identically in clients and not shared. On the one hand, this paper adopts the parameter decomposition strategy to avoid interference between different tasks. On the other hand, this paper uses consistency regularization between clients to maximize consensus between similar segment clients to solve the learning problem of variable small sample data. In addition, method in this paper only transfer parameter differences during the federated learning parameter transfer process. The experimental results show that the accuracy gap between our method and the supervised learning training method is minimal, which can effectively protect user privacy and does not require a large amount of labeled data and communication costs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573586
SP  - 875
EP  - 882
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573586
ER  - 

TY  - CONF
TI  - Application of the perspective based on virtual reality technology to relieve anxiety in practice
AU  - Li, Qian
AU  - Sui, Huajie
T3  - EITCE '22
AB  - Virtual reality technology is a new comprehensive technology with computer technology as the core. It makes comprehensive use of computer 3D graphics technology, simulation technology, sensing technology and display technology to generate almost real visual, auditory, tactile and sensory 3D models. The goal is to create a highly immersive and highly immersive non-realistic environment. With the help of computer programming, virtual reality technology can produce virtual scenes and related stimuli needed to relieve anxiety, with immersive, interactive and present-thinking ability. It can break through the limitation of traditional anxiety treatment and make the treatment process operable. This paper reviews the application of virtual reality technology in anxiety relief, chatbot generation model based on Seq2seq, equipment requirements and mechanisms. It has unique advantages over traditional therapies, but it also has some limitations. Future developments should consider technological innovation and standardization of treatment options.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573585
SP  - 870
EP  - 874
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573585
KW  - Anxiety relief
KW  - Practical Psychology
KW  - Seq2seq
KW  - Virtual reality exposure therapy
KW  - Virtual reality technology
ER  - 

TY  - CONF
TI  - Research on multi-processor real-time scheduling policies
AU  - Hui, Zengqiang
AU  - Liu, Lulu
T3  - EITCE '22
AB  - Multiprocessor real-time scheduling algorithm plays an important role in the system. Paper in combination with the RMS and EDF scheduling algorithm is proposed on the basis of a kind of real-time multiprocessor task scheduling model containing threshold, the task can be on the threshold value range within each processor to migrate, avoided some processors being idle, part of the processor is too busy lead to task suspended phenomenon, ensure the relative balance of each processor utilization.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573584
SP  - 865
EP  - 869
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573584
KW  - Multiprocessor systems
KW  - Real-time task scheduling model
KW  - The EDF scheduling algorithm
KW  - The RMS scheduling algorithm
ER  - 

TY  - CONF
TI  - Autonomous slope edge perception and guidance for excavators based on binocular vision
AU  - Ma, Changchun
AU  - Dong, Quancheng
AU  - Zhang, Ruwei
AU  - Hu, Bin
AU  - Tian, Congfeng
AU  - Sun, Xuan
T3  - EITCE '22
AB  - For the harsh environment and uneven ground during excavator slope repair operations, and to solve the problem of restricted vision of the driver during manual operation, a slope information perception method based on binocular cameras and auxiliary lines along the lower edge of the slope is proposed. The slope and the surrounding environment are matched in three dimensions by the binocular camera and the point cloud is reconstructed, and the auxiliary line point cloud is extracted by point cloud segmentation according to the difference in colour of the point cloud, and fitted to a spatial straight line as the position where the bucket stops working. For the typical working conditions of excavator slope repair construction, the most influential factors were selected for comparison experiments, and it was verified that the perception error of slope-related information by this method is within 4cm. The method can provide accurate information on the distance and coordinates of the slope and the auxiliary line, which improves the disadvantages of manual operation and provides information support for the autonomous slope repair of excavators.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573583
SP  - 860
EP  - 864
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573583
KW  - binocular vision
KW  - construction of slopes
KW  - point cloud processing
KW  - point cloud segmentation
KW  - stereo matching
ER  - 

TY  - CONF
TI  - YOLOX-EC: A Pedestrian and Vehicle Detection Algorithm in Automatic Driving Scenes
AU  - Guo, Di
AU  - Hu, Jie
AU  - Yan, Fuwu
T3  - EITCE '22
AB  - It is particularly significant that autonomous vehicles are able to accurately detect the dynamic information of pedestrians and vehicles in complex and changeable traffic scenes. However, the target detection is difficult in the automatic driving scene because the target scale varies drastically and there is mutual occlusion between targets. In order to solve the issues, we propose a pedestrian and vehicle detection algorithm that is named YOLOX-EC. Firstly, we design the Efficient Attention Module (EAM) according to the ideas of Efficient Channel Attention Network (ECANet) and Convolutional Block Attention Module (CBAM), and introduce it into backbone of YOLOX to enhance the feature extraction ability of network; Secondly, we use Content-aware reassembly of features(Carafe) to enlarge the receptive field of upsampling features and enrich the semantic information of the features; Finally, we change the bounding box regression loss to Efficient Intersection over Union Loss (EIoU Loss) for improving the regression accuracy. The experimental results on KITTI dataset show that compared with YOLOX, mean Average Precision (mAP) of the YOLOX-EC is increased by 2.8%, and the reasoning speed still keeps the real-time requirement of automatic driving platform.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573582
SP  - 853
EP  - 859
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573582
KW  - Attention mechanism
KW  - Computer vision
KW  - Pedestrian and vehicle detection
KW  - YOLOX
ER  - 

TY  - CONF
TI  - A Low Power Operational Amplifier Design Based on SOI DTMOS
AU  - He, Tao
AU  - Han, Qi
AU  - Li, Yu
AU  - Yuan, Peng
AU  - Huang, Huixiang
T3  - EITCE '22
AB  - In this work, a new operational amplifier using 0.13 μm SOI technology is proposed based on dynamic threshold voltage transistors (DTMOS) for low voltage applications such as the two stages operational amplifier of ultra-low power consumption Internet of Things (IoT) nodes. The operational amplifier uses a two stages configuration, where differential input transistor pairs followed by a single ended class AB output and the input stage uses a DTMOS device structure. Simulation results show that the novel designed operational amplifier has a loop gain of 65.5 dB, a phase margin of 67 ° and unit gain frequency of 37.37 MHz under a 5 pf and 10 kΩ load, using the 0.13 μm partially depleted (PD) SOI technology. In addition, if a lower operating voltage is applied, the power consumption of the circuit low voltage operational amplifier can be further reduced.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573581
SP  - 846
EP  - 852
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573581
ER  - 

TY  - CONF
TI  - Non-Euclidean Space Exploration for Reinforcement Learning State Embedding
AU  - Guan, Weijie
AU  - Li, Zhufeng
AU  - Liang, Qimin
T3  - EITCE '22
AB  - With the rapid increase of computer computing speed in recent years, mechanical learning is widely used in the field of artificial intelligence. Among them, the most popular one belongs to the field of deep learning in mechanical learning. The reason why the field of deep learning is attracting attention is the success and popularity of its application in industry. The success of graph neural networks in industry in recent years has made them a very popular direction nowadays. This paper is dedicated to exploring how to encode game states by means of graph neural networks and proposes a game state encoder combining Convolutional Neural Networks and Graph Neural Networks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573579
SP  - 834
EP  - 838
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573579
ER  - 

TY  - CONF
TI  - A Connection-Based Point Cloud Segmentation Method Using Bipartite Graph
AU  - Li, Ying
AU  - Chen, Fei
T3  - EITCE '22
AB  - Point cloud segmentation is a fundamental but necessary step for many real-life applications. However, most of the existing segmentation methods suffered from the multiple types of surfaces and noise data, which leads to the ‘over-’ and ‘under-’ segmentation, and inaccurate boundaries. To solve these problems, a new robust technique is proposed for segmenting the point cloud into planar or curved primitives in this study. First, the point cloud is decomposed into structural supervoxels. We employ the local dimensional feature to improve the performance of the supervoxel segmentation method near the boundary area. Second, a connection-based merging algorithm is proposed to cluster the adjacent supervoxel based on an optimal matching method. Comprehensive experiments demonstrate that the proposed method obtained better performance than other baseline methods on outdoor samples with low computation costs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573577
SP  - 822
EP  - 827
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573577
KW  - Bipartite graph
KW  - Point cloud
KW  - Supervoxels
KW  - Unsupervised segmentation
ER  - 

TY  - CONF
TI  - A Dynamic SLAM Algorithm Based on Lidar-Vision Fusion
AU  - Li, Yitian
AU  - Zhang, Ren
T3  - EITCE '22
AB  - SLAM (simultaneous localization and mapping) is based on the assumption of a static environment, and the external sensors equipped with SLAM have their own advantages and disadvantages. Therefore, poor lighting conditions, lack of geometric features and dynamic objects in the scene will interfere with the positioning accuracy of the SLAM algorithm based on a single sensor. To solve this problem, this paper proposes a dynamic SLAM algorithm based on Lidar-vision fusion. The algorithm provides depth information for image features through the fusion of monocular image sequences and Lidar scans. After rough positioning with fusion data, dynamic objects in the scenes are eliminated to further optimize the positioning accuracy. The comparative experimental results evaluated on 11 sequences in the KITTI odometry datasets demonstrate that the localization accuracy of the proposed algorithm is better than the vision-based ORB-SLAM2 and DynaSLAM algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573575
SP  - 812
EP  - 815
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573575
KW  - Lidar scans
KW  - Multi-sensor fusion
KW  - SLAM
ER  - 

TY  - CONF
TI  - Dynamic Scenes Visual SLAM Based on Improved Semantic Segmentation Method
AU  - Wu, Tao
AU  - Chen, Junqing
AU  - Guan, Jiansheng
T3  - EITCE '22
AB  - Visual SLAM systems represented by feature point extraction have the assumption that the scene is static, aiming at the problem that dynamic objects seriously affect the accuracy of visual SLAM, this paper proposes a new semantic segmentation method combining DeepLabV3+ and ORB-SLAM2 to improve the accuracy of pose. The traditional semantic segmentation model has a large amount of computation and the computing power of mobile terminal and terminal edge devices is limited. In order to ensure excellent semantic segmentation accuracy and improve segmentation speed, this method combines CoAtten (coordinate attention) and ShuffleNetV2 network as the feature extraction backbone of DeepLabV3+, and adds Channel Shuffle to DeepLabV3+ to obtain an efficient semantic segmentation model. Semantic segmentation model removes feature points of dynamic targets, and the remaining feature points are reserved for inter-frame matching and pose estimation. The experimental results show that the mIOU (mean Intersection over Union) of the semantic segmentation model tested on the data set Pascal VOC 2012 is 70.33%, and the FLOPs (FLoating point OPerations) of the model is only 22.5% of deeplabv3 + (Resnet50); When combining the segmentation model with ORB-SLAM2 in dynamic scene data of TUM RGB-D dataset, the error of pose estimation is significantly lower than that of traditional ORB-SLAM2.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573580
SP  - 839
EP  - 845
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573580
KW  - DeepLabV3+
KW  - ORB-SLAM2
KW  - semantic segmentation
KW  - ShuffleNetV2
KW  - SLAM
ER  - 

TY  - CONF
TI  - A Factorization Machines-based Participant Recruitment Approach in Mobile Crowdsensing
AU  - Ning, Hanyang
AU  - Ma, Miao
AU  - Yang, Bo
T3  - EITCE '22
AB  - Mobile Crowdsensing employs mobile devices to get massive data efficiently and economically, which is a people-centric sensing paradigm followed with the development of mobile communication technology. The key issue of mobile crowdsensing is to recruit suitable participants. Here we propose a new approach on participant recruitments that introduces factorization machine to cross features of participants and tasks in pairs to reduce the number of weight parameters and accelerates the process of model training. In this approach, both the quality of historical task implements and the constraints of time and location are integrated to mine the ability of each potential participant. Compared with some state-of-the-art approaches on Gowalla dataset, experimental results show that our approach is the best in term of precision, recall, hit rate, normalized discounted cumulative gain and mean reciprocal rank.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573578
SP  - 828
EP  - 833
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573578
KW  - Factorization machines
KW  - Mobile crowdsensing
KW  - Participant recruitment
KW  - Recommendation system
ER  - 

TY  - CONF
TI  - Deep Spatio-Temporal Correlation Model on Predicting Olfactory Perception
AU  - Guo, Juan
AU  - Ma, Yifei
T3  - EITCE '22
AB  - Predictive Olfactory perception plays a very important role in researching of spatial construction and reproduction of olfactory perception. At present, there have been a lot of researches on predicting the description of olfactory perception through physical and chemical characteristics, physiological signals and word vector correlation. However, based on the E-nose study of olfaction in the experiment, there are only experimental studies on predicting the degree of pleasure, and in such research only the spatial correlation of the E- nose signal is considered. In this paper, E-nose data is used to predict a variety of olfactory perceptions, and a ConvLSTM (CNN+LSTM) based deep spatio-temporal correlation model is proposed to solve the issues of odor perception prediction. The model predicts perception by using the spatio-temporal correlation of E-nose data and the similarity between odor perception. Experimental results show that the DSTC (Deep spatio-temporal correlation model) has better prediction accuracy than deep learning models such as CNN and LSTM.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573576
SP  - 816
EP  - 821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573576
KW  - CNN
KW  - DSTC
KW  - Electronic nose(E-nose)
KW  - LSTM
KW  - Olfactory perception
ER  - 

TY  - CONF
TI  - Research on the architecture of community policing platform based on blockchain technology
AU  - Liu, Pengcheng
AU  - Zhang, Jiqiang
T3  - EITCE '22
AB  - In recent years, with the rise and development of blockchain technology, the application of blockchain technology has been extended to the Internet of Things, financial services, social welfare, intelligent manufacturing, social management, medical treatment, education, and many other fields. In order to explore the application of blockchain technology in community policing work and promote the construction of smart community policing, this paper first analyzes the feasibility of applying blockchain technology to community policing platform. Then proposing a system architecture of community policing platform based on blockchain technology and analyzing the advantages of the platform. The architecture of community policing platform based on blockchain technology can be divided into six levels: infrastructure layer, data layer, network layer, consensus layer, application layer and management layer. The platform can provide various convenient services, strengthen the information exchange and sharing between community police and community residents, and improve the collaborative governance mechanism of the community, to improve the level of community governance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573779
SP  - 807
EP  - 811
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573779
KW  - Blockchain
KW  - Community policing
KW  - Information sharing platform
KW  - Platform architecture design
ER  - 

TY  - CONF
TI  - Research on distribution network planning of high permeability distributed generation
AU  - Liu, Yangyu
AU  - Shang, Longlong
T3  - EITCE '22
AB  - With the depletion of fossil fuels such as coal, oil and other resources and the aggravation of environmental pollution such as fog, the pressure of energy supply and environmental degradation in China has become increasingly prominent, and energy conservation and emission reduction have received more and more attention. Among them, distributed power supply and electric vehicle have become the industry and direction vigorously supported and promoted by the state due to their resource saving and environment-friendly characteristics. However, the rapid and healthy development of DG and EV cannot be separated from the scientific and reasonable planning of distribution network. In this context, the study of distribution network planning considering charging stations and high permeability DG is of great significance for promoting the application of EV, improving the consumption level of DG, making full use of clean energy, and enhancing the adaptability of distribution network. Therefore, from the perspective of the power grid, combining the charging load, distributed generation output and distribution network data of each station, and taking the minimum fixed investment cost and distribution network loss cost as the goal, the optimization scheme of high permeability distributed generation capacity configuration and distribution network expansion planning is obtained.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573572
SP  - 803
EP  - 806
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573572
KW  - Charging station
KW  - Distributed power supply
KW  - Distribution network planning
KW  - Electric vehicle
ER  - 

TY  - CONF
TI  - Research on Personalized Tourism Recommendation Technology Based on Improved S-TrustSVD Model
AU  - Wu, Yuqun
AU  - Li, Yongzhong
AU  - Xu, Bo
T3  - EITCE '22
AB  - With the rapid development of information technology, the problem of information overload is becoming more and more prominent. The recommendation system provides an effective way to solve the problem of information overload. The recommendation system is one of machine learning algorithms and has been widely used in areas Compared with other recommendation systems, tourism recommendation systems consider more factors, and there are data sparsity and cold start problems. In recent years, researchers have improved and proposed various tourism recommendation methods, and developed corresponding tourism recommendation systems. In this paper, after analyzing the different problems for the tourism recommendation system compared with other information recommendation systems, aiming at the problem that the existing scenic spot recommendation method does not consider users' personal scoring habits, the viewing effect of scenic spots, as well as the sparsity and cold start of users' scenic spot check-in data, Firstly we integrate the social information of users on the tourism platform into the TrustSVD model to improve it, Secondly, for the similarity calculation method in the TrustSVD model is the Pearson similarity calculation, and its calculation results have shortcomings, we introduce the category label of scenic spots and adopts the improved category similarity calculation method. An improved S-TrustSVD model of time evolution scenic spot recommendation with improved category similarity is proposed. The gradient descent method is used to solve the S-TrustSVD model, and the S-TrustSVD tourist attraction recommendation algorithm and experiment are completed. The experimental results show that proposed method not only improves the recommendation accuracy, but also alleviates the problems of data sparsity and cold start.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573571
SP  - 796
EP  - 802
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573571
ER  - 

TY  - CONF
TI  - Detection method of elevator space overload based on machine vision
AU  - Liu, Shaofeng
AU  - An, Ziliang
AU  - Wang, Junxiao
AU  - Li, Xinxin
AU  - Shang, Shuyu
T3  - EITCE '22
AB  - To further improve the efficiency of the elevator, and reduce unnecessary stop of elevator, a detection method of elevator space overload based on machine vision was proposed. The area of the target in the elevator was calculated by binocular camera modeling and image processing algorithm. The experimental results indicate that when the elevator transports objects with light weight and large floor area, the space occupancy rates of the elevator is 30% to 50% higher than the load rates of the elevator, which shows that this method can more accurately reflect the overload situation of the elevator. This study provides research reference for elevator manufacturers to formulate more efficient elevator control strategies.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573570
SP  - 791
EP  - 795
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573570
KW  - elevator
KW  - machine vision
KW  - space overload detection
ER  - 

TY  - CONF
TI  - Driver Distracted Behavior Detection Based on Deep Learning
AU  - Qi, Xinyu
T3  - EITCE '22
AB  - In the traffic control system, the driver's distracted behavior detection is particularly important for traffic safety. Traffic accidents caused by distracted behavior of motor vehicle drivers are a common problem in traffic control systems. Focusing on the driver's distracted behavior detection, based on the original YOLOv4 framework, this paper uses the lightweight network mobilenet as the backbone network for real-time requirements of detection, and uses Depthwise Separable Convolution (DSC) to reduce model calculation and improve detection speed; increases SE module to improve the detection accuracy. The actual surveillance video data shows that the detection speed is 27fps faster than YOLOv4, and the recognition accuracy is increased by 2%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573569
SP  - 786
EP  - 790
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573569
KW  - Depthwise Separable Convolution
KW  - Distracted behavior detection
KW  - Mobilenetv1
KW  - SE module
KW  - YOLOv4
ER  - 

TY  - CONF
TI  - Remote Sensing Image Registration Via Feature Fusion and Enhanced Matching
AU  - Li, Xianjing
AU  - Chen, Ying
AU  - Zhang, Wencheng
AU  - Wang, Jiahao
AU  - Wang, Wei
T3  - EITCE '22
AB  - Image registration is a basic problem in image analysis and image processing. Image registration has important applications in aerial image fusion, pattern recognition, three-dimensional reconstruction and other fields. Aiming at the problem of low registration accuracy and mismatching in remote sensing image registration, this paper proposes to use the Involution kernel to improve the ResNext network in the feature extraction stage and combines the SPANet attention mechanism with an improved ResNext network to improve the feature extraction ability of the network. In the feature matching stage, an enhanced matching method is proposed, which uses cross-correlation and nearest neighbor to second nearest neighbor ratio to filter out mismatched points to cope with complex images and background interference. The experimental results show that the proposed algorithm can achieve superior results in a variety of indexes compared with other algorithms, which proves that the proposed algorithm is effective.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573568
SP  - 782
EP  - 785
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573568
ER  - 

TY  - CONF
TI  - Research on Empathic Remediation Mechanism of Chatbots Mediated by Social Presence and Trust
AU  - Sun, Xuyan
AU  - Guan, Hui
T3  - EITCE '22
AB  - Chatbots are changing the way consumers interact with businesses. However, chatbots continue to be widely perceived to lack a human touch and inevitably fail to deliver service. This paper argues that emerging research on AI empathy will address the lack of human touch in chatbots and provide new ideas for remedying chatbots service. By combing research from different disciplines, we argue that the connotations of chatbots empathy can be understood through a three-tier structure of transpersonal thinking, empathic care, and emotional empathy. Additionally, we find that chatbots empathy contains three dimensions: cognitive empathy, emotional empathy and behavioral empathy. These three dimensions are not mutually exclusive but rather complement each other to form the overall empathy capacity of chatbots. Based on the mediating mechanisms of social presence and trust and the moderating mechanism of technology readiness, we summarize a framework for the impact of chatbots empathy on consumers' willingness to forgive. This paper can further enrich the research on chatbots service remediation and improve companies' understanding and use of empathic remediation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573566
SP  - 772
EP  - 776
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573566
KW  - Chatbots
KW  - Empathy
KW  - Service remediation
KW  - Social presence
KW  - Trust
ER  - 

TY  - CONF
TI  - Performance Evaluation of Bird Detection Radar in the Application of Airports
AU  - Wu, Honggang
AU  - Cheng, Zhi
AU  - Wei, Kaizhen
AU  - Ma, Jianrui
AU  - Li, Xiaojuan
T3  - EITCE '22
AB  - Bird strikes pose a significant danger to the takeoff and landing of aircraft in airports. Detecting and monitoring the bird activities around the airports is critical for preventing bird strikes. Traditional bird control methods rely on manual observation of airport staff, and the result of bird detection will directly determine the effect of bird strike prevention. Bird detection radar has been introduced to airports to provide comprehensive information about the status of bird activities. However, the environment of airports is complicated, and many factors can influence the performance of bird detection radar. Bad weather, such as clouds, fog, and rain, also plays a vital role in bird detection. The radar must maintain the ability of bird detection in different conditions with good performance. In this paper, multiple radars were applied to bird detection in airports. Active radar, such as mechanical and phased array radar, is typical and performs better in the application of bird detection, but the electromagnetic environment of airports is complicated, and the deployment of active radar needs to estimate the influence on the electromagnetic environment. Compared with active radar, passive radar does not have transmission models and can ignore the impact of other objects, such as terminal buildings, aircraft, cars, and people. With the experiment in airports, this paper analyses the advantages of different bird detection radars. Therefore, this paper evaluates the performance of different bird detection radars in the application of airports.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573563
SP  - 756
EP  - 760
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573563
KW  - active radar
KW  - bird control
KW  - bird strikes
KW  - electromagnetic radar
KW  - mechanical radar
KW  - optical radar
KW  - passive radar
KW  - phase array radar
ER  - 

TY  - CONF
TI  - Interpreting Deep Networks: by Ensemble Learning and Visualizing the Perturbation
AU  - Guo, Jiangpo
AU  - Wang, Xiaodong
T3  - EITCE '22
AB  - Most deep neural network models are black boxes and lack interpretability. As the interpretability is critical for deep models applied to high-risk tasks, many visual approaches are proposed to reveal what the model learns in recent years. However, the quality and completeness of important regions, which are exported by the most existing visualization methods, are still unsatisfactory. Thus, a method, interpreting deep networks by ensemble learning and visualizing the perturbation, is presented in this paper. The method firstly perturbs the original image using the mask to obtain the perturbed image. Secondly, it imports the perturbed image into the model to obtain the loss of the update mask. Finally, an Adaboost-like algorithm, which combines the extremal perturba- tions and the meaningful perturbation, is introduced to improve the interpretation. Experimental results confirm that the method can improve the quality and completeness of the important regions, and provide a more reasonable explanation for the prediction results.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573567
SP  - 777
EP  - 781
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573567
KW  - Completeness
KW  - Important regions
KW  - Interpret
KW  - Perturbation
KW  - Quality
ER  - 

TY  - CONF
TI  - Design of L-IDAKA Protocol for Lightweight Access Authentication and Encrypted Transmission of New Power System-Aware Terminals Based on Hash Pre-authentication
AU  - Feng, Yun
AU  - Zhai, Feng
AU  - Liang, Xiaobing
AU  - Zhang, Liang
T3  - EITCE '22
AB  - The introduction of massive heterogeneous IoT terminals poses new challenges to the access security of the edge-aware side of the power IoT. Marked cipher technology can realize direct authentication based on device identity without relying on digital certificates, which significantly simplifies the difficulty of key management and authentication process and has natural advantages in the large-scale deployment of power IoT terminal scenario. However, identification cryptography is based on bilinear pair operation, which has high operational overhead and is difficult to apply to resource-constrained terminals. In this paper, we design a lightweight authentication key negotiation protocol based on hash pre-certification based on the four-layer architecture of power IoT application-platform-network-awareness for the characteristics of huge scale and resource-constrained power IoT devices, which reduces the number of bilinear pairs in the traditional SM9 algorithm from two to one and improves the protocol efficiency by more than 50%. Meanwhile, a security analysis of the protocol based on the classical Dolev-Yao threat model shows that this scheme can achieve efficient and secure applications in resource-constrained terminals of power IoT.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573565
SP  - 766
EP  - 771
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573565
KW  - identification cipher
KW  - key negotiation
KW  - lightweight
KW  - power IoT
KW  - resource-constrained terminals
ER  - 

TY  - CONF
TI  - Research on real-time detection algorithm of fuel consumption for BDS positioning multi-tank tracked vehicle
AU  - Zhang, Pengwei
AU  - Wu, Yongjie
AU  - Wang, Qijin
AU  - Cao, Zumou
AU  - Peng, Bo
T3  - EITCE '22
AB  - In order to carry the fuel as much as possible and avoid excessive fuel concentration in the multi-tank tracked vehicles, the multiple fuel tanks are arranged in a corresponding space of the vehicle chassis. The adjacent fuel tanks are connected to each other by oil pipes, and all the tanks are divided into left groups and right group. Since the left and right group of fuel tanks are on the same level, a capacitance oil level sensor is fixed in the rear fuel tank of each group to detect the remaining total oil volume of the tanks. The fuel consumption measure is inaccurate and no real-time with the three-scale mete in the multi-tank tracked vehicles. So the real-time fuel quantity measurement system is developed by employing techniques of single-chip microcontroller, ultrasonic sensing, BDS positioning and wireless communication. An ultrasonic oil level sensor is stuck on the bottom of each tank to detect the remaining oil of tanks accurately. It can avoid destroying the existing equipment structure. BDS positioning module is applied to monitoring the location of vehicle. This technology is China complete autonomy. The special wireless transmission module and special network node are set up for transmitting the data of fuel consumption and position. It can guarantee the transmission secure and confidential. Especially, a fuel consumption detection algorithm is studied based on BDS Positioning and ranging. The prototype is mounted and tested on the carrier vehicle under four different road conditions. The error rate of fuel quantity detection is 3.79% on the highway with good road conditions. And the measured value is close to the manufacturer's nominal value. The experimental data analysis shows that the design of the measurement system is reasonable, the fuel quantity detection algorithm is correct and reliable, and the real-time fuel quantity detection and positioning for the multi-tank tracked vehicle can be realized.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573564
SP  - 761
EP  - 765
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573564
KW  - BDS Positioning
KW  - Fuel Consumption Detection
KW  - Special Vehicles
KW  - Ultrasonic Sensing
ER  - 

TY  - CONF
TI  - An extended frequency scaling algorithm for the dechirp received bistatic SAR with high squint angle
AU  - Zhang, Haohua
AU  - Zuo, Weihua
AU  - Liu, Bo
T3  - EITCE '22
AB  - Bistatic synthetic aperture radar (BiSAR) is an extended and complementary observation method to conventional monostatic SAR remote sensing. When high range and azimuth resolution are required in BiSAR, the transmitting platform, i.e., the LEO satellite, should work in the spotlight or sliding spotlight mode, which means a wide bandwidth Chirp signal is transmitted, and the targets are illuminated for a long enough time as well. In order to reduce the sampling frequency in the receiving system and improve the efficiency of the focusing procedure for this BiSAR con figuration, the echoes should be dechirp received. A bistatic extended frequency scaling algorithm (Bi-EFSA) is proposed in this paper to deal with the dechirp received bistatic SAR echoes. The first step of Bi-EFSA is the range walk correction in the 2-D time domain, which reduces the space variance of the range curvatures and removals the serious coupling between range and azimuth caused by the high squint angle. After that, the range compression is achieved by secondary range compression (SRC) and bulk shift. Then, the space variance of the azimuth frequency modulation rate, introduced by the range walk correction step, is corrected by implementing the azimuth nonlinear chirp scaling (ANCS) operation. Following this, the focused results in the range frequency and azimuth time domain are obtained by the azimuth compression. The point targets simulations validate the effectiveness of the proposed algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573560
SP  - 737
EP  - 745
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573560
KW  - azimuth nonlinear chirp scaling
KW  - bistatic extended frequency scaling algorithm
KW  - Bistatic SAR
KW  - dechirp received
KW  - high squint angle
ER  - 

TY  - CONF
TI  - Research on UAV swarm target search algorithm based on prior information
AU  - Liu, Xiaoyang
AU  - Shen, Xiangeng
T3  - EITCE '22
AB  - Aiming at the problem of limited sensing range and small search range of single UAV camera, this paper proposes a UAV cluster target search algorithm based on prior information. The algorithm firstly build tasks area target probability graph model, and according to the task of target location prior information to initialize parameters, set the objective function to maximize the task of search revenue environment, then USES the distributed model and to solve the objective function, optimal decision task, realize the coordinated search of UAV cluster. The simulation results show that the algorithm has fast search speed and can avoid obstacles, which has certain military application value.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573778
SP  - 752
EP  - 755
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573778
KW  - Collaborative search
KW  - Priori information
KW  - UAV
ER  - 

TY  - CONF
TI  - Automatic Scene Segmentation Algorithm for Image Color Restoration
AU  - Yu, Runde
AU  - Han, Lu
AU  - Zhang, Wenying
T3  - EITCE '22
AB  - In the process of the automatic coloring of black and white movies, due to the issue of inaccurate scene segmentation, the selected reference image coloring is not suitable for two scenes, which further leads to poor coloring effects. Towards the issue, this paper designs an automatic scene segmentation algorithm based on deep learning, which can combine depth features and semantic similarities and not use the color distribution in the video. More specifically, the method first employs the pre-trained model VGG19 to learn the multi-layer feature representation of adjacent two frames. Secondly, the residual network is adopted to combine the multi-layer feature representations produced by the pre-trained model VGG19 to form feature vectors. Finally, the paper calculates the semantic similarity between the two feature vectors and designs an adaptive threshold scheme for determining the boundary frames, which can perform well in the scene segmentation task for various categories of videos. Experimental results show that this paper can effectively address the scene segmentation issue in various movies and thus improve the coloring effect of the ones.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573777
SP  - 746
EP  - 751
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573777
KW  - Deep Learning
KW  - Image Color Restoration
KW  - Scene Segmentation
KW  - Semantic Similarity
ER  - 

TY  - CONF
TI  - The Iris Cassification Based on Gaussian Naive Bayes Agorithm
AU  - Shi, YuXuan
AU  - Xu, HongLi
T3  - EITCE '22
AB  - Bayes' theorem is one of the most famous theories in probabilistic models, which is adept to be combined in machine learning, especially in classification applications. IRIS set is the classical dataset of machine learning. Firstly, naive and Gaussian Bayes classifier are provided including their relationship. Secondly, preprocess IRIS dataset, use CSV Format or read dataset into a Pandans DataFrame, perform prior, divide them into training and test datasets in proportion. And then, perform train and test work according to corresponding data with Gaussian Bayes classifier. Finally, carry out cross validation and analyze the accuracy of the verification results. The emphasis is on the working of naive Bayes model with Gause principle and the improvement on the method of dataset feature extraction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573559
SP  - 732
EP  - 736
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573559
ER  - 

TY  - CONF
TI  - Support Vector Machine for HRRP Recognition based on Bald Eagle Search Optimization
AU  - Liu, Lili
AU  - Su, Min
AU  - Liu, Jia
AU  - Chen, Ruibei
T3  - EITCE '22
AB  - Applying support vector machine (SVM) on high resolution range profile (HRRP) is a topic of widespread concern in the radar automatic target recognition field. The classification performance of SVM largely depends on its kernel and penalty parameters, parameter optimization is a critical component in target recognition algorithm. In this paper, a target recognition method based on SVM and HRRP is proposed, the SVM method is optimized by introducing bald eagle search (BES) algorithm. The new method adopts BES to optimize the kernel parameter and penalty parameter of SVM, effectively solves the defects of slow convergence and low classification accuracy due to the improper selection of SVM classifier parameters. Experimental analysis shows that the BES-SVM could provide a higher recognition accuracy and lower time consumption compared with traditional SVM and GA-SVM, which has good applicability for HRRP based radar target recognition problems.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573557
SP  - 727
EP  - 731
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573557
KW  - bald eagle search (BES)
KW  - high-resolution range profile (HRRP)
KW  - radar automatic target recognition (RATR)
KW  - support vector machine (SVM)
ER  - 

TY  - CONF
TI  - Design and Implementation of 3D Visual System Based on Cloud Rendering
AU  - Zhong, Juanjuan
AU  - Li, Jiewei
AU  - Jin, Hengyu
T3  - EITCE '22
AB  - In order to fix the problem of running large-scale 3D visual system in non-professional graphics workstations of low computing power equipment such as mobile phones, light laptops, tablet computers and integrated display desktops, this paper proposes a solution based on cloud rendering. This paper mainly studies the underlying principle of cloud rendering, the overall structure design, and specific modules such as control center service, process control service and rendering services. Finally, we also studied the implementation of lightweight front-end rendering SDK.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573556
SP  - 723
EP  - 726
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573556
ER  - 

TY  - CONF
TI  - Analysis of Hotel Spatial Distribution Characteristics and Influencing Factors under GIS Method: ——Based on big data analysis of Ningbo hotel POI
AU  - Tong, Yuqiong
T3  - EITCE '22
AB  - The computer program is used to capture 2131 POI data containing various kinds of information, and the Gis software is used for image drawing and processing, so as to analyze the influence factors of the spatial distribution of hotels. With the help of nearest neighbor, spatial kernel density and standard deviation ellipse analysis, this paper finds that the network POI data can fully reflect the spatial distribution and agglomeration characteristics of hotels. Therefore, the research object of this paper is hotels of all grades in various districts and counties of Ningbo City. The purpose of the research is to analyze the layout of these hotels, explore the factors that affect their layout, and provide a basis for future hotels to use digital technology for site selection, construction and development. The results show that hotels are clustered in the central city, and the layout is closely related to scenic spots, shopping centers and other factors.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573555
SP  - 717
EP  - 722
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573555
KW  - hotel spatial distribution
KW  - image processing
KW  - POI data
KW  - python
ER  - 

TY  - CONF
TI  - Optimal Base Station Selection of Source Localization Based on UAV Swarm With Location Uncertainty
AU  - Xu, Fangwen
AU  - Wang, Chao
T3  - EITCE '22
AB  - In complex environments, the location of the unmanned aerial vehicle (UAV) swarm airborne base station is not precisely known. This paper focuses on the optimal base station selection of UAV airborne base station positioning system with base station position error. For the propagation of base station position error, this paper uses an estimation method based on belief propagation to improve localization accuracy. This paper proposes a UAV base airborne station selection criterion based on the Fisher information matrix (FIM). The base station selection problem is described as a nonconvex optimization problem. The problem is relaxed as the convex semidefinite program by the Semi-Definite Relaxation (SDR). Simulation results show that the proposed evaluation criterion effectively reduces the running time of base station selection. Compared with other base station selection methods, the proposed method has better location accuracy in the scene with base station position error.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573554
SP  - 712
EP  - 716
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573554
KW  - Base station selection
KW  - Belief propagation
KW  - SDR
KW  - UAV swarm
ER  - 

TY  - CONF
TI  - Improving Anomaly Detection in Smart Grid Big Data with Knowledge Graphs
AU  - Zhao, Yingying
AU  - Sun, Haoyu
AU  - Guo, Naiwang
AU  - Wu, Yi
AU  - Tian, Yingjie
AU  - Cheng, Dawei
T3  - EITCE '22
AB  - A knowledge graph is an intelligent database that integrates artificial intelligence technology and traditional database. It is a knowledge base that represents concepts, entities and their relationships in the objective world in the form of a graph. It can well reflect the relationship between entities. In the current era of big data, although the accuracy of abnormal value detection of power data is much higher than that of traditional methods, big data is lack of explicability, so it is difficult to trace the origin of abnormal values. Abnormal values caused by errors must also be checked manually on site, which wastes human and material resources. As a knowledge embodiment of "big data + artificial intelligence", it has natural advantages in the integrity and interpretability of behavior description. Therefore, this paper studies and discusses the relevant theories and technologies of knowledge graph construction and anomaly detection algorithm. Aiming at the power database table processing process that will cause errors, this paper constructs the knowledge graph and uses the Neo4j diagram database for storage, so as to visualize the data processing process, clarify the data processing relationship, and facilitate the tracking and traceability of the data. In addition, it also carries out experiments and analysis of different anomaly detection algorithms on the sample power consumption data.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573553
SP  - 707
EP  - 711
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573553
KW  - Anomaly detection
KW  - Big data
KW  - Knowledge graphs
ER  - 

TY  - CONF
TI  - An Adjustment Algorithm for Multiple UAVs Based on Local Averaging
AU  - Wang, Xinrui
AU  - Zhu, Yunwei
AU  - Lin, Shanyu
T3  - EITCE '22
AB  - As the unmanned aerial vehicle system plays an increasingly important role in modern society, the problem of UAV formation adjustment has also attracted more and more scholars' attention. Passive azimuth-only positioning technology can reduce the electromagnetic radiation required for positioning, but it also brings great challenges to positioning. Taking the circular formation as an example, this paper discusses the passive triangulation model of pure azimuth angle, and proposes an optimization strategy based on local averaging, which can effectively solve the formation adjustment problem when there are position errors of multiple measuring points. In this strategy, the UAV under positioning is localized by three measurement groups at a time, and the UAV iteratively adjusts its position with a local average polar coordinate. Simulation experiments show that the strategy can effectively realize the autonomous coordination and coordination of multiple UAV formations, which has certain theoretical and practical significance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573551
SP  - 695
EP  - 700
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573551
KW  - Adjustment algorithm
KW  - Local averaging
KW  - Passive azimuth-only positioning
KW  - Unmanned aerial vehicle
ER  - 

TY  - CONF
TI  - Characteristics Analysis of RODNet ConfMap for MMW Radar Target Detection
AU  - Li, Zhuang
AU  - Li, Yang
AU  - Wang, Yanping
AU  - Lin, Yun
AU  - Shen, Wenjie
T3  - EITCE '22
AB  - Unlike the Constant False-Alarm Rate (CFAR) based MMW radar target detection methods, RODNet ( A Real-Time Radar Object Detection Network ) is based on Convolutional Neural Networks ( CNNs ), and directly learns the radar target scattering signatures from the original range-azimuth ( RA ) radio frequency image sequence. Although this is a big advantage to keep more useful information, the generated confidence map (ConfMap) characteristics of predicated proximal pedestrian targets is unknown. It leads to a missed detection problem in the dense pedestrian scene. In this paper, we analyze the characteristics of ConfMap and the limitations of RODNet. The relationship among ConfMap value distribution, occupied grid spatial distribution and target number is analyzed. Through the CRUW dataset, the target detection experiment of dense pedestrian scene is carried out, and is used to support our analysis.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573552
SP  - 701
EP  - 706
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573552
KW  - ConfMap
KW  - Limitation analysis
KW  - Millimeter Wave Radar
KW  - OLS
KW  - Position post-processing
KW  - RODNet
ER  - 

TY  - CONF
TI  - DEPA: Determining Exploit Primitives Automatically for Interactive Programs
AU  - Liu, Jie
AU  - An, Hang
AU  - Li, Jin
AU  - Liang, Hongliang
T3  - EITCE '22
AB  - Automated Exploit Generation (AEG) is a well-known difficult task, especially for heap vulnerabilities. The premise of this task is the determination of exploit primitives, and prior research efforts for exploit primitive determination are usually based on vulnerability identification. However, it is not always easy to discovery bugs using fuzzing or symbolic technologies for some programs.In this paper, we present a solution DEPA to determine exploit primitives based on primitive-crucial-behavior model for heap vulnerabilities. The core of DEPA contains two novel techniques, 1) primitive-crucial-behavior identification through pointer dependence analysis, and 2) exploit primitive determination method which includes triggering both vulnerabilities and exploit primitives. We evaluate DEPA on real-world CTF (capture the flag) programs with heap vulnerabilities and DEPA can discovery arbitrary write and arbitrary jump exploit primitives for some programs except for program multi-heap. Results showed that primitive-crucial-behavior identification and determining exploit primitives are accurate and effective by using our approach. In addition, DEPA is superior to the state-of-the-art tools in determining exploit primitives for the heap internal overflow vulnerability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573550
SP  - 690
EP  - 694
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573550
KW  - Concolic execution
KW  - Exploit generation
KW  - Exploit primitive
KW  - Fuzzing
KW  - Primitive-crucial-behavior
ER  - 

TY  - CONF
TI  - Research on UAV apron positioning system based on FPGA
AU  - Xu, Chao
AU  - Chen, Xingwu
AU  - Zheng, Jishi
AU  - Chen, Yunfei
T3  - EITCE '22
AB  - A new hardware algorithm architecture based on field programmable gate array (FPGA) is proposed to address the complex background situation where the traditional edge detection algorithm on a software platform is less effective for UAV apron localization and cannot meet the demand for real-time processing when the image data volume is too large. The architecture uses a combination of morphology and edge detection to ensure high-precision localization of the UAV apron while considering real-time localization. The hardware test results show that the system achieves 96.5% accuracy in image localization of the UAV apron and 13.06ms localization time.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573549
SP  - 685
EP  - 689
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573549
ER  - 

TY  - CONF
TI  - Application of machine vision in the diagnosis and treatment of autistic patients
AU  - Cai, Ziqi
AU  - Chen, Zhencai
T3  - EITCE '22
AB  - Machine vision is a device that automatically receives and processes an image of a real object through an optical device and non-contact sensors to obtain the required information or for controlling the motion of a robot. With the development of artificial intelligence and the increasing maturity of machine vision technology, the application of machine vision has expanded to target the treatment of rehabilitated individuals. As a common developmental disorder, autism tends to be multimodal in its prediction, screening and treatment, and machine vision can be used for feedback training as well as various conventional rehabilitation therapies through the developed interactive rehabilitation system. It can break through the traditional single autism treatment paradigm and enable better operability and accuracy of the treatment process. This paper reviews the working principle of machine vision, and the algorithms used in machine vision for motion target detection, and finally summarizes the application of machine vision in the diagnosis and intervention treatment of early autistic patients.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573547
SP  - 676
EP  - 679
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573547
KW  - artificial intelligence
KW  - Autistic Spectrum Disorders
KW  - Machine vision technology
ER  - 

TY  - CONF
TI  - Spatial pattern analysis of high-level scenic spots under ArcGIS: —— Based on POI of Zhejiang high-level scenic spots
AU  - Wu, Xingtong
T3  - EITCE '22
AB  - The high-quality development of tourism has been paid more and more attention. Studying the spatial distribution pattern of high-level tourist attractions is beneficial to provide theoretical guidance for optimizing the allocation of tourism resources. This study takes the high-level tourist scenic spots in Zhejiang Province as the research object. Based on POI data and Python related technologies, using the kernel density analysis method and standard deviation ellipse analysis method in the GIS spatial analysis method, analyzing high-level tourist attraction's overall and various spatial distribution characteristics. The study found that the overall distribution of high-grade tourist attractions in Zhejiang Province is uneven, showing a pattern of agglomeration in the north and scattered in the south. And the distribution of various types of tourist attractions has its own characteristics. This study proposes relevant suggestions, in order to provide theoretical guidance for optimizing the spatial layout of scenic spots in Zhejiang Province and promoting the high-quality development of tourism.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573548
SP  - 680
EP  - 684
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573548
KW  - image processing
KW  - POI data
KW  - python
KW  - space analysis
ER  - 

TY  - CONF
TI  - Research on automatic mapping of electrical system diagram based on artificial intelligence algorithm
AU  - Ning, Baifeng
AU  - Li, Qing
AU  - Shi, Ji
AU  - Sun, Rongrong
T3  - EITCE '22
AB  - In the past, electric power companies often used manual guidance when implementing the power system mapping module. First, they added local sections to the mapping, and then manually completed branch direction and spacing adjustment, equipment marking, etc. The whole process requires a lot of manual participation, so there are unfavorable factors such as slow mapping efficiency, large manual adjustment workload, and long implementation period. Based on this, this paper proposes an automatic mapping scheme of electrical system diagram based on artificial intelligence algorithm. It focuses on the combination of intelligent algorithm and traditional electrical system mapping business. On the data scale of large depth, large scope and multiple connections, and with the purpose of "more computers, less brains, and less manpower", it studies the effective methods and means of rapid automatic layout, automatic mapping, and automatic labeling, and establishes an intelligent drive for electrical system diagram mapping.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573546
SP  - 671
EP  - 675
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573546
KW  - Artificial intelligence
KW  - Automatic mapping
KW  - Balanced layout
KW  - Electrical system diagram
ER  - 

TY  - CONF
TI  - A Design of Automatic Inspection Solution for Electric Power Marketing Documents
AU  - Li, Jianyi
AU  - Liu, Guanyao
T3  - EITCE '22
AB  - In the field of power marketing data inspecting, most of the documents need to be inspected for compliance with the specifications, where the main issue to check is whether their documents are stamped or signed. In the traditional technique, the documents are manually accessed by the inspectors and the documents that do not meet the specifications are manually selected. This approach is not only heavy workload, but also inefficient and less accurate. This paper proposes an automatic inspection [1] solution for electric power marketing documents (AISEM), which contains a set of automatic inspecting processes, a system, electronic devices and storage media, to solve the above problems.After obtaining the image to be inspected of the document to be inspected, AISEM determines the target title area in the image to be inspected and performs text recognition. It determines the document type of the document to be inspected based on the text recognition result. It matches by document type to the corresponding document template image. It determines the area to be inspected in the image to be inspected based on the coordinate position of the template inspectin area of the document template image. According to the type of inspection content, AISEM extracts the inspection characteristics of the area to be inspected and the template inspection area, so that the inspection characteristics of the area to be inspected and the template inspection area can be compared. The comparison result is obtained to determine whether the inspection verification passes or not, thus realizing automatic inspection of documents. Compared to manual inspection, automatic inspection reduce workload and improve efficiency and accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573544
SP  - 659
EP  - 663
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573544
KW  - Audit
KW  - Automatic Audit
KW  - Automatic Inspection
KW  - Electric Power Marketing
KW  - Inspection
ER  - 

TY  - CONF
TI  - Research on the distribution pattern and accessibility of scenic spots based on Baidu map API and GIS: A case study of Hangzhou City
AU  - Liang, Yanhao
T3  - EITCE '22
AB  - This paper uses the ArcGIS software Spatial Analyst function, with the Baidu lightweight route planning API interface as the data support, uses Java programming language to obtain relevant effective data information, and uses the ArcGIS inverse distance weight method to conduct a detailed analysis of the spatial distribution of 47 tourist attractions above 4A level in Hangzhou, as well as the accessibility level between each scenic spot and between each scenic spot and the central location of different tourist sources. The results show that the scenic spots above 4A grade in Hangzhou show agglomeration distribution in the central urban area of northeast China, and diverge in the central and southwest areas of Hangzhou. The level of accessibility between various scenic spots and between scenic spots and the central location of the source area is centered on the central urban area, and there is a decreasing trend in all directions.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573545
SP  - 664
EP  - 670
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573545
KW  - Accessibility
KW  - Anti-distance weighting method
KW  - Hangzhou City
KW  - Spatial Analyst
KW  - Tourist attractions
ER  - 

TY  - CONF
TI  - Design of a Robot for Automatically Hanging Ground Wires in Substations
AU  - Pan, Qingyu
AU  - Sun, Xiaoyi
AU  - Li, Danyong
AU  - Li, Ruolan
AU  - Fan, Li
T3  - EITCE '22
AB  - When the substation starts maintenance work, it is necessary to first hang the ground wire to discharge the residual charge of the power-off equipment to ensure the safety of personnel. At present, the hooking of ground wires mainly relies on manpower, the degree of automation is low, it is difficult to supervise after hooking, and the safety is not high. In this paper, an automatic ground wire hooking robot is designed. Through a reasonable structure and control algorithm, the robot can automatically hook the ground wire and supervise the ground wire. The actual test shows that the robot can hook up the ground wire independently in the substation, and can supervise the ground wire that has been hooked up.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573543
SP  - 650
EP  - 658
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573543
KW  - Hanging ground wire
KW  - Internet of Things
KW  - Substation robot
KW  - Wire identification algorithm
ER  - 

TY  - CONF
TI  - A Chinese word segmentation method based on dictionary and HMM
AU  - Liu, Chunling
AU  - Zhang, Qizhen
AU  - Feng, Jinlong
AU  - Tian, Yuqi
T3  - EITCE '22
AB  - Aiming at the problems of ambiguity segmentation and low success rate of new words discovery in Chinese word segmentation, this paper proposes a Chinese word segmentation method based on dictionary and Hidden Markov Model. Through forward maximum matching algorithm and backward maximum matching algorithm, the coarse segmentation results are obtained, and the ambiguous fragments are collected and input into the Hidden Markov model. The Hidden Markov Model performs secondary word segmentation through word order tagging and identifies new words, and adds new words to the dictionary to improve the dictionary. The experimental results show that the proposed algorithm improves the problem of low success rate of ambiguity recognition and new word discovery, improves the accuracy, recall and F1 value of ordinary text segmentation, and improves the problem that Jieba segmentation ability decreases in professional text.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573542
SP  - 644
EP  - 649
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573542
ER  - 

TY  - CONF
TI  - Spatial distribution analysis of hotels and scenic spots in Hangzhou, Zhejiang based on ArcGIS
AU  - Zhu, Jiajia
T3  - EITCE '22
AB  - This paper uses Hangzhou, Zhejiang Province as the study area, and uses ArcGIS to conduct spatial analysis to study the spatial distribution of Hangzhou hotels and the relationship between their distribution and the distribution of scenic spots. This paper adopts the kernel density analysis method and the nearest neighbor index method to analyze the spatial distribution of hotels, and obtains that the spatial distribution of hotels in Hangzhou shows a decreasing trend from the main city to the outside. The spatial clusters of all types of hotels are in the main urban area, but the number of clusters of different types of hotels is different, i.e., luxury and upscale hotels have low-density clusters in addition to this core cluster, while comfort and economy hotels have only one cluster. This paper also uses ArcGIS to combine the spatial distribution map of Hangzhou hotels with the distribution of scenic spots, and we find that the distribution of scenic spots is an important factor affecting the spatial distribution of Hangzhou hotels, and different types of hotels are affected to different degrees. This paper combines technology and practice to provide a direction for the future development of Hangzhou hotels.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573539
SP  - 627
EP  - 632
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573539
KW  - ArcGIS
KW  - Future Developments
KW  - Hangzhou
KW  - Hotel
KW  - Scenic Area
KW  - Spatial distribution
KW  - Technologies
ER  - 

TY  - CONF
TI  - FeaturesRank: An unsupervised keyphrase extraction approach based on features representation for Chinese documents
AU  - Zhao, Yining
AU  - Zhu, Xiaomin
AU  - Wang, Maoli
AU  - Wang, Xinming
AU  - Zou, Min
AU  - Li, Kaizhi
T3  - EITCE '22
AB  - Keyphrase extraction technology can obtain the main content and semantic expression of academic literature, which plays an essential role in text retrieval, classification and clustering. We propose a new method, FeturesRank, to automatically identify meaningful and authoritative keyphrases from Chinese academic texts. FeturesRank integrates three features of keyphrase: frequency, contextual relevance and grammatical relation to measure the likelihood of sequence of words to be a meaningful phrase and introduces a scoring mechanism that combines the influence of words in the network graph with a new “phraseness” feature to calculate a normalized score for every candidate. The experimental results show that the evaluation indexes of the proposed method on Chinese academic datasets are significantly improved compared with the four popular keyphrase extraction methods, which verifies the effectiveness of the method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573541
SP  - 637
EP  - 643
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573541
KW  - features representation
KW  - keyphrase extraction technology
KW  - scoring mechanism
KW  - TextRank
ER  - 

TY  - CONF
TI  - Design and implementation of general integration component for automation platform
AU  - Zhou, Xiaolu
AU  - Liu, Ying
AU  - Xu, Shuai
T3  - EITCE '22
AB  - The form translation component that provides support for the integration of ITSM and third-party business platforms is characterized by good reusability, high development efficiency, and strong dynamic integration capability, rapid integration of multiple business scenarios is realized after application, but during the integration of ITSM and automation platform, the relationship mapping between technical service catalog items and automation tools is added, the one-to-one mapping function between business forms and business service catalog items provided by the form translation component makes ITSM unable to select corresponding tools from multiple automated tools. It is urgent to upgrade the form translation component to realize the one to many mapping function between business forms and business service catalog items.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573540
SP  - 633
EP  - 636
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573540
KW  - Automation Tool
KW  - Integration components
KW  - Mapping Rules
KW  - Service Catalog
ER  - 

TY  - CONF
TI  - Key Technologies of Electronic Perimeter System Based on Deep Learning
AU  - Chen, Jie
AU  - Zeng, Yongjin
AU  - Mao, Jian
T3  - EITCE '22
AB  - This paper introduces the overall architecture of electronic perimeter system based-on the deep learning and its key technologies. The system adopts a microservice architecture, using deep learning algorithm services and Spring Cloud-based backend servers to implement the system architecture. Faster RCNN is used as the object detection algorithm and the processing mechanism of real-time video transmission and alarm information processing in the perimeter is introduced. Through the application of the system, the security of the perimeter is greatly improved, and to a certain extent, it has been applied to a certain extent.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573538
SP  - 623
EP  - 626
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573538
ER  - 

TY  - CONF
TI  - A 4H-SiC Trench MOSFET with the vertical field plate coupled floating island and two epi-layers
AU  - Wang, Wangda
AU  - Hu, Dongqing
AU  - Zhou, Xintian
AU  - Jia, Yunpeng
AU  - Wu, Yu
T3  - EITCE '22
AB  - A novel silicon carbide (SiC) U-shape trench MOSFET(UMOSET) with the vertical field plate coupled floating island structure (VFF-UMOSFET) is proposed. Double epitaxial layer is adopted. Simulations study is performed using Sentaurus TCAD. The effect of the field plate and floating island on the electric field distribution, breakdown voltage and specific ON-resistance (sRON, sp) are studies and the relationship between doping concentration and breakdown voltage in the first drift zone and the second drift zone is discussed respectively. The simulation results show that the VFF-UMOSFET with the vertical field plate coupled floating island structure exhibits a higher figure of merit related to the breakdown voltage and the specific on-resistance, which is improved by 37.5% and 65%, respectively, with comparison to the state-of-the-art source trench(ST-MOSFET) and reduce the peak of the electric field at the trench-gate bottom by 60%, compared with the standard UMOSFET, while effectively reducing the electric field at the field plate bottom. Finally, the optimization of parameters (field plate depth, floating island geometry) is discussed.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573537
SP  - 617
EP  - 622
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573537
ER  - 

TY  - CONF
TI  - Simulation study of 1200V SiC-based trench-gate MOSFET with vertical field plate protection
AU  - Zheng, Yuechao
AU  - Hu, Dongqing
AU  - Zhao, Chongning
AU  - Jia, Yunpeng
AU  - Zhou, Xintian
AU  - Wu, Yu
AU  - Li, Ting
T3  - EITCE '22
AB  - In this paper, a new structure of SiC-base trench-gate MOSFET protected by vertical field plate is proposed. Compared with conventional trench gate MOSFET, a deep trench connected to the source is added. The source trench is filled with polysilicon and acts as a vertical field plate. Under blocking state, the depletion charge between trenches is coupled with the vertical field plate, which can modify the electric field distribution near the gate oxide corner. Lower field strength in gate-oxide is the guarantee for long-term reliable operation of the device. In order to investigate the effect of charge-coupling, double doped epitaxial drift region is selected. The doping concentration of first epi-layer is lower than that of second eip-layer. The bottom of the deep source trench, that is, the end of vertical field plate, falls at the junction for the two epitaxial layer. The static characteristics are simulated for both conventional trench gate and dual trench dual epitaxy new structures by using Sentaurus TCAD. Simulation results show that the new structure with double trenches and double epitaxy has higher Baliga's figures of merit (FOM) Also, under the blocking state, the maximum electric field in gate oxide can be lower than 5MV/cm. That is desirable for the long-term operation reliability of the gate.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573535
SP  - 605
EP  - 610
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573535
ER  - 

TY  - CONF
TI  - Magnetic fluid deformation mirror for large scale aberration correction
AU  - Fu, Dongjie
AU  - Wu, Zhizheng
AU  - Ding, Haichun
T3  - EITCE '22
AB  - With the increasing use of adaptive optics and large telescope projects, new requirements have been placed on wavefront correctors. The magnetic fluid deformable mirror is a new type of wavefront corrector that changes the ferrofluid surface by changing the strength of the external magnetic field. The advantage is that it can provide larger stroke deformation on the basis of satisfying the continuity of the reflecting surface. In this paper, in order to achieve 1mm aberration correction, the device and driving coils of the magnetic fluid deformable mirror are discussed. The coil with built-in permalloy material magnetic column is used as the driver of the magnetic fluid deformable mirror, and the parameters of the coil are designed and optimized. In order to meet the 1mm aberration correction requirement, the influence of the actuator on the magnetic fluid deformation was theoretically analyzed. The Comsol software was used for simulation, and the magnetic fluid deformation mirror was built for experimental verification. The results show that the designed driving coil can support the millimeter-level deformation of the magnetic fluid.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573534
SP  - 600
EP  - 604
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573534
KW  - Aberration correction
KW  - Driver coil
KW  - The magnetic fluid deformable mirror
KW  - Wavefront Corrector
ER  - 

TY  - CONF
TI  - SOC Estimation of Lithium Battery Based on ELM-CKF Algorithm
AU  - Li, Dejun
AU  - Liu, Shilin
AU  - Ding, Feng
T3  - EITCE '22
AB  - For the problem of low accuracy of lithium battery state of charge (SOC) estimation by a single algorithm, this paper proposes an algorithm combining extreme learning machine (ELM) and cubature Kalman filter (CKF). By dynamically tracking the Thevenin equivalent circuit model parameters by recursive least squares (RLS), the initial estimate of SOC is obtained by the CKF algorithm. The battery operating voltage and current are used as input, corresponding to the estimation error of the CKF algorithm as output, using the ELM algorithm to build an error prediction model based on data-driven. Then the output of the ELM error prediction model is used to compensate for SOC initial estimation value to achieve the purpose of reducing the estimation error. The simulation results show that the proposed ELM-CKF algorithm effectively improves the SOC estimation accuracy compared with the CKF algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573533
SP  - 596
EP  - 599
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573533
KW  - Cubature Kalman filter
KW  - Error prediction
KW  - Extreme learning machine
KW  - SOC
ER  - 

TY  - CONF
TI  - Design Of A 450W Peak High Efficiency GaN Asymmetric Doherty Power Amplifier for Based-Station
AU  - Mei, Yunquan
AU  - Chen, Xinyu
AU  - Chen, Zhiyong
AU  - Zhu, Chao
AU  - Zhang, Zhendong
T3  - EITCE '22
AB  - In order to meet the requirements of power amplifier design for peak to average ratio modulation signal, this paper designs a GaN asymmetric Doherty power amplifier operating in 2.11GHz to 2.17GHz. By analyzing the impedance change process of load modulation network, the matching network of carrier and peak amplifier is redesigned by using double impedance matching method. At the same time, the Doherty power amplifier uses asymmetric structure to extend the backoff range. Pulse signal test results show that the saturation output power reaches 56.5dBm, and the saturation drain efficiency is greater than 69%. At power backoff of 8.5dB, the drain efficiency is between 53% and 61%. The power back-off efficiency is greater than 48% when the LTE modulated signal with 8.5dB peak to average power ratio (PAPR) is used in the test. And using LTE modulated signal with a 40MHz peak-to-average ratio of 8.5dB, the measured adjacent channel power ratio (ACPR) is less than -45dBc after digital predistortion (DPD), the asymmetric Doherty power amplifier can meet the demand of high efficiency amplification of peak to average ratio modulation signal in wireless communication system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573536
SP  - 611
EP  - 616
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573536
KW  - asymmetric
KW  - Doherty power amplifier
KW  - GaN HEMT
KW  - integrated circuit
ER  - 

TY  - CONF
TI  - Design and Application of Rocket Sled Test Equipment
AU  - Xiao, Jun
AU  - Zhang, Linrui
AU  - Xue, Qiang
AU  - Geng, Qiang
T3  - EITCE '22
AB  - Rocket sled test equipment is designed. The sled-mounted test equipment can measure the vibration, velocity, acceleration and position information of rocket sled test. The sled test equipment uses FPGA as the core embedded system structure to design the overall circuit. It uses 24-bit AD chip to complete the sled acceleration signal acquisition. The transmission of data acquisition is realized by wireless data transmission radio. The structure circuit of sled-mounted test equipment is designed by whole encapsulation. This improves the shock and vibration resistance of the equipment. The dynamic verification test shows that the sled-mounted test equipment is stable and reliable, and the velocity measurement error is ± 5 m/s.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573532
SP  - 591
EP  - 595
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573532
KW  - rocket sled
KW  - sled-mounted test equipment
KW  - speed
KW  - vibration
ER  - 

TY  - CONF
TI  - A regression test case generation method for avionics software
AU  - Zhu, Lingfeng
AU  - Hu, Jun
T3  - EITCE '22
AB  - With the continuous development of the aviation field, the avionics requirement is also changing, so it is also necessary to take appropriate methods to test the changing avionics requirement to ensure aviation safety. This paper presents a regression test case generation method for avionics software, which can identify the changes in requirement model from the perspective of model, and generate regression test cases according to the coverage criteria in the DO-178C standard. Regression test cases consist of baseline test cases and supplementary test cases. We introduced how to extract reusable test cases from baseline test cases and supplement test cases that do not meet the coverage requirements. Finally, a real avionics requirement proves the effectiveness of our method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573529
SP  - 575
EP  - 579
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573529
ER  - 

TY  - CONF
TI  - Design of lane change controller for vehicle steering based on fuzzy model predictive control
AU  - Yang, Mai
AU  - Qing, Ling
AU  - Wang, Lei
T3  - EITCE '22
AB  - In order to improve the driving stability of autonomous vehicles when steering lane change to avoid obstacles under high-speed conditions, a vehicle lane change controller based on Fuzzy control and Model predictive control was designed. The controller is based on the MPC algorithm and includes active vehicle steering with controlled front wheel angle as well as a five-polynomial lane-change trajectory model. determine the additional yaw moment needed by using the desired deviation of the yaw speed and its rate of change as the dual inputs to the fuzzy control. to increase the stability of the vehicle's high-speed lane change and proper body attitude. The results of a joint Carsim/Simulink simulation show that the controller improves the stability of the vehicle when steering and lane avoidance is performed at high speeds compared to a conventional model predictive controller.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573531
SP  - 585
EP  - 590
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573531
KW  - Autonomous driving
KW  - Fuzzy control
KW  - Model predictive control
KW  - Path tracking
KW  - Turn lane change
ER  - 

TY  - CONF
TI  - Deep Learning-based Road Crack Detection Technology
AU  - Zeng, Yongjin
AU  - Chen, Jie
AU  - Mao, Jian
T3  - EITCE '22
AB  - Most of the current road detection still adopts manual detection and evaluation. This method is not only time-consuming and labor-intensive, but also accompanied by greater security risks and risks. In this paper, the method of deep learning is used to detect road diseases on the collected road images, and generate corresponding thumbnail files of real roads. The YOLOV5 model is used for training and detection, which greatly facilitates road maintenance and evaluation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573530
SP  - 580
EP  - 584
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573530
KW  - Crack detection
KW  - Deep learning
KW  - YOLOv5
ER  - 

TY  - CONF
TI  - Non-singular Terminal Sliding Mode Control Algorithm for Buck Converter Based on Extended State Observer
AU  - Sun, Daoyou
AU  - Liu, Shilin
AU  - Li, Jingyi
T3  - EITCE '22
AB  - This paper proposes a non-singular terminal sliding mode control (NTSMC) algorithm based on an extended state observer (ESO) for the effect of load resistance disturbances on the output voltage of the buck converter. First of all, the extended state observer is designed to estimate the system state as well as the load resistance. Secondly, the non-singular terminal sliding mode control algorithm is used to create the system controller based on the estimated values of load resistance. Then, the stability of the designed extended state observer and the non-singular terminal sliding mode controller are verified by theoretical analysis. Finally, the simulation is verified by Matlab/Simulink. The simulation verified that the proposed non-singular terminal sliding mode control algorithm with extended state observer can achieve fast and accurate tracking of the buck converter system output voltage and improve the robustness of the system, compared with the traditional proportional-integral (PI) control algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573527
SP  - 564
EP  - 568
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573527
KW  - Buck converter
KW  - Extended state observer
KW  - Sliding mode control
ER  - 

TY  - CONF
TI  - An Alternate Iterative Optimization Algorithm for Space-Ground Cooperative Networking of Transmission Lines
AU  - Zhao, Kai
AU  - Yang, Kai
AU  - Tu, Chao
AU  - Tu, Weizheng
AU  - Lei, Xilian
AU  - Liu, Jie
T3  - EITCE '22
AB  - In the air-ground cooperative networking, UAV can be used as relay to expand the coverage of ground base stations, and are suitable for transmission line communications in remote areas. However, due to its limited energy, the life cycle of the UAV will affect the performance of the communication link. To this end, this paper adopts the UAV position optimization algorithm with given power and the power optimization algorithm with given UAV position, and then proposes an alternate iterative optimization algorithm. By alternately iterating the two optimization algorithms, the life cycle of the UAV is more effectively extended, and it can serve a wider range of transmission lines.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573526
SP  - 560
EP  - 563
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573526
KW  - alternate iterative optimization algorithm
KW  - life cycle
KW  - location deployment
KW  - transmission line
KW  - UAV relay
ER  - 

TY  - CONF
TI  - An Intelligent Cockpit System HMI Engine Based on COMO
AU  - Liu, Sichun
AU  - Pei, Xilong
AU  - Wang, Jiali
AU  - Huang, Jingru
AU  - Wang, Jianmin
AU  - Wang, Ning
T3  - EITCE '22
AB  - ICS (Intelligent Cockpit System) is a Human-Machine Interface (HMI) technology that integrates In-Vehicle Infotainment (IVI), Head Up Display (HUD), and Navigation (NAVI). The HMI technology stack in ICS involves engineering human-machine interaction creativity, component-based graphics systems and vehicle-level hardware system, etc. The HMI engine we developed is a middleware that implements human-machine interaction computing in in-vehicle electronic equipment, and the engine is also a software stack for graphics computing, scheduling management of computing devices in the cockpit and software runtime functions, it operates the display hardware through OpenGL. This paper introduces a COMO-based ICS HMI technology with functional safety SOA architecture. With the support of COMO RPC, devices are abstracted as services and integrated together. Under the premise of ensuring functional safety, it has a variety of ICS-oriented 2D, 3D controls with running state and design state, suitable for creative people and automotive engineers to work together.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573528
SP  - 569
EP  - 574
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573528
KW  - COMO
KW  - HMI-Engine
KW  - ICS
ER  - 

TY  - CONF
TI  - Design of a Time Detector with Adjustable Resolution
AU  - Liu, Xiaofan
AU  - Chen, Zhiming
AU  - Li, Xiaoran
AU  - Wang, Xinghua
AU  - Zhang, Lei
T3  - EITCE '22
AB  - With the continuous improvement of integrated circuit technology, the time detector, especially one with adjustable resolution, has a good development prospect. In this paper, a multi-bit time detector with adjustable resolution and configurable measurement range is presented, whose timing link composed of identical timing units is similar to ring oscillator. To adjust the resolution, the current and link of the timing unit are controlled by control code. The proposed time detector is implemented in CMOS 180nm technology. Simulation results show that the measuring range can reach the microsecond level under a 1.8-V supply. Meanwhile, the resolution corresponding to the control code 00, 01, 10 and 11 are 13.3ns, 25.8ns, 39.7ns and 48.5ns, respectively. Therefore, there is a linear relationship between the resolution and the value of control code.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573525
SP  - 554
EP  - 559
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573525
KW  - adjustable resolution
KW  - CMOS
KW  - linear relationship
KW  - ring oscillator
KW  - time detector
ER  - 

TY  - CONF
TI  - Lane Line Detection Based on Dynamic ROI and Adaptive Thresholding Segmentation
AU  - Yang, Xin
AU  - Yu, Houyu
T3  - EITCE '22
AB  - Aiming at the problem of large error in detecting lane lines on curved, long distance and complex roads by autonomous vehicles, a lane line detection algorithm based on dynamic ROI (Region Of Interest) and adaptive thresholding segmentation is proposed. According to the principle of inverse perspective transform, the original image is converted into an aerial view, and then the aerial view is preprocessed to calculate the gray column mean and full mean to dynamically determine the ROI. The image array is expanded for differentiation calculation. The adaptive threshold segmentation is carried out according to the characteristics of partition. The area and transverse and longitudinal span of each connected area in the binary diagram are calculated, and the interference factors are filtered out as required. Using the curve fitting algorithm of RANSAC (RANdom SAmple Consensus), the quadratic polynomial is defined as the target curve model to fit the characteristic points of lane line. The results show that the algorithm can accurately detect the lane lines under various road conditions.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573524
SP  - 549
EP  - 553
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573524
KW  - dynamic ROI
KW  - inverse perspective transform
KW  - lane line detection
KW  - RANSAC
KW  - threshold segmentation
ER  - 

TY  - CONF
TI  - A Review of Using MFC Actuators for Vibration Control of Beam and Plate Structures
AU  - Jiang, Jinhua
AU  - Chang, Xuan
AU  - Gao, Zhiyuan
AU  - Wang, Yiru
AU  - Zhang, Hesheng
AU  - Zhu, Xiaojin
T3  - EITCE '22
AB  - In order to achieve high-precision vibration control of beam and plate structures, the actuators need to be selected and installed according to the controlled structures. MFC (Macro Fiber Composite) is a thin slice piezoelectric composite material with large displacement output and fast response, which can be sticked or embedded in structures easily, so the research on vibration control of beam and plate structures using MFC actuators is still very active. This article introduces the theoretical basis of MFC firstly, and where includes the classification of MFC, internal structure, constitutive equations and common modeling methods. Then, introducing the applications in vibration control of beam and plate structures using MFC actuators and the controlling strategy used to solve the nonlinear problems in these applications. Finally, extends the applications of MFC actuators in complex structures, and the problems of nonlinear hysteresis behavior are summarized which existing in vibration control using MFC. For higher precision control of MFC, this feature can be researched in depth.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573523
SP  - 543
EP  - 548
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573523
KW  - Beam and plate structures
KW  - MFC actuator
KW  - Modeling
KW  - Nonlinear hysteresis
KW  - Vibration control
ER  - 

TY  - CONF
TI  - Influence of color lightness change on personnel identification performance in ship background environment for a long time
AU  - Chen, Ziang
AU  - Yang, Chao
AU  - Yin, Kaili
T3  - EITCE '22
AB  - This research according to the operating personnel use requirements, combining space variant adaptive technology and graphical interface technology, using the self-developed coding test system, according to the basis of the elements to reaction time and accuracy as performance indicators to carry out the experiment, by testing the subjects in the ship for a long time background environment for different coding identification of display elements. This paper analyzes and interprets the influence mechanism of operators' working ability change on basic display element coding. The experimental results show that when people are in the background environment of ships for a long time, the interface identification performance of people decreases due to the decrease of working ability, and the corresponding optimal color contrast changes from about 80% to about 60% when the reaction time is minimum. The experimental results are in line with the experimental hyp.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573522
SP  - 538
EP  - 542
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573522
KW  - For a long time
KW  - Identify performance
KW  - Ship's background
ER  - 

TY  - CONF
TI  - Maximizing Throughput for Coexisting Wireless Body: Sensor Networks (WBANs) Based on Clustering
AU  - Hu, Xiaokang
AU  - Guo, Kunqi
T3  - EITCE '22
AB  - The interference mitigation strategy of coexisting wireless body sensor networks (WBANs) is studied in this paper. Since all WBANs work in the same frequency band, the interference from adjacent WBANs severely affects the Signal-to-Interference-plus-Noise Ratio (SINR), and the throughput is significantly reduced. To improve the quality of service that is affected by interference from adjacent WBANs, firstly, we use the graph coloring algorithm for clustering coexisting WBANs, then, we propose a time slot reallocation (TSR) algorithm to make the optimal time slot allocation for the node according to the clustering result. The simulation results show that the proposed scheme can improve packet reception rate (PRR) and throughput for coexisting WBANs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573521
SP  - 533
EP  - 537
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573521
KW  - cluster
KW  - graph coloring
KW  - inter-WBAN interference
KW  - wireless body sensor network (WBAN)
ER  - 

TY  - CONF
TI  - Substation work ticket identification and extraction algorithm based on multi-task model
AU  - Sui, Renjie
AU  - Li, Danyong
AU  - Li, Ruolan
AU  - Fan, Li
AU  - Sun, Xiaoyi
T3  - EITCE '22
AB  - With the large-scale construction of new substations and the intelligent upgrading of existing substations, higher requirements have been put forward for efficient and intelligent maintenance of substations. In practical applications, the substation work ticket forms are complex and diverse, and the current mainstream work ticket key information extraction algorithms cannot meet the work needs. This paper proposed an intelligent recognition system for extracting safety measures from a work ticket in a substation. Based on the traditional text detection algorithm, a Multi-task network for text detection, frame extraction and form classification structure was proposed. The text recognition network used CRNN+CTC to train and tested the multi-model text recognition network on the work ticket interface text image data set. Advanced functions such as automatic generation, automatic execution, calibration and restoration of operation steps from a work ticket to safety measures in the substation were realized. In order to prove the effectiveness of the algorithm, an experimental study was carried out, and a comparative experiment was carried out in text detection and text recognition. The module has been tested in Yangzhou Power Supply Company of State Grid, and the results show that the scheme has good feasibility and effectively improves the work efficiency of operation and maintenance personnel.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573519
SP  - 520
EP  - 527
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573519
KW  - Key Information Extraction
KW  - Safety Measure Ticket
KW  - Smart Substation
KW  - Text Recognition
ER  - 

TY  - CONF
TI  - Circuit Simulation and Optimization of Quantum Search Algorithm
AU  - Liu, Xiaonan
AU  - Zhao, Chenyan
AU  - Xie, Haoshan
AU  - Liu, Zhengyu
T3  - EITCE '22
AB  - At present, the scale of quantum computers in the real sense is still small, and quantum simulation has become one of the important ways of quantum theory research, grover quantum search algorithm is suitable for the search problem of disordered database. Firstly, according to the implementation principle of Grover algorithm and Boolean logic relationship, the design idea of multi-objective Oracle is analyzed, based on IBMQ quantum cloud platform, the quantum circuit of Grover algorithm with multi-objective items is simulated. Based on the characteristics of Grover algorithm and the simulation process of quantum gate, the action of multiple identical quantum gates is combined to reduce the update times of probability amplitude and improve the simulation efficiency. The libquantum quantum simulator is used for experiments and the target item is successfully searched, which proves the feasibility of the optimization method and provides reference for the simulation and optimization of other quantum algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573520
SP  - 528
EP  - 532
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573520
ER  - 

TY  - CONF
TI  - A method for improving the efficiency of FIR filter operation
AU  - Wang, Yunhui
AU  - Zhou, Li
AU  - Sun, Yu
AU  - Feng, Yi
T3  - EITCE '22
AB  - When the software realizes the FIR filter, it usually carries on the cyclic shift to the multiple input data according to the FIR filtering formula. After the completion of the shift, it can get the filtering result by multiplying with the FIR parameters. The higher the filtering order, the more the filtering channels, the longer the software running time will be consumed. In order to save software running time, this paper proposes a software implementation method which called copying the filter parameters. The FIR parameters are copied once, and only the latest input data is assigned in the operation process. It can directly multiply the data and parameters to get the filtering result, so as to save the software running time.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573776
SP  - 515
EP  - 519
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573776
KW  - algorithm implementation
KW  - FIR (Finite Impulse Response) filter
KW  - high efficiency
ER  - 

TY  - CONF
TI  - Simulation of High Voltage DC Power Supply Based on MATLAB
AU  - Wang, Hai
AU  - Tian, Yimin
AU  - Zhang, Saisai
AU  - Shen, Liwen
AU  - Chen, Hongmei
AU  - Du, Yunfei
T3  - EITCE '22
AB  - In the power supply system, the previous low voltage DC, constant speed constant frequency, variable speed constant frequency electric system can not meet the actual demand. The permanent magnet synchronous motor and other synchronous motors are simulated in MATLAB. Magnetic synchronous motor has better performance. Firstly, the development of HVDC power system is introduced. Then the model of synchronous motor is sorted out. Then the simulation models of two kinds of motors are established. Finally, the electromagnetic synchronous motor model and permanent magnet synchronous motor model are simulated and analyzed. Through the construction of synchronous motor model and reasonable parameter setting, it is concluded that both kinds of motors can realize the simulation design of HVDC power supply, and the performance of permanent magnet synchronous motor is obviously better than electromagnetic synchronous motor, which is more suitable for the development of HVDC power system in the future.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573517
SP  - 509
EP  - 514
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573517
KW  - high voltage DC power supply system
KW  - MATLAB/Simulink
KW  - synchronous generator
ER  - 

TY  - CONF
TI  - Research on LOD Lightweight Method of Railway Four Electric BIM Model
AU  - Huo, Jiuyuan
AU  - Liu, Jinquan
AU  - Pei, Guanxiang
AU  - Wang, Tingjuan
T3  - EITCE '22
AB  - In view of the current BIM data volume, poor real-time rendering effect, and other problems. This paper proposes a research method to convert the BIM model of the four railways from RVT format to the 3DTiles data format and display it on the Web side with multiple LOD. The method is based on the secondary development of Revit to write a plug-in program, and realizes the application of the railway four-electrical model through lightweight model, model format conversion, and data dynamic scheduling. Firstly, the RVT model is converted to OBJ as an intermediate model through the secondary development of Revit. Then, the model is simplified to different degrees by the improved edge folding algorithm, to achieve the purpose of lightweight model. Finally, convert the simplified model to 3DTiles format, set the geometric error size, determine the LOD level, and introduce the Frustum Culling to achieve dynamic LOD display. Taking the model in railway engineering as an example, a high-speed railway station and components are selected for experimental analysis. The research results show that the proposed four-electric BIM model lightweight method can reduce the amount of model data as needed, and improve the real-time rendering efficiency and optimize the loading effect under the Cesium framework.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573514
SP  - 492
EP  - 497
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573514
KW  - 3D Tiles
KW  - BIM (Building Information Modeling)
KW  - electric &
KW  - electronic systems
KW  - Level of detail
KW  - lightweight
ER  - 

TY  - CONF
TI  - A transferable model for pedestrian intention prediction in crosswalks based on mobile phone sensors
AU  - Wang, Xinyu
AU  - Wang, Xikai
AU  - Guo, Sijing
T3  - EITCE '22
AB  - To accommodate the path planning of autonomous vehicle (AV), many researchers utilize on-board sensors to predict pedestrians’ intention, but the on-board sensors cannot detect occluded pedestrians. Roadside sensors can solve this problem, but with a high cost if deployed at every crosswalk. Hence, this paper aims at utilizing mobile phone sensors to predict the pedestrians’ intentions at crosswalks. A transferable prediction model is built in the paper, with a purpose of saving the expense of hardware and data collection. That is, the model trained by the pedestrians’ data at one crosswalk can provide high accuracy at other crosswalks, via extracting the features associating the geometric structure of the crosswalks and the pedestrians’ motion data. Various algorithms were applied to build the prediction model, and results showed that the prediction accuracy exceeds 90% in non-transfer task, 80% in normal transfer tasks, with a distance of 5 meters ahead of crossing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573516
SP  - 503
EP  - 508
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573516
KW  - Machine learning
KW  - Mobile phone
KW  - Pattern recognition
KW  - Pedestrian intention prediction
KW  - Pedestrian protection
KW  - V2X
ER  - 

TY  - CONF
TI  - Design and simulation study of multi-trench termination for 1200V SiC devices with charge coupled drift region
AU  - Zhao, Chongning
AU  - Hu, Dongqing
AU  - Zheng, Yuechao
AU  - Jia, Yunpeng
AU  - Zhou, Xintian
AU  - Wu, Yu
AU  - Li, Ting
T3  - EITCE '22
AB  - Charge coupled drift region are commonly used to obtain smaller specific on-resistance for majority carrier device. However, as the field distribution of edge terminations is concerned, charge coupled structure is well suited for power devices with low blocking voltage in the range of 30-200V. In this paper, three kinds of multi-trench termination are designed and simulated for 1200V SiC devices with charge coupled drift region. The results show that "the termination of deep trench coupled field plate (FP) with field limiting ring (FLR)" and "the termination of deep trench coupled field plate (FP) with field limiting ring (FLR) and floating island" can both meet the requirement of blocking voltage greater than 1200V, and the maximum efficiency of the termination can reach 87.8 %.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573515
SP  - 498
EP  - 502
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573515
ER  - 

TY  - CONF
TI  - Research on interaction strategy between large-scale electric vehicle and power grid
AU  - Shang, Longlong
AU  - Liu, Yangyu
T3  - EITCE '22
AB  - The large-scale interaction between electric vehicles and the power grid can provide peak shaving and valley filling, frequency modulation service and standby service, etc. The research on the interaction strategy has a positive significance for the security, stability and economic operation of the power grid. This paper puts forward the overall research idea of interaction between large-scale electric vehicles and power grid. Firstly, the electric vehicle interaction and coordination control system is proposed, which realizes the technical strategy of vehicle network interaction based on the two-way interaction of information flow; Secondly, relying on the two-way interaction of capital flow, the market strategy of vehicle network interaction is realized. Through reasonable adjustment of charging and discharging time, charging and discharging process and charging and discharging amount of electric vehicles, the two-way interaction of electric vehicles and power grid energy flow is realized; Finally, the application prospect of interaction between electric vehicle and power grid is prospected.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573513
SP  - 488
EP  - 491
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573513
KW  - Electric vehicle
KW  - FM service
KW  - Interactive coordination control system
KW  - Peak cutting and valley filling
KW  - Standby service
ER  - 

TY  - CONF
TI  - Application of diode in analog modulation circuit
AU  - Zhang, Jing
AU  - Tao, Binbin
T3  - EITCE '22
AB  - Diodes have many functions, such as isolation, amplitude limiting, rectification, detection, voltage stabilization, constant current, variable capacity, switch, light emission, photoelectric conversion. This paper mainly studies the application of diode in analog modulation circuit, including linear modulation, such as amplitude modulation, demodulation, and nonlinear modulation, such as frequency modulation and phase modulation. Finally, the diode amplitude modulation circuit, diode envelope detection circuit and varactor frequency modulation circuit are simulated by multisim.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573512
SP  - 483
EP  - 487
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573512
KW  - detection
KW  - diode
KW  - modulation
KW  - multisim
KW  - varactor diode
ER  - 

TY  - CONF
TI  - Ship Identification Based on Improved SSD
AU  - Hu, Cheng
AU  - Zhu, Zhilong
AU  - Yu, Ze
T3  - EITCE '22
AB  - Aiming at the low accuracy of ship recognition at sea and the fact that traditional target detection algorithms are greatly affected by the environment, this paper proposes a marine ship recognition method based on an improved SSD (Single shot multibox detector). On the basis of the original SSD algorithm, the original backbone network VGG16 was first replaced with resnet50, and the convolution in the last 5 layers of the Resnet50 Conv4_x structure was replaced by a hole convolution, followed by the removal of Conv5_x, followed by the subsequent prediction feature layer. A multiscale receptive field module was introduced to improve the feature extraction capabilities of the model. Finally, the high-level semantic information is enhanced by introducing a CBAM attention mechanism to improve the detection ability of the model. The experimental results show that the map of the algorithm is 94.5%, which is 17.7% higher than the original SSD algorithm, and the improved SSD algorithm has a better recognition effect of ships at sea.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573511
SP  - 476
EP  - 482
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573511
ER  - 

TY  - CONF
TI  - Research on a Simulation Algorithm for Display Effect of Rotating LED Device
AU  - Lin, Jianan
AU  - Weng, Xinkai
T3  - EITCE '22
AB  - Rotating LED device, because it can achieve the screen floating in the air display effect, is becoming more and more popular in everyday applications. It is necessary to simulate its display effect. The simulation algorithm of the display effect of the rotating LED device can obtain the predicted display effect in the software simulation after the hardware and software design of the rotating LED lamp is completed, without waiting for the completion of the hardware entity. After testing, the display effect predicted by the simulation algorithm is very close to the actual effect. So it has good practical value.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573509
SP  - 463
EP  - 468
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573509
ER  - 

TY  - CONF
TI  - Adaptive network selection strategy for vehicle velocity in multiple lanes
AU  - Liu, Xinyi
AU  - Di, Chenqi
AU  - Ke, Chenghu
AU  - Ke, Xizheng
AU  - Zhang, Hao
AU  - Zhao, Xin
T3  - EITCE '22
AB  - With the continuous development of wireless network technology, a heterogeneous network has emerged, characterized by integrating multiple networks and coverage overlaps. Vehicles traverse numerous species and coverage areas while on the road, network switching behavior may occur frequently and inefficiently, therefore an efficient network selection strategy is necessary. This paper considers the vehicle's mobility and analyze the transmission quantity within the wireless network's signal coverage area. First the effect of the velocity on the transmission quantity is considered, followed by the calculation of the transmission quantity's closed-form solution; the number of adjacent users by the vehicle's velocity is analyzed, and the effect of velocity on the transmission quantity is determined. Finally, the transmission quantity of vehicles is considered when determining network selection results. Compared to multi-attribute decision making, the Internet of Vehicle (IoV) transmission quantity has increased by 6%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573510
SP  - 469
EP  - 475
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573510
ER  - 

TY  - CONF
TI  - Research on vehicle Path Tracking Control based on MPC
AU  - Hou, Yang
AU  - Ren, Yanyong
AU  - Meng, Shaojie
T3  - EITCE '22
AB  - Aiming at the problem of path tracking of unmanned vehicles, this paper built a vehicle kinematics model and carried out discretization, designed a vehicle lateral motion controller based on model predict control (MPC) to track the vehicle's path on the basis of the existing path, and carried out controller simulation through MATLAB. Simulation results show that the controller has a certain path tracking accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573506
SP  - 449
EP  - 453
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573506
KW  - Kinematic model
KW  - Lateral control
KW  - Path following
KW  - The MPC
ER  - 

TY  - CONF
TI  - A two-way relay power allocation scheme against channel interference
AU  - Li, Junjie
AU  - Yang, Bin
T3  - EITCE '22
AB  - One of the key problems in cooperative communication is how to allocate and manage relay nodes, especially in cooperative communication, how to allocate and manage relay nodes. Especially when the secondary user system is constrained by interference temperature, the design of cooperation scheme should not only maximize the system performance, but also control the interference of the secondary user system to the primary user system. Aiming at this situation, a relay selection strategy based on cooperative beamforming is proposed in the secondary user system. With the goal of minimizing the outage probability of the secondary user system, this method derives a relay selection threshold, which ensures that limited transmission power is only allocated to efficient relay links, thus improving the system transmission performance. The simulation results show that the proposed method is superior to the single relay forwarding scheme and the full relay forwarding scheme, and can effectively reduce the outage probability of the secondary user system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573508
SP  - 459
EP  - 462
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573508
KW  - Amply-and-forward (AF)
KW  - Bit error rate
KW  - Channel estimation error
KW  - Co-channel interference
KW  - Outage probability
KW  - Two-way relay
ER  - 

TY  - CONF
TI  - Fingertip detection based on shapelet
AU  - Wang, Yihong
AU  - Gao, Lei
T3  - EITCE '22
AB  - This paper proposes a shapelet-based fingertip detection method. Firstly, an image of a hand with five fingers opening is collected, and then it is preprocessed by some measures, including median filtering, binarization according to the skin color space, morphological processing and palm edge extraction. Then, the palm position is calculated using the extracted palm contour, and the distances from the palm position to all points of the palm contour are calculated in turn and converted into a sequence. The sequences of the same length corresponding to five fingertip parts can be extracted, and the sequences of other parts can be divided into sequences with similar lengths to the fingertip sequences for shapelet extraction. Finally, the extracted shapelet is matched with the sequences converted from other palm images, and the position of the fingertip can be accurately detected.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573507
SP  - 454
EP  - 458
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573507
KW  - fingertip detection
KW  - sequences converted
KW  - Shapelet
ER  - 

TY  - CONF
TI  - Measurement of buried depth and inclination rate of concrete poles based on binocular vision
AU  - Chen, Chaoxin
AU  - Xu, Hengbo
AU  - Guo, Lei
AU  - Shen, Peng
AU  - Chen, Jiangyi
T3  - EITCE '22
AB  - Aiming at the low efficiency of the traditional detection methods of buried depth and inclination rate of concrete poles, a method of measuring concrete poles based on binocular vision was proposed. Firstly, an improved DeeplabV3+ semantic segmentation algorithm is proposed. Based on the original model structure, the backbone feature extraction network is modified, the feature fusion method is optimized, and the improved CBAM attention mechanism is added to reduce the model complexity and improved the accuracy of concrete pole area segmentation. Secondly, the sub-pixel edge extraction algorithm based on local area effect is used to determine the edge of the concrete pole in the image segmentation area, and the least squares method is used to fit the edge to determine the precise feature points. Finally, the coordinate transformation of binocular vision is used to calculate the depth and inclination of the concrete pole. Experiments show that the method has a buried depth measurement error of less than 10 cm, an error rate of less than 5%, and an inclination measurement error of less than 0.3°, which provides an automated concrete pole buried depth and inclination rate measurement solution
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573504
SP  - 437
EP  - 442
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573504
KW  - attention mechanism
KW  - binocular vision
KW  - Concrete pole
KW  - semantic segmentation
KW  - subpixel edges
ER  - 

TY  - CONF
TI  - IIoT-based Predictive Maintenance for Oil and Gas Industry
AU  - Jia, Zhiyang
AU  - Wang, Jihe
AU  - Deng, Cheng
T3  - EITCE '22
AB  - The Industrial Internet of Things (IIoT) promises to provide an expanded awareness of field assets and equipment, access to data from across locations, and actionable insights for maximizing operational performance and safety of the oil and gas industry. Using automation and machine learning, with the application of predictive maintenance, efficiencies can be boosted and problems can be mitigated sooner and more effectively. The proposed system is mainly based on the data collection, processing, analysis, and modeling of an enormous number of historical and real-time data generated during the operation of the equipment on the edge side. The data-driven predictive maintenance used machine learning models and deep learning models to predict the remaining useful life (RUL). Bi-LSTM based prediction model has been trained on the cloud, and deployed onto the edge devices. The predictive maintenance process includes data acquisition, data processing, training of machine learning model, equipment health assessment, remaining useful life prediction, strategy formulation, and strategy execution. The predictive maintenance solution driven by the IIoT helps oil and gas companies make predictions before equipment failures have a significant impact on their company's safety level and profits to improve asset reliability and promote cost savings.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573503
SP  - 432
EP  - 436
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573503
KW  - IIot
KW  - Long short-term memory
KW  - Oil and Gas Industry
KW  - Predictive maintenance
ER  - 

TY  - CONF
TI  - Study on transfer learning of shield tunneling parameters based on LSTM model
AU  - Liu, Huanhuan
AU  - Liu, Shanglin
AU  - Zhang, Qian
AU  - Guo, Wei
T3  - EITCE '22
AB  - During the excavation of the shield tunneling machine, the performance of the existing methods for shield tunneling machine parameter prediction often require a large amount of data to train a relatively accurate prediction model, which is in great contradiction with the limited data collected when the subway line is beginning to be constructed. In this paper, a set of transfer learning model based on long short-term memory (LSTM) is designed and built to improve the prediction process of shield tunneling machine parameter when the amount of data is small. The model selects the cutterhead torque as the prediction target and uses the Pearson coefficient method to filter the input features that are highly correlated with the prediction target. During transfer learning, the pre-training of the transfer model was first performed on the Beijing subway dataset. The best transfer learning scheme was selected by freezing the pre-training models with different layers and the optimal transfer learning model was transferred to the Tianjin Metro. Comparing the results of transfer learning and directly using LSTM model training with different data volumes, the results show that the use of transfer learning can effectively improve the accuracy of the prediction model when the data volume is small.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573505
SP  - 443
EP  - 448
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573505
KW  - cutterhead torque prediction
KW  - LSTM
KW  - shield tunneling machine
KW  - transfer learning
ER  - 

TY  - CONF
TI  - A Modified Motor Imagery Classification Method Based on EEGNet
AU  - Wang, Mincheng
T3  - EITCE '22
AB  - Brain-computer interfaces (BCIs) are a growing field of scientific research aiming to study how computers interpret human neural signals and take corresponding actions for communication purposes. Motor imagery-related EEG (MI-EEG) signals, generated by humans mentally simulating a given action, can be analyzed and learned by machine learning algorithms and deep learning models. EEGNet is one of the convolutional neural networks (CNNs) robust for different BCI paradigms because of its two-dimensional filters: temporal and spatial filters. In this study, I modified the EEGNet configurations into three new models with double convolutional layers for temporal, spatial, and both filters, respectively. I compared four models' binary classification performances on downsampling and normalized MI-EEG datasets without prior feature extraction methods. The results show that: 1. All four EEGNet models with max-pooling layers perform better than using their original average-pooling layers. 2. The model with double two-dimensional filters' layers received the highest mean F1 score (71.71%) and the lowest sample standard deviation (0.0168) among all four models after repeated five runs. Compared to the original EEGNet model, only the best-performed model has a statistically significant difference (p &lt; 0.05) in their mean F1 scores. The results suggest doubling layers for both temporal and spatial filters can increase EEGNet performance on MI-EEG classification. Therefore, it can be considered an approach to improve EEGNet in future studies.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573502
SP  - 427
EP  - 431
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573502
KW  - Brain-Computer Interface
KW  - EEGNet
KW  - Motor Imagery
ER  - 

TY  - CONF
TI  - Heart Disease Type Prediction Model Based on SVM-ANN
AU  - Han, Xinning
T3  - EITCE '22
AB  - Due to factors e.g., incorrect diet and exercise habits of modern people, the number of heart disease patients is rising yearly. It is extremely important to find a good method to try to predict the different types of heart diseases. Because it is so hard to distinguish the different types of heart disease. Considering this, the use of different models is important to predict the type of heart disease. Then this study is trying to find the suitable models to solve these problems. In this work, the different models were used, which are the combination of ANN and SVM to get the accuracy of the models. First, ANN was used to obtain the accuracy of the model. Next, the SVM and ANN were used together to predict the result. Also the use of ResNet, which solve the gradient disappearance problem. Besides, comparing the use of Naïve Bayes, the use of Random Forest is trying to make the model stable and reduce the risk of overfitting. Also, the PCA model did the feature extractor and emerge the new features. The methods achieve the accuracy is about 90% of the Random Forest. Also, the confusion matrix of the model was obtained. After using 10 epochs, the accuracy of the combination of SVM and ANN is about 90.56%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573501
SP  - 422
EP  - 426
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573501
KW  - ANN
KW  - Heart Disease
KW  - Naïve Bayes
KW  - PCA
KW  - Random Forest
KW  - ResNet
KW  - SVM
ER  - 

TY  - CONF
TI  - Design and Simulation of 1.2kV Semi-Super Junction FRD with Vertical Variation Doping
AU  - Wu, Yuefeng
AU  - Wu, Yu
AU  - Zhou, Xintian
AU  - Liu, Feng
AU  - Zong, Lei
T3  - EITCE '22
AB  - A 1200V vertical variable doped semi-super junction fast recovery diode (VVD-Semi-SJ-FRD) is presented in this paper. In super junction structure, P-pillar and drift region are needed to maintain charge balance. As a result, the reverse breakdown voltage of the semi-super junction fast recovery diode is very sensitive to the doping concentration of P-pillar, resulting in a narrow process window for ion implantation of P-pillar. The structure proposed in this paper uses three epitaxial layers, the epitaxial layer near the side of the P-type region and the epitaxial layer below the P-pillar is low-doping, and the middle is high-doping. By analyzing the influence of P-pillar concentration on reverse breakdown voltage and the electric field distribution at different concentrations, it is shown that the proposed structure can effectively reduce the sensitivity of reverse breakdown voltage to P-pillar doping concentration, thus enlarges the process window of P-pillar ion implantation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573500
SP  - 417
EP  - 421
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573500
ER  - 

TY  - CONF
TI  - Three recommendations to engage At-Risk Students in Critical Reflection on Intelligent Technologies through Remote Learning
AU  - Schaper, Marie-Monique
AU  - Ruiz Garcia, Aurelio
T3  - CHI EA '23
AB  - The agenda of Computational Empowerment points towards the need for inclusive approaches for supporting all students in learning about technology and the development of digital literacy. This paper aims at exploring how to develop remote learning activities in technology education during a pandemic for at-risk students. We present a case study with 23 primary students (11-12 years) who we involved in online and offline learning activities about both how intelligent technologies work but also on the implications that these technologies bring to our society. Our findings showed potential challenges to engage at-risk students in the agenda of Computational Empowerment. We propose three recommendations and future directions to scaffold at-risk students’ learning about intelligent technologies in remote contexts: (1) support the development of agency through the engagement of contexts-for-action; (2) reduce the complexity of remote communication through creative and bodily engagement; (3) reflect upon forces that marginalize oneself in a digitized society.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573862
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573862
KW  - At-Risk Students
KW  - Computational Empowerment
KW  - Critical reflection
KW  - Design Fiction
KW  - Emerging Technology Education
KW  - K-12 education
KW  - Remote Learning
KW  - Societal and ethical implications
ER  - 

TY  - CONF
TI  - SpeakFaster Observer: Long-Term Instrumentation of Eye-Gaze Typing for Measuring AAC Communication
AU  - Cai, Shanqing
AU  - Venugopalan, Subhashini
AU  - Tomanek, Katrin
AU  - Kane, Shaun
AU  - Morris, Meredith Ringel
AU  - Cave, Richard
AU  - Macdonald, Robert
AU  - Campbell, Jon
AU  - Casey, Blair
AU  - Kornman, Emily
AU  - Vance, Daniel E
AU  - Beavers, Jay
T3  - CHI EA '23
AB  - Accelerating communication for users with severe motor and speech impairments, in particular for eye-gaze-based augmentative and alternative communication (AAC) device users, is a longstanding area of research. However, observation of such users’ communication over extended durations has been limited. This case study presents the real-world experience of developing and field-testing a tool for observing and curating the gaze typing-based communication of an eye-gaze AAC user with amyotrophic lateral sclerosis (ALS). With the intent to observe and develop technology to accelerate eye-gaze typed communication, we designed a tool and a protocol called the SpeakFaster Observer to measure everyday conversational text entry by the gaze-typing user, as well as several consenting conversation partners of the AAC user. We detail the design of the Observer software and data curation protocol, along with considerations for privacy protection. The deployment of the data protocol from November 2021 to April 2022 yielded a rich dataset of gaze-based AAC text entry from everyday life, consisting of 130+ hours of gaze keystrokes and 5,000+ curated speech utterances from the AAC user and the conversation partners. We present the key statistics of the data, including the speed (8.1 ± 3.9 words per minute) and keystroke saving rate (-0.14 ± 0.83) of gaze typing, patterns of utterance repetition and reuse, and the temporal dynamics of conversation turn-taking in gaze-based communication. We share our findings and also open source our data collection tools to further research in this domain.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573870
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573870
KW  - accessibility
KW  - augmentative and alternative communication
KW  - context awareness
KW  - conversation
KW  - gaze typing
KW  - text corpus
ER  - 

TY  - CONF
TI  - The Cane Game: An Educational Tool for Orientation and Mobility
AU  - Ruvolo, Paul
AU  - Louie, Ryan
AU  - Jerman, Eric
T3  - CHI EA '23
AB  - Proficiency in Orientation and Mobility (O&amp;M) is vital for people who are blind or visually impaired (BVI) to access physical environments and economic opportunities. While much engineering effort has focused on using technology to augment the practice of using a mobility cane, there is comparatively little work on using technology in service of teaching the use of the cane itself. We report a case study of a multi-year collaboration between assistive technology researchers and a certified O&amp;M instructor at Perkins School for the Blind to utilize technology to create O&amp;M teaching tools that use the concept of gamification to make such training more fun and effective. In this collaboration we adopted an action research approach, and through the application of action research HCI methods created several prototype systems for teaching O&amp;M skills. These prototypes were refined to create the Cane Game: a system for teaching students cane sweeping technique using interactive music and sound. The Cane Game system can be constructed for less than $100 and is capable of being distributed at large-scale. A qualitative study of Perkins School for the Blind students’ O&amp;M educational trajectories while using the system illuminates the conditions in which this tool is effective as a teaching aid.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573859
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573859
KW  - Augmented Reality
KW  - Education
KW  - Gamification
KW  - Orientation and Mobility
ER  - 

TY  - CONF
TI  - Surfacing AI Explainability in Enterprise Product Visual Design to Address User Tech Proficiency Differences
AU  - Tandon, Sara
AU  - Wang, Jennifer
T3  - CHI EA '23
AB  - This case study presents an investigation on explainable artificial intelligence (AI) visualization in business applications. Design guidelines for human-AI interaction are broad and touch on a range of user experiences with AI. Oftentimes, guidelines are not specific to enterprise scenarios with late-stage end users with limited AI knowledge and experience. We present a three-phase study on a visual design of a machine learning (ML) algorithm output. We conducted a user study on an existing design with limited visual AI explanation cues, ran a redesign workshop with various design and data experts, and conducted a reassessment with systematically applied AI explanation guidelines in place. We surface how users with various tech proficiency and AI/ML backgrounds interact with designs and how visual explanation cues increase understanding and effective decision making of users with low AI/ML familiarity. This design process corroborated the application and impact of existing guidelines and surfaced specific design implications for AI explainability within enterprise design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573867
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573867
KW  - Artificial intelligence
KW  - enterprise
KW  - explainable AI
KW  - practitioners
KW  - user experience
KW  - user perceptions
ER  - 

TY  - CONF
TI  - Playful Co-Design: Creating an AR-Prototype with Nurses in Interlocking Remote and On-Site Workshops
AU  - Albrecht-Gansohr, Carina
AU  - Geisler, Stefan
AU  - Eimler, Sabrina Cornelia
T3  - CHI EA '23
AB  - Deeply engaging nurses in a participatory co-design process, especially in times of COVID-19, is challenging. In this case study, we shed light on the process of developing a prototype for AR-glasses in nursing. We show the challenges we faced, the methods we used and how they contribute to the core principles of participatory design. A special focus is laid on small-scale interventions with high-impact, that helped us to truly engage users. We introduce empathetic ways to connect contrasting work environments, establish mutual understanding, make the abstract more graspable with playful tools like PLAYMOBIL®, and support co-design development with online formats. Finally, we discuss the transferability to other projects.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573869
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573869
KW  - Augmented Reality
KW  - Co-Design
KW  - Design Thinking
KW  - Hospital Care
KW  - Participatory Design
ER  - 

TY  - CONF
TI  - Organizing Community-based Events in Participatory Action Research: Lessons Learned from a Photovoice Exhibition
AU  - Lu, Alex Jiahong
AU  - Sannon, Shruti
AU  - Brewer, Savana
AU  - Jackson, Kisha N
AU  - Green, Jaye
AU  - Reeder, Daivon
AU  - Wafer, Camaria
AU  - Dillahunt, Tawanna R
T3  - CHI EA '23
AB  - Participatory action research (PAR) approaches center community members’ lived experiences and can spur positive change around pressing challenges faced by communities. Even though PAR and similar approaches have been increasingly adopted in HCI research that focuses on social justice and community empowerment, public-facing events that are based on this research and center community members’ voices are less common. This case study sheds light on how to initiate and organize events that build on existing PAR efforts, and what practical challenges might exist in this process. Building on a photovoice research project, we—a collaborative team of university researchers and staff members of a community organization in Eastside Detroit—co-organized a community-based public-facing exhibition that featured community members’ photographic narratives of personal and communal safety and surveillance. In this case study, we reflect on the challenges we experienced in planning and holding the exhibition. We contribute a set of practical guidelines to help researchers facilitate community-based events when conducting participatory action research in HCI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573846
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573846
KW  - community event
KW  - community-based participatory research
KW  - exhibition
KW  - participatory action research
KW  - photovoice
KW  - surveillance
ER  - 

TY  - CONF
TI  - Minimizing change aversion through mixed methods research: a case study of redesigning Spotify’s Your Library
AU  - Pettersson, Ingrid
AU  - Fredriksson, Carl
AU  - Dadgar, Raha
AU  - Richardson, John
AU  - Shields, Lisa
AU  - McKenzie, Duncan
T3  - CHI EA '23
AB  - Launching a radical change to a habitual feature, used by millions every day, presents a challenge both to the end user and the organization making the change. Change aversion to habitually used features is a known factor in users experience design, but at times major changes are needed to encompass feature growth ultimately benefiting users. In this case study, we present examples of how data science and user research collaborated during the redesign the mobile Library feature at Spotify. Major adaptions were needed in order to enable future opportunities. The challenge required a high degree of sensitivity to users’ needs within what is often considered their space in the world of streaming. We believe that close collaboration between the product, design, engineering, data science, and user research disciplines, with a focus on quantitative and qualitative mixed methods insight work in early development phases, enabled the experience to be launched with the users’ experience at the forefront and thus minimising change aversion.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573875
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573875
KW  - audio streaming
KW  - change aversion
KW  - data science
KW  - library organization
KW  - mixed methods research
KW  - user experience
KW  - user research
ER  - 

TY  - CONF
TI  - Reading Together: A Case Study of a Collaborative Reading System in Classroom Teaching
AU  - Wang, Shuwen
AU  - Zhang, Lishan
AU  - Zhang, Sixv
AU  - Lin, Bocheng
AU  - Liu, Lili
AU  - Xv, Min
T3  - CHI EA '23
AB  - Social annotation is an effective tool to cultivate learners’ literacy skills. Besides the learners themselves, their peers and teachers are also involved in the annotating process. To facilitate effective interactions among the different types of subjects, we redesigned the social annotation activity into a four-step learning mode and developed a collaborative reading system to support this learning mode. In this system, learners can not only annotate on specific content but also interact with their peers to exchange ideas. Specifically, before the class, learners annotate individually. In the meantime, they can see their peers’ annotations and make replies. During the class, each group collaboratively reflects on the individuals’ before-class annotations and completes an assigned group learning task on the system. At last, the teacher gives a summarization for the whole class. Through conducting three studies in different settings and data analysis, we found that individual annotation can positively influence the learners’ understanding of learning materials and the following collaborative learning process. During the before-class annotation activity, making learners able to see peers’ annotations encourages the learners to think deeply and constructively. Moreover, the detailed learning feedback on the group's annotation performance is helpful for individual and collaborative learning. Now that most of the feedbacks are crafted manually or by traditional machine learning algorithms, state-of-the-art natural language processing technology like pre-trained language model has been used to automatically detect learners’ cognitive engagement and will be used to automatically generate feedback in the future. Finally, we put forward two recommendations for further design of social annotation tools: (1) Using annotation filtering mechanisms to hide low-quality comments; (2) Providing automatic learning feedback and interventions to encourage learners to interact with their teammates.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573840
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573840
ER  - 

TY  - CONF
TI  - Near-Live Simulations to the Rescue: Lessons Learned from Using Alternative Simulation Approaches for Evaluating New Technologies
AU  - Mastrianni, Angela
AU  - Sarcevic, Aleksandra
T3  - CHI EA '23
AB  - The near-live simulation method has advantages over other methods when testing technologies for supporting team-based work because testing can be conducted without requiring an entire team to assemble. In this case study, we describe our experiences in conducting 14 remote near-live simulation sessions to evaluate a digital checklist application used in pediatric trauma resuscitation. The remote near-live simulation sessions were complex to design and conduct because participants did not have direct access to a device that could run the checklist application and the digital checklist needed to integrate with the vital sign monitor used during resuscitations. We describe how we designed the environment for running the near-live simulations and discuss the lessons learned from conducting these simulations. We highlight three factors that need to be considered when using the near-live simulation approach: (1) filming or selecting the video of the simulated event, (2) providing participants with access to the system that is being evaluated, and (3) integrating the system being tested with other systems in the simulation scenario.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573850
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573850
KW  - near-live simulation
KW  - pediatric trauma resuscitation
KW  - remote user testing
ER  - 

TY  - CONF
TI  - Location-based AR for Social Justice: Case Studies, Lessons, and Open Challenges
AU  - Schroeder, Hope
AU  - Tokanel, Rob
AU  - Qian, Kyle
AU  - Le, Khoi
T3  - CHI EA '23
AB  - Dear Visitor and Charleston Reconstructed were location-based augmented reality (AR) experiences created between 2018 and 2020 dealing with two controversial monument sites in the US. The projects were motivated by the ability of AR to 1) link layers of context to physical sites in ways that are otherwise difficult or impossible and 2) to visualize changes to physical spaces, potentially inspiring changes to the spaces themselves. We discuss the projects’ motivations, designs, and deployments. We reflect on how physical changes to the projects’ respective sites radically altered their outcomes, and we describe lessons for future work in location-based AR, particularly for projects in contested spaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573855
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573855
KW  - Augmented reality
KW  - human-centered computing
ER  - 

TY  - CONF
TI  - Lessons Learned for Data-Driven Implementation Intentions with Mental Contrasting
AU  - Sefidgar, Yasaman S.
AU  - Jörke, Matthew
AU  - Suh, Jina
AU  - Saha, Koustuv
AU  - Iqbal, Shamsi
AU  - Ramos, Gonzalo
AU  - Czerwinski, Mary P
T3  - CHI EA '23
AB  - Goal setting and realization are important but challenging. These challenges can be mitigated through effective application of behavior change realization techniques such as implementation intention and mental contrasting&nbsp;(IIMC). IIMC relies on identifying situations compromising desired behavior (i.e.,&nbsp;obstacles) and creating action plans to handle those situations&nbsp;(i.e.,&nbsp;identifying what, when, and where of actions to prevent or overcome the obstacles). We explore ways historical personal data can enhance the efficacy of IIMC application in the context of improving work-nonwork balance in a probing study with 16 information workers at a large technology company. We share lessons learned from this study that can help designers in further supporting goal realization with data, guide researchers interested in more formal studies of IIMC, and point the research community to important areas of future work on data-driven IIMC, particularly in the work context&nbsp;(e.g.,&nbsp;the social dimensions of sense-making and planning).
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573851
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573851
KW  - Behavior Change
KW  - Goal-Setting
KW  - Implementation Intention
KW  - Mental Contrasting
KW  - Personal Data
KW  - Reflection
KW  - Work-Nonwork Balance
ER  - 

TY  - CONF
TI  - ImpactBot: Chatbot Leveraging Language Models to Automate Feedback and Promote Critical Thinking Around Impact Statements
AU  - Mukherjee, Anwesha
AU  - Santana, Vagner Figueredo De
AU  - Baria, Alexis
T3  - CHI EA '23
AB  - Impact statements articulate the impacts of a research project with concise and unambiguous statements about problems addressed, actions to resolve, and explanations of any impacts. Researchers and technologists often rely on impact statements as means to provoke introspective critical thinking around the impacts of technology being developed. However, due to factors such as technocentrism, positivity bias, marketization, or hyperinflation of impact statements, the claims presented in these statements do not cover all important aspects when creating technology – for instance, negative and delayed impacts. This work contributes to the development of a chatbot called ImpactBot to promote critical thinking while researchers create impact statements for research projects or scientific papers. The proposed chatbot leverages two fine-tuned state-of-the-art RoBERTa models for sequence classification and was assessed in this case study with 5 researchers from a large information technology company and 7 university engineering research scientists or students. This approach may be reused as part of content management or a paper submission system, for instance, to dialogue with researchers and promote critical thinking about negative impacts and how to mitigate them (if any) while creating impact statements for their projects or scientific papers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573844
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573844
KW  - chatbot
KW  - natural language processing.
KW  - User studies
KW  - user-centered design
ER  - 

TY  - CONF
TI  - From VizBlocks to the Data-Driven Actor: Reimagining an open-ended data physicalisation prototype with a creative business
AU  - Lechelt, Susan
AU  - Morgan, Evan
AU  - Duffy, Clare
AU  - Murray-Rust, Dave
AU  - Nissen, Bettina
T3  - CHI EA '23
AB  - In this case study, we document the process of engaging in an initially unplanned and informal knowledge exchange activity between academic researchers and a local performing arts company. This knowledge exchange activity quickly became a fruitful collaboration during which an academic design research prototype was reimagined as a wholly new product to expand the offering of a creative business. We document the factors that led to the success of this collaboration, reflecting on both features of the collaboration itself and how the design of the initial research prototype configured its repurposing. In terms of the latter, we consider how the original prototype's ambiguity, open-endedness, customisability and flexible assembly afforded its reimagining. Through the case study, we demonstrate that there is much to be gained from facilitating access to research prototypes for small and medium enterprises and supporting them in appropriating these toward their own goals.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573847
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573847
KW  - data literacy
KW  - data physicalisation
KW  - Design research
KW  - industry collaboration
KW  - research through design
ER  - 

TY  - CONF
TI  - Improving Railway Safety: Human-in-the-loop Invariant Finding
AU  - Lloyd-Roberts, Ben
AU  - James, Phillip
AU  - Edwards, Michael
AU  - Robinson, Simon
AU  - Werner, Thomas
T3  - CHI EA '23
AB  - Formal methods is a field that has a long standing history within Computer Science. At its core, it involves the use of mathematical formalisms to model and reason about computer systems and programs. The application of formal methods to verify that railway signalling systems operate safely and correctly is particularly well established within academia and is now beginning to see real applications in the railway sector. However, many contemporary approaches frequently detect false positive safety violations necessitating lengthy manual analysis by expert engineers. It has been shown that such errors can be mitigated with strengthening invariants, non-trivially generated properties which hold for all reachable states, or configurations, of a program under verification. In this work, we report on the use of machine learning to explore such state spaces autonomously and provide various visual aids to assist engineers in understanding and inducing invariant properties to support verification. We conducted a focus group with an engineering team specialising in railway signalling systems, soliciting feedback on these visualisations while co-designing suggested improvements for the application domain. The results were two-fold; our visualisations allowed participants to explore candidate invariants, but also highlighted improvements to our machine learning approach by leveraging their domain knowledge.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573853
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573853
KW  - data visualisation
KW  - formal verification
KW  - machine learning
ER  - 

TY  - CONF
TI  - How to Organise Engaging Online Conferences and Escape the Zoom Rectangle
AU  - Kowalski, Jaros\law
AU  - Skorupska, Kinga H.
AU  - Kopacz, Agata
AU  - Muczynski, Bartosz
AU  - Kopec, Wieslaw
AU  - Bohdanowicz, Zbigniew
AU  - Górska, Gabriela
AU  - Biele, Cezary
T3  - CHI EA '23
AB  - As an increasing number of academic conferences transition to the online sphere, new event paradigms must be explored and developed to better utilise the unique multimedia opportunities offered by the virtual world. With this in mind, we conducted in-depth interviews with researchers, performed a SWOT analysis of remote conferences, and developed experimental conference functionalities. We implemented these during the 9th edition of a two-day international scientific IT conference, which was attended by over 277 participants on the first day and 199 on the second. In this article, we describe how these innovative functionalities met the participants’ needs based on qualitative and quantitative data. We present how the experiences of remote and in-person events differ, and offer recommendations on organising remote conferences that encourage participants to exchange knowledge and engage in activities.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573858
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573858
KW  - online conferences
KW  - participant engagement
KW  - scientific community
ER  - 

TY  - CONF
TI  - Exploring Values of Energy Justice: A Case Study of a Burgeoning Energy Community
AU  - Jensen, Victor Vadmand
AU  - Jensen, Rikke Hagensby
T3  - CHI EA '23
AB  - We increasingly see local community energy initiatives unfold to support sustainable energy transitions. The notion of energy communities may aid these initiatives as HCI researchers, practitioners, and political organizations argue for their potential benefits. However, envisionments of energy communities carry assumed expectations of a just energy future for community members. This paper presents a case study of a burgeoning energy community where diverse stakeholders reflect on their expectations of a newly established Danish energy cooperative. Through a value-sensitive design study, we identify ten values reflecting social-technical expectations of how the community may be organized and supported by technology in the future. We structure the values into three tenets of energy justice to discuss value tensions regarding the; i) distribution of energy community benefits and threats, ii) enabling energy community engagement, and iii) recognizing the energy community. Lastly, we discuss how HCI may steer technology design toward a just energy future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573864
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573864
KW  - energy communities
KW  - energy justice
KW  - qualitative case study
KW  - sustainable HCI
KW  - value tensions
KW  - value-sensitive design
ER  - 

TY  - CONF
TI  - Exploring the future of design tooling: The role of artificial intelligence in tools for user experience professionals
AU  - Knearem, Tiffany
AU  - Khwaja, Mohammed
AU  - Gao, Yuling
AU  - Bentley, Frank
AU  - Kliman-Silver, Clara E
T3  - CHI EA '23
AB  - Recently, artificial intelligence (AI) has been introduced into a variety of consumer applications for creative work. Although AI-driven features in design tooling are nascent, there is growing interest in utilizing AI to support user experience (UX) workflows. In this case study, we surveyed industry UX professionals to understand how they perceive AI-driven assists in their tools, their concerns about accepting AI in design tools and which design-related workflows could be promising for future research. Our results suggest that UX professionals are overall positive about AI-driven features in design tools; looking to AI as a creative partner to iterate with and as an assistant with mundane tasks. We offer practical directions for the future of AI in UX tooling, but caution against developing tools that do not sufficiently address UX professionals’ concerns around bias and trust.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573874
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573874
KW  - artificial intelligence
KW  - Design tools
KW  - product design
ER  - 

TY  - CONF
TI  - Experience: Barriers and Opportunities of Wearables for Eating Research
AU  - Pedram, Mahdi
AU  - Fernandes, Glenn
AU  - Romano, Christopher
AU  - Wei, Boyang
AU  - Sen, Sougata
AU  - Hester, Josiah
AU  - Alshurafa, Nabil
T3  - CHI EA '23
AB  - Wearable devices have long held the potential to provide real-time objective measures of behavior. However, due to challenges in real-world deployment, these systems are rarely tested rigorously in free-living settings. To reduce this challenge for future researchers, in this paper, we describe our experience developing several generations of a multi-sensor, neck-worn eating-detection system that has been tested with 130 participants across multiple studies in both laboratory and free-living settings. We describe the challenges faced in the development and deployment of the system by (1)&nbsp;presenting example deployment details captured either by the sensing system or the ground truth collector and (2)&nbsp;using structured interviews and surveys with developers and stakeholders of the system, collecting qualitative data on their experience. We performed thematic analysis and provided detailed lessons learned explaining factors that impact the experience of building and deploying such a wearable in a free-living setting, reducing challenges for future researchers. We believe that our experience will help future researchers develop successful mobile health (mHealth) systems that translate into reliable free-living deployments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573841
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573841
KW  - Case study
KW  - eating detection
KW  - wearable sensors
ER  - 

TY  - CONF
TI  - Evaluation of a collaborative reading annotation system through multimodal data analysis
AU  - Liu, Lili
AU  - Zhang, Lishan
AU  - Shu, Yan
AU  - Wang, Shuwen
AU  - Wu, Han
AU  - Xv, Min
T3  - CHI EA '23
AB  - Technological advances and the explosion of epidemics have contributed to a surge in the number of online learning platforms. Because single modal data is often not enough in evaluating the usability of interface interaction design for online learning platforms and multimodal data (eye movement, Electroencephalogram, skin conductance response) with advanced sensing technologies provide new possibilities to address this issue, this case study explores how multimodal data can be used to evaluate the interface design for our self-developed collaborative reading system. The results of our randomized between-subject experiments showed that, from eye movement analysis, constructive-level annotations prompt students to allocate more attention to the annotation area than active level annotations and facilitate the transition between the annotation and reading areas. From EEG data analysis, all the students stayed high concentration levels no matter the types of annotations they were reading. From SCRs analysis, although no significant difference in the level of excitement between experimental conditions was identified, students showed great individual difference within the same conditions. This study illustrated how multimodal data can be applied to interface design evaluation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573854
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573854
KW  - Collaborative reading annotation system
KW  - Machine learning
KW  - Multimodal data analysis
ER  - 

TY  - CONF
TI  - Do you have time for a survey? Challenges and Lessons Learned from the Recruitment Process for an Online Survey
AU  - Langlois, Danielle K
AU  - Kriglstein, Simone
T3  - CHI EA '23
AB  - Regardless of study design, recruitment is always an important challenge for researchers. In the current paper, we would like to share some lessons learned in the recruitment techniques for an online survey study. In order to recruit for a survey study on Esports, the authors decided to try and recruit from a diverse population. To this end, they recruited both from their personal networks and via social media. While they were unable to recruit the desired number of participants (30- 50), they were able to learn a great deal about what worked and what did not in the recruitment process. Some of the issues encountered involved survey length and timing issues. Also, they learned that researchers need to be mindful about the limitations of the social media sites they use. We hope that sharing these lessons will be helpful to future researchers as they plan future research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573865
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573865
KW  - ESports
KW  - online survey
KW  - study recruitment
KW  - survey methodology
ER  - 

TY  - CONF
TI  - Conducting Remote Design Research on Embodied, Collaborative Museum Exhibits
AU  - Long, Duri
T3  - CHI EA '23
AB  - Research activities in interaction design and HCI were widely altered by the COVID-19 pandemic, with many studies shifting online as health concerns inhibited in-person research. Tangible and collaborative activities are often used in informal learning spaces and child-computer interaction, but they are neither designed for nor easily adapted to online formats. In this case study, I present findings and reflections on my experience adapting an in-situ study of embodied, collaborative museum exhibits to a remote user study during COVID-19. I identify several considerations and notes of inspiration for researchers working on similar projects, which I hope can aid in furthering iterative design research on embodied and/or collaborative activities both during the ongoing pandemic and in other current and future contexts that require remote research or interactions. The reflections I present in this case study additionally play a role in documenting the ongoing history of interaction design as researchers adapt to the rapidly changing global circumstances caused by COVID-19.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573842
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573842
KW  - Additional Keywords and Phrases AI literacy
KW  - at-home learning
KW  - collaborative
KW  - COVID-19
KW  - design research
KW  - embodied
KW  - informal learning
KW  - methods
KW  - museum exhibits
KW  - pandemic
KW  - remote user study
KW  - tangible
ER  - 

TY  - CONF
TI  - Adapting to Challenges in Qualitative Fieldwork through Theoretical Sampling
AU  - Cohoon, Johanna
AU  - Howison, James
T3  - CHI EA '23
AB  - We present a case study of theoretical sampling from a recent experience conducting grounded theory research. This example demonstrates how theoretical sampling can be used to adapt to challenges during data collection. By providing a detailed account of our methodological decisions and a description of the major aspects of data collection in a grounded theory study, this case study demystifies theoretical sampling. We provide several guiding questions that researchers can use to ensure thoughtful theoretical sampling. By committing to answering these questions, grounded theorists can preregister their work while maintaining analytical flexibility.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573873
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573873
KW  - case study
KW  - grounded theory
KW  - open science
KW  - preregistration
KW  - research methods
KW  - theoretical sampling
KW  - trace data
ER  - 

TY  - CONF
TI  - Designing Access in Sound Art Exhibitions: Centering Deaf Experiences in Musical Thinking
AU  - May, Lloyd
AU  - Miller, Sarah
AU  - Bakri, Sehuam
AU  - Quandt, Lorna C
AU  - Malzkuhn, Melissa
T3  - CHI EA '23
AB  - This case study details the process of generating recommendations for the implementation of specific haptic technologies in an upcoming exhibition of sound and video art in order to improve the museum experience for Deaf and Hard of Hearing patrons. Various haptic technologies and intensity settings were evaluated by D/deaf and Hard of Hearing participants through a combination of structured user experience surveying and a focus group. Insights gained from this mixed-methods approach were then used to generate recommendations for specific vibro-tactile technologies for each artwork in the exhibition. Additionally, general design insights into designing more accessible sound-art experiences, such as the need for tailored haptic signal design instead of using native audio signals, were also provided.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573872
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573872
KW  - Accessibility
KW  - Haptics
KW  - Sound Art
ER  - 

TY  - CONF
TI  - AI for human assessment: What do professional assessors need?
AU  - Arakawa, Riku
AU  - Yakura, Hiromu
T3  - CHI EA '23
AB  - Recent organizations have started to adopt AI-based decision support tools to optimize human resource development practices, while facing various challenges of using AIs in highly contextual and sensitive domains. We present our case study that aims to help professional assessors make decisions in human assessment, in which they conduct interviews with assessees and evaluate their suitability for certain job roles. Our workshop with two industrial assessors elucidated troubles they face (i.e.,&nbsp;maintaining stable and non-subjective observation of assessees’ behaviors) and derived requirements of AI systems (i.e.,&nbsp;extracting their nonverbal cues from interview videos in an interpretable manner). In response, we employed an unsupervised anomaly detection algorithm using multimodal behavioral features such as facial keypoints, body and head pose, and gaze. The algorithm extracts outlier scenes from the video based on behavioral features as well as informing which feature contributes to the outlierness. We first evaluated how the assessors would perceive the extracted cues and discovered that the algorithm is useful in suggesting scenes to which assessors would pay attention, thanks to its interpretability. Then, we developed an interface prototype incorporating the algorithm and had six assessors use it for their actual assessment. Their comments revealed the effectiveness of introducing unsupervised anomaly detection to enhance their feeling of confidence and objectivity of the assessment along with potential use scenarios of such AI-based systems in human assessment. Our approach, which builds on top of the idea of separating observation and interpretation in human-AI collaboration, will facilitate human decision making in highly contextual domains, such as human assessment, while keeping their trust in the system.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573849
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573849
KW  - behavior analysis
KW  - human assessment
KW  - human-AI collaboration
ER  - 

TY  - CONF
TI  - A Case Study on H2O OpenCasebook : Uncovering Digital Reading in Law School
AU  - Lee, Seonghee
AU  - Cushman, Jack
AU  - Brobston, Catherine
AU  - Eidolon, Harmony Dawn
T3  - CHI EA '23
AB  - This study investigates the digital reading experiences of law students and conducts a usability test on H2O, a digital open-casebook platform developed by the Harvard Library Innovation Lab. 9 in-depth user interviews and 16 user surveys on digital reading experiences of law students were conducted. The results of this study provide insights into the reading preferences and habits of law students that can be used to inform the design of digital learning tools in law school. Despite anecdotal reports that earlier users of the platform preferred physical casebooks, we found that many law students now prefer using digital casebooks. More than half of the participants (53.3%) in our study reported that they preferred digital casebooks or that the format did not matter. Even for those preferring print books, cost or weight reduction was often more important than format preference, and print-preferring users expressed an interest in using digital annotation tools, collaboration and additional search features. This study suggests that student preferences for learning materials are rapidly changing — a change that may have been accelerated by the pandemic — and that assumptions about student preference may need to be reevaluated. It also demonstrates the importance of comparing old vs. new offerings, such as print vs. digital, to evaluate the strength of the preference relative to other preferences such as cost, and to teach participants what new features are enabled by the new format.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573857
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573857
KW  - digital reading
KW  - digital reading interaction
KW  - law school
KW  - learning technology
ER  - 

TY  - CONF
TI  - A Tool for Guiding Teachers and their Learners: the Case Study of an Art Class
AU  - Gennari, Rosella
AU  - Melonio, Alessandra
AU  - Rizvi, Mehdi
T3  - CHI EA '23
AB  - There is growing interest in how to enable in-service teachers to promote computational skills in their classes. Different researchers also highlight the importance of developing a critical mindset toward digital technology. This paper reports a case study, part of a training program for in-service teachers, organised by researchers and the local School District, to bring physical computing into class, and foster critical reflections on technology along the process. The program included teachers for diverse subjects, across primary and high schools. It used the novel IoTgo tool, adaptable to the needs of the different teachers. The study in this paper considers the case of an art class in a high school. According to the reported data analysis, the tool and the structure it offered enabled the teacher to bring computing into her art class, on her own, and learners to reflect along the process from different perspectives.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573863
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573863
KW  - independence
KW  - IoT
KW  - learner
KW  - phygital
KW  - reflection
KW  - smart
KW  - teacher
KW  - tool
ER  - 

TY  - CONF
TI  - A Case Study on the Design and Use of an Annotation and Analytical Tool Tailored To Lead Climbing
AU  - Fruchard, Bruno
AU  - Avezou, Cécile
AU  - Malacria, Sylvain
AU  - Casiez, Géry
AU  - Huot, Stéphane
T3  - CHI EA '23
AB  - Annotating sport performances enables to quantitatively and qualitatively analyze them, and profile athletes to identify their strengths and weaknesses. We present the case study of the design and use of an annotation and analytical tool tailored to lead climbing analysis, developed with and for the French climbing federation. We used an iterative design cycle mostly fueled by virtual meetings with the federation trainer and analyst to identify requirements and implement essential features over time. We complemented these meetings with two workshops involving them, as well as French athletes competing at the international level, to identify the tool advantages and limitations. We contribute a list of insights based on the design process and feedback from stakeholders that inform the design of annotation and analytical tools for lead climbing and potentially other sports.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573876
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573876
KW  - case study
KW  - sport analysis
KW  - user-centered design
KW  - video annotation
ER  - 

TY  - CONF
TI  - A Case Study on Student Experiences of Social VR in a Remote STEM Classroom
AU  - Young, Gareth W.
AU  - O'Dwyer, Néill C.
AU  - Smolic, Aljosa
T3  - CHI EA '23
AB  - Extended reality (XR) technologies continue gaining traction in multiple higher education contexts. As XR becomes more commercially accessible to students and universities, its convenience for educational purposes presents a renewed potential for exploration. Due to Covid-19 restrictions, there is also a growing interest in cross-platform, socially orientated software for remote educational practices. However, the precise role of XR technologies and how they contribute to student experiences of remote learning, particularly the unique affordances of social virtual reality (VR) for evoking an embodied sense of presence, is relatively unknown. Based on real-world experiences, we present a case study on a social VR intervention in a remote higher education classroom to inspire Human-Computer Interaction (HCI) researchers to investigate further the issues that arise from our practice-based research. Our motivations were to report, analyze, and summarize everyday virtual learning environment (VLE) challenges, identify design considerations for VLE technologies, and comment on social VR’s utility in delivering Science, Technology, Engineering, and Mathematics (STEM) subjects in a remote setting. We apply a practical approach to investigate and identify potential HCI problems, capture the unique experiences of STEM students during the lockdown, and explore the effects of tutorial activities that give students agency in constructing VLEs. The findings of this student-focused case study draw attention to the design of social VR activities that support conventional, web browser-based VLEs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573852
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573852
KW  - Higher Education
KW  - Social VR
KW  - Virtual Learning Environments
ER  - 

TY  - CONF
TI  - A Case Study Exploring Users’ Perceptions and Expectations of Shapes for Dialog Designs
AU  - Yan, Xinghui (Erica)
AU  - Feldman, Julia
AU  - Bentley, Frank
AU  - Khwaja, Mohammed
AU  - Gilbert, Michael
T3  - CHI EA '23
AB  - Shape is a fundamental visual characteristic in the design of common UI components like buttons, switches, and dialogs. It has commonly been used to enhance the visual aesthetic of a UI, or to express a distinct perspective in style or brand. However, it remains understudied how the shape of UI components convey semantic meaning and impact user perception of the information displayed in those UI components. As a first step to address this gap, we chose to study the dialog UI component. We first explored the shape of a dialog and created 6 different designs (e.g., dialogs with rounded corners, circle, and wiggly-circle) for an online survey study with 200 participants. We examined whether different dialog designs alter user perceptions and expectations of different messages displayed within them. This work serves as a practical study to explore the opportunity for shapes to be used intentionally in UI design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573845
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573845
KW  - dialog UI
KW  - shape
KW  - UI design
KW  - user perceptions
ER  - 

TY  - CONF
TI  - Workshop on Trust and Reliance in AI-Human Teams (TRAIT)
AU  - Bansal, Gagan
AU  - Buçinca, Zana
AU  - Holstein, Kenneth
AU  - Hullman, Jessica
AU  - Smith-Renner, Alison Marie
AU  - Stumpf, Simone
AU  - Wu, Sherry
T3  - CHI EA '23
AB  - As humans increasingly interact (and even collaborate) with AI systems during decision-making, creative exercises, and other tasks, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. Specifically, people should understand when to trust or rely on an algorithm’s outputs and when to override them. Significant research focus has aimed to define and measure trust in human-AI interaction, and design and implement interactions that promote and calibrate trust. However, conceptualizing trust and reliance, and identifying the best ways to measure these constructs and effectively shape them in human-AI interactions remains a challenge, especially across contexts and domains. This workshop aims to establish building appropriate trust and reliance on (imperfect) AI systems as a vital, yet under-explored research problem. The workshop will provide a venue for exploring three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance? The workshop will build on the success from running it at CHI 2022,1 with a focus on “Learning from Practice" — how can we better tie theory-building to real-life use cases? As these problems and solutions involving humans and AI are interdisciplinary in nature, we invite participants with expertise in HCI, AI, ML, psychology, and social science, or other relevant fields to foster closer communications and collaboration between multiple communities.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573831
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573831
KW  - human-centered artificial intelligence
KW  - reliance
KW  - trust
KW  - uncertainty
ER  - 

TY  - CONF
TI  - Towards an Inclusive and Accessible Metaverse
AU  - Parker, Callum
AU  - Yoo, Soojeong
AU  - Lee, Youngho
AU  - Fredericks, Joel
AU  - Dey, Arindam
AU  - Cho, Youngjun
AU  - Billinghurst, Mark
T3  - CHI EA '23
AB  - The push towards a Metaverse is growing, with companies such as Meta developing their own interpretation of what it should look like. The Metaverse at its conceptual core promises to remove boundaries and borders, becoming a decentralised entity for everyone to use - forming a digital virtual layer over our own “real” world. However, creation of a Metaverse or “new world” presents the opportunity to create one which is inclusive and accessible to all. This challenge is explored and discussed in this workshop, with an aim of understanding how to create a Metaverse which is open and inclusive to people with physical and intellectual disabilities, and how interactions can be designed in a way to minimise disadvantage. The key outcomes of this workshop outline new opportunities for improving accessibility in the Metaverse, methodologies for designing and evaluating accessibility, and key considerations for designing accessible Metaverse environments and interactions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573811
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573811
KW  - Accessiblity
KW  - AR
KW  - Human Computer Interaction
KW  - Metaverse
KW  - VR
ER  - 

TY  - CONF
TI  - The Second Workshop on Intelligent and Interactive Writing Assistants
AU  - Chang, Minsuk
AU  - Chung, John Joon Young
AU  - Gero, Katy Ilonka
AU  - Huang, Ting-Hao Kenneth
AU  - Kang, Dongyeop
AU  - Lee, Mina
AU  - Raheja, Vipul
AU  - Wambsganss, Thiemo
T3  - CHI EA '23
AB  - In recent years, writing assistants have become increasingly sophisticated and ubiquitous, fueled by advances in artificial intelligence, particularly large language models. As new use cases and models emerge, we expect the adoption rate to accelerate. In this interdisciplinary workshop, we, as a diverse group of researchers and practitioners interested in intelligent and interactive writing assistants, will create a taxonomy of writing assistants and discuss their desirable features and potential consequences. We invite writers, educators, researchers, industry practitioners, students, and anyone interested in creating, using, and testing future writing assistant technologies to join the conversation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573826
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573826
KW  - AI-assisted writing
KW  - Creativity support tools
KW  - Human-AI interaction
KW  - Human-computer interaction
KW  - Language models
KW  - Natural language processing
KW  - Writing assistants
KW  - Writing support tools
ER  - 

TY  - CONF
TI  - The Future of Hybrid Care and Wellbeing in HCI
AU  - Bhat, Karthik S
AU  - Ismail, Azra
AU  - Hall, Amanda K
AU  - Karusala, Naveena
AU  - Mentis, Helena M.
AU  - Vines, John
AU  - Kumar, Neha
T3  - CHI EA '23
AB  - This workshop focuses on remote care and wellbeing as we transition into a world increasingly adopting hybrid lifestyles and modes of operation. Care and care work have predominantly been researched in traditionally in-person interpersonal contexts. The burgeoning uptake and incorporation of information and communication technologies towards remote care have created new workflows and resulted in emerging questions around the definitions and scope of care practice in response. The confluence of technological, sociocultural, geopolitical, and climatic realities of the current day brings into focus the need to unpack the idea of “care,” and the role that HCI researchers could play in creating equitable futures of remote and hybrid care. This workshop will focus on questions such as “What does holistic wellbeing look like in the era of hybrid caregiving?” and “How does environmental care factor into our research practice?” We invite researchers and practitioners from academia and industry in this workshop to reflect on these questions and advance the future of remote care work at CHI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573829
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573829
KW  - care
KW  - future of work
KW  - hybrid
KW  - remote
ER  - 

TY  - CONF
TI  - The EmpathiCH Workshop: Unraveling Empathy-Centric Design
AU  - Drouet, Luce
AU  - Meijer, Wo
AU  - O'Kane, Aisling Ann
AU  - Singh, Aneesha
AU  - Wambsganss, Thiemo
AU  - Mauri, Andrea
AU  - Verma, Himanshu
T3  - CHI EA '23
AB  - EmpathiCH aims to bring together and blend a diverse set of expertise to develop a new research agenda in the context of “Empathy-Centric Design”. Building on the discussions that emerged in the previous edition, the main research objective is to form a comprehensive and coherent framework that utilizes empathy as a new dimension of human-factors research and practice. We aim to consolidate the existing theoretical and conceptual constructs of empathy from diverse domains to reflect on its temporality, materiality, and the risks related to its instrumentalization. With a mix of author panels, expert discussion, and interactive activities, we aim to make this workshop the ideal venue to foster collaboration, expand the community, and shape the future direction of “Empathy-Centric Design”.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573796
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573796
KW  - assessment of empathy
KW  - attributes of empathy
KW  - collaboration
KW  - empathy
KW  - empathy-centric design
KW  - ethics of empathy
ER  - 

TY  - CONF
TI  - The Future of Computational Approaches for Understanding and Adapting User Interfaces
AU  - Jiang, Yue
AU  - Lu, Yuwen
AU  - Lutteroth, Christof
AU  - Li, Toby Jia-Jun
AU  - Nichols, Jeffrey
AU  - Stuerzlinger, Wolfgang
T3  - CHI EA '23
AB  - Building on the success of the first workshop on understanding, generating, and adapting user interfaces at CHI2022, this workshop will advance this research area further by looking at existing results and exploring new research directions. Computational approaches for user interfaces have been used in adapting interfaces for different devices, modalities, and user preferences. Recent work has made significant progress in understanding and adapting user interfaces with traditional constraint/rule-based optimization and machine learning-based data-driven approaches; however, these two approaches remain separate. Combining the two approaches has great potential to advance the area but remains under-explored and challenging. Other contributions, such as datasets for potential applications, novel representations of user interfaces, the analysis of human traces, and models with multi-modalities, will also open up future research options. The proposed workshop seeks to bring together researchers interested in computational approaches for user interfaces to discuss the needs and opportunities for future user interface algorithms, models, and applications.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573805
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573805
ER  - 

TY  - CONF
TI  - Symposium: Workgroup on Interactive Systems in Healthcare (WISH)
AU  - Epstein, Daniel A.
AU  - O'Kane, Aisling Ann
AU  - Miller, Andrew D
T3  - CHI EA '23
AB  - The Workgroup on Interactive Systems in Healthcare (WISH) connects academic and industry researchers across human-computer interaction, medical informatics, health informatics, digital health, and beyond to foster a community around innovations in consumer and medical health and wellbeing. The WISH Symposium at CHI 2023 will regather the HCI health and wellbeing research community for the first in-person community meeting in four years, allowing us to discuss and disseminate findings, methods, and approaches towards understanding and creating interactive health and wellbeing systems. We will continue the tradition of providing mentoring opportunities for early- and mid-career researchers, ranging from undergraduates to post-PhD, to establish future generations of scholars in the area. This will be the tenth WISH meeting, following a successful tradition of workshops at relevant venues including CHI over the past decade.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573804
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573804
KW  - health
KW  - healthcare
KW  - interactive systems
KW  - wellbeing
ER  - 

TY  - CONF
TI  - Supporting Social Movements Through HCI and Design
AU  - Petterson, Adrian
AU  - Thuppilikkat, Ashique Ali
AU  - Gupta, Paridhi
AU  - Klassen, Shamika
AU  - Jack, Margaret C
AU  - Liu, Jun
AU  - Chandra, Priyank
T3  - CHI EA '23
AB  - The use of digital technologies in grassroots community organizing has multifaceted implications. It has extended the scope of sharing information and experiences, building solidarities and coordination, and fostering common identities to enable participation and amplify the voice of diverse actors in social movements. However, the rise of surveillance technologies, computational propaganda and internet shutdowns are creating novel barriers to democratic action, particularly affecting the participatory parity of marginalized grassroots groups. This one-day hybrid workshop will invite conversations on the complex interrelation between ICTs and social movements and devise ways to support grassroots movements by bringing together HCI researchers, activists and designers. We invite formal position papers to participate in workshop and encourage participants to ideate and contribute to creating zines that can serve as a helpful resource for supporting grassroots movements.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573812
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573812
KW  - Activism
KW  - Design
KW  - Social Movements
ER  - 

TY  - CONF
TI  - Socially Assistive Robots as Decision Makers: Transparency, Motivations, and Intentions
AU  - Nault, Emilyann
AU  - Bettosi, Carl J
AU  - Baillie, Lynne
AU  - Smith, Ronnie
AU  - Mataric, Maja
AU  - Nallur, Vivek
AU  - Tscheligi, Manfred
AU  - Sackl, Andreas
AU  - Paternò, Fabio
AU  - Macleod, Scott A
AU  - Cooper, Sara
T3  - CHI EA '23
AB  - Socially Assistive Robots (SARs) are being developed to fulfil a range of roles that support humans. As the complexity and capability of SARs increase, they will be expected to adopt higher degrees of responsibility and execute greater levels of autonomous decision-making. Therefore, it is imperative that the Human-Robot Interaction (HRI) and more widely the Human-Computer Interaction (HCI) community seriously consider how SARs communicate about their role and the motivations and intentions behind their decisions. The proposed workshop will address challenges with respect to SAR decision-making, discuss current approaches to these challenges, and develop ideas and strategies for how the wider CHI community should move forward in this area.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573822
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573822
KW  - Machine ethics
KW  - Robotic autonomy
KW  - Socially assistive robots
KW  - Transparency
KW  - Trust
ER  - 

TY  - CONF
TI  - Sharing and Experiencing Hardware and Methods to Advance Smell, Taste, and Temperature Interfaces
AU  - Brooks, Jas
AU  - Bahremand, Alireza
AU  - Lopes, Pedro
AU  - Spackman, Christy
AU  - Amores Fernandez, Judith
AU  - Ho, Hsin-Ni
AU  - Inami, Masahiko
AU  - Niedenthal, Simon
T3  - CHI EA '23
AB  - There has been a monumental push from the CHI community to bring more human senses to interactive devices. This trend is significant because we use&nbsp;all our senses&nbsp;in everyday interactions but only an&nbsp;extremely narrow subset&nbsp;when interacting with computers. This workshop focuses on bringing together researchers to advance some of the most challenging senses to embed into interfaces, but arguably the most exciting:&nbsp;smell, taste, and temperature. To integrate these modalities into interfaces, researchers not only use methods from traditional mechanics or haptics (e.g., pumps, heating pads, etc.) but must also acquire tacit skills and understandings from psychophysics, neuroscience, anatomy, and chemistry (e.g., receptor signaling pathways or food chemistry). This demo-based workshop provides a platform to come together and bring their demonstrations, experiments, and hardware to experience, discuss, and advance the field.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573828
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573828
KW  - chemesthesis
KW  - demonstrations
KW  - Smell
KW  - taste
KW  - temperature
ER  - 

TY  - CONF
TI  - Privacy Interventions and Education (PIE): Encouraging Privacy Protective Behavioral Change Online
AU  - Smith, Garrett
AU  - Chapman, Kirsten
AU  - Agha, Zainab
AU  - Ruppert, Janet
AU  - Cullen, Spring
AU  - Khan, Sushmita
AU  - Knijnenburg, Bart
AU  - Vitak, Jessica
AU  - Kumar, Priya C.
AU  - Wisniewski, Pamela J.
AU  - Page, Xinru
T3  - CHI EA '23
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573816
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573816
ER  - 

TY  - CONF
TI  - Physicalization from Theory to Practice: Exploring Physicalization Design across Domains
AU  - Sauvé, Kim
AU  - Brombacher, Hans
AU  - Van Koningsbruggen, Rosa
AU  - Veldhuis, Annemiek
AU  - Houben, Steven
AU  - Alexander, Jason
T3  - CHI EA '23
AB  - Currently, physicalization research is dominated by technology-centric explorations with limited insights into the broader domain implications. The goal of this workshop is to bring together researchers and practitioners who share an interest in using data physicalizations to solve real-world problems. Hence, we aim to further explore the utility of physicalization for different domains that (already) apply data physicalization in their practices (e.g., sustainability, office vitality, education, and personal informatics). The objective of the workshop is to combine the expertise of researchers working in physicalization and/or exemplar domains to (i) develop an understanding of common challenges, (ii) map out overarching factors across domains, (ii) operationalize design strategies for common domains, and (iv) reflect on the implementation of data physicalizations for different domains. Upon completion of our workshop, we plan to create a BIT Special Issue addressing the challenges and potential directions of the domain application of data physicalizations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573824
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573824
KW  - Data Physicalization
KW  - Domain application
KW  - Education
KW  - Office Vitality
KW  - Personal Informatics
KW  - Sustainability
ER  - 

TY  - CONF
TI  - Moral Agents for Sustainable Transitions: Ethics, Politics, Design
AU  - Laschke, Matthias
AU  - Bucher, Amy
AU  - Coulton, Paul
AU  - Hassenzahl, Marc
AU  - Kuijer, Lenneke
AU  - Lallemand, Carine
AU  - Lockton, Dan
AU  - Ludden, Geke
AU  - Deterding, Sebastian
T3  - CHI EA '23
AB  - Artificial moral agents – systems that engage in explicit moral reasoning on their own and with users – present a potential new paradigm for behavior and system change for social and environmental sustainability. Moral agents could replace current individualist, prescriptive, inflexible, and opaque interventions with systems that transparently state their values and then openly deliberate and contest these with users, or agents that represent human and non-human stakeholders such as future generations, species, or ecosystems. Indeed, moral agents could mark a genuine new form of more-than-human interactions and human-technology relation, where we relate to artificial systems as a counterpart. To jointly articulate key questions and possible futures around moral agents, this workshop convenes HCI, AI, behaviour change, and critical and speculative design researchers and practitioners.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573814
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573814
KW  - artificial moral agents
KW  - behaviour change
KW  - more-than-human
KW  - sustainable HCI
ER  - 

TY  - CONF
TI  - Living Bits and Radical Aminos: A Workshop on Bio-Digital Interfaces for Human-Computer Interaction
AU  - Forman, Jack
AU  - Pataranutaporn, Pat
AU  - Gough, Phillip
AU  - Kim, Raphael
AU  - Bell, Fiona
AU  - Ofer, Netta
AU  - Lu, Jasmine
AU  - Vujic, Angela
AU  - Bai, Muqing
AU  - Maes, Pattie
AU  - Ishii, Hiroshi
AU  - Sra, Misha
T3  - CHI EA '23
AB  - As knowledge around bio-digital interaction continues to unfold, there are new opportunities for HCI researchers to integrate biology as a design and computational material. Our motivation for the workshop is to bring together interdisciplinary researchers with interest in exploring the next generation of biological HCI and exploring novel bio-digital interfaces implicating diverse contexts, scales, and stakeholders. The workshop aims to provide a space for interactive discussions, presentations, and brainstorming regarding opportunities and approaches for HCI around bio-digital interfaces. We invite researchers from both academia and industry to submit a short position paper in the following areas: Synthetic Biology, Biological Circuits, Do-It-Yourself Biology (DIYBio), Biomimetic Interfaces, Living Interfaces, Living Artefacts, and Bio-ethics. We will evaluate submissions on fit, ability to stimulate discussion, and contribution to HCI. On our website we have included examples of past work in this area to help inspire and inform position papers. Our website will host a recording of the entire workshop session with accepted papers to support asynchronous viewing for participants who are unable to attend in-person or synchronously.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573813
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573813
KW  - Bio-HCI
KW  - Biological Interfaces
KW  - Biomaterials
KW  - Biotechnology
KW  - Living Artefacts
KW  - Microbial-HCI
KW  - Microorganism
KW  - Synthetic Biology
ER  - 

TY  - CONF
TI  - Intervening, Teaming, Delegating: Creating Engaging Automation Experiences
AU  - Fröhlich, Peter
AU  - Baldauf, Matthias
AU  - Palanque, Philippe
AU  - Roto, Virpi
AU  - Paternò, Fabio
AU  - Ju, Wendy
AU  - Tscheligi, Manfred
T3  - CHI EA '23
AB  - Automated systems are becoming common in private, public and professional life. Given their increasing ubiquity and availability to a growing diversity of users, it is important to explore requirements, design principles, and user experience factors across application sectors and scientific disciplines. This workshop provides a forum for researchers and practitioners active in the field of "Automation Experience". In a keynote talk, a poster madness, discussions, and hands-on sessions, the participants will explore and discuss specific opportunities and challenges related to future forms of engagement with an increasing number of automated entities (automations). To this end, the focus topics for the workshop comprise (1) novel ways for monitoring of and intervening with increasingly intelligent agents and artifacts, (2) collaborative interaction to support teaming up and cooperation among humans and automations, and (3) orchestration and delegation of increasingly complex tasks to smart spaces. The results of the workshop are a set of research ideas and drafts of joint research initiatives to drive further automation experience research in a collaborative and interdisciplinary manner.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573799
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573799
KW  - Automation
KW  - engagement
KW  - intervention
KW  - teaming
KW  - user experience
ER  - 

TY  - CONF
TI  - Integrating Individual and Social Contexts into Self-Reflection Technologies
AU  - Bhattacharjee, Ananya
AU  - Kulzhabayeva, Dana
AU  - Reza, Mohi
AU  - Kumar, Harsh
AU  - Seong, Eunchae
AU  - Wu, Xuening
AU  - Rifat, Mohammad Rashidujjaman
AU  - Bowman, Robert
AU  - Kornfield, Rachel
AU  - Mariakakis, Alex
AU  - Ahmed, Syed Ishtiaque
AU  - De Choudhury, Munmun
AU  - Doherty, Gavin
AU  - Czerwinski, Mary P
AU  - Williams, Joseph Jay
T3  - CHI EA '23
AB  - Technology for promoting reflection can help people better understand their emotions and thought patterns, eventually motivating them to take action to adopt healthy or productive behaviors. However, existing work has often viewed users individualistically, addressing people’s behaviors and emotions rather than recognizing the external factors that shape them (e.g., economic status, culture). We envision that the individualistic approaches can be extended and reimagined in ways that can consider such broader contexts. We believe such a shift in the design of interventions will help individuals reflect in a more holistic manner, supporting collaborative reflection processes that involve more than one person. With these aims in mind, we will discuss the two questions in our workshop. First, what individual and social contexts should HCI researchers consider while promoting reflection? Second, what role can various forms of technology (e.g., just-in-time adaptive interventions, peer-support platforms) play in supporting and augmenting reflective practices? Through our workshop, we hope to bring together a community of multidisciplinary researchers and practitioners who aim to design and develop reflection interventions that are situated within the fabric of users’ individual and social contexts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573803
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573803
KW  - behavior change
KW  - mental health
KW  - psychology
KW  - reflection
KW  - social determinant
ER  - 

TY  - CONF
TI  - Integrating AI in Human-Human Collaborative Ideation
AU  - Shin, Joon Gi
AU  - Koch, Janin
AU  - Lucero, Andrés
AU  - Dalsgaard, Peter
AU  - Mackay, Wendy E.
T3  - CHI EA '23
AB  - People can generate more innovative ideas when they collaborate with one another, collectively exploring ideas and exchanging viewpoints. Advancements in artificial intelligence have opened up new opportunities in people’s creative activities where individual users ideate with diverse forms of AI. For instance, AI agents and intelligent tools have been designed as ideation partners that provide inspiration, suggest ideation methods, or generate alternative ideas. However, what AI can bring to collaborative ideation among a group of users has not been fully understood. Compared to ideating with individuals, ideating with multiple users would require understanding users’ social interaction, transforming individual efforts into a group effort, and—in the end—making users satisfied that they collaborated with other group members. This workshop aims to bring together a community of researchers and practitioners to explore the integration of AI in human-human collaborative ideation. The exploration will center around identifying the potential roles of AI as well as the process and form of collaborative ideation, considering what users want to do with AI or humans.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573802
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573802
KW  - AI agent
KW  - Collaborative ideation
KW  - Facilitator
KW  - Human-AI collaboration
KW  - Human-Human collaboration
KW  - Ideation partner
ER  - 

TY  - CONF
TI  - Identifying Challenges and Opportunities for Intelligent Data-Driven Health Interfaces to Support Ongoing Care
AU  - Knoche, Hendrik
AU  - Abdul-Rahman, Alfie
AU  - Clark, Leigh
AU  - Curcin, Vasa
AU  - Huo, Zhiqiang
AU  - Iwaya, Leonardo Horn
AU  - Lemon, Oliver
AU  - Mikulík, Robert
AU  - Neate, Timothy
AU  - Roper, Abi
AU  - Skovfoged, Milo Marsfeldt
AU  - Verdezoto, Nervo
AU  - Wilson, Stephanie
AU  - Ziadeh, Hamzah
T3  - CHI EA '23
AB  - This workshop will explore future work in the area of intelligent, conversational, data-driven health interfaces both from patients’ and health care professionals’ perspectives. We aim to bring together a diverse set of experts and stakeholders to jointly discuss the opportunities and challenges at the intersection of public health care provisioning, patient and caretaker empowerment, monitoring provisioning of health care and its quality. This will require AI-supported, conversational decision-making interfaces that adhere to ethical and privacy standards and address issues around agency, control, engagement, motivation, and accessibility. The goal of the workshop is to create a community around intelligent data-driven interfaces and create a road map for their future research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573798
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573798
KW  - agency
KW  - care pathways
KW  - clinical settings
KW  - conversational user interfaces
KW  - data sharing
KW  - data-driven interfaces
KW  - decision support
KW  - healthcare professionals
KW  - NLP
KW  - patient engagement
KW  - patient journey
KW  - patient-clinician interaction
KW  - trust
ER  - 

TY  - CONF
TI  - Human-Centered Explainable AI (HCXAI): Coming of Age
AU  - Ehsan, Upol
AU  - Wintersberger, Philipp
AU  - Watkins, Elizabeth A
AU  - Manger, Carina
AU  - Ramos, Gonzalo
AU  - Weisz, Justin D.
AU  - Daumé Iii, Hal
AU  - Riener, Andreas
AU  - Riedl, Mark O
T3  - CHI EA '23
AB  - Explainability is an essential pillar of Responsible AI that calls for equitable and ethical Human-AI interaction. Explanations are essential to hold AI systems and their producers accountable, and can serve as a means to ensure humans’ right to understand and contest AI decisions. Human-centered XAI (HCXAI) argues that there is more to making AI explainable than algorithmic transparency. Explainability of AI is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. In this third CHI workshop on Human-centered XAI (HCXAI), we build on the maturation through the first two installments to craft the coming-of-age story of HCXAI, which embodies a deeper discourse around operationalizing human-centered perspectives in XAI. We aim towards actionable interventions that recognize both affordances and potential pitfalls of XAI. The goal of the third installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we emphasize “operationalizing.” Within our research agenda for XAI, we seek actionable analysis frameworks, concrete design guidelines, transferable evaluation methods, and principles for accountability.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573832
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573832
ER  - 

TY  - CONF
TI  - HCI for Climate Change: Imagining Sustainable Futures
AU  - Mencarini, Eleonora
AU  - Bremer, Christina
AU  - Leonardi, Chiara
AU  - Liu, Jen
AU  - Nisi, Valentina
AU  - Nunes, Nuno Jardim
AU  - Soden, Robert
T3  - CHI EA '23
AB  - As the climate crisis is turning into one of the most critical issues of our time, HCI researchers keep reflecting on the role their work can play in reducing the impact of adverse environmental changes. Suggestions have been made to expand Sustainable HCI (SHCI)’s intervention area to policy design to have a larger impact, consider non-human actors’ perspective to incorporate the value of biodiversity, develop multidisciplinary competencies and work across disciplines to understand climate change, and finally make it understandable to citizens and pave the way for their action. This workshop calls to discuss the different angles from which the problem of climate change has been addressed by the CHI community so far. We believe these different angles have several contact points, and the convergence of these different perspectives would help HCI researchers better imagine sustainable futures.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573833
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573833
KW  - Climate change
KW  - Environmental data
KW  - Future scenarios
KW  - More-than-human
KW  - Policy Design
KW  - Social Justice
KW  - Sustainability
ER  - 

TY  - CONF
TI  - HCI Across Borders: Towards Global Solidarity
AU  - Cannanure, Vikram Kamath
AU  - Varghese, Delvin
AU  - Rivera-Loaiza, Cuauhtémoc
AU  - Noor, Faria
AU  - Das, Dipto
AU  - Jain, Pranjal
AU  - Chang, Meiyin
AU  - Wong-Villacres, Marisol
AU  - Karusala, Naveena
AU  - Ahmed, Nova
AU  - Till, Sarina C
AU  - Akhigbe, Bernard Ijesunor
AU  - Densmore, Melissa
AU  - Dray, Susan
AU  - Sturm, Christian
AU  - Kumar, Neha
T3  - CHI EA '23
AB  - Recent global developments, such as the war in Ukraine and uprisings in Iran, motivate this year’s HCI Across Borders (HCIxB) workshop at CHI 2023, asking how we can foster greater global solidarity. Our workshop aims to brainstorm and discuss pathways to engage in solidarity as a global research, practice, and education community. HCIxB has already gathered a diverse audience annually by conducting workshops and symposia annually since CHI 2016. At CHI 2023, we hope to hold a hybrid workshop to focus on themes of solidarity and resilience, and how we might support and nurture the growth of a diverse and growing body of students and early career researchers across the SIGCHI community.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573806
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573806
KW  - Cultural Diversity
KW  - Geographic Diversity
KW  - HCI Across Borders
KW  - HCI and Global Development
ER  - 

TY  - CONF
TI  - GenAICHI 2023: Generative AI and HCI at CHI 2023
AU  - Muller, Michael
AU  - Chilton, Lydia B
AU  - Kantosalo, Anna
AU  - Liao, Q. Vera
AU  - Maher, Mary Lou
AU  - Martin, Charles Patrick
AU  - Walsh, Greg
T3  - CHI EA '23
AB  - This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. Following a successful workshop in 2022, we convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573794
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573794
KW  - Bias
KW  - Design
KW  - Generative AI
KW  - Uncertainty.
ER  - 

TY  - CONF
TI  - Failed yet successful: Learning from discontinued civic tech initiatives
AU  - Hamm, Andrea
AU  - Shibuya, Yuya
AU  - Cerratto Pargman, Teresa
AU  - Bendor, Roy
AU  - Hansen, Nicolai Brodersen
AU  - Raetzsch, Christoph
AU  - Shoji, Masahiko
AU  - Bieber, Christoph
AU  - Hendawy, Mennatullah
AU  - Klerks, Gwen
AU  - Schouten, Ben
T3  - CHI EA '23
AB  - The design of civic tech is often confronted with impediments, barriers, and a lack of resources. These and other causes may lead to the discontinuation and even abandonment of initiatives. Since seemingly failed projects are much more difficult to publish as articles, this workshop will provide academics and practitioners with a rare opportunity to exchange experiences and insights on discontinued civic tech initiatives. The goal of the workshop is to develop a better understanding of why some civic tech initiatives fail and ask whether discontinued initiatives may still somehow contribute to social change and the growth of digital civics. A variety of sub-questions around discontinued civic tech will be addressed in the workshop, including matters of participation, citizen science, public management, power structures and biases, and communication.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573818
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573818
KW  - Bottom-up
KW  - Civic Design
KW  - Civic Tech
KW  - Digital Civics
KW  - Engaged Communities
ER  - 

TY  - CONF
TI  - Edu-larp @ CHI
AU  - Robinson, Raquel B
AU  - Johansson, Karin
AU  - Fey, James Collin
AU  - Márquez Segura, Elena
AU  - Back, Jon
AU  - Waern, Annika
AU  - Bowman, Sarah Lynne
AU  - Isbister, Katherine
T3  - CHI EA '23
AB  - Role-play has long been used as an active learning technique in educational and training contexts. In particular, Edu-larp (a structured, live action roleplay experience that teaches through social enactment and reflection [1]) has been used in therapeutic contexts, training courses, and even an entire course curriculum [4]. We propose to host a workshop at CHI 2023 which will connect CHI attendees of various disciplines interested in this topic, with the outcome to understand how edu-larp might be an effective way of augmenting existing teaching and research within HCI. During the workshop, attendees will participate in numerous edu-larp exercises designed to introduce and orient them to the concept, and facilitate discussion about the different ways edu-larp can be leveraged in the broad domain of HCI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573819
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573819
KW  - design
KW  - edu-larp
KW  - human-computer interaction
KW  - pedagogy
KW  - research
KW  - roleplay
ER  - 

TY  - CONF
TI  - Futuring (CHI)Art: Building a Collective Common Future
AU  - Lewis, Makayla
AU  - Sturdee, Miriam
AU  - Hoang, Thuong
AU  - Alaoui, Sarah Fdili
AU  - Strohmayer, Angelika
AU  - Gamboa, Mafalda
T3  - CHI EA '23
AB  - Human-Computer Interaction and the Arts have a relatively recent history, but computers have opened the world to new forms of expression and wide audiences. The way in which we think of art has changed, from webcomics and digital painting to AI-generated imagery and NFTs. However, these changes have also caused tension, and a disparity between what art is, and how it reconciles with research. This workshop aims to bring together artists and researchers to explore the current worldview of HCI and Art and speculate as to its possible, plausible, and probable futures, via discussion, collaboration, and the formation of new expressive artworks, objects, and performances. Through this process, we will also create a roadmap for a common future and imagine new ways of sharing this dual practice with the SIGCHI community and beyond.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573791
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573791
KW  - Art
KW  - comics
KW  - craft
KW  - dance
KW  - design fiction
KW  - drawing
KW  - futuring
KW  - making
KW  - painting
KW  - photography
KW  - sewing
KW  - sketching
ER  - 

TY  - CONF
TI  - EduCHI 2023: 5th Annual Symposium on HCI Education
AU  - Gray, Colin M.
AU  - Macdonald, Craig M.
AU  - Lallemand, Carine
AU  - Oleson, Alannah
AU  - Carter, Anna R. L.
AU  - St-Cyr, Olivier
AU  - Pitt, Caroline
T3  - CHI EA '23
AB  - EduCHI 2023 will bring together an international community of scholars, practitioners, and researchers to shape the future of Human–Computer Interaction (HCI) education. Held as part of the CHI 2023 conference, the one-day symposium will feature interactive discussions about HCI educational research, pedagogical innovations, teaching practices, and current and future challenges facing HCI educators. In addition to providing a platform to share pedagogical strategies and continue to build a scholarly knowledge base for HCI education, EduCHI 2023 will also provide opportunities for HCI educators to learn new instructional strategies and deepen their pedagogical knowledge.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573790
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573790
KW  - Community of Practice
KW  - design and technology education
KW  - HCI education
KW  - HCI pedagogy
ER  - 

TY  - CONF
TI  - Digital Skills for the Creative Practitioner: Supporting Informal Learning of Technologies for Creativity
AU  - Helgason, Ingi
AU  - Smyth, Michael
AU  - Panneels, Inge
AU  - Lechelt, Susan
AU  - Frich, Jonas
AU  - Rawn, Eric
AU  - Mccarthy, Bronnie
T3  - CHI EA '23
AB  - The creative industries play an important role in economic, cultural and social life, and in many creative disciplines much of the workforce is made up of individual practitioners including freelancers, sole traders and small or micro enterprises. These talented creatives often need to be responsible for their own ongoing learning within challenging and ever-evolving digital and technological domains. Whether their creative practice is primarily analogue or digital, Creativity Support Tools (CSTs) and digital platforms are being adopted for use in many phases of the creative production and dissemination process. By necessity, much of the learning that creatives undertake during the adoption of technologies is self-directed, informal, and often involves peer-to-peer support. This is an important contextual factor that HCI research needs to address when developing tools and support systems for this user group. This one-day workshop will bring together participants from the HCI, creative and educational communities to discuss and share knowledge of technology learning and skills acquisition for working creatives. The workshop aims to examine ideas, strategies and experiences around supporting digital literacy, competency and confidence. The goal is to develop further collaborative research addressing support structures and frameworks in the area of informal learning about digital creativity tools for working practitioners.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573825
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573825
KW  - Creative Industries
KW  - Creative Practice
KW  - Creativity Support Tools
KW  - Digital Skills
ER  - 

TY  - CONF
TI  - Designing Technology and Policy Simultaneously: Towards A Research Agenda and New Practice
AU  - Yang, Qian
AU  - Wong, Richmond Y.
AU  - Gilbert, Thomas
AU  - Hagan, Margaret D.
AU  - Jackson, Steven
AU  - Junginger, Sabine
AU  - Zimmerman, John
T3  - CHI EA '23
AB  - Accounting for technologies’ unintended consequences—whether they are misinformation on social media or issues of sustainability and social justice—increasingly requires HCI to consider technology design at a societal-level scale. At this scale, public and corporate policies play a critical role in shaping technologies and user behaviors. However, the research and practices around tech and policy design have largely been held separate. How can technology design and policies better inform and coordinate with each other in generating safe new technologies? What new solutions might emerge when HCI practitioners design technology and its policies simultaneously to account for its societal impacts? This workshop addresses these questions. It will 1) identify disciplines and areas of expertise needed for a tighter, more proactive technology-and-policy-design integration, 2) launch a community of researchers, educators, and designers interested in this integration, 3) identify and publish an HCI research and education agenda towards designing technologies and technology policies simultaneously.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573827
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573827
ER  - 

TY  - CONF
TI  - Diverse Migration Journeys and Security Practices: Engaging with Longitudinal Perspectives of Migration and (Digital) Security
AU  - Abu-Salma, Ruba
AU  - Talhouk, Reem
AU  - Such, Jose
AU  - Aradau, Claudia
AU  - Meloni, Francesca
AU  - He, Shijing
AU  - Ahmed, Syed Ishtiaque
AU  - Ekmekcioglu, Cansu
AU  - Sabie, Dina
AU  - Jensen, Rikke Bjerg
AU  - McClearn, Jessica
AU  - Weibert, Anne
AU  - Krüger, Max
AU  - Hussain, Faheem
AU  - Baguma, Rehema
T3  - CHI EA '23
AB  - There has been a growing body of work on migration within the HCI community, as well as within the social science and public policy communities. More specifically, human-centered security researchers have been exploring the needs and concerns of migrants, starting to contend with the harms created by digital technologies and experienced by those who are and have been marginalized. Case studies through which migration and (digital) security within the HCI domain intersect have been localized to specific contexts such as, e.g., particular issues related to data processing and sharing in refugee camps, or a narrow set of security threats and harms experienced by migrant workers in their new places of work. However, more holistic approaches to understanding the intersections of migration and (digital) security are yet to be fully explored while accounting for the past (including home country security practices, use of localized digital technologies, and interactions with technologies throughout the migration journey), the present (current security practices and experiences in the place or country migrants are situated), and the future migrants are trying to secure for themselves and their families. This workshop aims to build a community of HCI researchers interested in how migration and (digital) security intersect to braid together research narratives, perspectives, and methods, design for inclusive technologies, and build an agenda for future research and practice.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573800
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573800
ER  - 

TY  - CONF
TI  - Data as a Material for Design: Alternative Narratives, Divergent Pathways, and Future Directions
AU  - Lee-Smith, Matthew L.
AU  - Benjamin, Jesse Josua
AU  - Desjardins, Audrey
AU  - Funk, Mathias
AU  - Odom, William
AU  - Oogjes, Doenja
AU  - Park, Young-Woo
AU  - Pierce, James
AU  - Sanches, Pedro
AU  - Tsaknaki, Vasiliki
T3  - CHI EA '23
AB  - This one-day workshop will bring together a diverse group of practitioners and researchers within the CHI community to discuss and explore data's increasing use as a material for design. This workshop encourages the submission of design exemplars, i.e., physical or digital works (in progress), design processes, or provocative or controversial pieces on the topic of data as a design material. If we are to continue to explore what data means as a design material and how we will continue to co-exist with them in our everyday lives through new and exciting ways and means, we must develop new strategies, tactics, tools, and outcomes. By bringing together products, processes, and provocations, this workshop will nurture and extend the continuation of research inquiring into data as a design material in its many forms. Our workshop will be conducted through physical and digital activities before, during, and after the onsite event at CHI 2023.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573817
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573817
KW  - Data Narratives
KW  - Human-Data Interaction
KW  - Material for Design
KW  - Research through Design
ER  - 

TY  - CONF
TI  - CUI@CHI: Inclusive Design of CUIs Across Modalities and Mobilities
AU  - Sin, Jaisie
AU  - Candello, Heloisa
AU  - Clark, Leigh
AU  - Cowan, Benjamin R.
AU  - Lee, Minha
AU  - Munteanu, Cosmin
AU  - Porcheron, Martin
AU  - Völkel, Sarah Theres
AU  - Branham, Stacy
AU  - Brewer, Robin N.
AU  - Chaves, Ana Paula
AU  - Jaber, Razan
AU  - Lazar, Amanda
T3  - CHI EA '23
AB  - Conversational user interfaces (CUIs) are often advertised to be accessible and easy-to-use, yet it is still not known how to make them fully inclusive and acceptable for all of their potential users, especially for those who may stand to benefit the most from CUIs. This workshop is the latest installment of a workshop series on conversational user interfaces &nbsp;[15, 20] and will bring together scholars, practitioners, and researchers to discuss the state of CUI design for marginalized and vulnerable populations, how inclusive design is considered (or neglected) in current CUI design practice, and how to move forward when it comes to designing CUIs for inclusion and diversity. Our aim is to spark vigorous and interesting discussions from multiple perspectives on issues related to inclusive design, marginalization, and the benefits and harms of CUIs. We aim for this workshop to serve as a platform on which to build a community and determine future directions to tackle important topics of inclusivity and equity in CUI design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573820
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573820
KW  - conversational user interface
KW  - CUI
KW  - digital design marginalization
KW  - inclusive design
KW  - intelligent personal assistants
KW  - speech interface
KW  - voice user interface
ER  - 

TY  - CONF
TI  - Collective Healing to Support Design Futures: Building Community and Exploring Methods
AU  - Wieczorek, Catherine
AU  - Biggs, Heidi
AU  - Jack, Margaret C
AU  - Forlano, Laura
AU  - Bardzell, Shaowen
T3  - CHI EA '23
AB  - This workshop explores the role of healing ourselves as a key aspect for transformative social change. It brings together social justice and community based work in HCI that engages with healing and joy to expand on current methodologies such as autoethnography, somaesthetics, and embodied design which aim to describe different ways of knowing and describing and living experiences as inputs for design futuring. Our concern of interest is the ways in which all of us have lived through continuous community grief and loss due to the ongoing COVID-19 pandemic and a continued climate crisis; and the resulting symptoms like anxiety, depression, body pain, and scattered focus. We believe that we must acknowledge these experiences and feelings about these events in order to effectively work towards more optimistic futures. This workshop takes the space and time to consider our recent collective traumas and explore how to integrate them into futures that support the development of futures that fit our emotional, ethical, social and physical needs. Our aim is to build a greater understanding of how the CHI community can integrate healing in support of social change.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573810
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573810
KW  - Design
KW  - futures
KW  - politics
KW  - social justice
ER  - 

TY  - CONF
TI  - Combating Toxicity, Harassment, and Abuse in Online Social Spaces: A Workshop at CHI 2023
AU  - Mandryk, Regan L
AU  - Frommel, Julian
AU  - Goyal, Nitesh
AU  - Freeman, Guo
AU  - Lampe, Cliff
AU  - Vieweg, Sarah
AU  - Wohn, Donghee Yvette
T3  - CHI EA '23
AB  - Online social spaces provide much needed connection and belonging—particularly in a context of continued lack of global mobility due to the ongoing Covid-19 pandemic and climate crisis. However, the norms of online social spaces can create environments in which toxic behaviour is normalized, tolerated or even celebrated. This can occur without consequence, leaving its members vulnerable to hate, harassment, and abuse. A vast majority of adults have experienced toxicity online and the harm is even more prevalent for members of marginalized and minoritized groups, who are more often the targets of online abuse. Although there is significant work on toxicity in the SIGCHI community, approaches and knowledge have typically been siloed by the domain of investigation (e.g., social media, multiplayer games, social VR). We argue that cross-disciplinary efforts will benefit not only the various communities and situations in which abuse occurs, but that bringing together researchers from different backgrounds and specialties will provide a robust and rich understanding of how to tackle online toxicity at scale.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573793
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573793
KW  - abuse
KW  - doxxing
KW  - flaming
KW  - griefing
KW  - harassment
KW  - hate speech
KW  - metaverse
KW  - multiplayer games
KW  - social media
KW  - social VR
KW  - toxicity
KW  - trolling
ER  - 

TY  - CONF
TI  - Bridging HCI and Implementation Science for Innovation Adoption and Public Health Impact
AU  - Lyon, Aaron
AU  - Munson, Sean A.
AU  - Reddy, Madhu
AU  - Schueller, Stephen M.
AU  - Agapie, Elena
AU  - Yarosh, Svetlana
AU  - Dopp, Alex
AU  - von Thiele Schwarz, Ulrica
AU  - Doherty, Gavin
AU  - Graham, Andrea K
AU  - Kruzan, Kaylee Payne
AU  - Kornfield, Rachel
T3  - CHI EA '23
AB  - Human computer interaction (HCI) and implementation science (IS) each have been applied to improve the adoption and delivery of innovative health interventions, and the two fields have complementary goals, foci, and methods. While the IS community increasingly draws on methods from HCI, there are many unrealized opportunities for HCI to draw from IS and to catalyze bidirectional collaborations. This workshop will explore similarities and differences between fields, with a goal of articulating a research agenda at their intersection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574132
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574132
KW  - health
KW  - impact
KW  - implementation science
KW  - translational science
ER  - 

TY  - CONF
TI  - Body x Materials: A workshop exploring the role of material-enabled body-based multisensory experiences
AU  - Petreca, Bruna Beatriz
AU  - Tajadura-Jiménez, Ana
AU  - Turmo Vidal, Laia
AU  - Nascimento, Ricardo O
AU  - Seifi, Hasti
AU  - Ley-Flores, Judith
AU  - Singh, Aneesha
AU  - Berthouze, Nadia
AU  - Obrist, Marianna
AU  - Baurley, Sharon
T3  - CHI EA '23
AB  - Over the last 15 years, HCI and Interaction Design have experienced a “material turn” characterized by a growing interest in the materiality of technology and computation, and in methods that support exploring, envisioning, and crafting with and through materials. The community has experienced a similar turn focused on the body, on how to best design for and from a first-person, lived experience, and the moving and sensual body. In this workshop, we focus on the intersection of these two turns. The emerging developments in multimodal interfaces open opportunities to bring in materiality to the digital world as well as to transform the materiality of objects and bodies in the real-world, including the materiality of our own bodies. The different sensory qualities of (touchable and untouchable, physical and digital) objects and bodies, including our own, can be brought into the design of digital technologies to enrich, augment, and transform embodied experiences. In this “materials revolution” [15], what are the current theories, approaches, methods, and tools that emphasize the critical role of materiality to body-based interactions with technology? To explore this, in this workshop we will focus on five related themes: material enabling expression, material as a catalyst for human action, material enabling reflection and awareness, material enabling transformation and material supporting the design process for the re-creation of the existing and the yet-to-exist. This workshop with technology presentations, panel sessions with experts, and multidisciplinary discussions will: (i) bring together researchers who work on (re)creating sensory properties of materials through technology with those who investigate experiential effects of materials and material-enabled interactions, (ii) discuss methods, opportunities, difficulties in designing materiality and material-enabled interactions, and (iii) form a multidisciplinary community to build synergies and collaborations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573807
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573807
ER  - 

TY  - CONF
TI  - Child-Centred AI Design: Definition, Operation, and Considerations
AU  - Wang, Ge
AU  - Sun, Kaiwen
AU  - Atabey, Ayça
AU  - Pothong, Kruakae
AU  - Lin, Grace C.
AU  - Zhao, Jun
AU  - Yip, Jason
T3  - CHI EA '23
AB  - AI systems and related algorithms are starting to play a variety of roles in the digital ecosystems of children - being embedded in the connected toys, smart home IoT technologies, apps, and services they interact with on a daily basis. Going forward, AI systems will, in all likelihood, become even more pervasive in children’s applications simply due to their sheer usefulness in creating compelling, adaptive, and personal user experiences. Yet, understanding the ways that AI-driven systems used by children operate, and how AI could be designed to better anticipate and respond to children’s diverse requirements is still a new and emerging area of investigation. Our goals of this workshop are to (1) extend the current critically constructive dialogue around the meaning of child-centred AI design and (2) explore ways to operationalise such child-centred AI design in practice, and finally (3) further expand and foster a community for those who are interested in designing and developing child-centred AI systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573821
KW  - Child-Centred AI design
KW  - child-computer interaction
ER  - 

TY  - CONF
TI  - Building Credibility, Trust, and Safety on Video-Sharing Platforms
AU  - Niu, Shuo
AU  - Lu, Zhicong
AU  - Zhang, Amy X.
AU  - Cai, Jie
AU  - Griggio, Carla F.
AU  - Heuer, Hendrik
T3  - CHI EA '23
AB  - Video-sharing platforms (VSPs) such as YouTube, TikTok, and Twitch attract millions of users and have become influential information sources, especially among the young generation. Video creators and live streamers make videos to engage viewers and form online communities. VSP celebrities obtain monetary benefits through monetization programs and affiliated markets. However, there is a growing concern that user-generated videos are becoming a vehicle for spreading misinformation and controversial content. Creators may make inappropriate content for attention and financial benefits. Some other creators also face harassment and attack. This workshop seeks to bring together a group of HCI scholars to brainstorm technical and design solutions to improve the credibility, trust, and safety of VSPs. We aim to discuss and identify research directions for technology design, policy-making, and platform services for video-sharing platforms.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573809
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573809
KW  - credibility
KW  - disinformation
KW  - misinformation
KW  - monetization
KW  - safety
KW  - TikTok
KW  - trust
KW  - Twitch
KW  - videos
KW  - YouTube
ER  - 

TY  - CONF
TI  - Bridging Distances for Global Participation: Conducting and Theorizing Participatory Design and Research in Hybrid Contexts: Conducting and Theorizing Participatory Design and Research in Hybrid Contexts
AU  - Luusua, Aale
AU  - Ylipulli, Johanna
AU  - Kalarikalayil Raju, Dani
AU  - Rönkkö, Emilia
T3  - CHI EA '23
AB  - Participatory Design (PD) must increasingly be able to serve various global contexts. Overall, a fundamental need has been identified in the PD community to raise previously unheard global voices in design and development work, and to bring various underrepresented stakeholders together. On the other hand, the rapid adoption of various synchronous and asynchronous communication methods through collaborative online tools offers opportunities for more dispersed and more diverse PD research teams, settings and processes. This raises new possibilities for bridging global distances and bringing various stakeholders together for the purposes of conducting multicultural, multi-site PD. Importantly, while there exists extensive research literatures both on PD, on remote ethnography and on Computer-Supported Collaborative Work, we posit that these literatures have not been brought together; nor have the practices and methodologies of these communities been sufficiently jointly explored to support the goals of multisite, multicultural PD. In this workshop, we strive to bridge this gap in knowledge through exploring the opportunities of conducting hybrid multi-site Participatory Design (HMPD) research through synchronous and asynchronous present–telepresent participatory methods, and to share issues, challenges, opportunities, methods and empirical examples pertaining to this as a goal.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573823
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573823
KW  - Distance work
KW  - Global North
KW  - Global South
KW  - Hybrid research settings
KW  - Participatory design
KW  - Participatory methodology
KW  - Remote ethnography
ER  - 

TY  - CONF
TI  - Beyond prototyping boards: future paradigms for electronics toolkits
AU  - Bianchi, Andrea
AU  - Hodges, Steve
AU  - Cuartielles, David J.
AU  - Oh, Hyunjoo
AU  - Lambrichts, Mannu
AU  - Roudaut, Anne
T3  - CHI EA '23
AB  - Electronics prototyping platforms such as Arduino enable a wide variety of creators with and without an engineering background to rapidly and inexpensively create interactive prototypes. By opening up the process of prototyping to more creators, and by making it cheaper and quicker, prototyping platforms and toolkits have undoubtedly shaped the HCI community. With this workshop, we aim to understand how recent trends in technology, from reprogrammable digital and analog arrays to printed electronics, and from metamaterials to neurally-inspired processors, might be leveraged in future prototyping platforms and toolkits. Our goal is to go beyond the well-established paradigm of mainstream microcontroller boards, leveraging the more diverse set of technologies that already exist but to date have remained relatively niche. What is the future of electronics prototyping toolkits? How will these tools fit in the current ecosystem? What are the new opportunities for research and commercialization?
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573792
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573792
KW  - electronics
KW  - physical computing
KW  - prototyping
KW  - toolkits
ER  - 

TY  - CONF
TI  - Behind the Scenes of Automation: Ghostly Care-Work, Maintenance, and Interferences: Exploring participatory practices and methods to uncover the ghostly presence of humans and human labor in automation
AU  - Boeva, Yana
AU  - Berger, Arne
AU  - Bischof, Andreas
AU  - Doggett, Olivia
AU  - Heuer, Hendrik
AU  - Jarke, Juliane
AU  - Treusch, Pat
AU  - Søraa, Roger Andre
AU  - Tacheva, Zhasmina
AU  - Voigt, Maja-Lee
T3  - CHI EA '23
AB  - Industry and media have long represented automation as a harbinger of development and convenience in different areas of life. An anxious prospect to some, automation systems promise “progress” and profitability to others by conjuring corporate computational futures. What remains behind the scenes of these predictions and imaginaries of automation is the invisible human labor of global ghost workers caring for, maintaining, and repairing technologies. Invisible but irreplaceable, computation performed by humans in precarious conditions fills gaps that computer technologies lack skills and sensibility for. In this hybrid workshop, we ask who the “ghosts” are in the machines. The workshop will address the ghostly presence of humans and human labor in automation and its challenges to HCI research and design.&nbsp;
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573830
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573830
KW  - Automation
KW  - Design Fiction
KW  - Ghost work
KW  - Labor
ER  - 

TY  - CONF
TI  - Behavioural Design in Video Games: Ethical, Legal, and Health Impact on Players
AU  - Birk, Max V.
AU  - Van Der Hof, Simone
AU  - Hodent, Celia
AU  - Gerling, Kathrin
AU  - Van Rooij, Antonius J.
T3  - CHI EA '23
AB  - Video games use behavioural design strategies, i.e., dark patterns, to increase engagement and drive revenue. These practices affect consumer behaviour, e.g., lead to extended playtime, and subsequently health, such as social well-being. HCI approaches such as motivational design or personalization are central to behavioural design strategies. Some approaches, e.g., in-game messages to guilt trip users, are ethically and legally questionable. In this workshop, we explore the ethical, health, and legal implications of behavioural design strategies. Our workshop aims to integrate interdisciplinary viewpoints, to co-develop a road map to address behavioural design, and collect contemporary perspectives on the issue. Participants will take away knowledge from different expert perspectives, concrete steps to address the impact of behavioural design, and a multidisciplinary expert network that will tackle existing and emerging future challenges.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573801
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573801
KW  - behavioural design
KW  - consumer health
KW  - video games
ER  - 

TY  - CONF
TI  - Asian CHI Symposium: HCI Research from Asia and on Asian Contexts and Cultures
AU  - Ghazali, Masitah
AU  - Sari, Eunice
AU  - Tedjasaputra, Josh (Adi)
AU  - Wong, Chui Yin
AU  - Ong, Ethel
AU  - Binti Mohd Norowi, Noris
AU  - Abu Bakar, Juliana Aida
AU  - Kurniawan, Yohannes
AU  - Zulaikha, Ellya
AU  - Asfarian, Auzi
T3  - CHI EA '23
AB  - The Asian CHI symposium is an annual event organized by researchers and practitioners in Asia. The symposium aims to bring together both early-career and senior HCI academia and UX practitioners from industries in Asia and bring about cross-exchange of information and transfer of knowledge in a multidisciplinary environment and multi-socio-economic aspects of HCI research and also foster social ties and collaboration in the field of HCI. Beyond showcasing the latest Asian-inspired HCI work and those focusing on incorporating Asian sociocultural factors in their design, implementation, evaluation, and improvement, the Asian CHI Symposium 2023 is a sandbox for academically rigorous discourse platform for both HCI academic and UX practitioners to present their latest research findings and solutions that reflect the expansion of HCI theory and applications towards culturally inclusive design for diverse audiences in Asia. In addition to circulating ideas and envisioning future research in HCI, this symposium aims to foster social networks among academics (researchers and students) and practitioners and grow a research community from Asia.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573797
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573797
KW  - Asia
KW  - Interaction design
KW  - Interaction techniques
KW  - Interactive systems
KW  - Technology design
KW  - User interfaces
ER  - 

TY  - CONF
TI  - Advancing HCI Research and Education within and across South Asia
AU  - Gamage, Dilrukshi
AU  - Wani, Asra Sakeen
AU  - Jain, Pranjal
AU  - Padhi, Deepak Ranjan
AU  - Borah, Pranjal Protim
AU  - Menon, Ambika R
AU  - Mishra, Wricha
AU  - Ahmad, Muneeb
AU  - Ahmed, Nova
AU  - Sarcar, Sayan
AU  - Shahid, Suleman
AU  - Balkrishan, Devanuj Kanta
T3  - CHI EA '23
AB  - With the advancements in technologies, the need for Human’s perspective and human-centered designs are in much demand and its essential to understand diverse cultural needs. The community in South Asia has been recognized to have a unique and diverse socio-cultural, political, infrastructural, and geographical background of the region. However, we continue to see that the studies presented to the CHI community about South Asia primarily focus on working with and unpacking the regional contextual constraints (of the users and the infrastructures), thus taking a developmental stance. We witness a lack of HCI work presented by South Asian research community promoting diverse methods, cultures and behaviors. We believe this is due to limited experience in the field and resources. In this online workshop, we take advanced steps to operationalize collaborations and resource sharing between HCI researchers by presenting their half-baked ideas, presenting published HCI work on other venues, or even sharing challenges faced in a Rejected HCI work in the context of South Asia. Our aim is to broaden the perspective of the CHI research and community towards the contributions from the region including and beyond development, by bringing together researchers, designers, and practitioners working or are interested in working within these regions on diverse topics.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573815
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573815
KW  - Beyond development
KW  - HCI
KW  - South Asia
KW  - Vision building
ER  - 

TY  - CONF
TI  - “You’re not smart enough for it. You can’t do it anyway.” - Experiences and Coping Strategies of Female System Administrators
AU  - Bumiller, Franziska
AU  - Eichenmüller, Christian
AU  - Benenson, Zinaida
T3  - CHI EA '23
AB  - The profession of system administration is currently very male-dominated. This is also reflected in research on system administrators which largely relies on male-dominated samples as well. We conducted and analyzed 8 interviews with female system administrators working in Germany and investigated the experiences they encounter in their professional and private environments. Our findings show that female system administrators make negative as well as positive gender-specific experiences. To deal with the negative experiences the female system administrators have developed certain coping strategies. These include adapting to their male-dominated environment in terms of language and dress choices, confronting misbehaving colleagues or clients and even exploiting existing gender stereotypes to their advantage. Furthermore, our results highlight the huge impact that both professional and personal environment can have on female system administrators.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585648
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585648
KW  - gender
KW  - qualitative interviews
KW  - sysadmin
KW  - system administration
ER  - 

TY  - CONF
TI  - “You said da da...”: A Short Echoing Tweak for Journaling with VA
AU  - Ryou, Jisu
AU  - Lee, Kihun
AU  - Lee, Joongseek
T3  - CHI EA '23
AB  - AI and deep learning have enabled development of voice agents (VAs) and conversational agents (CAs) for more varied uses, including audio journaling which requires longer, more nuanced conversations. Current technology is capable of utilizing additional data, but VAs still remain limited to single-turn, task-oriented interactions. In this study, we investigate whether current turn-taking system is suitable for interactions with long speech in the form of audio journaling, and suggest ways that would make VAs more appropriate to handle longer sentences and turns by the user. To this end, we designed three types of responses, Empathetic, Reading-back, and Mixed, which all echo the user’s speech in different ways. From a week-long journaling experiment with 23 subjects, we collected long speech data (average number of syllables: Empathetic=425, Reading-back=438, Mixed=304). The most effective response in this case is a Reading-back in terms of quality of data and journaling experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585901
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585901
KW  - audio journaling
KW  - interruption
KW  - multi-turn
KW  - turn-taking
KW  - Voice Agent (VA)
ER  - 

TY  - CONF
TI  - AI Literacy: Finding Common Threads between Education, Design, Policy, and Explainability
AU  - Long, Duri
AU  - Roberts, Jessica
AU  - Magerko, Brian
AU  - Holstein, Kenneth
AU  - DiPaola, Daniella
AU  - Martin, Fred
T3  - CHI EA '23
AB  - Fostering public AI literacy has been a growing area of interest at CHI for several years, and a substantial community is forming around issues such as teaching children how to build and program AI systems, designing learning experiences to broaden public understanding of AI, developing explainable AI systems, understanding how novices make sense of AI, and exploring the relationship between public policy, ethics, and AI literacy. Previous workshops related to AI literacy have been held at other conferences (e.g., SIGCSE, AAAI) that have been mostly focused on bringing together researchers and educators interested in AI education in K-12 classroom environments, an important subfield of this area. Our workshop seeks to cast a wider net that encompasses both HCI research related to introducing AI in K-12 education and also HCI research that is concerned with issues of AI literacy more broadly, including adult education, interactions with AI in the workplace, understanding how users make sense of and learn about AI systems, research on developing explainable AI (XAI) for non-expert users, and public policy issues related to AI literacy.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573808
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573808
KW  - AI education
KW  - AI ethics
KW  - AI literacy
KW  - AI4K12
KW  - explainable AI
KW  - public policy
ER  - 

TY  - CONF
TI  - Zoo Visitors’ Initial Assessment of an Animaloid Robot as a Zoo Exhibit
AU  - dos Santos, Robin
AU  - Eßmann, Kai
AU  - Fartmann, Niklas
AU  - Meier, Heiko
AU  - Sandberg, Eric
AU  - Schulze, Alexander
AU  - Luzar, Sven
AU  - Bauer, Gernot
T3  - CHI EA '23
AB  - Animaloid robots currently have few to no applications other than as a toy in private contexts or as an operational tool in rescue scenarios. A potential further field of use could be zoos, e.g. to offer an additional attraction, to substitute sick animals, to replace already extinct species or to fulfill a certain educational mission. In order to investigate such purposes an animaloid walking robot was exhibited unannounced in an enclosure of a city’s large zoo. Interviews with visitors were conducted in order to answer two research questions: Is an animaloid robot suitable as a zoo exhibit from the visitors’ point of view? How do the visitors to a zoo perceive and judge an animaloid robot? The evaluation showed that according to the visitors, the robot, although not perceived as an animal, is considered just as much an attraction and equally suitable as an object of observation in a zoo.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585762
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585762
KW  - animaloid robotics
KW  - human-robot interaction
KW  - zoo
ER  - 

TY  - CONF
TI  - Wow! I Have Tiny Hands: Design And Evaluation Of Adaptive Virtual Hands For Small Object Selection Within Arms Length In Dense Virtual Environment
AU  - Bhowmick, Shimmila
AU  - Biswas, Nilotpal
AU  - Kalita, Pratul Chandra
AU  - Sorathia, Keyur
T3  - CHI EA '23
AB  - Object selection is essential to VR applications, but selecting small objects within arms’ reach in dense virtual environments can be challenging. We introduce Tiny Hands, which allows reducing the size of the dominant virtual hand in immersive VR to navigate efficiently and accurately select the desired object. This study compares the tiny hands technique with ray casting and pinch-to-select techniques. Our results indicate that the tiny hands technique is significantly faster and more accurate than the other two techniques. It is also significantly easier to use and learn, perceived as natural, playful, and the most preferred technique. Participants appreciated its ability to resize virtual hands for selecting small objects and ease in navigating a dense VE. They also liked its similarity to mouse and cursor-based interactions and flexibility in adjusting hand size according to various object sizes. Participants perceived tiny hands as potentially fatigued for prolonged use and reported a sense of incorrect depth perception when hand sizes are too small.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585686
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585686
KW  - Dense virtual environment
KW  - Object selection
KW  - Selection technique
KW  - Small objects
ER  - 

TY  - CONF
TI  - You Know What I’m Saying: Designing Conversational Strategies of AI Agent for Tip of the Tongue Phenomenon
AU  - Ha, Juhye
AU  - Lee, Dayoung
AU  - Oh, Changhoon
T3  - CHI EA '23
AB  - The phenomenon of being unable to recall a specific word or term from memory is called “tip-of-the-tongue” (TOT). Despite its significance, potential applications for solving TOT from the user experience (UX) and human–computer interface (HCI) perspectives are yet to be fully explored. With the advent of advanced artificial intelligence (AI) interfaces and technologies, new opportunities have emerged to address TOT. This study aims to investigate the applicability of AI in addressing TOT and the roles of conversation design strategies in mitigating this phenomenon. To this end, we developed a prototype called “Tip-pong,” which is a turn-taking user interface that provides semantic and episodic clues, as well as targeted and optional answers to assist users in resolving TOT. Through a quantitative and qualitative study involving 23 participants, we evaluated the prototype and found that while the type of clue had no significant impact on usability, users preferred optional answers over targeted answers. Additionally, we found that allowing users to experience the process of approaching the answer on their own was more effective than providing the correct answer immediately. Based on these findings, we discuss the design implications for the development of AI agents to solve TOT in everyday life.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585670
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585670
KW  - Conversational agent
KW  - meta-cognition
KW  - priming effect
KW  - tip of the tongue
ER  - 

TY  - CONF
TI  - Xpandables: Single-filament Multi-property 3D Printing by Programmable Foaming
AU  - Ozdemir, Mehmet
AU  - Doubrovski, Zjenja
T3  - CHI EA '23
AB  - We propose a new approach to obtain local property variations in 3D-printed objects using a single-nozzle 3D printer and one filament. We use foaming filaments which expand at different rates due to different temperatures. We present an approach to harness this varying expansion by including parameters of the 3D printing process in the design space. This makes the foaming programmable and allows for achieving a wide variety of properties from a single material. We show how objects with locally varying shade, translucency, gloss, and texture can be fabricated. Our approach turns single-nozzle 3D printers into more versatile systems while eliminating the challenges of multi-material 3D printing. This is in contrast to the drive towards an increasing number of printable materials and more complex 3D printers. We demonstrate the capability of our approach by 3D printing objects with embedded barcodes, QR codes, and varying tactile properties.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585731
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585731
KW  - 3D printing
KW  - digital fabrication
KW  - foaming filaments
KW  - personal fabrication
ER  - 

TY  - CONF
TI  - Workplace Rhythm Variability and Emotional Distress in Information Workers
AU  - Nepal, Subigya Kumar
AU  - Hernandez, Javier
AU  - Amores Fernandez, Judith
AU  - Bin Morshed, Mehrab
AU  - Lewis, Robert
AU  - Prafullchandra, Hemma
AU  - Czerwinski, Mary P
T3  - CHI EA '23
AB  - Regularity in daily activities has been linked to positive well-being outcomes, but previous studies have mainly focused on clinical populations and traditional daily activities such as sleep and exercise. This research extends prior work by examining the regularity of both self-reported and digital activities of 49 information workers in a 4-week naturalistic study. Our findings suggest that greater variability in self-reported mood, job demands, lunch time, and sleep quality may be associated with increased stress, anxiety, and depression. However, when it comes to digital activity-based measures, greater variability in rhythm is associated with reduced emotional distress. This study expands our understanding of workers and the potential insights that can be gained from analyzing technology interactions and well-being.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585626
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585626
KW  - Future of Work
KW  - Information Workers
KW  - Passive Sensing
KW  - Regularity
KW  - Routine
KW  - Social Computing
KW  - Well-being
KW  - Workplace Rhythm
ER  - 

TY  - CONF
TI  - What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions
AU  - Huang, Shih-Hong
AU  - Huang, Chieh-Yang
AU  - Lin, Ya-Fang
AU  - Huang, Ting-Hao Kenneth
T3  - CHI EA '23
AB  - The proliferation of automated conversational systems such as chatbots, spoken-dialogue systems, and smart speakers, has significantly impacted modern digital life. However, these systems are primarily designed to provide answers to well-defined questions rather than to support users in exploring complex, ill-defined questions. In this paper, we aim to push the boundaries of conversational systems by examining the types of nebulous, open-ended questions that can best be answered through conversation. We first sampled 500 questions from one million open-ended requests posted on AskReddit, and then recruited online crowd workers to answer eight inquiries about these questions. We also performed open coding to categorize the questions into 27 different domains. We found that the issues people believe require conversation to resolve satisfactorily are highly social and personal. Our work provides insights into how future research could be geared to align with users’ needs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585600
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585600
KW  - Conversational Systems
KW  - Question Answering
KW  - Reddit
ER  - 

TY  - CONF
TI  - WebJump: AR-facilitated Distributed Display of Web Pages
AU  - Zeng, Xin
AU  - Wang, Xiaoyu
AU  - Gou, Zhengtai
AU  - Chen, Yiqiang
AU  - Zhang, Tengxiang
T3  - CHI EA '23
AB  - Head-mounted displays (HMD) like AR glasses support powerful 3D displays and intuitive input modalities. However, there is a lack of collaboration between the HMD and other displays like PC monitors. In this paper, we propose WebJump, a software tool that analyzes HTML web pages and enables UI elements ‘jump’ from the PC monitor to the HMD. This way, contents like high-resolution images and long texts can take full advantage of the high-quality monitor display. Auxiliary contents like sidebars and menus, on the other hand, are offloaded to the HMD for easier access albeit with a lower display quality. We describe our software tool and explain in detail its implementation. We develop two applications to demonstrate WebJump’s feasibility and potential.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585669
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585669
KW  - distributed display
KW  - mixed reality
KW  - web pages
ER  - 

TY  - CONF
TI  - VRtoER: When Virtual Reality leads to Accidents: A Community on Reddit as Lens to Insights about VR Safety
AU  - Jelonek, Markus
T3  - CHI EA '23
AB  - Virtual Reality (VR) has gained a relevant market share as a product for consumers in the gaming industry. Compared to other hardware, VR headsets isolate users from reality visually to create immersive experiences. However, when not used correctly, VR can lead to accidents, for instance, when colliding with objects in the real environment. A community on Reddit has formed around the topic of VR-related accidents and injuries called r/VRtoER, in which users upload media of accidents and injuries through the use of VR. 82 posts of the community were analyzed to understand 1) the cause for the accident, 2) why it happened, and 3) how it could be prevented. Preliminary findings are presented based on the analysis. The results show that in 26.83% of analyzed cases, the environment was not suitable for VR use. The analysis has also shown six cases in which VR use led to child endangerment.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585783
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585783
KW  - Accidents
KW  - r/VRtoER
KW  - Reddit
KW  - Safety
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Woes, Workarounds, and Wishes of Users Living in a Multinetwork Reality
AU  - Hossain, Md Nazmul
AU  - Vigil-Hayes, Morgan
T3  - CHI EA '23
AB  - Despite efforts towards pervasive, high-speed broadband connectivity, users worldwide continue to experience a persistent multinetwork reality–a reality of intermittent Internet access over multiple networks of varying capacities across space and time. In this late-breaking work, we investigate the challenges users face while using different Internet-based services and the mitigating strategies they adopt to overcome those challenges in a multinetwork reality. In addition, we also investigate how users envision software-based interventions that might augment their existing strategies and help them better manage their activities in a multinetwork reality. Finally, based on our findings from a qualitative analysis of semi-structured interviews, we explore a two-dimensional design space defined by cognitive and resource costs and discuss directions for future work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585795
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585795
KW  - broadband connectivity
KW  - design space
KW  - digital divide
KW  - multinetwork reality
KW  - qualitative analysis
ER  - 

TY  - CONF
TI  - What Can We Learn From Educators About Teaching in Makerspaces?
AU  - Turakhia, Dishita G
AU  - Ludgin, David
AU  - Mueller, Stefanie
AU  - Desportes, Kayla
T3  - CHI EA '23
AB  - Current research examining learning in makerspaces is primarily centered around the learners’ experiences and not the educators, thus presenting a gap not only in our understanding of educators’ perspectives but also in how we design educational technologies for learning in makerspaces. In our work, we address this gap through an interview study investigating seven educators’ experiences of teaching maker skills across five diverse makerspaces. Our thematic analysis of the educators’ practices resulted in an outline of the competencies that the educators centralize in their teaching, the strategies they integrate into their teaching practices, and the challenges they encounter while teaching in makerspaces. We discuss how this analysis can give insights into the educators’ values and perspectives of makerspace learning and inform the design of learning tools and experiences within the makerspaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585687
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585687
KW  - learning in makerspaces
ER  - 

TY  - CONF
TI  - Wearing Awareness: Designing Pedestrian-Wearables for Interactions with Autonomous Vehicles
AU  - Lakhdhir, Sabrina
AU  - Somanath, Sowmya
AU  - Sharlin, Ehud
T3  - CHI EA '23
AB  - Fully autonomous vehicles (AVs) are said to become part of our streets, however, their introduction raises certain challenges for vulnerable road users when it comes to making confident street-crossing decisions. To mitigate such concerns, researchers have proposed novel external human-machine interfaces (eHMI) that transmit vehicle intent and awareness information to pedestrians. However, many proposed eHMIs are limited to being deployed on vehicles or street infrastructures, and therefore offer limited opportunities to provide more personal forms of feedback to diverse pedestrians. In this work, we introduce a new category of eHMIs, pedestrian-wearables, which include clothing- and accessories-based devices that provide information about AVs directly to pedestrians. We report on a study wherein participants proposed designs for pedestrian-wearables that provide relevant alerts to wearers and help them make safer street-crossing decisions. Informed by our participants’ designs, we discuss three main facets of pedestrian-wearables: their perceived strengths and potential for inclusiveness and social acceptability.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585655
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585655
KW  - AV-pedestrian interactions
KW  - communication.
KW  - pedestrian-wearables
ER  - 

TY  - CONF
TI  - VRisbee: How Hand Visibility Impacts Throwing Accuracy and Experience in Virtual Reality
AU  - Borgwardt, Malte
AU  - Boueke, Jonas
AU  - Sanabria, María Fernanda
AU  - Bonfert, Michael
AU  - Porzel, Robert
T3  - CHI EA '23
AB  - Hand interaction plays a key role in virtual reality (VR) sports. While in reality, athletes mostly rely on haptic perception when holding and throwing objects, these sensational cues can be missing or differ in virtual environments. In this work, we investigated how the visibility of a virtual hand can support players when throwing and what impact it has on the overall experience. We developed a Frisbee simulation in VR and asked 29 study participants to hit a target. We measured the throwing accuracy and self-reports of presence, disc control, and body ownership. The results show a subtle advantage of hand visibility in terms of accuracy. Visible hands further improved the subjective impression of realism, body ownership and subjective control over the disc.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585868
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585868
KW  - embodiment
KW  - self-avatar
KW  - sports
KW  - throwing
KW  - virtual reality
ER  - 

TY  - CONF
TI  - VisaudiBlow: Fine-grained Blowing Interaction Based on Visual and Auditory Detection
AU  - Chen, Yuxuan
AU  - Jin, Yi
AU  - Zeng, Zhaoning
AU  - Chen, Shiyu
AU  - Zhou, Yang
AU  - Xu, Xinchi
AU  - Liu, Jie
AU  - Feng, Guihuan
T3  - CHI EA '23
AB  - More and more studies regard blowing as a means of reflecting the user’s physiological conditions. Its potential as an independent input channel has not been fully explored. In this paper, we analyze the design space of blowing as an independent interactive channel and propose a novel blowing recognition approach, VisaudiBlow, based on visual and audio detection. VisaudiBlow uses Facial Tracker to capture the mouth expression when doing specific blowing actions, and audio information generated by blowing is obtained by a microphone beside the mouth, enabling identification and detection of the input parameters such as blowing type, direction, and intensity. In order to verify the validity of blowing as an independent input channel, a prototype system BlowUI is implemented. The experimental results demonstrate that blow interaction can effectively complete the menu control tasks and achieve the same interaction efficiency as controllers in specific scenarios.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585829
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585829
KW  - blowing interaction
KW  - blowing parameters
KW  - BlowUI
KW  - mouth expression
ER  - 

TY  - CONF
TI  - VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality
AU  - Wieland, Markus
AU  - Sedlmair, Michael
AU  - Machulla, Tonja-Katrin
T3  - CHI EA '23
AB  - As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a conversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585726
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585726
KW  - assistive technology
KW  - eye contact
KW  - social virtual reality
KW  - visual impairment
ER  - 

TY  - CONF
TI  - VR Haptics at Home: Repurposing Everyday Objects and Environment for Casual and On-Demand VR Haptic Experiences
AU  - Fang, Cathy Mengying
AU  - Suzuki, Ryo
AU  - Leithinger, Daniel
T3  - CHI EA '23
AB  - This paper introduces VR Haptics at Home, a method of repurposing everyday objects in the home to provide casual and on-demand haptic experiences. Current VR haptic devices are often expensive, complex, and unreliable, which limits the opportunities for rich haptic experiences outside research labs. In contrast, we envision that, by repurposing everyday objects as passive haptics props, we can create engaging VR experiences for casual uses with minimal cost and setup. To explore and evaluate this idea, we conducted an in-the-wild study with eight participants, in which they used our proof-of-concept system to turn their surrounding objects such as chairs, tables, and pillows at their own homes into haptic props. The study results show that our method can be adapted to different homes and environments, enabling more engaging VR experiences without the need for complex setup process. Based on our findings, we propose a possible design space to showcase the potential for future investigation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585871
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585871
KW  - Interaction Techniques
KW  - Passive Haptics
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Virtual Trackball on VR Controller: Evaluation of 3D Rotation Methods in Virtual Reality
AU  - Kim, Sunbum
AU  - Lee, Geehyuk
T3  - CHI EA '23
AB  - Rotating 3D objects is an essential operation in virtual reality (VR). However, efficient rotation methods with the current VR controllers have not been considered extensively yet. Users must repeatedly move their arms and wrists to rotate an object with the current VR controller. We considered utilizing the trackpad available in most VR controllers as a virtual trackball for an efficient rotation method and implemented two types of virtual trackballs (Arcball and Two-axis Valuator) to enable additional rotation using the thumb while holding an object with a VR controller. In this study, we investigated whether a controller with a virtual trackball would be effective for 3D manipulation tasks. The results showed that participants could perform the tasks faster with Arcball but not faster with Two-axis Valuator than with the regular VR controller. Also, most participants preferred Arcball to Two-axis Valuator and felt Arcball more natural than Two-axis Valuator.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585682
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585682
KW  - rotation method
KW  - virtual trackball
KW  - VR controller
ER  - 

TY  - CONF
TI  - Virtual Tourism, Real Experience: A Motive-Oriented Approach to Virtual Tourism
AU  - Wolf, Sara
AU  - Weber, Michael
AU  - Hurtienne, Jörn
T3  - CHI EA '23
AB  - Virtual tourism products promise to combine the best of two worlds: Staying in the safety of one’s home while having engaging tourism experiences. Previous tourism research has emphasised that tourism experiences involve more than just seeing other places. They address cultural motives such as novelty and education and socio-psychological motives like relaxation, escape from a mundane environment or facilitation of social interaction. We suggest applying the motive-oriented perspective in HCI research on virtual tourism and report on a corresponding analysis of 21 virtual tourism products. Our findings show that current virtual tourism products neglect the breadth of tourist motives. They mainly focus on cultural motives while rarely addressing socio-psychological motives, especially kinship relationships and prestige. Our findings demonstrate the usefulness of the motive-oriented perspective for HCI and inspired conceptual ideas for addressing motives in virtual tourism products that may be useful for future research and design in this area.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585594
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585594
KW  - tourist
KW  - tourist experience
KW  - tourist needs
KW  - virtual tour
KW  - Virtual tourism
ER  - 

TY  - CONF
TI  - Virtual Reality and Creativity: How do Immersive Environments Stimulate the Brain during Creative Idea Generation?
AU  - Hagedorn, Laura Josephine
AU  - De Rooij, Alwin
AU  - Alimardani, Maryam
T3  - CHI EA '23
AB  - Virtual Reality (VR) environments are promising creativity support tools that can be designed to enhance factors related to the creative process such as immersion, engagement, and flow. However, it is still unclear how brain responses associated with creativity are influenced by VR. To address this gap, we collected EEG signals from 21 participants during a creative idea generation task in two conditions; 2D Screen vs. 3D VR. The EEG power in the alpha (8-13 Hz), beta (13-30 Hz), and gamma (30-45 Hz) frequency bands were compared. The results showed that participants experienced higher enjoyment, immersion, and temporal dissociation in the 3D VR condition. Additionally, a significant increase of oscillations in the high-frequency bands of beta and gamma was observed in VR. The findings suggest that VR can induce a more pronounced sense of flow that is associated with distinct brain activation patterns.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585848
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585848
KW  - Brain activity
KW  - Creativity
KW  - EEG
KW  - Flow
KW  - Immersion
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Virtual Fidgets: Opportunities and Design Principles for Bringing Fidgeting to Online Learning
AU  - Ross, Sam H
AU  - Sullivan, Nicole
AU  - Yoon, Jina Aris
T3  - CHI EA '23
AB  - We present design guidelines for incorporating fidgeting into the virtual world as a tool for students in online lectures. Fidgeting is associated with increased attention and self-regulation, and has the potential to help students focus. Currently there are no fidgets, physical or virtual, designed for preserving attention specifically in online learning environments, and no heuristics for designing fidgets within this domain. We identify three virtual fidget proxies to serve as design probes for studying student experiences with virtual fidgeting. Through a study of eight students using our virtual fidget proxies in online lectures, we identify eight emergent themes that encompass student experience with virtual fidgeting in lectures. Based on these themes, we present four principles for designing domain-specific virtual fidgets for online lectures. We identify that virtual fidgets for lectures should be context-aware, visually appealing, easy to adopt, and physically interactive.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585729
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585729
KW  - Fidgets
KW  - Online Learning
KW  - User Study
ER  - 

TY  - CONF
TI  - Up, Up and Away - Investigating Information Needs for Helicopter Pilots in future Urban Air Mobility
AU  - Meinhardt, Luca-Maxim
AU  - Colley, Mark
AU  - Faßbender, Alexander
AU  - Rietzler, Michael
AU  - Rukzio, Enrico
T3  - CHI EA '23
AB  - This qualitative work aims to address the emerging challenges and opportunities through advanced automation and visualization capabilities in the field of helicopter piloting for future Urban Air Mobility. A workshop was conducted with N=6 professional helicopter pilots to gather insights on these topics. The participants discussed key themes, including information needs, user interfaces, and automation. The results unveiled novel opportunities and highlighted challenges for research on aiding helicopter pilots in the fields of obstacle avoidance, map visualization, and air traffic visualization, such as augmenting flight paths to increase their situation awareness.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585643
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585643
KW  - Helicopters
KW  - Urban Air Mobility
KW  - Virtual Reality
KW  - Workshop
ER  - 

TY  - CONF
TI  - Unlocking the Tacit Knowledge of Data Work in Machine Learning
AU  - Cha, Inha
AU  - Oh, Juhyun
AU  - Park, Cheul Young
AU  - Han, Jiyoon
AU  - Lee, Hwalsuk
T3  - CHI EA '23
AB  - Creating datasets for ML is an inherently human endeavor, as the data’s heterogeneity mandates human intervention. However, most data workflows being one-time and hardly transferable leads to a lack of standardization and reusability. There has been a push to impose more structure on the data work process, but little is known about the implicit or "tacit" knowledge of data workers, i.e., "know-how"s that is difficult to transfer to others. Identifying and formalizing this knowledge can help data work improve, leading it from current "exploration" to more systematic "engineering." We interviewed 19 ML practitioners in this study to find "why" they use "what" tacit knowledge. As a result, we identified the following themes: 1) data is context/situation dependent, 2) human workers are inseparable from data, and 3) models must be understood to build data. We finally discuss future systematic supports and research to convert what is implicit to explicit.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585616
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585616
KW  - Data Construction
KW  - Machine Learning
KW  - Practitioners
KW  - Semi-structured In-depth Interviews
ER  - 

TY  - CONF
TI  - “Unfold and Go Touch”: A Portable Method for Making Existing Touchscreens Accessible to Blind and Low Vision People in Self-Service Terminals
AU  - Lin, Weiyue
AU  - Li, Ting
AU  - Liu, Liu
AU  - Zhu, Qian
T3  - CHI EA '23
AB  - Self-service terminals (SSTs) are almost everywhere in our daily life and increasingly use capacitive and infrared touchscreens as the interface. Most of the current solutions to help blind and low vision (BLV) people access existing touchscreens mostly are only suitable for capacitive touchscreens and not for infrared touchscreens. In this paper, we proposed a voice-based interactive method using a conductive folding stand with the phone camera to allow BLV people to access both touchscreens of SSTs. Voice feedback was provided to guide users to move the phone close to the button and touch it with the end of the unfolded stand. Using a portable accessory, this method directly guided users to touch the target and effectively avoids false triggering. A preliminary evaluation indicated that our approach enabled users to access the target buttons on the touchscreen with high accuracy and a short completion time.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585819
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585819
KW  - accessibility
KW  - computer vision
KW  - mobile devices
KW  - Non-visual interfaces
KW  - visually impaired users
ER  - 

TY  - CONF
TI  - Utilizing a Conversational Agent to Promote Self-efficacy in Children: A Pilot Study on Low Cognitive Ability Children with Attention Deficit Hyperactivity Disorder
AU  - Park, Doeun
AU  - Choo, Myounglee
AU  - Jin, Bohyun
AU  - Chung, Un Sun
AU  - Kim, Jinwoo
AU  - Lee, Junghan
AU  - Shin, Yee-Jin
T3  - CHI EA '23
AB  - Self-efficacy is important for children trying to learn new things. However, children with attention deficit hyperactivity disorder (ADHD), mild intellectual disability (MID), or borderline intellectual function (BIF) have less experience with success and lower self-efficacy compared to other children. This study is based on the hypothesis that the self-efficacy of children is enhanced by independently practicing and completing daily tasks. This study aims to promote self-efficacy in low cognitive ability children with ADHD. We developed a conversational agent that helps children initiate and complete their daily tasks. A pilot study was conducted in which ten children with 1) ADHD and 2) MID or BIF used the conversational agent for eight weeks. The participants exhibited an average compliance rate of 76.1%. Statistical analysis of the survey results revealed improvements in children's self-efficacy and ADHD symptoms. This pilot study discusses new possibilities for conversational agents for low cognitive ability children with ADHD.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585887
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585887
KW  - Assistive Technology
KW  - Attention Deficit Hyperactivity Disorder (ADHD)
KW  - Borderline Intellectual Functioning (BIF)
KW  - Conversational Agent
KW  - Mild Intellectual Disability (MID)
ER  - 

TY  - CONF
TI  - User engagement behaviors: Exploring predictors of ARMY’s active and passive media usage behaviors using social cognitive theory
AU  - Naderi, Azadeh
AU  - Wohn, Donghee Yvette
T3  - CHI EA '23
AB  - This study examines the active and passive media usage behaviors of ARMY, the fanbase of the Korean pop music group BTS. Active media use includes actions such as posting, commenting, and sharing, while passive media use includes simply consuming content without actively participating. We conducted an online survey (N=262) and used Social Cognitive Theory as a framework to investigate how parasocial relationships with BTS members and other factors contribute to active and passive social media use. The results indicated that parasocial relationships were positively related to passive media use, but were not related to active use. Furthermore, guidance needs and community belonging needs were positively related to both active and passive media use, whereas social integrative needs were not related to either type of media use. These findings have implications in terms of understanding how to improve engagement and user experience in social media.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585764
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585764
KW  - Active media use
KW  - ARMY
KW  - BTS
KW  - Media usage
KW  - Parasocial
KW  - Passive media use
KW  - User engagement
ER  - 

TY  - CONF
TI  - Understanding Uses’ Needs in the Development of Indoor Navigation for Visually Impaired Users in Saudi Arabia
AU  - Binkhonain, Manal
AU  - Najm, Maha Bin
AU  - Alharbi, Ohoud
T3  - CHI EA '23
AB  - People with visual impairments find it challenging to navigate unfamiliar buildings independently. This study aimed to understand the experiences and attitudes of people with visual impairments in Saudi Arabia toward indoor assistive technologies and the impact of using such tools. To this end, we conducted an experiment that involved interviewing and empirically comparing the performance and perceived mental workload of people with visual impairments in Saudi Arabia using the two most-used technologies for indoor navigation. The results indicate that Saudi users with visual impairments rely on sighted guides to navigate confidently inside unfamiliar buildings rather than on technologies. This reliance affects their trust in and use of technical assistive technology. Based on their attitudes and experiences, this study provides several design recommendations that can be used as a guide for building assistive tools for Saudis and other people with visual impairments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585909
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585909
KW  - Assistive technology
KW  - interaction analysis
KW  - interdependence
KW  - sighted guiding.
KW  - vision impairment
ER  - 

TY  - CONF
TI  - Understanding Job Coaches’ Perspectives on Using Virtual Reality as a Job Training Tool for Training People with Intellectual Disabilities
AU  - Babar, Pinaki Prasanna
AU  - Barry, Mike
AU  - Peiris, Roshan L
T3  - CHI EA '23
AB  - This study aimed to investigate the potential of virtual reality (VR) as a training tool for job coaches working with people with intellectual disabilities (ID). In this work, we conducted a qualitative study with job coaches of people with ID that included a workshop, design sprint, and interviews where existing and prototype VR apps aimed at job training people with ID were introduced and explored. The results of the study indicated positive feedback from the job coaches, with all stating that the VR had the potential as an effective training tool and that its ability to deliver customized experiences was appreciated. The study also highlighted the unique challenges and needs of trainees with ID and the importance of adapting training methods accordingly. Future research should aim to include a larger sample size, control group, long-term follow-up, more diverse simulation scenarios, and study other disabilities and demographic groups. Overall, this study suggests that VR-based training has the potential as an effective tool for job coaches working with people with ID.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585915
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585915
KW  - accessibility
KW  - job training
KW  - people with intellectual disabilities
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Understanding Fitness Tracker Users’ and Non-Users’ Requirements for Interactive and Transparent Privacy Information
AU  - Theis, Sabine
AU  - Stellmacher, Carolin
AU  - Pütz, Sebastian
AU  - Arend, Matthias G.
AU  - Nitsch, Verena
T3  - CHI EA '23
AB  - While fitness tracker users consent to the processing of their sensitive data based on privacy policies, previous research has demonstrated that legal texts often remain unread or incomprehensible. This questions whether the given consent is indeed informed. While past research concentrated on improving privacy comprehension, our research aims to better understand user requirements for interactive and transparent privacy information and control systems. We mainly focus on users’ assessment of contextual and functional aspects. Findings from an online survey with fitness tracker users and non-users (N = 204) reveal that such systems need to support users and potential users throughout the usage life cycle, illustrating a dynamic change in requirements and their prioritization of information transparency and privacy control. Design recommendations derived from our results support the development of interactive and comprehensible privacy systems that enable more knowledgeable decisions on sharing and processing fitness tracker data.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585698
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585698
KW  - fitness tracker
KW  - interactive visualization
KW  - privacy choice
KW  - Privacy information
KW  - user requirements
ER  - 

TY  - CONF
TI  - Trust Issues with Trust Scales: Examining the Psychometric Quality of Trust Measures in the Context of AI
AU  - Perrig, Sebastian A. C.
AU  - Scharowski, Nicolas
AU  - Brühlmann, Florian
T3  - CHI EA '23
AB  - Trust is crucial for human interaction with artificial intelligence (AI) and is frequently measured through questionnaires or rating scales. One commonly used questionnaire in AI research is the Trust between People and Automation scale (TPA). However, its psychometric quality has yet to be examined in the context of AI. More recently, a Trust Scale for Explainable AI (TXAI) was recommended but not empirically evaluated. In this study, we assessed the psychometric qualities of both scales, using confirmatory and exploratory factor analyses to test the scales’ validity and coefficients α and ω for reliability estimation. Our results suggested good psychometric quality for the TXAI after removing one item. Concerning the TPA, acceptable quality was only achieved when using a two-factor model (trust and distrust) and after removing two items. We provide recommendations for using the two scales and evidence to distinguish trust and distrust as separate psychological constructs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585808
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585808
KW  - AI
KW  - Measurement
KW  - Psychometrics
KW  - Questionnaires
KW  - Trust
KW  - Validation
KW  - XAI
ER  - 

TY  - CONF
TI  - Understanding Farmers’ Expectations and Experiences in Using Sensor Technologies
AU  - Bi, Nanyi
AU  - Lu, An-Pang
AU  - Yuan, Chien Wen (Tina)
T3  - CHI EA '23
AB  - Sensor-enabled tracking technologies have been applied in farming systems to enhance the efficiency by documenting detailed information about farms and making predictions. However, less is known about how farmers make sense of the tracked data and act upon them. Investigating how some Taiwanese farmers respond to a system that monitors those data, this study found that farmers need historical data as well as real-time ones from multiple sources and that it could be challenging for them to make sense of the data to the point that they want to outsource part of their decision-making to the system.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585902
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585902
KW  - knowledge transfer
KW  - prototype
KW  - smart farming
KW  - user experience
ER  - 

TY  - CONF
TI  - Trust and Reliance in Consensus-Based Explanations from an Anti-Misinformation Agent
AU  - Ueno, Takane
AU  - Kim, Yeongdae
AU  - Oura, Hiroki
AU  - Seaborn, Katie
T3  - CHI EA '23
AB  - The illusion of consensus occurs when people believe there is consensus across multiple sources, but the sources are the same and thus there is no "true" consensus. We explore this phenomenon in the context of an AI-based intelligent agent designed to augment metacognition on social media. Misinformation, especially on platforms like Twitter, is a global problem for which there is currently no good solution. As an explainable AI (XAI) system, the agent provides explanations for its decisions on the misinformed nature of social media content. In this late-breaking study, we explored the roles of trust (attitude) and reliance (behaviour) as key elements of XAI user experience (UX) and whether these influenced the illusion of consensus. Findings show no effect of trust, but an effect of reliance on consensus-based explanations. This work may guide the design of anti-misinformation systems that use XAI, especially the user-centred design of explanations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585713
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585713
KW  - consensus
KW  - explainable AI
KW  - intelligent agent
KW  - misinformation
KW  - reliance
KW  - trust
KW  - user experience
ER  - 

TY  - CONF
TI  - Trust and Perceived Control in Burnout Support Chatbots
AU  - Degachi, Chadha
AU  - Tielman, Myrthe Lotte
AU  - Al Owayyed, Mohammed
T3  - CHI EA '23
AB  - Increased levels of user control in learning systems is commonly cited as good AI development practice. However, the evidence as to the effect of perceived control over trust in these systems is mixed. This study investigated the relationship between different trust dimensions and perceived control in postgraduate student burnout support chatbots, and modelled the moderating factors therein. We present an in-between subject controlled experiment using simulated therapy-goal learning to study the effect of perceived control (as manipulated by feedback incorporation) on perceived agent benevolence, competence, and trust. Our results showed that perceived control was moderately correlated with benevolence (r = 0.448, BF10 = 7.150), and weakly correlated with competence and trust.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585780
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585780
KW  - chatbots
KW  - human-in-the-loop
KW  - percieved control
KW  - trust modelling
ER  - 

TY  - CONF
TI  - Training Users to Recognize Persuasion Techniques in Vishing Calls
AU  - Hashmi, Sumair Ijaz
AU  - George, Niklas
AU  - Saqib, Eimaan
AU  - Ali, Fatima
AU  - Siddique, Nawaal
AU  - Kashif, Shafay
AU  - Ali, Shahzaib
AU  - Bajwa, Nida Ul Habib
AU  - Javed, Mobin
T3  - CHI EA '23
AB  - Voice-based phishing attacks, in which a scammer uses social engineering techniques over a phone call to convince victims to divulge sensitive information, cause losses of several million dollars. We present a pilot study of a novel intervention that trains users to recognize phishing calls by identifying the persuasion principles used by the scammer. The training is implemented via a Whatsapp chatbot that includes example audio recordings and exercises of scam calls, and how the scammer employs the principle of authority in order to persuade the victim. 50 students from a university participated in the persuasion principles training. We then conducted a simulated vishing call a few days later to test how well the participants recognize the call compared to a control group (also 50 students) that was only given a general awareness training, and was not specifically trained to recognize authority via chatbot exercises. We also conducted interviews with participants from both the groups to understand the perceived usefulness of the training.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585823
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585823
ER  - 

TY  - CONF
TI  - Tracking the Experience of Self in Everyday Life
AU  - Hoefer, Michael
AU  - Voida, Stephen
T3  - CHI EA '23
AB  - This study explores the potential benefits of an interactive system that supports individuals in collecting data and reflecting on their self-concept and self-aspects in daily life. Through a think-aloud study (N = 10) and in-situ deployment (N = 7), we design, deploy, and evaluate a self-tracking technology probe. The results suggest that participants found benefit in participating in the study and tracking their self-aspects, with all seven participants in the in-situ deployment expressing interest in continuing to use the system after the study. The study highlights the usefulness of supporting self-reflection at various temporal scales, and has implications for the design of personal informatics systems utilizing the multiple self-aspects framework and Day Reconstruction Method. This research contributes to the understanding of the potential benefits of interactive systems in supporting self-tracking of the experience of self-aspects in daily life.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585785
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585785
KW  - daily life
KW  - day reconstruction method
KW  - design for the self
KW  - multiple self-aspects
KW  - personal and visual analytics
KW  - personal informatics
KW  - quantified self
KW  - technology probe
KW  - think-aloud
ER  - 

TY  - CONF
TI  - Towards User-Aware VR Learning Environments: Combining Brain-Computer Interfaces with Virtual Reality for Mental State Decoding
AU  - Lingelbach, Katharina
AU  - Diers, Daniel
AU  - Vukelić, Mathias
T3  - CHI EA '23
AB  - User-aware adaptive systems can greatly benefit from brain-computer interface (BCI) technologies. BCIs allow continuous monitoring of users’ mental states and tailoring of the system to their individual skills and needs. We conducted a feasibility study integrating a BCI using functional near-infrared spectroscopy (fNIRS) into a virtual reality (VR) environment for realistic industrial learning scenarios. Using a fNIRS-based BCI allowed us to a) identify learning progress of individuals based on their working memory load across multiple learning sessions and b) investigate the underlying brain patterns. Our results showed a non-linear relationship between task difficulty and brain responses in the prefrontal cortex (PFC). Finally, we were able to draw four major conclusions regarding architecture components and vital research perspectives, to progress towards a vision of user-aware adaptive system design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585716
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585716
KW  - Brain-Computer Interface (BCI)
KW  - Learning
KW  - Mental State Monitoring
KW  - Working Memory
KW  - Workload
ER  - 

TY  - CONF
TI  - Towards Understanding Sense of Inclusion in Social VR Onboarding
AU  - Fang, Shitao
AU  - Yatani, Koji
T3  - CHI EA '23
AB  - Being included in social interactions is a fundamental human need in both physical and virtual worlds. However, it is overlooked in the context of social VR user experience. Based on social psychology, we define the sense of inclusion as the degree to which an individual perceives a sense of belonging and authenticity from a group. We initially use non-verbal behavior, which is commonly used in social VR, as an entry point to understanding the role of the sense of inclusion in social VR. We examine how the reactive behaviors of existing community members would influence the sense of inclusion during social VR onboarding. Our between-subject experiment (N=39) with three reactive behavioral conditions confirms that positive responses from existing community members increased the sense of inclusion. And the sense of inclusion positively mediates several user experiences including enjoyment and immersion. We highlight potential design implications and future research for social VR.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585751
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585751
KW  - Non-verbal Behavior
KW  - Sense of Inclusion
KW  - Social VR
ER  - 

TY  - CONF
TI  - Towards Accessible Sports Broadcasts for Blind and Low-Vision Viewers
AU  - Jain, Gaurav
AU  - Hindi, Basel
AU  - Courtien, Connor
AU  - Wyrick, Conrad
AU  - Xu, Xin Yi Therese
AU  - Malcolm, Michael C
AU  - Smith, Brian A.
T3  - CHI EA '23
AB  - Blind and low-vision (BLV) people watch sports through radio broadcasts that offer a play-by-play description of the game. However, recent trends show a decline in the availability and quality of radio broadcasts due to the rise of video streaming platforms on the internet and the cost of hiring professional announcers. As a result, sports broadcasts have now become even more inaccessible to BLV people. In this work, we present Immersive A/V, a technique for making sports broadcasts —in our case, tennis broadcasts— accessible and immersive to BLV viewers by automatically extracting gameplay information and conveying it through an added layer of spatialized audio cues. Immersive A/V conveys players’ positions and actions as detected by computer vision-based video analysis, allowing BLV viewers to visualize the action. We designed Immersive A/V based on results from a formative study with BLV participants. We conclude by outlining our plans for evaluating Immersive A/V and the future implications of this research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585610
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585610
KW  - accessibility
KW  - computer vision
KW  - sports
KW  - Visual impairments
ER  - 

TY  - CONF
TI  - Towards Transparent, Reusable, and Customizable Data Science in Computational Notebooks
AU  - Choi, Frederick
AU  - Rahman, Sajjadur
AU  - Kim, Hannah
AU  - Zhang, Dan
T3  - CHI EA '23
AB  - Data science workflows are human-centered processes involving on-demand programming and analysis. While programmable and interactive interfaces such as widgets embedded within computational notebooks are suitable for these workflows, they lack robust state management capabilities and do not support user-defined customization of the interactive components. The absence of such capabilities hinders workflow reusability and transparency while limiting the scope of exploration of the end-users. In response, we developed Magneton, a framework for authoring interactive widgets within computational notebooks that enables transparent, reusable, and customizable data science workflows. The framework enhances existing widgets to support fine-grained interaction history management, reusable states, and user-defined customizations. We conducted three case studies in a real-world knowledge graph construction and serving platform to evaluate the effectiveness of these widgets. Based on the observations, we discuss future implications of employing Magneton widgets for general-purpose data science workflows.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585807
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585807
KW  - Computational notebooks
KW  - Data Science
KW  - Exploratory Programming
KW  - Interactive programming
KW  - Literate Programming
ER  - 

TY  - CONF
TI  - Towards Embodying Emotions in Play with Neurodivergent Children using Haptic Technologies
AU  - Ju, Yulan
AU  - Shibasaki, Mina
AU  - Kim, Christopher Changmok
AU  - Kunze, Kai
AU  - Minamizawa, Kouta
T3  - CHI EA '23
AB  - As neurodivergent cases in children are steadily increasing, we are also seeing increased awareness regarding personalized neurological development and efforts towards social inclusion. Children struggling with these conditions should engage in education curricula custom-tailored and personalized for their individual needs. In this initial work, we describe the first steps of the development of an interactive system that created a multi-sensory environment embedded into a participatory performance to help neurodivergent children learn about emotions. We first report on the co-design process and research insights from our work integrating haptic technology and neurodivergent children’s emotion learning activity. Then we report on a study in which 28 children were involved in testing the implementation of our system and share our insights that we gained about designing haptic interventions for neurodivergent children and the collaborative process with their instructors and other related parties.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585613
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585613
KW  - assistive technology
KW  - emotion
KW  - haptic
KW  - neurodivergent
KW  - participatory performance
KW  - vibrotactile
ER  - 

TY  - CONF
TI  - Towards an Empirical Study to Determine the Effectiveness of Support Systems against E-Mail Phishing Attacks
AU  - Schiller, Katharina
AU  - Adamsky, Florian
AU  - Benenson, Zinaida
T3  - CHI EA '23
AB  - E-mail phishing attacks are still the number one gateway for attackers. Even when the patch level of a network is up to date, if one employee clicks on a link in a phishing e-mail and enters their credentials on a malicious website or downloads malware, the whole organization might get compromised. Anti-phishing support systems highlight different aspects of an e-mail to help users to detect phishing e-mails. However, little is known about their effectiveness, especially in comparison to each other. This paper presents our experimental design to investigate the efficacy of various support systems. For this purpose, we created a fictional scenario and an interactive tool to display e-mails. In addition, we present our preliminary study with the first results to classify test e-mails in different difficulty levels that serve as a basis for our main study.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585658
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585658
ER  - 

TY  - CONF
TI  - Towards a Preliminary Ontology of Dark Patterns Knowledge
AU  - Gray, Colin M.
AU  - Santos, Cristiana
AU  - Bielova, Nataliia
T3  - CHI EA '23
AB  - Deceptive design practices are increasingly used by companies to extract profit, harvest data, and limit consumer choice. Dark patterns represent the most common contemporary amalgamation of these problematic practices, connecting designers, technologists, scholars, regulators, and legal professionals in transdisciplinary dialogue. However, a lack of universally accepted definitions across the academic, legislative and regulatory space has likely limited the impact that scholarship on dark patterns might have in supporting sanctions and evolved design practices. In this late breaking work, we seek to harmonize regulatory and academic taxonomies of dark patterns, proposing a preliminary three-level ontology to create a shared language that supports translational research and regulatory action. We identify potential directions for scholarship and social impact building upon this ontology.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585676
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585676
KW  - dark patterns
KW  - deceptive design
KW  - ontology
KW  - regulation
ER  - 

TY  - CONF
TI  - Towards a Human-Centred Artificial Intelligence Maturity Model
AU  - Hartikainen, Maria
AU  - Väänänen, Kaisa
AU  - Olsson, Thomas
T3  - CHI EA '23
AB  - Artificial intelligence (AI) is becoming a central building block of computational systems. Following the long traditions of human-centered design, Human-Centered AI (HCAI) emphasises the importance of putting humans and various societal considerations in the centre of the development. However, the question is: how to realise HCAI when designing systems that utilise novel computational tools and require consideration of increasingly broad set of requirements, spanning from fairness and transparency to accountability and ethics? The purpose of our study is to support the AI development practices in companies in order for the humans to have AI solutions that are efficient, trustworthy, and safe. To this end, we propose a maturity model for HCAI (HCAI-MM). In this paper we present the first phase of the model development, in which the central building blocks of HCAI are specified and initial company requirements for the model's structure and content are evaluated with four AI developers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585752
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585752
KW  - artificial intelligence
KW  - company practices
KW  - human-centered artificial intelligence
KW  - human-centered design
KW  - maturity models
ER  - 

TY  - CONF
TI  - Toward Designing for Social Support Through Compassionate Interactions
AU  - Prabhakar, Annu Sible
AU  - Pong, Joseph
T3  - CHI EA '23
AB  - Prior research shows that compassion can promote social connection and well‐being. Compassion is characterized by noticing another’s suffering, connecting empathically, feeling concerned, and responding in a caring way. In this research, we engaged sixteen first-time parents in research activities to investigate how compassion is understood, perceived, and experienced by new parents to inform the design of potential technology solutions to foster support between new parenting partners. We posit that interventions facilitating compassionate interactions between new parents can improve support for new mothers, promote relationship satisfaction, and thus positively affect the overall wellness of new mothers during the transition to motherhood.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585774
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585774
KW  - Compassion
KW  - Compassion cultivation
KW  - fatherhood
KW  - Journey Maps
KW  - Life Transitions
KW  - Maternal Wellness
KW  - motherhood
KW  - Mothers
KW  - parenthood
KW  - support intervention
ER  - 

TY  - CONF
TI  - Throughput and Effective Parameters in Crossing
AU  - Kasahara, Nobuhito
AU  - Oba, Yosuke
AU  - Yamanaka, Shota
AU  - Stuerzlinger, Wolfgang
AU  - Miyashita, Homei
T3  - CHI EA '23
AB  - In pointing, throughput TP is used as a performance metric for the input device and operator. Based on the calculation of effective parameters (width We and amplitude Ae), TP should be independent of the speed-accuracy tradeoff. To examine the validity of TP and effective parameters for crossing actions, we conducted two experiments using two established crossing tasks. Our results demonstrate that applying effective parameters to Fitts’ law model improves the fit to the data for mixed biases in both tasks. Besides, we observed that effective parameters smoothed TPs across biases. However, unlike pointing, TP was observed to be unstable across IDs in one task, while was stable across IDs in the other task. Analyzing speed profiles showed that this was likely due to the fact that one of the tasks could be completed with a ballistic movement at low IDs, whereas this was impossible for the other task.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585817
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585817
KW  - effective parameters
KW  - Fitts’ law
KW  - human motor performance
KW  - Pen Crossing
KW  - throughput
ER  - 

TY  - CONF
TI  - Tingle Just for You: A Preliminary Study of AI-based Customized ASMR Content Generation
AU  - Oh, Ji Yeon
AU  - Kim, Daun
AU  - Jeong, Jae-Yeop
AU  - Jeong, Jin-Woo
AU  - Lukianova, Elizaveta
T3  - CHI EA '23
AB  - With the recent surge in interest in autonomous sensory meridian response (ASMR), numerous contents that stimulate the user’s visual and auditory senses by using various triggers are consumed a lot. However, due to individual differences, people have different reactions to triggers, therefore, have to manually search for the content that suits their preferences. In this paper, we present an AI-based ASMR content generation service and conduct a preliminary user study to figure out its feasibility and usability. Through a user study with 42 participants, we find that the AI-based customized ASMR content generation service could be used to satisfy users. However, we could also learn about various issues to be addressed for better user experience and satisfaction, such as audio-video synchronization, appropriateness, level of noise, and so on.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585872
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585872
KW  - AI-created Contents
KW  - ASMR
KW  - Generative model
KW  - Sound generation
ER  - 

TY  - CONF
TI  - Three Perspectives on Embodied Learning in Virtual Reality: Opportunities for Interaction Design
AU  - Chatain, Julia
AU  - Kapur, Manu
AU  - Sumner, Robert W.
T3  - CHI EA '23
AB  - With the fast evolution of Virtual Reality (vr) technology, new prospects opened for embodied learning. Learners can now manipulate digital representations of abstract concepts and make sense of them through sensorimotor stimulation. However, in research, embodiment is explored from several perspectives, which, we argue, should be considered within a same framework. In this paper, we describe three major perspectives relevant for embodied learning in Virtual Reality (vr): embodied cognition, embodied interaction, and avatar embodiment. We organize these perspectives within one common interdisciplinary framework, and discuss resulting design opportunities for vr embodied learning interactions. Specifically, we show that embodied interaction does not necessarily support embodied cognition, and that breaking recommendations of avatar embodiment can actually support meaning-making. We believe our work offers novel avenues for future research and will foster interesting conversations in the hci community.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585805
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585805
KW  - avatar embodiment
KW  - embodied cognition
KW  - embodied interaction
KW  - learning sciences
KW  - virtual reality
ER  - 

TY  - CONF
TI  - “This Could Be The Day I Die”: Unpacking Interpersonal and Systems Trust in a Local Sharing Economy Community
AU  - Fedosov, Anton
AU  - Zavolokina, Liudmila
AU  - Krumhard, Sina
AU  - Huang, Elaine M.
T3  - CHI EA '23
AB  - The rapid development of the “sharing economy” enables the effective and efficient coordination, acquisition, distribution, and sharing of many kinds of different resources. Beyond the well-known sharing economy services such as Airbnb and Uber, an increasing number of local sharing initiatives have established online platforms and services to facilitate access to the shared resources within their local communities. With the automation and complexity of digital tools and platforms, and the specific challenges of online sharing communities, users’ trust and reliance become increasingly critical for successful use and adoption. In our qualitative study in collaboration with two industry partners (a local sharing community and a large infrastructure provider in Switzerland), we unpack various perspectives of interpersonal trust in the community and the systems trust of the supporting technologies. On this basis, we elicited a set of design opportunities for future platforms in the context of sharing economy.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585744
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585744
KW  - digital platforms
KW  - interpersonal trust
KW  - qualitative study
KW  - sharing economy
KW  - systems trust
ER  - 

TY  - CONF
TI  - ‘There’s more to it than allure...’ – Navigating Socio-cultural Roles of Digital Jewellery
AU  - Walczak, Anna
AU  - Woźniak, Miko\laj P.
AU  - Wysokińska, Aleksandra
AU  - Wróbel-Lachowska, Magdalena
AU  - Müller, Heiko
AU  - Romanowski, Andrzej
AU  - Boll, Susanne
T3  - CHI EA '23
AB  - Over the recent years, digital jewellery has been creatively explored in research and commercial products. However, the symbolic layers of these artefacts which are inherent to traditional jewellery are not yet understood. Exploring the anthropological dimensions of wearable ornaments is necessary for digital jewellery to become enduring assets of personal importance. Drawing on participatory design methods, we conducted an explorative workshop with experts in design, art, and technology (N=16) discussing the socio-technical dimensions of designing interactive jewellery. In this work, we build upon a multidisciplinary framework describing traditional jewellery from an anthropological perspective. We examine whether and how novel digital ornaments fulfil five major socio-cultural roles of jewellery. Our work contributes insights for designing digital jewellery with social relevance and hints new directions for future implementations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585851
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585851
KW  - Digital Jewellery
KW  - Interactive Jewellery
KW  - Participatory Design
KW  - Wearable Computing
ER  - 

TY  - CONF
TI  - The Time is Ticking: The Effect of Limited Time Discounts on Consumers’ Buying Behavior and Experience
AU  - Tiemessen, Jelmer
AU  - Schraffenberger, Hanna
AU  - Acar, Gunes
T3  - CHI EA '23
AB  - Deceptive countdown timers indicate a limited-time offer that is not truly limited-time, as the deal continues after the timer reaches zero. The effects of such deceptive (dark) patterns on consumers’ buying behavior are largely unknown. We present a setup to research such effects and use it in this exploratory study to investigate deceptive countdown timers through a simulated online shopping task (N=245), followed by a questionnaire. We compared the reaction of participants who encountered i) no special offers, ii) only a discount, and iii) a discount accompanied by a deceptive countdown timer. The results show that both types of discounts increase customers’ preference for the discounted product. However, we observe various negative responses towards deceptive timers (e.g., they are perceived as manipulative, immoral, and unethical). Our findings indicate that deceptive timers can induce a fear of missing out and make consumers averse to offers and websites that use such practices.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585735
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585735
KW  - countdown timers
KW  - Deceptive design patterns
KW  - manipulation
KW  - online shopping
ER  - 

TY  - CONF
TI  - THERIF: Themes for Readability from Iterative Feedback
AU  - Cai, Tianyuan
AU  - Niklaus, Aleena Gertrudes
AU  - Kerr, Bernard
AU  - Kraley, Michael
AU  - Bylinskii, Zoya
T3  - CHI EA '23
AB  - Digital reading applications give readers the ability to customize fonts, sizes, and spacings, all of which have been shown to improve the reading experience for readers from different demographics. However, tweaking these text features can be challenging, especially given their interactions on the final look and feel of the text. Our solution is to offer readers preset combinations of font, character, word and line spacing, which we bundle together into reading themes. To arrive at a recommended set of reading themes, we combine crowdsourced text adjustments, ML-driven clustering of the resulting text formats, and design sessions. After four iterations of these steps, we converge on a set of three COR (Compact, Open, and Relaxed) themes that are designed for different readers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585679
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585679
KW  - human-in-the-loop
KW  - presets
KW  - reading
ER  - 

TY  - CONF
TI  - The Impact of System Transparency on Analytical Reasoning
AU  - Hepenstal, Sam
AU  - Zhang, Leishi
AU  - Wong, B. L. William
T3  - CHI EA '23
AB  - In this paper, we present the hypothesis that system transparency is critical for tasks that involve expert sensemaking. Artificial Intelligence (AI) systems can aid criminal intelligence analysts, however, they are typically opaque, obscuring the underlying processes that inform outputs, and this has implications for sensemaking. We report on an initial study with 10 intelligence analysts who performed a realistic investigation exercise using the Pan natural language system [10, 11], in which only half were provided with system transparency. Differences between conditions are analysed and the results demonstrate that transparency improved the ability of analysts to reason about the data and form hypotheses.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585786
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585786
KW  - Artificial Intelligence
KW  - Decision Support
KW  - Expert Decision Making
KW  - Intelligence Analysis
ER  - 

TY  - CONF
TI  - The Reflective Make-AR In-Action: Using Augmented Reality for Reflection-based Learning of Makerskills
AU  - Turakhia, Dishita G
AU  - Jiang, Peiling
AU  - Mueller, Stefanie
T3  - CHI EA '23
AB  - Recent work on reflective learning supports self-paced learning of skills like breadboarding and using power tools in makerspaces through a reflection exercise toolkit. This toolkit monitors the learners’ performances in real-time and prompts them to reflect both in-action and on-action i.e., during and after their maker activities. In this paper, we build on this prior work and use an augmented reality system to monitor, prompt, and record in-action reflections, i.e., while the maker activity is in progress. In particular, we propose a framework to design multi-modal reflective prompts for self-learning exercises using augmented reality with three specific goals - (1) adding real-world contextualization, (2) overlaying personalized multimodal contextual information for supporting in-action reflections, and (3) maintaining an immersive experience during the reflection exercises. We conclude with a discussion of three application case studies for reflective AR maker exercises.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585850
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585850
KW  - augmented reality
KW  - makerskills
KW  - makerspaces
KW  - reflective learning
ER  - 

TY  - CONF
TI  - The Indoor Air Quality Trilemma: Improving Air Quality, Using Less Energy, and Meeting Stakeholder Requirements
AU  - Hussain, Iman
AU  - Friday, Adrian
AU  - Booker, Douglas
T3  - CHI EA '23
AB  - Good indoor air quality (IAQ) is critically important for many aspects of our lives, including as we’ve found recently in reducing the transmission of airborne diseases such as COVID-19. Delivering good IAQ poses several challenges to organisations: it can require changes in working practices, be bounded by infrastructure capabilities such as buildings and their heating and ventilation systems, and result in substantial energy usage. In this study we have conducted a preliminary investigation measuring IAQ in a typical ‘science lab’ classroom, and engaging with stakeholders to jointly explore these data. Our mixed methods approach uncovers an indoor air quality ‘trilemma’, which relates air quality, energy usage, and stakeholder practices that can be mediated by, and understood as, a site for potentially impactful future HCI designs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585898
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585898
KW  - Classrooms
KW  - CO2
KW  - Distributed Sensors
KW  - Energy Penalties
KW  - HVAC Control
KW  - Indoor Air Quality
KW  - PM10
KW  - PM2.5
KW  - Smart Sensors
KW  - UK Schools
ER  - 

TY  - CONF
TI  - The Human Behind the Data: Reflections from an Ongoing Co-Design and Deployment of a Data-Navigation Interface for Front-Line Emergency Housing Shelter Staff
AU  - Masrani, Teale W
AU  - He, Helen Ai
AU  - Messier, Geoffrey
T3  - CHI EA '23
AB  - On any night in Canada, at least 35,000 individuals experience homelessness. These individuals use emergency shelters to transition out of homelessness and into permanent housing. We designed and deployed a technology to support front-line staff at the largest emergency housing shelter in Calgary, Canada. Over a period of five months in 2022, we worked closely with front-line staff to co-design an interface for supporting a holistic understanding of client context and facilitating decision-making. The tool is currently in-use and our collaboration is ongoing. In this paper, we reflect on preliminary findings regarding the second iteration of the tool. We find that supporting shelter staff in understanding the human behind the data was a critical component of design. This work contributes to literature on how data tools may be integrated into homeless shelters in a way that aligns with shelters’ values.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585694
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585694
KW  - data visualization
KW  - emergency shelters
KW  - homelessness
KW  - interface design
KW  - participatory design
KW  - vulnerable populations
ER  - 

TY  - CONF
TI  - The HCI User Studies Toolkit: Supporting Study Designing and Planning for Undergraduates and Novice Researchers in Human-Computer Interaction
AU  - Schwind, Valentin
AU  - Resch, Stefan
AU  - Sehrt, Jessica
T3  - CHI EA '23
AB  - Planning and organizing user studies can be a challenge for novices and student researchers in human-computer interaction (HCI). We present a web-based study planning toolkit for researchers to support their planning and organization with human subjects. The free and open toolkit contains multiple interactive research applications for (1) the selection of quantitative and qualitative research methods in HCI, (2) automated study design planning for experimental user studies, (3) an automated informed consent generation for studies with human subjects, (4) calendar booking for experimental user studies in shared laboratories, and (5) automated participation confirmation certificates. The toolkit can be helpful for Ph.D. students in supervising novices and undergraduates who need support with their planning and study design choices. The toolkit was actively used over two semesters in multiple HCI lectures and formatively evaluated. We contribute with the whole toolkit and encourage other researchers to contribute and further improve the content.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585890
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585890
KW  - HCI Toolkit
KW  - Organization
KW  - Study Design Planning
KW  - User Studies
ER  - 

TY  - CONF
TI  - The Art of Creating Code-Based Artworks
AU  - Verano Merino, Mauricio
AU  - Sáenz, Juan Pablo
T3  - CHI EA '23
AB  - Programming has become an artistic medium for artists; it provides expression possibilities built on top of the computer’s interactivity and multimedia features. However, implementing code-based artworks encloses defining characteristics that differ from traditional programming. This paper reports on an in-depth interview with 5 code artists with diverse backgrounds, levels of experience, and working on different code-based artistic expressions. Through their experience, we identified characteristics and commonalities in their development process, the tools they use, their sources of inspiration, and their expectations. Accordingly, we reflect on the particularities of Creative Coding, indicate commonalities with other domains, and suggest opportunities and challenges for HCI researchers and practitioners in proposing tools to support it better.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585743
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585743
KW  - code artists
KW  - code-based artworks
KW  - creative coding
KW  - interviews
ER  - 

TY  - CONF
TI  - Text Me if You Can: Investigating Text Input Methods for Cyclists
AU  - Matviienko, Andrii
AU  - Durand-Pierre, Jean-Baptiste
AU  - Cvancar, Jona
AU  - Mühlhäuser, Max
T3  - CHI EA '23
AB  - Cycling is emerging as a relevant alternative to cars. However, the more people commute by bicycle, the higher the number of cyclists who use their smartphones on the go and endanger road safety. To better understand input while cycling, in this paper, we present the design and evaluation of three text input methods for cyclists: (1) touch input using smartphones, (2) midair input using a Microsoft Hololens 2, and (3) a set of ten physical buttons placed on both sides of the handlebar. We conducted a controlled indoor experiment (N = 12) on a bicycle simulator to evaluate these input methods. We found that text input via touch input was faster and less mentally demanding than input with midair gestures and physical buttons. However, the midair gestures were the least error-prone, and the physical buttons facilitated keeping both hands on the handlebars and were more intuitive and less distracting.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585734
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585734
KW  - cycling
KW  - mobile interaction
KW  - smartphone
KW  - text input
ER  - 

TY  - CONF
TI  - Technology Deployment for Social Connection in Residential Aged Care: Care and Technology Providers' Experiences During the COVID-19 Pandemic
AU  - Zhao, Wei
AU  - Kelly, Ryan M.
AU  - Waycott, Jenny
T3  - CHI EA '23
AB  - Information and communication technologies are being used for the social connection of people living in residential aged care. However, in HCI research concerning technology use in aged care, the perspectives of care and technology providers have received limited attention. We conducted semi-structured interviews with 15 aged care workers and technology providers to investigate the challenges and opportunities of deploying technologies in aged care during the COVID-19 pandemic. Our findings highlighted that technologies such as videoconferencing and smart displays connected residents with family and friends, kept families informed and reassured, and were used in small groups to meet individual needs. However, limitations in video calling, staff fatigue, volunteer availability, and infrastructural resources presented barriers to technology deployment. Future use of technology for social connection in aged care requires careful facilitation from staff, better resourcing and infrastructural support, collaborations with volunteers, and more attention to individual needs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585662
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585662
KW  - aged care
KW  - COVID-19
KW  - older adult
KW  - older people
KW  - social connection
KW  - technology
ER  - 

TY  - CONF
TI  - Tailoring Interactions: Exploring the Opportune Moment for Remote Computer-mediated Interactions with Home-alone Dogs
AU  - Kim, Yewon
AU  - Gong, Taesik
AU  - Lee, Sung-Ju
T3  - CHI EA '23
AB  - We argue for research on identifying opportune moments for remote computer-mediated interactions with home-alone dogs. We analyze the behavior of home-alone pet dogs to find specific situations where positive interaction between the dog and toys is more likely and when the interaction might induce more stress. We highlight the importance of considering the timing of remote interactions with pet dogs and the potential benefits it brings to the effectiveness of the interaction, leading to greater satisfaction and engagement for both the pet and the pet owner.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585757
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585757
KW  - Computer-mediated Human-animal Interaction
KW  - Interruptibility
ER  - 

TY  - CONF
TI  - Tackling Discrimination in Tech: The Anti-Bias Cards (ABC) in Use
AU  - Burtscher, Sabrina
AU  - Spiel, Katta
T3  - CHI EA '23
AB  - How to engage with the consequences of systemic biases and subsequent calls to ensure more equity in technologically oriented teams without any prior education on these matters presents an open question within Human-Computer Interaction (HCI). Based on a previous literature study and the development of the Anti-Bias Card Deck (ABC), this paper presents the findings and insights from various workshops in which the cards were applied. The settings varied in their thematic and geographic contexts as well as with regard to participants and their backgrounds. Overall, participants agreed that the card deck could be of help to detect and tackle different aspects of discrimination over a project’s life cycle. Hence, the ABC deck fulfilled its intended role as a potential conversation starter for reflecting on matters of bias and equity in teams of technology developers without prior expertise.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585592
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585592
KW  - gender
KW  - intersectionality
KW  - methodology
KW  - sensitivity
ER  - 

TY  - CONF
TI  - Studying Children’s Object Interaction in Virtual Reality: A Manipulative Gesture Taxonomy for VR Hand Tracking
AU  - Baykal, Gökçe Elif
AU  - Leylekoğlu, Ali
AU  - Arslan, Sude
AU  - Ozer, Demet
T3  - CHI EA '23
AB  - In this paper, we propose a taxonomy for the classification of children’s gestural input elicited from spatial puzzle play in VR hand tracking. The taxonomy builds on the existing manipulative gesture taxonomy in human-computer interaction, and offers two main analytical categories; Goal-directed actions and Hand kinematics as complementary dimensions for analysing gestural input. Based on our study with eight children (aged between 7-14), we report the qualitative results for describing the categories for analysis and quantitative results for their frequency in occurring in children’s interaction with the objects during the spatial task. This taxonomy is an initial step towards capturing the complexity of manipulative gestures in relation to mental rotation actions, and helps designers and developers to understand and study children’s gestures as an input for object interaction as well as an indicator for spatial thinking strategies in VR hand tracking systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585865
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585865
KW  - Gesture
KW  - hand tracking
KW  - HCI
KW  - spatial thinking
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Tacit Knowledge Elicitation for Shop-floor Workers with an Intelligent Assistant
AU  - Kernan Freire, Samuel
AU  - Wang, Chaofan
AU  - Ruiz-Arenas, Santiago
AU  - Niforatos, Evangelos
T3  - CHI EA '23
AB  - Many industries face the challenge of capturing workers’ knowledge to share it, particularly tacit knowledge. The operation of complex systems such as a manufacturing line is knowledge-intensive. Considering this knowledge’s breadth and dynamic nature, existing knowledge-sharing solutions are inefficient and resource intensive. Conversational user interfaces are an efficient way to convey information that mimics how humans share knowledge; however, we know little about how to design them specifically for knowledge sharing, especially regarding tacit knowledge. In this work, we present an intelligent assistant that we have developed to support the elicitation of tacit knowledge from workers through systematic reflection. The system can interact with workers by voice or text and generate visualizations of shop floor data to support reflective prompts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585755
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585755
KW  - chatbots
KW  - human-centered AI
KW  - industry 5.0
KW  - intelligent assistant
KW  - knowledge sharing
KW  - systematic reflection
KW  - tacit knowledge
ER  - 

TY  - CONF
TI  - Sympathetic Activation in Deadlines of Deskbound Research - A Study in the Wild
AU  - Hasan, MD Tanim
AU  - Zaman, Shaila
AU  - Wesley, Amanveer
AU  - Tsiamyrtzis, Panagiotis
AU  - Pavlidis, Ioannis
T3  - CHI EA '23
AB  - Paper and proposal deadlines are important milestones, conjuring up emotional memories to researchers. The question is if in the daily challenging world of scholarly research, deadlines truly incur higher sympathetic loading than the alternative. Here we report results from a longitudinal, in the wild study of n = 10 researchers working in the presence and absence of impeding deadlines. Unlike the retrospective, questionnaire-based studies of research deadlines in the past, our study is real-time and multimodal, including physiological, observational, and psychometric measurements. The results suggest that deadlines do not significantly add to the sympathetic loading of researchers. Irrespective of deadlines, the researchers’ sympathetic activation is strongly associated with the amount of reading and writing they do, the extent of smartphone use, and the frequency of physical breaks they take. The latter likely indicates a natural mechanism for regulating sympathetic overactivity in deskbound research, which can inform the design of future break interfaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585585
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585585
KW  - arousal
KW  - deadlines
KW  - multimodal dataset
KW  - physical break
KW  - research work
KW  - smartphone use
KW  - sympathetic activation
KW  - thermal imaging
ER  - 

TY  - CONF
TI  - Structuring Collaboration in Programming Through Personal-Spaces
AU  - Hayatpur, Devamardeep
AU  - Helfenbaum, Tehilla
AU  - Xia, Haijun
AU  - Stuerzlinger, Wolfgang
AU  - Gries, Paul
T3  - CHI EA '23
AB  - The effectiveness of pair programming in pedagogy depends on the frequency and quality of communication of the driver. We explore an alternative collaboration paradigm that tackles this imbalance through Parsons problems: students are given fragments of code out of order and tasked with re-organizing them into the correct order. We then create an interdependence between students by assigning each to a different sub-problem in their own space, termed Personal-spaces – they must engage in dialog to negotiate, exchange, and share fragments. In an exploratory study with nine pairs of undergraduate students, we find evidence pointing to affordances of different coordination conditions: Personal-spaces promoted ownership and engagement, while Turn-taking (akin to pair programming) helped maintain a consistent train of thought. Our results provide considerations for design of appropriate problem sets and interfaces to structure collaborative learning.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585630
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585630
KW  - collaborative learning
KW  - pair programming
KW  - Parsons problems
ER  - 

TY  - CONF
TI  - Stiff-switch: Finite Stiffness Control Method Using a Thermo-Mechanical Structure and a Low-voltage Pinpoint Heater
AU  - Tokuda, Yutaka
AU  - Kobayashi, Tatsuya
T3  - CHI EA '23
AB  - We propose Stiff-switch, thermo-mechanical stiffness control method. Phase change material (PCM) is often used to control stiffness by heat. However, high-voltage requirements and slow heating speed still limit the practical application. We present new thermo-mechanical structures that can efficiently control the stiffness by heating the minimum portion of the structure where stress is concentrated. We employed phase change materials in an H-beam structure and mechanical linkage joint to control stiffness against linear stress and torque, respectively. Additionally, we investigated carbon-based electrically heating paint as a novel joule heating method to achieve fast temperature control speed while requiring low voltage. We demonstrate the proof-of-concept by deploying a PLA filament and hot melt as phase change materials and experimentally show the wide-range stiffness control capability and robust shape-recovery function from large deformation. Finally, we discuss the possible future application scenario for airless tires, tactile tablet pens, robot hands, and finger exoskeletons.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585618
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585618
KW  - 3D printing
KW  - elasticity
KW  - heating paint
KW  - metamaterial
KW  - paper interface
KW  - phase change material
KW  - shape memory
KW  - stiffness switch
KW  - structural mechanics
ER  - 

TY  - CONF
TI  - Statistically Controlling for Processing Fluency Reduces the Aesthetic-Usability Effect
AU  - Preßler, Jan
AU  - Schmid, Lukas
AU  - Hurtienne, Jörn
T3  - CHI EA '23
AB  - The aesthetic-usability effect asserts that user interfaces that appear aesthetic also appear easier to use. Most explanations for the effect see aesthetics in a causal role. In contrast, we propose that processing fluency as a third variable causes both judgements of aesthetics and usability. Processing fluency refers to the subjective ease of information processing and has been shown to influence, among others, judgements of aesthetics and usability. We tested our proposition in an experiment in which users rated screenshots of city websites. The aesthetic-usability effect was replicated by our data: aesthetics and usability correlated .79. When controlling for fluency, however, the aesthetic-usability effect was considerably diminished; the correlation decreased to .34. Future research will address the limitations of this study by investigating a wider range of website designs and adding interactivity to the interfaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585739
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585739
KW  - aesthetic-usability effect
KW  - expected usability
KW  - processing fluency
KW  - websites
ER  - 

TY  - CONF
TI  - StandARone: Infrared-Watermarked Documents as Portable Containers of AR Interaction and Personalization
AU  - Dogan, Mustafa Doga
AU  - Siu, Alexa F.
AU  - Healey, Jennifer
AU  - Wigington, Curtis
AU  - Xiao, Chang
AU  - Sun, Tong
T3  - CHI EA '23
AB  - Hybrid paper interfaces leverage augmented reality (AR) to combine the desired tangibility of paper documents with the affordances of interactive digital media. Typically, the instructions for how the virtual content should be generated are not an intrinsic part of the document but rather accessed through a link to remote resources. To enable hybrid documents to be portable containers of also the AR content, we introduce StandARone documents. Using our system, a document author can define AR content and embed it invisibly on the document using a standard inkjet printer and infrared-absorbing ink. A document consumer can interact with the embedded content using a smartphone with a NIR camera without requiring a network connection. We demonstrate several use cases of StandARone including personalized offline menus, interactive visualizations, and location-aware packaging.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585905
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585905
KW  - augmented reality
KW  - documents
KW  - fabrication
KW  - infrared imaging
KW  - mixed reality
KW  - paper interfaces
KW  - watermarking
ER  - 

TY  - CONF
TI  - STAMPER: Human-machine Integrated Drumming
AU  - Uriu, Daisuke
AU  - Iiyama, Shuta
AU  - Okada, Taketsugu
AU  - Handa, Takumi
AU  - Maekawa, Azumi
AU  - Inami, Masahiko
T3  - CHI EA '23
AB  - STAMPER enables drummers to generate innovative performances by controlling multiple bass drums. STAMPER consists of several “Actuated Pedals (APs),” bass drum pedals embedded with an EC motor, paired with bass drums, and a machine vision system. The APs are used both as input and output. One AP in input mode senses the position of the pedal being used by the drummer. Other APs in actuated mode respond to the input mode AP’s motion. Machine vision is used to monitor the drummer’s movements to control the behavior of the actuated APs. In this paper, we describe the current prototype of STAMPER and what kind of drum performances can be achieved with the system by reporting a study conducted with an experienced drummer.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585619
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585619
KW  - Digital Musical Instruments
KW  - Drums
KW  - Human Augmentation
KW  - Human-machine Integration
KW  - New Interfaces for Musical Expression
ER  - 

TY  - CONF
TI  - Stage, Studio and Screen: Reimagining Dance Online
AU  - Sabherwal, Medhavi
AU  - Eden, Grace
T3  - CHI EA '23
AB  - Dance is a field of study expressed through a series of improvised or choreographed movements and steps that involve arms, legs, and torsos extending across physical space. When these activities shift online, the challenges for performance and teaching are more novel than those found in verbal or text-based communication. This paper discusses preliminary results from a qualitative study conducted to understand how performers and students adapted to online spaces when in-person events were not available. We examine how performers reconstructed the stage and overcame obstacles to building rapport with audiences. We also investigate how students assembled makeshift dance studios in the home and challenges they faced when trying to make sense of choreographed instructions. Preliminary analysis shows that existing technologies lack support for performing and learning dance online, and we conclude with suggestions for how more sophisticated systems might be designed to support embodied knowledge production and transfer.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585717
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585717
KW  - dance and technology
KW  - dance performance
KW  - embodied interaction
KW  - remote collaboration
ER  - 

TY  - CONF
TI  - Speak in Public: an Innovative Tool for the Treatment of Stuttering through Virtual Reality, Biosensors, and Speech Emotion Recognition
AU  - Vona, Francesco
AU  - Pentimalli, Francesca
AU  - Catania, Fabio
AU  - Patti, Alberto
AU  - Garzotto, Franca
T3  - CHI EA '23
AB  - Stuttering is a common speech disorder that affects over 80 million people worldwide. Exposure therapy (ET) is a well-established approach to treating stuttering, but it can be complex and risky to simulate challenging real-life situations. Virtual reality (VR) is a promising tool that can help overcome these limitations. This article presents Speak in Public, a system that combines VR, biosensors, and speech emotion recognition to provide objective measures of patients’ stress and emotional state during ET sessions. In a preliminary study with five participants, we found that the use of VR successfully replicated stressful situations as indicated by biosensors. Additionally, speech emotion recognition showed that patients primarily experienced fear during these activities. Findings are preliminary, and further research with larger samples is needed to validate them. This study highlights the potential of VR and biosensors to enhance ET for stuttering and provides insights for future research in this area.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585612
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585612
KW  - biosensors
KW  - exposure therapy
KW  - speech emotion recognition
KW  - stuttering
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Something Borrowed: Exploring the Influence of AI-Generated Explanation Text on the Composition of Human Explanations
AU  - Ferguson, Sharon A
AU  - Aoyagui, Paula Akemi
AU  - Kuzminykh, Anastasia
T3  - CHI EA '23
AB  - Recent advances in Human-AI interaction have highlighted the possibility of employing AI in collaborative decision-making contexts, particularly in cases where the decision is subjective, without one ground truth. In these contexts, researchers argue that AI could be used not just to provide a final decision recommendation, but to surface new perspectives, rationales, and insights. In this late-breaking work, we describe the initial findings from an empirical study investigating how complementary AI input influences humans’ rationale in ambiguous decision-making. We use subtle sexism as an example of this context, and GPT-3 to create explanation-like text. We find that participants change the language, level of detail, and even the argumentative stance of their explanations after seeing the AI explanation text. They often borrow language directly from this complementary text. We discuss the implications for collaborative decision-making and the next steps in this research agenda.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585727
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585727
KW  - Explainable AI
KW  - GPT-3
KW  - Human Explanations
KW  - Human-AI Collaboration
KW  - User Study
ER  - 

TY  - CONF
TI  - Spot The Difference: AI, Please Make This for Me!
AU  - Hong, Yeong-Gi
AU  - Jeong, Jae-Yeop
AU  - Jeong, Jin-Woo
AU  - Lukianova, Elizaveta
T3  - CHI EA '23
AB  - Play and games are an inseparable part of our lives, and we have been playing various games from our childhood to adulthood. One of the widely recognized games is "Spot-the-Difference", which has been played and employed in a variety of domains, such as education, training, and entertainment. However, designing a custom "Spot-the-Difference" game for a certain domain requires consideration in terms of the level of game difficulty, game interest, and human intervention, therefore, is non-trivial. In this paper, we propose a novel framework based on Human-AI collaboration to automatically generate images for the "Spot-the-Difference" game. We employ Maskformer and Inpainting Stable Diffusion to automatically identify and re-draw a set of regions in the image. Finally, we conducted a user study with 19 participants to evaluate our framework. From the experimental result, we found that AI-generated game images were enjoyable, but there is still room for improvement in the quality of the overall game playing.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585879
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585879
KW  - Game
KW  - Generative AI
KW  - Image Generation
KW  - Instance Segmentation
ER  - 

TY  - CONF
TI  - Spectators of AI : Football Fans vs. the Semi-Automated Offside Technology at the 2022 FIFA World Cup
AU  - Viswanathan, Sruthi
AU  - Shankar, Ravi
AU  - Jackson, Jack
AU  - Binns, Reuben
T3  - CHI EA '23
AB  - More than half of the global population were spectators of AI-assisted decision making during the recent 2022 FIFA World Cup. For the first time in a Football World Cup, via news and social media, fans were briefed about the Semi-Automated Offside Technology (SAOT), which determined the position of players to be offside or not, in real time, with the help of AI. In this paper, we collect and analyse news articles related to offside decisions made with SAOT, published during and around the tournament. Our findings reveal alternating positive and negative portrayals of SAOT in the news, gaps in communication, and needs of Football fans to gain a better spectator experience. In conclusion, we discuss general implications for designing a better relationship between Spectators and AI, specific implications for bettering the experience of Football fans when using SAOT, and introduce our future research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585870
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585870
KW  - explainable AI
KW  - Football
KW  - interactive AI
KW  - offside
KW  - soccer
KW  - spectator sports
KW  - spectators of AI
ER  - 

TY  - CONF
TI  - Spatiality and Semantics - Towards Understanding Content Placement in Mixed Reality
AU  - Ellenberg, Mats Ole
AU  - Satkowski, Marc
AU  - Luo, Weizhou
AU  - Dachselt, Raimund
T3  - CHI EA '23
AB  - Mixed Reality (MR) popularizes numerous situated applications where virtual content is spatially integrated into our physical environment. However, we only know little about what properties of an environment influence the way how people place digital content and perceive the resulting layout. We thus conducted a preliminary study (N = 8) examining how physical surfaces affect organizing virtual content like documents or charts, focusing on user perception and experience. We found, among others, that the situated layout of virtual content in its environment can be characterized by the level of spatial as well as semantic coupling. Consequently, we propose a two-dimensional design space to establish the vocabularies and detail their parameters for content organization. With our work, we aim to facilitate communication between designers or researchers, inform general MR interface design, and provide a first step towards future MR workspaces empowered by blending digital content and its real-world context.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585853
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585853
KW  - Augemented Reality
KW  - Content Organization
KW  - Design Space
KW  - Layout
KW  - Mixed Reality
KW  - User Study
ER  - 

TY  - CONF
TI  - Social Virtual Reality Is My Therapist: Overcoming Social Anxiety Disorder Through Using Social Virtual Reality
AU  - Zamanifard, Samaneh
AU  - Robb, Andrew
T3  - CHI EA '23
AB  - Virtual Reality (VR) has long been an important research focus in HCI for treating different phobias. More recently, we have seen a more noticeable upgrade in VR, especially social VR. This research explores how socially anxious people use social VR to interact and practice social skills. The study analyzed 351 Reddit posts and comments and found that the immersive and embodied features of social VR, such as physicality, sense of presence, nonverbal communication and shared activities, can help individuals with a social anxiety disorder (SAD) overcome their fear of social interaction. Additionally, the study investigated if social skills gained in social VR can transfer to the offline world. This work highlights the potential of social VR in treating SAD and can inform the design of future social VR platforms to better support individuals with SAD.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585888
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585888
KW  - Fear of Social interaction
KW  - Social Anxiety
KW  - Social Phobia
KW  - Social VR
ER  - 

TY  - CONF
TI  - Smart Authenticity Experience Design With and For Airbnb Hosts
AU  - An, Jingrui
AU  - Chuang, Ya-Liang
AU  - Eggen, Berry
T3  - CHI EA '23
AB  - This paper presents a co-design study that aimed to explore how to design authentic experiences for prospective guests by collaborating with seven Airbnb hosts. Through contextual inquiry, we investigated the authentic requirements of different hosts and co-created design ideas with them. Together, we generated 58 interactive design concepts, 19 of which were contributed by the hosts themselves. By discussing these concepts with Airbnb participants and systematically analyzing the qualitative data, we identified five new dimensions for designing authentic guest experiences: serendipity of discovery, sense of welcome, extensions and connections, taking or leaving mementos, and co-generating experiences. Our findings provide valuable insights for designers and researchers looking to create more authentic experiences for Airbnb guests.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585702
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585702
KW  - Airbnb
KW  - Authentic
KW  - Co-design
KW  - Guest experience
KW  - Internet of things
KW  - Smart home
ER  - 

TY  - CONF
TI  - Simulating Participant Behavior in Experience Sampling Method Research
AU  - Khanshan, Alireza
AU  - Van Gorp, Pieter
AU  - Markopoulos, Panos
T3  - CHI EA '23
AB  - The Experience Sampling Method (ESM) is applied widely for collecting self-reports from participants in free-living environments. Preserving high compliance in ESM remains challenging, especially when a study lasts more than a few weeks. Markedly, participants get increasingly bothered by prompts delivered at inconvenient moments. To alleviate that, personalization techniques have shown their potential. Particularly, ESM protocols that delivered prompts at more convenient times have significantly fewer drop-outs. Such personalization may lead to sampling bias, while ESM should be ecologically valid. Therefore, it is critical to equip experimenters with tools that enable trade-off analyses between the minimization of dropout versus the maximization of ecological validity. This paper lays the foundations for such analyses: we propose a novel ESM-specific participant behavior simulator, demonstrate its resemblance to real-life data and expected behaviors indicated by psychological theories. Such simulators enable trade-off analyses and they can help avoid the cold start of reinforcement learning agents.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585586
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585586
KW  - decision-making process
KW  - experience sampling method
KW  - human behavior simulation
ER  - 

TY  - CONF
TI  - Semi-Automated Approach for Evaluating Severe Weather Risk Communication
AU  - Jit, Sophia
AU  - Spinney, Jennifer
AU  - Chandra, Priyank
AU  - Soden, Robert
T3  - CHI EA '23
AB  - Communicating risk to the public in the lead-up to and during severe weather events has the potential to reduce losses from such events. Globally, severe weather events are anticipated to increase due to climate change rendering effective risk communication an integral component of climate adaptation policies. The identification of best practices in risk communication has long been studied by risk communication professionals. However, few articles have attempted to quantify the compliance of severe weather risk messages with these best practices at scale or developed tools that can be used by this population. The current work makes two contributions toward this goal. First, we use string-matching to evaluate the degree to which risk communication issued in Canada complies with best practices and suggest ways to improve this messaging. Second, we suggest a writing support tool to be used by risk communication professionals to evaluate risk messages.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585753
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585753
KW  - Severe Weather Risk Communication
KW  - String-Matching
KW  - Writing Support Tool
ER  - 

TY  - CONF
TI  - Searching for the Whole Truth: Harnessing the Power of Intellectual Humility to Boost Better Search on Debated Topics
AU  - Rieger, Alisa
AU  - Bredius, Frank
AU  - Tintarev, Nava
AU  - Pera, Maria Soledad
T3  - CHI EA '23
AB  - We often use search engines when seeking information for opinion-forming and decision-making on debated topics. However, searching for resources on debated topics to gain well-rounded knowledge is cognitively demanding, leaving us vulnerable to cognitive biases, such as confirmation bias. This can impede well-informed decision-making, and on a societal level, snowball to compel extremism and polarization. Most existing approaches to support better search apply nudges that directly modify user behavior. Such interventions bear the risk of harming user autonomy. Here, we discuss the shift we envision towards autonomy-preserving interventions that boost users’ metacognitive skills, specifically their intellectual humility (IH)–the ability to recognize the fallibility of one’s beliefs and the limits of one’s knowledge. While simple interventions to boost IH have shown promise, the effect on users’ search behavior has yet to be investigated. We present critical research questions, challenges, and an initial research plan to advance knowledge in this area.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585693
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585693
KW  - Boosting
KW  - Cognitive Bias Mitigation
KW  - Intellectual Humility
KW  - Opinion Formation
KW  - Web Search
ER  - 

TY  - CONF
TI  - Scent as a Sensory Modality for Data Physicalisation for Office Well-being
AU  - Brombacher, Hans
AU  - Nikolov, Vasil
AU  - Vos, Steven
AU  - Houben, Steven
T3  - CHI EA '23
AB  - While the office environment is increasingly viewed as an opportune setting to improve the health and well-being of individuals, the use of scent to physicalize data in this field is mostly under-explored. To study the role of olfactory artifacts in the context of office well-being, we developed two artifacts: Re-cafeen and Whiff. Both artifacts use different scent modalities based on different data types and spatial placements. The used scents in the artifacts are based on a study of 10 scents which asked participants (N=13) to express which scents correspond to the following activities: (i) having an active meeting, (ii) taking a break from work, and (iii) working behind a standing desk. The artifacts were evaluated using smell space mapping. Based on this evaluation, we reflect on the challenges for future work on this topic. Our insights are relevant for the development of olfactory artifacts on the topic of office well-being.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585866
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585866
KW  - Data physicalisation
KW  - Office Well-being
KW  - Olfactory Design
KW  - Scent
ER  - 

TY  - CONF
TI  - Rebo at Work: Reflecting on Working, Learning, and Learning Goals with the Reflection Guidance Chatbot for Apprentices
AU  - Wolfbauer, Irmtraud
AU  - Bangerl, Mia Magdalena
AU  - Maitz, Katharina
AU  - Pammer-Schindler, Viktoria
T3  - CHI EA '23
AB  - In Rebo at Work, chatbot Rebo helps apprentices to reflect on a work experience and associate it with their training's learning objectives. Rebo poses questions that motivate the apprentice to look at a work experience from different angles, pondering how it went, the problems they encountered, what they learned from it, and what they take away for the future. We present preliminary results of a 9-month field study (analysis of 90 interactions of the first 6 months) with 51 apprentices in the fields of metal technology, mechatronics, and electrical engineering. During reflection with Rebo at Work, 98% of apprentices were able to identify their work experience as a learning opportunity and reflect on that, and 83% successfully connected it with a learning objective. This shows that self-monitoring of learning objectives and reflection on work tasks can be guided by a conversational agent and motivates further research in this area.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585827
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585827
KW  - apprentices
KW  - chatbot
KW  - learning goals widget
KW  - reflection guidance
KW  - Reflective learning
ER  - 

TY  - CONF
TI  - Regret, Delete, (Do Not) Repeat: An Analysis of Self-Cleaning Practices on Twitter After the Outbreak of the COVID-19 Pandemic
AU  - Diaz Ferreyra, Nicolás Emilio
AU  - Shahi, Gautam Kishore
AU  - Tony, Catherine
AU  - Stieglitz, Stefan
AU  - Scandariato, Riccardo
T3  - CHI EA '23
AB  - During the outbreak of the COVID-19 pandemic, many people shared their symptoms across Online Social Networks (OSNs) like Twitter, hoping for others’ advice or moral support. Prior studies have shown that those who disclose health-related information across OSNs often tend to regret it and delete their publications afterwards. Hence, deleted posts containing sensitive data can be seen as manifestations of online regrets. In this work, we present an analysis of deleted content on Twitter during the outbreak of the COVID-19 pandemic. For this, we collected more than 3.67 million tweets describing COVID-19 symptoms (e.g., fever, cough, and fatigue) posted between January and April 2020. We observed that around 24% of the tweets containing personal pronouns were deleted either by their authors or by the platform after one year. As a practical application of the resulting dataset, we explored its suitability for the automatic classification of regrettable content on Twitter.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585583
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585583
KW  - COVID-19
KW  - crisis communication
KW  - deleted tweets
KW  - online regrets
KW  - privacy
KW  - self-disclosure
ER  - 

TY  - CONF
TI  - Reddit Insights: Improving Online Discussion Culture by Contextualizing User Profiles
AU  - Waltenberger, Franz
AU  - Höferlin, Simon
AU  - Froehlich, Michael
T3  - CHI EA '23
AB  - More than forty years after the creation of the first online messaging board, the quality of online discussion culture remains a topic of significant scientific and public debate. Social media platforms have struggled to maintain a free marketplace of ideas while addressing issues such as censorship, propaganda, and misinformation. Traditional methods of content moderation have been ineffective in addressing these issues, with incivility in online discussions remaining a major concern. In an effort to address the ongoing challenges facing online discussion culture, we have developed a browser extension called Reddit Insights, designed to improve discourse quality through design interventions. The extension provides context to user profiles by aggregating information from past commenting behavior. Results from a small-scale qualitative assessment with 9 users indicate that the extension helped users contextualize posts, identify implicit political tendencies and decide with whom to interact and choose in which discussions to engage more wisely.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585671
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585671
KW  - computational social science
KW  - online discussion culture
KW  - reddit
ER  - 

TY  - CONF
TI  - Read It Now, Not Later! Integrating Semantic Recommendation into In-Browser Web Page Scrap Tool
AU  - Jo, Jeongmin
AU  - Kim, Sangyeon
AU  - Lee, Sangwon
T3  - CHI EA '23
AB  - “Read-It-Later” is a generic term for web page scrap tools. However, research in Personal Information Management (PIM) has mainly focused on bookmarks, and little is known about Read-It-Later, especially when users interact with various scrap tools and devices. This study aims to understand users' mental model of Read-It-Later and derive design implications that account for a new in-browser web page scrap tool, called “Read-It-Now.” Specifically, we conducted semi-structured interviews to develop the mental model of web scraping behaviors and extracted three implications (tool hierarchy, contextual aids, and proactive triggers) for encouraging the creation and retrieval of scraps. Based on the implications, we designed "Read-It-Now" which focuses on semantic recommendation: it detects the title of the currently activated tab and searches for the semantically closest scraps. We checked the empirical potentiality of the suggested prototype by testing with a sample dataset, and this provided insights for practitioners to design Read-It-Later tools.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585858
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585858
KW  - information scrap
KW  - personal information management
KW  - prototyping
KW  - semantic recommendation
KW  - user interface
ER  - 

TY  - CONF
TI  - Reach Prediction using Finger Motion Dynamics
AU  - Valkov, Dimitar
AU  - Kockwelp, Pascal
AU  - Daiber, Florian
AU  - Krüger, Antonio
T3  - CHI EA '23
AB  - The ability to predict the object the user intends to grasp or to recognize the one she is already holding offers essential contextual information and may help to leverage the effects of point-to-point latency in interactive environments. This paper investigates the feasibility and accuracy of recognizing un-instrumented objects based on hand kinematics during reach-to-grasp and transport actions. In a data collection study, we recorded the hand motions of 16 participants while reaching out to grasp and then moving real and synthetic objects. Our results demonstrate that even a simple LSTM network can predict the time point at which the user grasps an object with 23 ms precision and the current distance to it with a precision better than 1 cm. The target’s size can be determined in advance with an accuracy better than 97%. Our results have implications for designing adaptive and fine-grained interactive user interfaces in ubiquitous and mixed-reality environments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585773
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585773
KW  - datasets
KW  - grasp prediction
KW  - hand gesture
KW  - neural networks
ER  - 

TY  - CONF
TI  - QWriter: Technology-Enhanced Alphabet Acquisition based on Reinforcement Learning
AU  - Shakerimov, Aidar
AU  - Sarmonov, Shamil
AU  - Amirova, Aida
AU  - Oralbayeva, Nurziya
AU  - Zhanatkyzy, Aida
AU  - Telisheva, Zhansaule
AU  - Aimysheva, Arna
AU  - Sandygulova, Anara
T3  - CHI EA '23
AB  - In Kazakhstan, the ongoing Cyrillic-to-Latin alphabet shift raises challenges for early literacy development and acquisition in the Kazakh language. This paper proposes the QWriter system to help young children learn the Latin-based Kazakh alphabet and its handwriting. The system consists of a humanoid robot NAO, a tablet with a stylus, and a Reinforcement Learning (RL) agent that learns a child’s mistakes and progress to maximize alphabet learning in the shortest period of time by adapting the order of practice words according to the child’s mistakes. To evaluate the effectiveness of the QWriter system, we conducted a between-subject design experiment with 59 Kazakh children aged 6-8 years old and compared their learning performance with a human tutor and the CoWriting Kazakh robot system. The results did not support our assumption, we found that the proposed system received significantly higher likability scores than the baseline human tutor.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585611
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585611
KW  - chilld-robot interaction
KW  - Kazakh
KW  - reinforcement learning
KW  - robot-assisted language learning
ER  - 

TY  - CONF
TI  - Prototypes, Platforms and Protocols: Identifying Common Issues with Remote, Unmoderated Studies and their Impact on Research Participants
AU  - Schirra, Steven
AU  - Volkov, Sasha G
AU  - Narasimha, Shraddhaa
AU  - Bentley, Frank
T3  - CHI EA '23
AB  - Remote, unmoderated research platforms have increased the efficiency of traditional design research approaches such as usability testing, while also allowing practitioners to collect more diverse user perspectives than afforded by lab-based methods. The self-service nature of these platforms has also increased the number of studies created by requestors without formal research training. Past research has explored the quality and validity of research findings on these platforms, but little is known about the everyday issues participants face while completing these studies. We conducted an interview-based study with 22 experienced research participants to understand what issues are most commonly encountered and how participants mitigate issues as they arise. We found that a majority of the issues surface across research platforms, requestor protocols and prototypes, and participant responses range from filing support tickets to simply quitting studies. We discuss the consequences of these issues and provide recommendations for researchers and platforms.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585836
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585836
KW  - participant experience
KW  - remote research
KW  - unmoderated testing
KW  - usability testing
ER  - 

TY  - CONF
TI  - Project Mihr: Enabling Gestural Interactions on a Keyboard using a Graphene-based Fabric
AU  - Luo, Yiyue
AU  - Barhudarian, Evelina
AU  - Seyed, Teddy
T3  - CHI EA '23
AB  - The physical keyboard has long been the de facto input mechanism for computers, despite advances in other input forms and modalities. Even with these advances, the augmentations of physical keyboards have still been limited to keystroke-based entry. We leverage the inevitable physical touch and motions over a keyboard during keystroke-based input to present Project Mihr, a physical keyboard that has been augmented to be touch-sensitive. We leveraged passive capacitive sensing with a graphene-based textile to detect and classify rich and expressive gestural interactions over a keyboard. We conclude this work by describing our characterization on the sensing performance and presenting several different application scenarios that are enabled by our technique over keyboards.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585873
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585873
KW  - keyboard interaction
KW  - Smart textiles
ER  - 

TY  - CONF
TI  - QuickRef: Should I Read Cited Papers for Understanding This Paper?
AU  - Park, Sangjun
AU  - Lee, Chanhee
AU  - Han, Jieun
AU  - Lee, Uichin
T3  - CHI EA '23
AB  - Researchers spend lots of time for reading scientific papers as they need to stay updated with recent trends. However, navigating citations, which are indispensable elements of research papers, can act as a barrier for junior researchers as they do not have enough background knowledge and experience. We conduct a formative user study to identify challenges in navigating cited papers. We then prototype QuickRef, an interactive reader that provides additional information about cited papers on the side panel. A preliminary user study documents the usability of QuickRef. Further, we present practical design implications for citation navigation support.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585899
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585899
KW  - citation
KW  - interactive reader
KW  - reference
ER  - 

TY  - CONF
TI  - Query Execution Plans and Semantic Errors: Usability and Educational Opportunities
AU  - Taipalus, Toni
T3  - CHI EA '23
AB  - Syntax errors are typically separated from semantic errors in query formulation, the former being detected by the database management system (DBMS), and the latter seemingly not. On the other hand, query execution plans are typically utilized in query optimization, and not interconnected with syntax errors, as a syntactically invalid query produces no execution plan. In this study, we show and argue for breaking the confound between execution plans and error messages for better query formulation usability and education. We show how several popular DBMSs detect semantic errors and complications in queries, yet often do not inform the user of such problems. This study is a demonstration of how decades old technology could be used more effectively in novel contexts of usability and software engineering education with little effort by showing query writers not merely syntax errors, but also semantic errors and complications detected by DBMSs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585794
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585794
KW  - database management system
KW  - error
KW  - query execution plan
KW  - SQL
KW  - usability
ER  - 

TY  - CONF
TI  - PromptInfuser: Bringing User Interface Mock-ups to Life with Large Language Models
AU  - Petridis, Savvas
AU  - Terry, Michael
AU  - Cai, Carrie Jun
T3  - CHI EA '23
AB  - Large Language Models have enabled novices without machine learning (ML) experience to quickly prototype ML functionalities with prompt programming. This paper investigates incorporating prompt-based prototyping into designing functional user interface (UI) mock-ups. To understand how infusing LLM prompts into UI mock-ups might affect the prototyping process, we conduct a exploratory study with five designers, and find that this capability might significantly speed up creating functional prototypes, inform designers earlier on how their designs will integrate ML, and enable user studies with functional prototypes earlier. From these findings, we built PromptInfuser, a Figma plugin for authoring LLM-infused mock-ups. PromptInfuser introduces two novel LLM-interactions: input-output, which makes content interactive and dynamic, and frame-change, which directs users to different frames depending on their natural language input. From initial observations, we find that PromptInfuser has the potential to transform the design process by tightly integrating UI and AI prototyping in a single interface.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585628
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585628
KW  - Design
KW  - Generative AI
KW  - Large Language Models
KW  - Prototyping
ER  - 

TY  - CONF
TI  - Programming without a Programming Language: Challenges and Opportunities for Designing Developer Tools for Prompt Programming
AU  - Fiannaca, Alexander J.
AU  - Kulkarni, Chinmay
AU  - Cai, Carrie J
AU  - Terry, Michael
T3  - CHI EA '23
AB  - Existing tools for writing prompts for language models (known as “prompt programming”) provide little support to prompt programmers. Consequently, as prompts become more complex with the addition of multiple input/output examples (“few-shot” prompts), they can be hard to read, understand, and edit. In this work, we observe that prompts are often used to solve complex problems, but lack the strict grammar of a traditional programming language. We describe methods for extracting the semantically meaningful structure of natural language prompts (e.g., regions of the prompt representing a preamble or input/output examples) in the absence of a rigid formal grammar, and demonstrate a range of editor features that can leverage this information to assist prompt programmers. Finally, we relate initial feedback from design probe explorations with a set of domain experts and provide insights to help guide the development of future prompt editors.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585737
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585737
KW  - language models
KW  - prompt programming
ER  - 

TY  - CONF
TI  - Print Your Money: Cash-Like Experiences with Digital Money
AU  - Zhou, Chenhang
AU  - Chen, Yu
AU  - Wattenhofer, Roger
AU  - Wang, Ye
T3  - CHI EA '23
AB  - The use of digital money has become increasingly popular, but it comes with certain drawbacks. For instance, it can be challenging to make payments during power outages or internet failures. Additionally, some groups may find it difficult to use digital money. To address these concerns, we propose a design for a central bank digital currency (CBDC) similar to physical cash but also integrates with digital payment systems. This would enable users to access digital money without needing a third party. Our design also addresses technical and security concerns by implementing a trust-level model and ensuring that the system meets users’ security needs. Ultimately, our design has the potential to replace physical banknotes and coins.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585772
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585772
KW  - central bank digital currency
KW  - Digital money
ER  - 

TY  - CONF
TI  - Preparing Children with Level 1 ASD for Social Interactions through Storytelling with Amy: An Exploratory Study
AU  - Gagan, Isser Troy
AU  - Matias, Maria Angela Mikaela
AU  - Tan, Ivy
AU  - Vinco, Christianne Marie
AU  - Ong, Ethel
T3  - CHI EA '23
AB  - Technology-based interventions can help children with autism spectrum disorder (ASD) prepare for social interactions by addressing their limited social communication and emotion regulation skills. In particular, chatbots’ natural language abilities can provide a conversation-based interaction that is safe and individualized. This motivates us to design Amy as a virtual talking companion that delivers social stories to children with Level 1 ASD. Through a week-long experiment, we captured the perception and feedback of four children and their parents on Amy’s story-based conversations using performance, humanity and affect as the evaluation metrics. Children found the story themes to be relevant and the accompanying visuals to be helpful in their understanding of the stories and their engagement with Amy. Parents and child educators praised Amy for being considerate of the children’s feelings. Large scale experiments can further shed insights on the utility of a chatbot that anchors its delivery on social-emotional learning theories.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585916
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585916
KW  - autism spectrum disorder
KW  - conversational agent
KW  - social-emotional learning
KW  - storytelling
ER  - 

TY  - CONF
TI  - Positional Control in Node-Based Programming
AU  - Jiang, Peiling
T3  - CHI EA '23
AB  - Visual programming languages enable novices to code with a lowered barrier. These languages typically employ one of two popular design approaches — block-based editing (e.g. Scratch), which allows users to control the execution order of code blocks, and node-based editing (e.g. Grasshopper), which enables users to control the data flow through nodes and wires. We propose integrating these two approaches by utilizing positional control in node-based programming to visualize and allow manipulation of both the execution order and data flow. A grid system organizes blocks and determines their sequence. Effect block is introduced, which controls other blocks within its effective range through positional constraints. As relocating blocks is easier than wiring that targets tiny inlets and outlets, we aim to shorten the feedback loop time and encourage exploration. We present b5, a web-based novel visual interface for creative coding, to demonstrate and evaluate this design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585878
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585878
KW  - Authoring environment
KW  - Creative coding
KW  - Visual programming
ER  - 

TY  - CONF
TI  - PostGuard: Towards Easy and Secure Email Communication
AU  - Botros, Leon
AU  - Brandon, Merel
AU  - Jacobs, Bart
AU  - Ostkamp, Daniel
AU  - Schraffenberger, Hanna
AU  - Venema, Marloes
T3  - CHI EA '23
AB  - This paper presents PostGuard: a secure email encryption solution for communication in the private and public sectors. The novelty of PostGuard lies in the combination of identity-based encryption with a digital identity wallet. Within this setting, senders specify who should be able to read/decrypt their emails in terms of the recipient’s attributes (e.g., their name and/or email address). Subsequently, recipients use the digital identity wallet app Yivi to prove that they possess these attributes to decrypt the mails. Thus, PostGuard reduces decryption to authentication. The underlying mental model is: to see confidential information, you need to prove that you are the intended recipient. The main contribution of this paper is the working prototype of PostGuard for Outlook and Thunderbird. This paper describes the concept, setup, implementation, and design of PostGuard and discusses current limitations and plans for future work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585622
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585622
KW  - ABE
KW  - attribute-based identity management
KW  - cryptography
KW  - Email encryption
KW  - IBE
KW  - user experience design
KW  - Yivi
ER  - 

TY  - CONF
TI  - Point Cloud Alignment through Mid-Air Gestures on a Stereoscopic Display
AU  - Krug, Katja
AU  - Satkowski, Marc
AU  - Docea, Reuben
AU  - Ku, Tzu-Yu
AU  - Dachselt, Raimund
T3  - CHI EA '23
AB  - Manual point cloud registration is often a crucial step during the mapping of 3D point clouds and usually performed on a conventional desktop setup with mouse interaction. Since 3D point clouds are inherently spatial, these 2D applications suffer from impaired depth perception and inconvenient interaction. Nonetheless, there are few efforts to improve the usability of these applications. To address this, we propose an alternative setup, consisting of a stereoscopic display and an external hand tracker, allowing for enhanced depth perception and natural interaction without the need for body-worn devices or handheld controllers. We developed interaction techniques for point cloud alignment in 3D space, including visual feedback during alignment, and implemented a proof-of-concept prototype in the context of a surgical use case. We describe the use case, design and implementation of our concepts and outline future work. Herewith we provide a user-centered alternative to desktop applications for manual point cloud registration.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585862
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585862
KW  - image guidance navigation systems
KW  - mid-air interaction
KW  - point cloud alignment
KW  - point cloud registration
KW  - stereoscopic display
ER  - 

TY  - CONF
TI  - Play and Resistance: Intersecting Identities and Implicit Biases in Gamified Educational Tools
AU  - Pastushenko, Olena
AU  - Passmore, Cale J.
T3  - CHI EA '23
AB  - As Human-Computer Interaction (HCI) researchers, we can create digital tools which facilitate growth, liberate, and heal, or create tools for trauma, discrimination, and increasing social power divides. Thus, it is extremely important to follow intersectionally grounded, qualitatively sound approaches with a diversity of participants situated across different axes of oppression, not only to improve the effectiveness of our explicit interfaces, but also to change the implicit messages and power structures we encode in them. The outcome of this paper, which represents a middle step between several larger studies, is twofold: a definition of the research methodology used to more accurately study bias in gamification in education, and outreach to potential study participants for the followup study. From current literature on the effects of (mis)representation, inaccessible and harmful designs, and oppressive technologies in HCI, we see that a crucial step in HCI research around gamified education tools is missing: the experiences, stories, and design input of marginalised students.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585792
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585792
KW  - biases
KW  - educational tools
KW  - gamification
KW  - intersectionality
KW  - narratives
KW  - norms
KW  - representation
ER  - 

TY  - CONF
TI  - Persona Co-Design for Improving Digital Accessibility
AU  - Heitmeier, Kathy-Ann
AU  - Kersken, Verena
AU  - Piskorek, Patricia
AU  - Böhm, Ann-Katrin
AU  - Egger, Niklas
AU  - Lang, Markus
AU  - Zimmermann, Gottfried
T3  - CHI EA '23
AB  - This paper examines approaches to developing authentic accessibility personas that can help improve the design of products for persons with disabilities. Personas have been a controversial empathy-building tool that have been shown to have potentially harmful effects on the design of accessible products when they are not well-made or used appropriately. In this study we describe a nested co-design approach that involves personas as product and tool, and that includes persons with disabilities at multiple stages and in multiple functions within the design process. These approaches are used in the context of the improvement of digital accessibility teaching and learning materials at higher education institutions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585857
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585857
KW  - Co-Design
KW  - Digital Accessibility
KW  - Higher Education
KW  - Personas
ER  - 

TY  - CONF
TI  - PianoHandSync: An Alignment-based Hand Pose Discrepancy Visualization System for Piano Learning
AU  - Liu, Ruofan
AU  - Wu, Erwin
AU  - Liao, Chen-Chieh
AU  - Nishioka, Hayato
AU  - Furuya, Shinichi
AU  - Koike, Hideki
T3  - CHI EA '23
AB  - Video-based lessons are becoming a popular way for distance piano education. However, limited by the fixed camera angle, a video is difficult to tell precise 3D hand posture, which is one of the most essential factors for learning piano. This paper presents a visualization system providing the intuitive discrepancy of hand postures in two piano performance videos. Through a motion capture system, the estimated 3D postures are visualized and discrepancies based on distinct metrics are displayed, integrated with modular functions assisting skill acquisition. A pilot study proves that the proposed visualization can be a supplementary means for only video-based lessons in terms of correcting hand postures and fingering.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585705
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585705
KW  - Motion Analysis
KW  - Piano Training
KW  - Virtual Visualization
ER  - 

TY  - CONF
TI  - Perceived Communication Experiences of Children and Young People with Down Syndrome: The Impact of People, Places, and AAC Methods
AU  - Scougal, Elaine
AU  - Waller, Annalu
AU  - Melinger, Alissa
AU  - Crabb, Michael
T3  - CHI EA '23
AB  - People with Down syndrome can experience communication challenges, impacting daily interactions. Augmentative and Alternative Communication (AAC) can be beneficial, including signing and electronic communication aids. Research mostly focuses on intervention studies, limiting insight into real-world AAC experiences. An online survey was developed to investigate perceived challenges and opportunities related to AAC experienced by children and young people with Down syndrome and their families, completed by 264 caregivers. We report on AAC currently used, support received, and contextual influences. The results highlight that despite signing being the most used form of AAC for the group, its use presents barriers in wider social contexts due to required communication partner skill. Electronic AAC, however, appears under-used, and challenges related to support and the physical properties of communication aids are reported. Further research should extend understanding related to AAC use across social contexts and device onboarding to enhance societal participation and independence.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585660
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585660
KW  - AAC
KW  - Augmentative and Alternative Communication
KW  - Communication
KW  - Down syndrome
ER  - 

TY  - CONF
TI  - Pencil-E: Crafting Functional Electronics Using Pencils and Paper
AU  - Li, Yiyang
AU  - Guo, Tianze
AU  - He, Jiajun
AU  - Yu, Jiazheng
AU  - Dong, Hao
AU  - Zhang, Ting
AU  - Wang, Guanyun
T3  - CHI EA '23
AB  - We present Pencil-E, a low-cost, ubiquitous, and accessible sensing and actuating method using pencils and paper for personal fabrication. The basic architectures of this method are the principal electrical features of the pencil as a conductive material and the properties of the paper as a carrier of pencil traces. By combining paper craft methods, including single-layer, multi-layer, and constructive structures, we developed resistive and capacitive sensors with haptic feedback and allowed customization. This paper describes the design guidelines, sensing mechanics, primitive constructions, and the fabrication process. Multiple pre-designed elements and application scenarios are demonstrated, including tangible user interfaces, wearable devices, and interactive art crafts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585759
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585759
KW  - flexible electronics
KW  - paper interface
KW  - pencil
KW  - personal fabrication
KW  - rapid prototyping
ER  - 

TY  - CONF
TI  - Paraflow: A Computational Design Tool for Support-free Multimaterial 3D Printing
AU  - Lipkowitz, Gabriel
AU  - Shaqfeh, Eric
AU  - Desimone, Joseph
T3  - CHI EA '23
AB  - While 3D printing affords designers unprecedented geometric complexity, currently it requires cumbersome support structures that are not user-friendly in many ways: materially wasteful, human labor-intensive, time-consuming to remove, damaging to surface finish, and often unreliable in ensuring printability at all. We describe our novel 3D printing method, Injection 3D printing, which, as an add-on extension to existing resin printers requiring minimal hardware changes, offers an alternative to support structures. Our approach innervates the part with fluidic channels that introduce one, or multiple different, resins into the printer, effectively offsetting forces otherwise necessitating support. To allow any resin 3D printer user to implement multimaterial injection printing on their system, we present Paraflow, a computational inverse design tool that innervates a 3D model to be 3D printed by our approach.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585891
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585891
KW  - 3D printing
KW  - Design for Additive Manufacturing
KW  - Generative design
ER  - 

TY  - CONF
TI  - Patterns of Effective Human-Agent Teams
AU  - Momose, Kazuhiko
AU  - Weekes, Troy
AU  - Mehta, Rahul
AU  - Wright, Cameron
AU  - Moukpe, Josias
AU  - Eskridge, Thomas
T3  - CHI EA '23
AB  - Intelligent systems are increasingly interacting with people, both in their daily lives and through their use in safety critical systems. Current research is focused on how to use intelligent systems in a collaborative way as a teammate, rather than a tool. This requires a better understanding of what behaviors enable effective human-agent teams. This paper reports an experiment where a human player collaborates with an agent to perform a maneuvering task while concurrently performing a memory task. The player must determine in which contexts the agent requires their input to achieve better combined game plus memory task accuracy scores. We hypothesized that high-performing teams would exhibit different patterns of control inputs when compared to low-performing teams and that these patterns of control would be made more evident with user interfaces that increased operator situation awareness. Preliminary results are inconclusive, but show different patterns of interaction between high- and low-performing teams.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585608
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585608
KW  - Human-agent teamwork
KW  - patterns of interactions
KW  - user interface design
ER  - 

TY  - CONF
TI  - Pareto Optimal Layouts for Adaptive Mixed Reality
AU  - Johns, Christoph Albert
AU  - Evangelista Belo, João Marcelo
AU  - Klokmose, Clemens Nylandsted
AU  - Pfeuffer, Ken
T3  - CHI EA '23
AB  - Adaptive mixed reality applications adjust their user interfaces based on the context in which they are used to provide a smooth experience for different users and environments. This involves carefully positioning UI elements, which can be challenging due to the many possible placements and need to balance competing goals. Current approaches employ global criterion optimization methods like weighted sums, which can be difficult to use, inflexible, and might not find preferred solutions. This can prevent the adaptations from meeting end-user expectations. We suggest using online multi-objective optimization methods which generate a set of Pareto optimal adaptation proposals, giving users more control and adding flexibility to the computational decision-making. We explore the feasibility of our approach by generating adaptations for a basic synthetic example and discuss relevant dimensions for a formal evaluation with end-users, including the choice of algorithm, decomposition technique, and objectives.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585732
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585732
KW  - mixed reality
KW  - multi-objective optimization
KW  - Pareto frontier
KW  - UI adaptation
ER  - 

TY  - CONF
TI  - OpenBCI + 3D-Printed Headphones = Open ExG Headphones – An Open-Source Research Platform for Biopotential Earable Applications
AU  - Knierim, Michael Thomas
AU  - Puhl, Daniel
AU  - Ivucic, Gabriel
AU  - Röddiger, Tobias
T3  - CHI EA '23
AB  - Earables research is a promising field in Human-Computer Interaction (HCI) due to the variety of observable phenomena that can be captured by sensors placed in the ear region. However, this field is hindered by the use of custom-built hardware and software, which can create barriers for less experienced researchers and lead to high assessment heterogeneity. To address this challenge, we have developed a platform for electrophysiological ear-centered research. This platform combines the established amplifier hardware and recording software stack of the OpenBCI biosignal ExG system with a low-cost 3D-printed over-ear headphone design, based on electrode positioning best practices from neuroscientific research. To demonstrate the flexibility and potential of this platform, we have conducted two studies replicating classical EEG, EOG, ECG, and EMG patterns, and showing that the system is reliable and easy to use in a promising application scenario: detecting mental workload levels across multiple tasks.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585875
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585875
KW  - Earables
KW  - ECG
KW  - EEG
KW  - EMG
KW  - EOG
KW  - Headphones
KW  - Mental Workload
KW  - OpenBCI
ER  - 

TY  - CONF
TI  - Ocularone: Exploring Drones-based Assistive Technologies for the Visually Impaired
AU  - Raj, Suman
AU  - Padhi, Swapnil
AU  - Simmhan, Yogesh
T3  - CHI EA '23
AB  - Fleets of Unmanned Aerial Vehicles (UAVs), also called drones, are becoming commonplace to support diverse applications in logistics and urban safety. These rely on advances in computer vision and Artificial Intelligence (AI) for autonomous navigation and control, facilitated by onboard sensors and accelerated edge computing devices attached to their base stations. This article examines how drones can be used for social good to enhance the lifestyle of Visually-Impaired People (VIP) through navigational assistance and situation awareness, enabled through visual analytics over drone video streams. We propose Ocularone, a platform for coordinating and managing a heterogeneous UAV fleet that offers drones as buddies to guide users. It uses onboard sensors and edge accelerators, and two-way communication using gestures and audio prompts, to enhance the safety and autonomy of the VIP. We validate our early prototype using Tello nano-drones and Jetson Nano edge accelerators, and present preliminary results for several safety scenarios.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585863
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585863
KW  - Artificial Intelligence
KW  - Assistive technologies
KW  - Cloud computing
KW  - Computer Vision
KW  - Distributed coordination
KW  - Drones
KW  - Edge computing
KW  - Unmanned Aerial Vehicles
KW  - Visually Impaired
ER  - 

TY  - CONF
TI  - ObjGen: Constructing Objects with Digital Genetic Information
AU  - Matusik, Hanna
AU  - Konakovic Lukovic, Mina
T3  - CHI EA '23
AB  - The genome of each living organism encodes its phenotype. Inspired by this phenomenon, we have designed a new method that allows embedding digital genetic information in everyday objects, which we call the ObjGen. These embeddings encode detailed information on how each object is built as well as additional metadata (e.g., manufacturing instructions, assembly instructions, or user’s manual). By scanning only a small fragment of an object, the whole object can be recreated and its metadata read. We show how this workflow can be implemented for different manufacturing processes: laser cutting, CNC milling, and molding. Our method creates digital genetic codes in the form of digital textures incorporated into the object’s surface. The embedded construction code can be decoded using standard digital cameras. We demonstrate this workflow on a variety of different objects.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585781
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585781
KW  - fabrication
KW  - identification
KW  - laser cutting
KW  - making
KW  - manufacturing
KW  - tags
ER  - 

TY  - CONF
TI  - NotiFade: Minimizing OHMD Notification Distractions Using Fading
AU  - Janaka, Nuwan
AU  - Zhao, Shengdong
AU  - Chan, Samantha
T3  - CHI EA '23
AB  - While animations can minimize attention costs for desktop notifications, their application for Optical see-through Head-Mounted Display (OHMD) notifications is underexplored. To investigate the effectiveness of animation on OHMD notifications in minimizing attention costs, we conducted a study comparing fade-in, blast, and scrolling notification animations. Results showed that fade-in animation minimizes notification interference with the primary task, unlike blast and scrolling animations. Its effectiveness depends on multiple factors, including fade-duration and location of the primary task. Finally, we discuss how fade-in animation can improve OHMD notifications and its associated trade-offs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585784
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585784
KW  - animation
KW  - distraction
KW  - fade
KW  - fading
KW  - interruption
KW  - notification
KW  - OHMD
KW  - OST HMD
KW  - scroll
KW  - smart glasses
ER  - 

TY  - CONF
TI  - New Insights into User-Defined Smart Ring Gestures with Implications for Gesture Elicitation Studies
AU  - Gheran, Bogdan-Florin
AU  - Vatavu, Radu-Daniel
AU  - Vanderdonckt, Jean
T3  - CHI EA '23
AB  - We conduct a replication of a previously published gesture elicitation study, which collected and examined user-defined gestures performed with smart rings. Our findings reveal that only 50% of the gestures elicited during our replication match those proposed by the participants of the original study, although our sample of participants had the same characteristics as the sample from the original study, and our participants spent the same amount of time to propose gestures and rated the goodness of their gesture-to-function mappings at the same level as the participants of the original study. Furthermore, the new gestures elicited in our replication present different articulation characteristics in terms of their structure, complexity, symmetry, and locale, compared to the gestures from the original study. Our results have implications for the theory and practice of gesture elicitation studies, for which we provide several recommendations for researchers and practitioners.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585590
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585590
KW  - electronic rings
KW  - Gesture elicitation
KW  - gesture input
KW  - replicability
KW  - RepliCHI
KW  - RepliGES.
KW  - smart rings
KW  - study
ER  - 

TY  - CONF
TI  - NoPhobiar: Designing A VR Game to Prevent Childhood Dark Phobia with Children and Stakeholders
AU  - Su, Xinyi
AU  - Yan, Shuo
T3  - CHI EA '23
AB  - Children's dread of the dark at night is a common occurrence as they develop, but if we disregard their worries without taking action, then they will develop a phobia of the dark, which will negatively impact their future. This study investigates the use of VR games in the prevention and treatment of dark phobia in youngsters. The majority of VR research, though, is not entirely appropriate for treating psychiatric disorders in young patients. We therefore invited children and their stakeholders to explore solutions to this issue in order to better grasp the issues and needs of treating children's phobia of darkness. In this paper, we develop a VR game for the prevention and treatment of dark phobia for children aged 4 to 6 years by engaging children and their stakeholders personally in our research to understand the design requirements and elements. Our research seeks to offer fresh design concepts for the VR treatment of mental illness in children between the ages of 4 and 6.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585733
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585733
KW  - Children's phobia of darkness
KW  - Participatory design
KW  - VR games
ER  - 

TY  - CONF
TI  - Narrative Transportation in Gamified Information Systems: The Role of Narrative-Task Congruence
AU  - Schmidt-Kraepelin, Manuel
AU  - Thiebes, Scott
AU  - Warsinsky, Simon Lukas
AU  - Petter, Stacie
AU  - Sunyaev, Ali
T3  - CHI EA '23
AB  - Gamification refers to the use of game design elements in non-game contexts to evoke both instrumental and experiential outcomes within users. Although narratives are an integral part of most video games, little academic attention has been paid toward narratives as part of gamification design. In this research, we investigate two distinct aspects of narratives in gamified information systems (IS): (1) the mental state of narrative transportation, and (2) the congruence between a narrative and an instrumental task. In an online experiment in the context of physical activity among 325 individuals, we find that high levels of narrative-task congruence make it easier for users to experience narrative transportation, which in turn positively influences the dual outcomes of gamified IS. We contribute to research by contextualizing narrative transportation theory and empirically investigating the affective and behavioral effects of congruence between instrumental task and game design elements.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585595
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585595
KW  - Gamification
KW  - Gamified information systems
KW  - Narrative
KW  - Online experiment
ER  - 

TY  - CONF
TI  - Multi-User Smart Speakers - A Narrative Review of Concerns and Problematic Interactions
AU  - Meng-Schneider, Nicole
AU  - Yasa Kostas, Rabia
AU  - Vaniea, Kami
AU  - Wolters, Maria K
T3  - CHI EA '23
AB  - Smart speakers in multi-user spaces, such as Amazon Echos, introduce risks to both owners and anyone sharing the space. They store voice recordings of user requests, and anyone in range can potentially interact with the device. As smart speakers are usually bound to a single account, despite being shareable by design, it introduces potential tensions between users. We systematically searched the literature for findings on concerns and scenarios in which problems may arise and synthesised the resulting 20 papers in a narrative review. Owners were concerned about other users’, potentially malicious, interactions, device faults, and third party sharing. In contrast, bystanders worried about "being listened" to and a lack of awareness and protections. Our findings show a clear gap in literature on the privacy concerns of regular and incidental secondary users of smart speakers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585689
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585689
KW  - bystander
KW  - incidental user
KW  - multi-user
KW  - smart speaker
KW  - voice assistant
ER  - 

TY  - CONF
TI  - MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models
AU  - Liang, Paul Pu
AU  - Lyu, Yiwei
AU  - Chhablani, Gunjan
AU  - Jain, Nihal
AU  - Deng, Zihao
AU  - Wang, Xingbo
AU  - Morency, Louis-Philippe
AU  - Salakhutdinov, Ruslan
T3  - CHI EA '23
AB  - The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585604
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585604
KW  - explainable AI
KW  - human-in-the-loop
KW  - interpretability
KW  - model analysis and debugging
KW  - multimodal machine learning
KW  - visualization
ER  - 

TY  - CONF
TI  - Motivations for Collecting Digital NFT Fashion: A Uses and Gratifications Theory Approach for Understanding Digital NFT Fashion Collectors’ Behavior
AU  - Cork, Alicia G
AU  - Joinson, Adam
AU  - Smith, Laura G. E.
AU  - Ellis, David A
AU  - Stanton Fraser, Danaë
T3  - CHI EA '23
AB  - Non-fungible tokens (NFTs) allow individuals to demonstrate ownership of digital and physical assets. NFTs are scarce, unique, and authentic; three properties known to be key for determining perceived value. Whilst previous research has primarily focused on NFTs as a source of economic value, here we assess the psychological motivations of collectors of digital fashion NFTs. Specifically, NTFs related to digital fashion are particularly relevant to HCI researchers as they sit at the intersection between business, culture, and self-expression. Here, we survey 19 users of a digital avatar fashion company, Genies, to understand the gratifications users derive from collecting digital NFT fashion. Results demonstrate that the primary motivations for collecting fashion NFTs are self-expression and utility and that motivations associated with value are secondary. We make design recommendations based on these results, indicating that developers should distinguish between expression-based motivations and value-based motivations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585824
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585824
KW  - avatars
KW  - digital fashion
KW  - non-fungible tokens
KW  - uses and gratifications theory
ER  - 

TY  - CONF
TI  - Modulating Interoceptive Signals for Influencing the Conscious Experience
AU  - Jain, Abhinandan
AU  - Choi, Kyung Yun
AU  - Ishii, Hiroshi
AU  - Maes, Pattie
T3  - CHI EA '23
AB  - Interoceptive signals play a key role in genesis of our conscious experience. Modulation of interoceptive signals holds great potential for developing new human-computer interactions by creating dynamic experiences that are able to engage on user’s emotional level. We present design of a wearable system for modulating interoceptive sympathetic signal of heart rate by closed-loop feedback via pneumatic haptic stimulation on carotid baroreceptors. Our preliminary results showcase potency of the system to modulate the sympathetic activity and consequently user’s conscious experience. We discuss the potential of modulating interoceptive signals as a new paradigm towards developing interactions and affective interventions for dynamically reshaping the conscious experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585791
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585791
KW  - Biofeedback
KW  - Emotion Regulation
KW  - Haptics
KW  - Health
KW  - Interoception
KW  - Pneumatic
KW  - Wearable
ER  - 

TY  - CONF
TI  - Modular-Things: Plug-and-Play with Virtualized Hardware
AU  - Read, Jake Robert
AU  - Mcelroy, Leo
AU  - Bolsee, Quentin
AU  - Smith, B
AU  - Gershenfeld, Neil
T3  - CHI EA '23
AB  - We present a collection of tools for building plug-and-play modular physical computing systems that we call Modular-Things. Our tools consist of a set of single purpose embedded devices, a link layer agnostic message passing system for communication between devices, and a web-based programming environment. The devices are dynamically discovered and virtualized into software objects that can be programmed in the web IDE. We tested Modular-Things in a classroom setting where groups of novice machine builders constructed custom machines that integrated embedded systems modules with high-level responsive interfaces built with web and computer vision technologies. Users also extended our system by constructing new customized devices.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585642
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585642
KW  - composability
KW  - modular physical systems
KW  - prototyping frameworks
KW  - virtualization
ER  - 

TY  - CONF
TI  - Modeling reciprocal adaptation in HCI: a Multi-Agent Reinforcement Learning Approach
AU  - Gupta, Tanay
AU  - Gori, Julien
T3  - CHI EA '23
AB  - Adaptation between users and computers is difficult because of the reciprocal long-term adaptation between the user and an adaptive tool. In this work in progress, we present a novel method for designing adaptive systems, by simulating reciprocal adaptation between a user and an intelligent tool via Multi-Agent Reinforcement Learning (MARL). We report on a simple target-selection simulation in which a simulated, rational user tries to reach a target and is aided by an intelligent tool that manipulates the user’s environment. The user and the tool’s behavior are jointly determined by an adaptive algorithm that maximizes their utility. Our approach shows that both agents are capable of learning realistic policies, with the user and tool combination being 30% more effective than the user alone.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585913
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585913
KW  - co-evolution
KW  - deep reinforcement learning
KW  - human-computer interaction
KW  - multi-agent systems
ER  - 

TY  - CONF
TI  - Modeling and Improving Text Stability in Live Captions
AU  - Liu, Xingyu "Bruce"
AU  - Zhang, Jun
AU  - Ferrer, Leonardo
AU  - Xu, Susan
AU  - Bahirwani, Vikas
AU  - Smus, Boris
AU  - Olwal, Alex
AU  - Du, Ruofei
T3  - CHI EA '23
AB  - In recent years, live captions have gained significant popularity through its availability in remote video conferences, mobile applications, and the web. Unlike preprocessed subtitles, live captions require real-time responsiveness by showing interim speech-to-text results. As the prediction confidence changes, the captions may update, leading to visual instability that interferes with the user’s viewing experience. In this paper, we characterize the stability of live captions by proposing a vision-based flickering metric using luminance contrast and Discrete Fourier Transform. Additionally, we assess the effect of unstable captions on the viewer through task load index surveys. Our analysis reveals significant correlations between the viewer’s experience and our proposed quantitative metric. To enhance the stability of live captions without compromising responsiveness, we propose the use of tokenized alignment, word updates with semantic similarity, and smooth animation. Results from a crowdsourced study (N=123), comparing four strategies, indicate that our stabilization algorithms lead to a significant reduction in viewer distraction and fatigue, while increasing viewers’ reading comfort.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585609
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585609
KW  - Flickering Metric
KW  - Live Captions
KW  - Real-Time Transcription
KW  - Speech-to-text
KW  - Text Stability
KW  - Visual Instability
ER  - 

TY  - CONF
TI  - Mirror Placement Matters in Remote Collaboration
AU  - Branch, Boyd
AU  - Mirowski, Piotr
AU  - Ppali, Sophia
AU  - Von Jungenfeld, Rocio
AU  - Allain, Paul
AU  - Efstratiou, Christos
T3  - CHI EA '23
AB  - Video Feedback (VF) in tele-conferences is reported to contribute to ‘Zoom Fatigue’ (ZF). However, such feedback is important for many remote collaborative tasks where users must be aware of their relationship to the camera. Tele-immersion (TI) is presented as an alternative to traditional interfaces that can mitigate symptoms of ZF while maintaining the benefit of VF. The effects of TI on behaviour are understudied. Therefore, we present the findings of a novel field study of 14 domain experts performing a remote collaborative task—improvisational theatre—under all three conditions: 1) with video feedback (VF) in an isolated window, 2) within a tele-immersive environment, and 3) without video feedback at all. A qualitative study was conducted using surveys measuring improv performance metrics. ‘Physical engagement’ and ‘presence’ were perceived highest with tele-immersion, while ‘attunement’ and ‘flow’ between performers were comparable between tele-immersion and no mirror. Isolated VF was perceived worse for most conditions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585798
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585798
KW  - tele-conferencing
KW  - tele-immersion
KW  - video feedback mirrors
ER  - 

TY  - CONF
TI  - Mirror Hearts: Exploring the (Mis-)Alignment between AI-Recognized and Self-Reported Emotions
AU  - Chen, Si
AU  - Cheng, Haocong
AU  - Situ, Jason
AU  - Huang, Yun
T3  - CHI EA '23
AB  - Previous research has found that learners’ reflections on their own emotions can improve their learning experience, and AI-based technologies can be used to automatically recognize learners’ emotions. We conducted user studies involving 32 participants to investigate the relationship between AI-recognized emotions and their self-reported emotions using emojis and text comments. We found that, even though AI recognized a similar amount of positive-high-arousal and negative-low-arousal emotions, participants self-reported more positive-high-arousal emojis. Participants explained the causality and temporality of the self-reported emojis using text comments. Our findings suggest ways of using AI to capture learners’ emotions and support their reflections.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585607
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585607
KW  - Emoji
KW  - Facial Recognition
KW  - Reflection
KW  - Self-Regulated Learning
ER  - 

TY  - CONF
TI  - Measuring the Latency of Graphics Frameworks on X11-Based Systems
AU  - Schmid, Andreas
AU  - Wimmer, Raphael
T3  - CHI EA '23
AB  - Latency is an intrinsic property of all human-computer systems. As it can affect user experience and performance, it should be kept as low as possible for real-time applications. To identify the source of latency, measuring partial latencies is necessary. We present a new method for measuring the latency of graphics frameworks on X11-based systems. Our tool measures the time between an input event arriving at the kernel until a pixel is updated in graphics memory. In a systematic evaluation with 36 test applications, we found that our method delivers consistent results for most tested frameworks, and does not add a significant amount of additional end-to-end latency. Even though further investigation is required to explain inconsistencies with Qt-based frameworks, our method measures the latency of graphics frameworks reliably and accurately in all other cases.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585779
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585779
KW  - graphics frameworks
KW  - latency measurement
ER  - 

TY  - CONF
TI  - May I Still Define Myself? Exploring How Dissonance in Displaying Personal Information Through Head-Mounted Augmented Reality Can Affect Personal Information Sovereignty
AU  - Rixen, Jan Ole
AU  - Funk, Christian
AU  - Rukzio, Enrico
AU  - Gugenheimer, Jan
T3  - CHI EA '23
AB  - Head-mounted Augmented Reality enables individuals to overlay digital information onto the physical world, consequently influencing how they assess and react to augmented social situations. While prior work has shown that augmenting social situations with faithful personal information can benefit a conversation, honest mistakes or an attempt to deceive might lead to a dissonance between augmentation and verbally disclosed information. In this work, we take the first steps towards understanding the happenings in case of information dissonance by conducting a preliminary within-subject online video study (N=30), investigating how it affects users, perception of the interlocutor, and if augmentation or interlocutor would act as the more trusted instance. We found that only 26.7% trusted the interlocutor’s verbally uttered information, while a majority believed the AR device (46.7%) or were undecided (26.7%). We discuss this split in trust and argue for the importance of and factors for a follow-up study on this topic.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585821
KW  - Augmented Reality
KW  - Conflict
KW  - Data Glasses
KW  - Disagreeing
KW  - Information Sovereignty
KW  - Mixed Reality
KW  - Personal Information
KW  - Social Acceptability
KW  - User Acceptance
ER  - 

TY  - CONF
TI  - Memento Player: Shared Multi-Perspective Playback of Volumetrically-Captured Moments in Augmented Reality
AU  - Liu, Yimeng
AU  - Ritchie, Jacob
AU  - Kratz, Sven
AU  - Sra, Misha
AU  - Smith, Brian A.
AU  - Monroy-Hernández, Andrés
AU  - Vaish, Rajan
T3  - CHI EA '23
AB  - Capturing and reliving memories allow us to record, understand and share our past experiences. Currently, the most common approach to revisiting past moments is viewing photos and videos. These 2D media capture past events that reflect a recorder’s first-person perspective. The development of technology for accurately capturing 3D content presents an opportunity for new types of memory reliving, allowing greater immersion without perspective limitations. In this work, we adopt 2D and 3D moment-recording techniques and build a moment-reliving experience in AR that combines both display methods. Specifically, we use AR glasses to record 2D point-of-view (POV) videos, and volumetric capture to reconstruct 3D moments in AR. We allow seamless switching between AR and POV videos to enable immersive moment reliving and viewing of high-resolution details. Users can also navigate to a specific point in time using playback controls. Control is synchronized between multiple users for shared viewing.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585588
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585588
KW  - augmented reality
KW  - moment reliving
KW  - multi-perspective
KW  - shared and social experience
KW  - volumetric capture
ER  - 

TY  - CONF
TI  - Measuring the Impact of Explanation Bias: A Study of Natural Language Justifications for Recommender Systems
AU  - Balog, Krisztian
AU  - Radlinski, Filip
AU  - Petrov, Andrey
T3  - CHI EA '23
AB  - Despite the potential impact of explanations on decision making, there is a lack of research on quantifying their effect on users’ choices. This paper presents an experimental protocol for measuring the degree to which positively or negatively biased explanations can lead to users choosing suboptimal recommendations. Key elements of this protocol include a preference elicitation stage to allow for personalizing recommendations, manual identification and extraction of item aspects from reviews, and a controlled method for introducing bias through the combination of both positive and negative aspects. We study explanations in two different textual formats: as a list of item aspects and as fluent natural language text. Through a user study with 129 participants, we demonstrate that explanations can significantly affect users’ selections and that these findings generalize across explanation formats.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585748
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585748
KW  - evaluating explanations
KW  - Explainable recommendation
KW  - explanation bias
KW  - explanation types
KW  - natural language justifications
ER  - 

TY  - CONF
TI  - MaskCircuit: 3D Circuits with Acrylic Sheets and Laser Cutting
AU  - Han, Bo
AU  - Liu, Xin
AU  - Yen, Ching Chiuan
AU  - Zheng, Clement
T3  - CHI EA '23
AB  - Laser cutting is an accessible fabrication technique for designers to create supporting structures for tangible interfaces and electronic devices. However, it is challenging to integrate electronics into laser-cut prototypes due to bulky prefabricated components and wiring. To address these challenges, we propose MaskCircuit, a maker-friendly fabrication approach for 3D circuits based on commonly used laser cutters and acrylic sheets. MaskCircuit leverages the protective film of acrylic sheets as a mask. Circuits are created on acrylic sheets by laser engraving traces into the masked acrylic sheets, manually applying conductive paint into traces, and removing the mask to reveal inlaid conductive traces. We also explored circuit features supported by MaskCircuit, including double-layer circuit fabrication, mounting electronic components, and creating 3D circuits by deforming or assembling acrylic sheets with circuits. We demonstrate several applications to showcase the capabilities of the MaskCircuit approach.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585603
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585603
KW  - Digital Fabrication
KW  - Laser Cutting
KW  - Tangible Interfaces
ER  - 

TY  - CONF
TI  - Invalid Message Risks and Analysis of Laws to Restrict Cyber Crime in Social Applications
AU  - Chen, Haobin
AU  - Yang, Yuer
AU  - Wu, Yubing
T3  - ICNCC '22
AB  - Information systems that support interaction with users, especially social applications, when there are many functions, may omit the filtering of user input data due to functional cross-reference and improper switch logic settings. It leads to a series of risk issues when information systems process illegal format information. This paper, taking Android operating system as an example, analyzes the security problem of information system risks caused by the invalid messages in social applications so as to try carrying out a risk assessment on the harm to information systems caused by such events. Relevant laws are gathered. It would be discussed how to effectively curb cybercrime in social applications through legal means.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579946
SP  - 341
EP  - 347
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579946
KW  - Information System
KW  - Internet Crime
KW  - Legal System
KW  - Risk Management
KW  - Social Application
ER  - 

TY  - CONF
TI  - Method of Webpage Entity Extraction Based on Mixed Attribute Measurement and DOM Tree
AU  - Xiong, Guan Ye
AU  - Yang, Bai Long
AU  - He, Jing Yuan
AU  - Su, Yang
T3  - ICNCC '22
AB  - Most mainstream web information extraction models adopt multidimensional analysis and then fusion evaluation, which has issues such as the high cost of vectorization and unreasonable fusion. For this reason, a text mining method of webpages based on the mixed attribute measure and DOM tree segmentation is proposed, which uses the K-Nearest Neighbor algorithm to measure the similarity of the mixed attributes of nodes in the DOM tree to alleviate the shortcomings of previous algorithms that focus solely on categorical or numeric attributes, and improves extraction quality, in addition, the web page segmentation algorithm is used to find the set of target DOM tree nodes, and ultimately information extraction is completed and effectively reduces extraction costs. Experimental results show that, compared to multiple baseline models, the method has over 6.5% and 11.6% improvement in the accuracy and recall rate evaluation indicators across numerous scenarios and clear speed benefits.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579947
SP  - 348
EP  - 354
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579947
KW  - DOM tree
KW  - K-Nearest Neighbor
KW  - Mixed attribute
KW  - Web entity extraction
ER  - 

TY  - CONF
TI  - Development and Evaluation of Enhanced National Greening Program Monitoring and Document Archiving System using DeLone and McLean IS Success Model
AU  - Pitao, Joana Victoria S
AU  - Nabas, Jenie P
AU  - Matias, Junrie B
AU  - Timosan, Jesterlyn Q
AU  - Rollorata, Godwin G
T3  - ICNCC '22
AB  - The information system was developed to aid the critical operations of the enhanced national greening program within the Caraga region, eliminate the risk of human error, and lift the tedious manual processing and progress monitoring. However, the sudden shift of processes from manual to automated information systems can affect the user adoption of the system. For this reason, a survey was conducted eight (8) months after the software development to assess and evaluate the development and implementation of the information system adopting the Delone and Mclean IS Success Model and hypothesizing nine (9) relationships to examine the information system success. This work used Fornell-Lacker's Criterion to measure the discriminant validity of the constructs - Information Quality, Intention to Use, Perceived Net Benefits, System Quality, Service Quality, and User Satisfaction. Results show that the intention to use positively affects Perceived Net Benefits. Moreover, Service Quality and User Satisfaction affect users’ Intention to Use; evidently, the user's perceptions of the quality of the services delivered and service performance are motivating factors for users’ continued use of the system. Lastly, user satisfaction, intention, system quality, and quality of service are contributory factors that affect the usage and adoption of the system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579945
SP  - 334
EP  - 340
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579945
KW  - DeLone and McLean IS Success Model
KW  - IS Implementation
KW  - Net Benefits
KW  - Use Intention
ER  - 

TY  - CONF
TI  - Automation of Curriculum-based Student-Subject Encoding: A Web Application
AU  - Almonteros, Jayrhom R.
AU  - Pacot, Mark Phil B.
AU  - Pitogo, Vicente A.
T3  - ICNCC '22
AB  - Timetabling is a procedure of arranging examinations or class events into a specific time slot. Universities carriages many timetable recurring problems, one of which is the demand to schedule subject offerings with no collisions in space, time, and resources. At Caraga State University, scheduling was done by the department chairs, and the faculty carried out the enrolment. Based on the curriculum, the faculty evaluates the students' eligibility to take the specific subject and creates a conflict-free timetable based on the offered subjects and schedule plotted by the department chairs. The heavy involvement of faculty diverts their focus, accommodating enrolment requests instead of preparing their lecture for the upcoming opening of classes. With this, a web-based application using Django was developed to automate the student-subject encoding process.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579944
SP  - 328
EP  - 333
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579944
ER  - 

TY  - CONF
TI  - Formal Verification of Smart Contract Based on Timed Colored Petri Net
AU  - He, Yaqiong
AU  - Dong, Hanjie
AU  - Wang, Runliu
AU  - Wu, Huaiguang
T3  - ICNCC '22
AB  - The Blockchain 2.0 era integrated with smart contract along with its platforms and applications have experienced explosive growth in recent years. However, many smart contracts deployed in practice are prone to errors and cannot be modified due to the immutability of the blockchain. In light of this, it is vital to ensure the security of correctness of smart contracts before deployment. This paper proposes a formal modeling method based on Timed Colored Petri net (TCPN) to anlyze smart contracts with time constrains. We apply this formalism to a concrete voting contract system. Its functional requirements are formalized by the improved computing timing logic ASK-CTL with ML (Meta Language). Simulation and experiment show that the security and reliability of the voting contract can be effectively guaranteed.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579943
SP  - 321
EP  - 327
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579943
KW  - ASK-CTL
KW  - formal Verification
KW  - Smart Contract
KW  - TCPN
ER  - 

TY  - CONF
TI  - Exploiting Character-Word Fusion to Enhance Chinese Named Entity Recognition Combined with Multi-head Attention Mechanism
AU  - Luo, Jinshang
AU  - Hou, Mengshu
T3  - ICNCC '22
AB  - Named Entity Recognition (NER) is a fundamental subtask in natural language processing. The specific challenge of Chinese NER, as opposed to English NER, lies primarily in word segmentation ambiguity. To tackle the concerns, a novel weighted character-word fusion model (CWMA-LSTM) is developed in conjunction with the multi-head attention mechanism. Specifically, character and word representations are encoded using the pre-trained model. By matching the lexicon, the weighted lexical features are included in the character sequence. The feature vectors are subsequently fed into the Long Short-Term Memory (LSTM) for the extraction of contextual semantic information. The multi-head attention is utilized to improve the implicit awareness of the sentence. Experiments on benchmark datasets show that CWMA-LSTM exceeds other state-of-the-art methods, and validates the efficacy of weighted character-word fusion.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579941
SP  - 307
EP  - 312
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579941
ER  - 

TY  - CONF
TI  - A Real-Time Voice Conversion Method Based on A Non-Parallel Corpus for Training
AU  - Li, Yang
AU  - Nie, Tong
AU  - Shao, Yucheng
AU  - Zhu, Zesheng
AU  - Yang, Tian
AU  - Zhang, Shengnan
AU  - Zhu, Ze
AU  - Zhang, Fang
T3  - ICNCC '22
AB  - Voice conversion (VC) is a modification of a person's voice to imitate a certain target person. Real-time VC can be widely used in confidential communication, voice enhancement, speech synthesis, and other fields, and has important research value. According to current research, high-quality VC methods tend to be computationally complex, and it is difficult to achieve real-time processing on computing platforms with different performances, which limits the usefulness of these methods. In this study, the authors proposed a VC method that can simplify computation based on different hardware processing capabilities to achieve real-time processing. The method also uses the vowel /a/ for speech feature alignment during training, which is a method with a non-parallel corpus and has stronger practicality. The authors designed and implemented a real-time VC system by using this method. Through a series of experiments, it was demonstrated that the system has good VC quality while ensuring real-time processing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579942
SP  - 313
EP  - 320
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579942
ER  - 

TY  - CONF
TI  - Generation of Chinese Tang Dynasty Poetry Based on BERT Model
AU  - He, Zekai
AU  - You, Jieshun
AU  - Lin, Shunying
AU  - Chen, Ling
T3  - ICNCC '22
AB  - From prehistoric times to the present, the creation of poetry has long been considered the exclusive domain of humans. With the development of deep learning, many researchers have begun to address the challenge of how to generate poetry using algorithms. To capture more contextual continuity and semantically related information in Chinese poetry, this paper applies the BERT (Bidirectional Encoder Representations from Transformers) model with improvement in the full Tang dynasty poem dataset. In addition, this model is also used for inference to generate acrostic poetry and sequel poetry. Under the automatic evaluation metric BLEURT algorithm, Tang Dynasty poetry generated by the model used outperforms those generated by Long Short-Term Memory model. Good poetry generated from the model used was also approved by Chinese poets. This paper suggests that the BERT model can generate higher quality and more various forms of poetry, which is of some certain reference and application value in the field of poetry.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579940
SP  - 300
EP  - 306
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579940
KW  - BERT
KW  - BLEURT
KW  - Natural Language Generation
KW  - Tang Poetry
ER  - 

TY  - CONF
TI  - A Comparative Study of CNN and Bi-LSTM in Text-Based Sentiment Analysis
AU  - Ke, Kaiyao
T3  - ICNCC '22
AB  - Sentiment analysis is an important natural language processing task that seeks to extract contextual subjective information and perform classification. CNN and Bi-LSTM are two of the most popular models in text-based sentiment analysis. However, with intense training computations on large datasets, it is costly to decide among , Bi-LSTM and many of their composite models by simple trial-and-error. This paper conducts a comparison between CNN and Bi-LSTM across different datasets, analyzing the causes of differences and drawing conclusions assisting the selection of models. Also, the paper finds that certain disparities within input may impact performance, and proposes standards to pre-stratify dataset and configure different CNN/Bi-LSTM based models on different sub-datasets.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579939
SP  - 289
EP  - 299
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579939
KW  - Bi-LSTM
KW  - CNN
KW  - Model Configuration
KW  - Model Selection
ER  - 

TY  - CONF
TI  - Network Business Intention Classification and Slot Filling Method Based on LC-BERT
AU  - Li, Sihan
AU  - Xie, Kun
AU  - Chen, Ziwei
AU  - Li, Chengcheng
AU  - Zhang, Yasheng
T3  - ICNCC '22
AB  - With the development of new network structures, how to quickly understand the network intentions expressed by users in natural language is very important. Aiming at the problem of feature sparseness and semantic ambiguity caused by the limited number of words in the network business text, a method dealing with the joint intention classification and slot filling LC-BERT is proposed. The position vector, original word vector, and segmentation vector are used as the input of BERT, and the long-distance dependency is obtained through the multi-head self-attention mechanism, and the global semantic features and word vectors are extracted. The LDA topic model is used to extend the feature representation method of short texts to solve the problem of sparse data and lack of subject information. The experimental results show that the LC-BERT model has better classification and slot filling effects than traditional models, proving this method's feasibility and effectiveness.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579938
SP  - 284
EP  - 288
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579938
KW  - BERT
KW  - intent classification
KW  - LDA
KW  - slot filling
ER  - 

TY  - CONF
TI  - PT-Fuzz: A Transformer Based Fuzzing Data Generation Method
AU  - Ye, Yingyun
AU  - Zhuang, Yan
T3  - ICNCC '22
AB  - American Fuzzy Lop (AFL) is one of the most widely used overlay-oriented fuzzers in the field of fuzz processing. In the process of analyzing AFL, we found that the number of tests per code block in the AFL testing process is very unevenly distributed. The AFL spends a lot of testing time on a small number of code blocks. In addition, the fuzzing cannot discover new paths for a long time because new basic blocks cannot be discovered in time. These two reasons lead to a waste of fuzz testing performance. In this paper, we propose a test case generation method that combines path information and deep learning. The deep learning model is used to analyze the relationship between the program execution path and test cases. In addition, the deep learning model also learns the syntactic rules of program input to generate better test cases. We implemented our approach based on the AFL and Transformer model. And test the effect of our method in a real program. Experimental results show that our method can improve the efficiency of fuzzing. On average, PT-Fuzz found 14.4% more paths and 7.2% more code blocks than AFL.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579937
SP  - 277
EP  - 283
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579937
KW  - Deep learning
KW  - Fuzzing
KW  - Vulnerability mining
ER  - 

TY  - CONF
TI  - Roadmap on Industrial Knowledge System for Data-Oriented Intelligent Operation and Maintenance in Chinese Power Industry
AU  - Qiao, Lin
AU  - Qu, Ruiting
AU  - Liu, Shenglong
AU  - Zhang, Yu
AU  - Wang, Huiying
AU  - Liu, Biqi
T3  - ICNCC '22
AB  - To effectively and efficiently manage the information of power industry, especially in the State Grid of China, data-oriented intelligent operation and maintenance have always been a crucial task. Hence, in this paper, the roadmap on industrial knowledge system is presented for data-oriented intelligent operation and maintenance in Chinese power industry. Firstly, the background of the data-oriented intelligent operation and maintenance is described, and it has been pointed out that the core problem is data explosion and lack of knowledge in the data-oriented intelligent operation and maintenance in the State Grid of China. This is important not only for the construction of smart grid, but also for global energy savings. Secondly, as for data-oriented intelligent operation and maintenance, the State Grid data-oriented knowledge graph can be constructed. Then, we study the knowledge-driven multi-scenario intelligent operation decision technologies and information deployment technologies. Finally, the possible research direction of industrial knowledge systems is briefly presented for data-oriented intelligent operation and maintenance in State Grid.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579936
SP  - 267
EP  - 276
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579936
KW  - data-oriented Intelligent maintenance
KW  - data-oriented Intelligent operation
KW  - Industrial knowledge system
KW  - Knowledge Graph
ER  - 

TY  - CONF
TI  - Research on Layout Model of Unmanned Clothing Supermarket
AU  - Kang, Yong
AU  - Zhai, Chenggong
AU  - Zhou, Yihan
AU  - Yuan, Xinguang
AU  - Xu, Hongsi
AU  - Wan, Fei
T3  - ICNCC '22
AB  - In this paper, the system layout design method is used to design and plan the clothing unmanned supermarket. Firstly, through the analysis of material flow, the logistics relationship of clothing unmanned supermarket is obtained. Secondly, the relationship between the garment enterprises and the garment logistics center is analyzed, and the relationship between the garment enterprises and the garment logistics center is the highest; finally, combined with the relative area proportion of each operation unit, the layout of clothing unmanned supermarket is obtained.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579933
SP  - 247
EP  - 253
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579933
KW  - clothing supermarket
KW  - Layout model
KW  - Systematic Layout Planning
KW  - Unmanned
ER  - 

TY  - CONF
TI  - AXI, APB and AXI NOC Model Design Based on SysmteC
AU  - Ma, Shuaiting
AU  - Sui, Jinxue
AU  - Zhang, Xia
T3  - ICNCC '22
AB  - With the increasing complexity of system-on-a-chip (SoC) design, in order to improve the design speed and to make the function verification of complex system more efficient, we need to conduct in-depth system level model verification of the system in the early stage of design. Due to SystemVerilog language is used to establish a RTL(Register Transfer Level) level model in the chip modeling in the past few years, which was not high in abstraction, long in development time and simulation time, and poor in the co-verification ability of software and hardware. Therefore, many institutions have carried out research on system level modeling and simulation verification by using SystemC language. While the TLM(Transaction Level Modeling) level model developed by SystemC language is more abstract, the development time is shorter, and the simulation time is at least 10 times faster than RTL level. Moreover, SystemC model has outstanding ability of software and hardware co-verification. Therefore, SystemC system level modeling method has gradually become the mainstream in industry. This paper presents a method of complex system verification based on SystemC. The modeling of AMBA(Advanced Microcontroller Bus Architecture) architecture through AXI(Advanced eXtensible Interface) and APB(Advanced Peripheral Bus) protocols is performed. It also includes a NoC(network-on-chip) module named AXI_NOC that provides network interfaces and packet-switched communications for slaves. In order to coordinate the data transmission within each module, an open data structure is defined. In each module, the data structure package is used to transmit data, rather than the respective protocol data format. This method unifies the transmission specification. AXI, AXI_NOC and APB modules are all transaction level modeling with periodicity accuracy. Finally, a verification platform based on UVM-SystemC to validate and test modules is designed. After analyzing the print information and verification waveform of the verification platform, the conclusion that the accuracy of the function of AXI, APB, AXI_ NOC module is abtained.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579935
SP  - 261
EP  - 266
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579935
KW  - APB
KW  - AXI
KW  - NoC
KW  - SystemC
KW  - UVM-SystemC
ER  - 

TY  - CONF
TI  - Personalized Point-of-Interest Recommendation with Relation-Enhanced Graph Convolutional Network
AU  - Bai, Zijian
AU  - Zhang, Suzhi
AU  - Li, Pu
AU  - Chang, Yuanyuan
T3  - ICNCC '22
AB  - Point-of-Interest (POI) recommendation recommends different personalized services to interested users, which are widely used in people's daily life. However, with the massive increase in users and POIs, the POI recommendation system faces the following challenging problems: (1) The results of the recommendation service are not personalized enough, and little attention is paid to the details and semantic relevance. (2) Often face the problem of cold start (3) Recommended accuracy can be further improved. In order to cope with these difficulties, this paper proposes a POI recommendation method POI-Graph Convolutional Network with relation-enhanced Graph Convolutional Network(P-GCN). First, this paper mining the user's preferred POI information with a quantitative emotion from the user's comment information and historical information in the Yelp and DianPing datasets, and builds a representation of the relationship between the service user preferences knowledge graph (KG). On this basis, the P-GCN model is introduced, and uses end-to-end learning to mine the associated attributes between projects, and to make the high-order structural information and semantic information in the knowledge graph discovered. Finally, through the method of node aggregation of multi-hop neighbor node information, the high-order semantic relevance of user nodes and their potential preferences are obtained, and POI recommendations are made to users. Through extensive experiments, our method can better utilize the characteristics and POI of different users who own the same preferences, which can improve the precision and personalization of recommendation. The experimental results are superior to the baseline method in terms of evaluation indexes.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579934
SP  - 254
EP  - 260
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579934
ER  - 

TY  - CONF
TI  - ∗Application of BP Neural Network Model in Surface Water Quality Evaluation
AU  - Yang, Chen
AU  - Kui, Liu Han
AU  - Yu, Qiu Zhen
AU  - Hang, Liu Zhong
T3  - ICNCC '22
AB  - According to the "national surface water monitoring and evaluation scheme for the 14th Five-Year plan" issued by the Ministry of ecological environment of the people's Republic of China, this study constructs a back propagation (BP) neural network model for comprehensive water quality evaluation with five indexes of pH value, dissolved oxygen, ammonia nitrogen, permanganate index and total phosphorus as input characteristic parameters. Some historical monitoring data in 2021 provided by Nanchong surface water monitoring station are randomly selected for water quality classification test. The experimental results show that the comprehensive evaluation method of water quality based on BP neural network proposed in this study is more reasonable than the classification result of water quality grade obtained by single factor evaluation method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579932
SP  - 241
EP  - 246
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579932
KW  - BP Neural Network
KW  - Surface Water
KW  - Water Quality Evaluation
ER  - 

TY  - CONF
TI  - Blockchain-based Transaction Scheme for Massive MIMO Channel Estimation
AU  - Huang, Yu
AU  - Zhi, Hui
T3  - ICNCC '22
AB  - In wireless communication systems, accurate channel estimation is essential to ensure the performance of wireless communication systems. Massive Multiple Input Multiple Output (M-MIMO) systems have a dramatic increase in the number of channels to be estimated due to the large number of antennas, which poses a great challenge to the computing resources of the base station, and one solution is offloading these computing tasks of channel estimation to other computing nodes with more computing resources (such as servers). However, in real life, computing nodes are not willing to participate in channel estimation because of their equipment and operation cost. In order to solve this problem, this paper introduces blockchain technology and designs a blockchain-based transaction scheme for channel estimation (BTS-CE) to solve the problem of computing resources transaction for massive MIMO channel estimation, and designs the specific process of the scheme. In order to solve the problem that computing nodes cannot complete the computation task due to failure or malicious disconnection, a task allocation model is designed to assign a computation task to multiple computation nodes. The security of the transactions is guaranteed through the blockchain. Practical Byzantine Fault Tolerance (PBFT) consensus mechanism cannot be applied to the public chain due to its low performance caused by a large number of nodes participating in consensus, this problem is solved by selecting some active nodes as consensus nodes. Simulation results show that improved PBFT(IPBFT) is lower in transaction delay and higher in throughput than PoW consensus mechanism.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579928
SP  - 210
EP  - 214
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579928
KW  - Blockchain
KW  - Computation offloading
KW  - Consensus mechanism
KW  - Electronic money
ER  - 

TY  - CONF
TI  - Modified Butterfly Optimization Algorithm based on Convergence Factor and Disturbance Strategy
AU  - Hao, Congwang
AU  - Chen, Lei
AU  - Ma, Yunpeng
T3  - ICNCC '22
AB  - The butterfly optimization algorithm (BOA) is a relatively new optimization technology with strong competitiveness compared with other meta-heuristic algorithms. However, BOA has shortcomings in convergence accuracy, convergence speed, and jumping out of local optimum. This paper proposes an improved Butterfly Optimization Algorithm based on convergence factor and disturbance strategy (LCD-BOA) to solve these shortcomings. Based on the BOA algorithm, the Levy flight strategy and disturbance factor strategy are added to improve the exploration ability of the algorithm. In addition, the convergence factor strategy is added to improve the exploitation ability of the algorithm further so that the exploration and exploitation of the algorithm are balanced as far as possible. Finally, the experimental results on 11 benchmark functions prove the effectiveness of the improved algorithm. The experimental results show that the improved algorithm significantly improves the performance of BOA compared with other meta-heuristic algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579931
SP  - 235
EP  - 240
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579931
ER  - 

TY  - CONF
TI  - Enhancing the elderly disease rehabilitation based on semantic understanding and knowledge graph
AU  - Zhang, Suzhi
AU  - Zhang, Yawen
AU  - Li, Pu
T3  - ICNCC '22
AB  - Recent research shows that intake of the corresponding nutrients can enhancing disease rehabilitation in the elderly. The traditional medical question and answer (Q&amp;A) system can provide convenient query services for the elderly. However, the traditional medical Q&amp;A system also has defects, for instance, the traditional medical Q&amp;A system is not very targeted to the elderly, along with this cannot meet the storage needs of massive data. In this paper, a semantic-based word separation method was proposed, which uses Chinese semantic segmentation to obtain keyword information. Meanwhile, we use knowledge inference to perform answer inference, and leverage Cypher statement to query the answers. In the evaluation experiment, we invited 50 volunteers (25 female and 25 male) who living in a community to be divided into two groups for the experiment. The experimental group made dietary adjustments based on the Q&amp;A system and track record their blood pressure values. As suggested by the experimental results, the answers given by the system in this paper have a positive feedback effect on enhancing the rehabilitation of elderly diseases.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579930
SP  - 226
EP  - 234
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579930
KW  - A system
KW  - knowledge graph
KW  - nutrition
KW  - Q&
KW  - the elderly diseases
ER  - 

TY  - CONF
TI  - AUV underwater 3D path planning based on particle swarm optimization-adaptive step-size cuckoo search algorithm
AU  - Wang, Lei
AU  - Li, Jinghang
AU  - Qi, Junyan
AU  - He, Junyi
T3  - ICNCC '22
AB  - Aiming at the problems of unreachable search target, weak path finding and obstacle avoidance ability, and slow algorithm convergence speed when dealing with the 3D path planning of autonomous underwater vehicles (AUV) in the traditional cuckoo algorithm in complex waters, an AUV path planning algorithm PSO-ASCS (Particle Swarm Optimization-Adaptive Step-size Cuckoo Search Algorithm) is proposed, which combines the improved Adaptive Step-size Cuckoo Search and Particle Swarm Optimization. This research uses the idea of spatial layering to establish a three-dimensional model of complex waters to conduct path planning and obstacle avoidance experiments on the PSO-ASCS algorithm; The PSO-ASCS algorithm is tested and compared with the adaptive step size cuckoo search algorithm, standard cuckoo algorithm and particle swarm optimization by constructing a fitness function considering the three factors of path length, path smoothness and path hazard. Experiments show that the improved algorithm has strong global search ability and optimization performance, and the algorithm converges well, so that the AUV has the ability of efficient obstacle avoidance and path planning.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579929
SP  - 215
EP  - 225
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579929
KW  - 3D path planning
KW  - Autonomous underwater vehicle
KW  - Improved cuckoo algorithm
KW  - particle swarm optimization
ER  - 

TY  - CONF
TI  - Signal Synchronization Performance for 5G Power Internet of Things*
AU  - Zhang, Yanan
AU  - Wang, Qian
AU  - Ai, Yan
T3  - ICNCC '22
AB  - During the design of 5G power Internet of Things (IoT), the clock sources for clock synchronization mainly come from IEEE 1588, satellite synchronization and local crystal oscillator synchronization. On the basis of unified time service, local clock sources are added, and the selection of clock sources can be automatically switched according to the system, so as to ensure the effectiveness of clock synchronization, maximize clock synchronization, reduce time slot interference, and reduce communication delay. This paper analyzes the typical methods and technical effects of time synchronization of power Internet of Things, and tests and analyzes the time synchronization based on the integration of 5G communication network and power network. The results show that 5G power Internet of Things time synchronization plays an important role in power grid performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579926
SP  - 198
EP  - 201
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579926
KW  - 5G
KW  - Power Internet of Things
KW  - Time Synchronization
ER  - 

TY  - CONF
TI  - Research on Ultra-wideband Ranging Method in Tunnel Environment
AU  - Wang, Lei
AU  - Zhang, Wenbo
AU  - Qi, Junyan
AU  - He, Junyi
AU  - Zhang, Shangqi
T3  - ICNCC '22
AB  - Aiming at the serious non-visual range problem in the complex and variable tunneling environment, which leads to the unsatisfactory results of most existing ultra-wideband (UWB) clock drift optimization schemes. We propose a straightforward and powerful high accuracy ranging method for tunnel environment. First, to address the impact of severe occlusion on UWB ranging in tunnels, we propose a simple non-line-of-sight (NLOS) error identification and correction scheme to minimize the clock drift error caused by NLOS. Moreover, for the clock drift problem of two-way ranging (TWR), we employ automatic correction by sending messages twice in a short period of time, taking into account the high mobility of nodes and NLOS range occlusion errors in the correction, which improves the ranging accuracy without increasing the equipment cost. Finally, the distance values are classified and filtered using the DBSCAN clustering algorithm and Gaussian filtering to achieve accurate distance measurements. Experimental results show that the algorithm can achieve a range accuracy of 0.1 m in a non-direct aiming and high maneuverability environment, which has a higher range accuracy compared with other algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579927
SP  - 202
EP  - 209
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579927
KW  - Clock drift
KW  - DBSCAN
KW  - High mobility
KW  - NLOS
KW  - TWR
ER  - 

TY  - CONF
TI  - Research on Whole-Link Risk Situational Awareness Index System and Dynamic Risk Pool Supervision
AU  - Sun, Jingchun
AU  - Deng, Fei
AU  - Du, Boya
T3  - ICNCC '22
AB  - With the development of society, network security becomes more and more important. It is inevitable to establish the risk index system to effectively monitor the security of network. In the previous study, due to absence of risk indicators, the risk supervising system is not perfect. However, there are few researches on the whole-link risk index system, and the determination of risk indicators lacks basis. Therefore, this paper firstly constructs a new risk index system of situational awareness, which can avoid the omission of risk indicators. Then the sliding window is used to observe this system and the optimal window width is found to determine the dynamic risk pool. Finally, the indicators of dynamic risk pool are used to dynamically monitor the whole link risk index system. The whole technical framework not only proves advantages of the mature risk index system of situational awareness, but also overcomes the disadvantage that the risk index of the whole link cannot be determined, and the dynamic risk pool has the sharing characteristics in the whole process.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579925
SP  - 190
EP  - 197
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579925
KW  - Dynamic risk pooling
KW  - Situational awareness
KW  - Sliding window
KW  - The whole-link network
ER  - 

TY  - CONF
TI  - Research on Intelligent Routing Technology Based on Improved DQN
AU  - Zheng, Xiangyu
AU  - Huang, Wanwei
AU  - Zhang, Xiaohui
AU  - Li, Hui
AU  - Xiao, Qiangyong
T3  - ICNCC '22
AB  - With the rise of artificial intelligence, intelligent routing technology has become a research hotspot in the current academic circles. In view of the problems of poor load balancing ability of traditional routing algorithms and difficulty in guaranteeing quality of service (QoS), this paper proposes an intelligent routing algorithm DQN-Route based on deep reinforcement learning (DRL). The algorithm adopts the deep Q network (DQN) as the training framework, and introduces the convolutional neural network (CNN) as the neural network. Based on the algorithm advantages of DQN processing continuous state space, as well as the local perception and parameter sharing capabilities of CNN, we can input the dynamically changing network state into the neural network for training. After the algorithm training converges, the action value output by the neural network is used as the network link weight to realize the dynamic adjustment of the routing strategy. Finally, the DQN-Route routing algorithm is compared with the OSPF, ECMP and Q-Learning routing algorithms respectively. The results show that the DQN-Route has better convergence, and compared with the Q-Learning routing algorithm, DQN-Route reduces the delay by 14.13%, increases the throughput by 11.34%, and reduces the packet loss rate by 9.17%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579924
SP  - 183
EP  - 189
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579924
KW  - Deep Q network
KW  - deep reinforcement learning
KW  - Quality of service
KW  - Software-defined network
ER  - 

TY  - CONF
TI  - Traffic Classification Using an Efficient Lightweight Convolutional Network
AU  - Zhang, Xu
AU  - Han, Fang
AU  - Fu, Hui
AU  - Wang, Ping
AU  - Zheng, Jingjing
AU  - Liu, Pancheng
T3  - ICNCC '22
AB  - Traffic classification is playing a key role in network security domain with rapid growth of current Internet network, since traffic characterization is an important step for network management and network anomaly detection. Numerous researches have been done on this topic which have led to many different methods. Most of them use predefined features extracted by an expert to classify network traffic, which is costly and time consuming. In contrast, in the work, we propose a deep learning (DL) based approach, and it can automatically extract and select features through training, which has made DL-based method a highly desirable approach for traffic classification. Especially, inspired by the ConvNeXt, we believe that, compared with other DL-based method, 2D ConvNet can achieve a better performance by training techniques, while maintaining the simplicity and efficiency of standard ConvNets. Experimental results have verified this. After an initial pre-processing phase on data, the data are fed into DL framework to classify network traffic. Experiments have demonstrated that the proposed method enhanced the initial DL architecture (99.24% accuracy), and achieved accuracy of 99.47% in traffic categorization on UNB ISCX VPN-nonVPN dataset.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579921
SP  - 167
EP  - 172
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579921
KW  - 2D convolutional networks
KW  - deep learning (DL) based method
KW  - training techniques
ER  - 

TY  - CONF
TI  - End-to-End Delay Performance for Mobile Cyber-Physical Systems with Edge Computing
AU  - Wu, Yan
AU  - Yang, Qinghai
AU  - Qiao, Feiyu
AU  - Pan, Guangchuan
T3  - ICNCC '22
AB  - In this letter, we investigate the end-to-end (E2E) delay performance for mobile cyber-physical systems (M-CPS) with edge computing. The traditional delay analysis is based on flow conservation law, whereas the flow is not conserved in the M-CPS with edge computing due to the existence of edge computing node and remote controller. To tackle this problem, we introduce two scaling factors to ensure the flow conservation, then the E2E delay bound of M-CPS with edge computing is derived via stochastic network calculus. In addition, to cater for the delay demand for M-CPS stability, the stable-aware delay bound is obtained. Numerical results show the gap between the analytic bound and simulation can be narrower as the average signal-to-noise (SNR) growing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579923
SP  - 178
EP  - 182
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579923
KW  - end-to-end delay
KW  - mobile physical systems
KW  - stable-aware
KW  - stochastic network calculus
ER  - 

TY  - CONF
TI  - Real-Time Scheduling of Asynchronous TSN Traffic
AU  - Cheng, Yufan
AU  - Wang, Ying
AU  - Wen, Jiachen
AU  - Yu, Peng
T3  - ICNCC '22
AB  - Time sensitive networking (TSN) is a new set of Ethernet standards that provide real-time and security for automotive, aerospace and industrial automation applications. Traffic in time sensitive networks has combination, complexity and flexibility. Due to the differences of devices in the actual network, time synchronization on time sensitive networks is sometimes difficult to achieve. Ensuring latency performance for critical traffic becomes a challenge. To solve this problem, we propose a non-synchronous time sensitive network traffic scheduling model and implement a Flexible window based GCL(FWND) scheduling. Experimental results show that the proposed scheduling method achieves traffic scheduling for non-synchronous TSN networks at the cost of a small worst end to end delay and average bandwidth usage.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579922
SP  - 173
EP  - 177
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579922
KW  - Asynchronous passes
KW  - Flexible GCL based on Windows
KW  - Time sensitive network
KW  - Traffic scheduling
ER  - 

TY  - CONF
TI  - Energy Efficient Computation Offloading and Resource Allocation for Satellite Multi-access Edge Computing
AU  - Hao, Yuanyuan
AU  - Zhang, Qian
AU  - Zheng, Zhong
AU  - Miao, Zhongyu
AU  - Zheng, Hanyu
T3  - ICNCC '22
AB  - In this article, the energy-efficient computation offloading and resource allocation for satellite multi-access edge computing (MEC) is studied. The problem is formulated to minimize the sum energy consumption of users while ensuring the task tolerance latency requirement. The formulated problem is divided into two subproblems, which are solved by exploring the convex structure and applying Lagrangian dual decomposition, respectively. Based on the obtained solutions of the two subproblems, we design an iterative algorithm for satellite MEC, and theoretically analyze its effectiveness, convergence and complexity. Simulation results verify that our proposed algorithm converges fast, and outperforms both full offloading and local computing algorithms. Besides, it is also observed that improving the computing capacities of satellite MEC servers helps to save the energy of users.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579920
SP  - 161
EP  - 166
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579920
KW  - computation offloading
KW  - multi-access edge computing
KW  - resource allocation
KW  - Satellite networks
ER  - 

TY  - CONF
TI  - Development of Real-Time Traffic Monitoring and Visualization System Using Stationary Roadside Sensor
AU  - Molina, Jundee Mark G.
AU  - Sotis, Angelica S.
AU  - Pascual, Rogamestica C.
AU  - Cubillas, James Earl D.
AU  - Matias, Junrie B.
T3  - ICNCC '22
AB  - This study presented the development of a web-based system that visualizes real-time traffic by deploying lightweight and mobile monitoring devices at roadside intersections in the vicinity of Butuan City to assist commuters and drivers in making optimal decisions regarding efficient roadways for travel. The system can visualize the traffic situation at an intersection using IoT devices, wireless communication devices, and artificial intelligence. To analyze captured real-time traffic conditions and quantify traffic parameters using YOLOv5s and DeepSort Algorithm. DeepSort Algorithm is utilized for object tracking, whereas YOLOv5s is utilized for real-time object detection. The system has been successfully tested and is functional, providing a dashboard with real-time traffic information and a great platform for commuters and drivers in the vicinity of Butuan City to be aware of what is occurring on that particular roadway. This aids motorists, travelers, traffic and transportation offices, and organizations in obtaining traffic data for optimal decision-making, such as selecting the quickest route and boosting productivity and services. This would also aid in identifying specific transportation or traffic problems and generating cogent solutions.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579919
SP  - 154
EP  - 160
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579919
KW  - DeepSort Algorithm
KW  - Real-Time Traffic Monitoring
KW  - YOLO
ER  - 

TY  - CONF
TI  - 3D Body Sensor-Based Martial Arts Demonstration and Teaching System
AU  - Zhang, Shangqi
AU  - Wang, Lei
AU  - Xu, Yangyang
AU  - Chen, Kefu
AU  - Wang, Fei
AU  - Zhao, Minjun
AU  - Dou, Yuebo
T3  - ICNCC '22
AB  - The existing human action recognition methods have imperfect models, resulting in low recognition accuracy, lack of famous teacher resources, shortage of judges, and strong subjectivity in competition and test scoring. Based on Kinect 2.0, through Unity3D program development and 3D character model development, this system designs innovative continuous action algorithms ( mainly including segmented depth search method and weighted matching method), and realizes Chinese martial arts action demonstration, standard action entry, martial arts action scoring and other functions
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579918
SP  - 147
EP  - 153
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579918
KW  - Action demonstration
KW  - Action evaluation
KW  - Chinese martial arts
KW  - Kinect 2.0
ER  - 

TY  - CONF
TI  - Research on auxiliary driving system engineering for color vision impaired
AU  - Cao, Yong
AU  - Fu, Hui
AU  - Jin, Zongxin
T3  - ICNCC '22
AB  - With the development of science &amp; technology and the Progress of society, Cars have entered thousands of households, and most people, especially young people, have gotten their dream of driving. However, some people are disadvantaged in the field of driving. they are excluded from driving because of their abnormal color perception. This paper is to discuss how to make the weak color perception drive cars and enjoy the dividends of scientific and technological development through the implementation of science and technology supporting systems and relevant laws and regulations, imagine that you can also drive your own car in the future, so as to eliminate the inferiority complex caused by abnormal color vision. The content in this paper is to discuss and design such systems and measures under the condition of ensuring traffic safety. So that our society will be more harmonious, and each social group can enjoy the pleasure of driving with the support of science and technology.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579917
SP  - 141
EP  - 146
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579917
KW  - Abnormal color perception
KW  - Auxiliary driving
KW  - Internet of things technology
KW  - Systems and facilities
KW  - Traffic safety
ER  - 

TY  - CONF
TI  - An Indoor Positioning Approach based on Vision and INS
AU  - He, Junyi
AU  - Fan, Guanghui
AU  - Zhang, Min
AU  - Wu, Mengxiang
AU  - Han, Yijie
T3  - ICNCC '22
AB  - Aiming at the problems of poor real-time performance of indoor visual positioning and low positioning accuracy caused by mismatching, an indoor combined positioning method based on vision and INS (Inertial navigation system) was proposed. The method uses the position information calculated by the INS solution to establish an offline search list, and narrows the search range while suppressing mismatch. Image acceleration points are quickly extracted using accelerated robust features to obtain visual positioning positions. The INS position information and the visual position information are fused by the Kalman filter, and the feedback correction of the INS position information is realized. The experimental results show that the combined positioning method can effectively improve the visual positioning calculation efficiency and indoor positioning accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579916
SP  - 135
EP  - 140
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579916
KW  - Combined positioning
KW  - Image retrieval
KW  - Speed up robust features
KW  - Visual positioning
ER  - 

TY  - CONF
TI  - Improved YOLOv4 Based on Transformer and Feature Fusion Module
AU  - Zhao, Shan
AU  - Yuan, Yang
AU  - Wu, Xuan
AU  - Tian, Kaiwen
T3  - ICNCC '22
AB  - In order to solve the problem that mainstream object detection models such as R-CNN, YOLO and SSD focus too much on network depth and neglect the fusion of deep semantic feature information with shallow layers, this paper proposes a new network model based on transformer and feature fusion module, named as YOLOv4-RFEM and FGFM(YOLOv4-RF). YOLOv4-RF can show better results in the use and fusion of multi-scale feature maps. Firstly, to solve the spatial pyramid pooling layer used in YOLOv4 is deficient in integrating global information, we propose a Receptive Field Enhancement Module, named RFEM, based on the idea of transformer. RFEM can better handle the global information and enhance the feature map to achieve higher detection accuracy. Secondly, a Feature-Guided Fusion Module (FGFM) is designed to solve the problem of inadequate fusion between different feature maps. By introducing channel attention, different feature maps are fully fused to enhance network performance. Our experiments on the PASCAL VOC2007+2012 dataset achieved the mAP of 91.55%. The experimental results show that the model can improve the accuracy of object detection.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579914
SP  - 123
EP  - 128
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579914
KW  - Feature Fusion
KW  - Keywords:Object Detection
KW  - Receptive Field
KW  - Transformer
KW  - YOLO
ER  - 

TY  - CONF
TI  - Apple Counting Network Before Fruit Thinning Period Based On Dilated Convolution
AU  - Song, Mengyang
AU  - Jiang, Guoquan
AU  - Huo, Zhanqiang
AU  - Yang, Zhengyuan
AU  - Zhang, Hongxu
T3  - ICNCC '22
AB  - Abstract: Fruit counting is an integral part of achieving precision orchard management. Accurate counting of the number of fruits on a tree can provide critical information for yield estimation, thus promoting precision agriculture. However, today fruit farmers can only support their fieldwork by manual counting, and a reliable and accurate automatic fruit counting method is missing. A pre-thinning apple counting network (FTACNet) is proposed to address the problems of shading, uneven distribution, and fruit scale differences and is validated on the produced dataset. The method uses deep learning algorithms in the field of population counting. FTACNet shows good performance on the dataset, with mean absolute error (MAE) down to 4.14 and mean square error (MSE) down to 5.62. Moreover, the model is end-to-end, the model is small, and can be easily deployed to mobile devices, which has good potential for application in orchards.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579915
SP  - 129
EP  - 134
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579915
KW  - Deep learning
KW  - Fruit counting
KW  - Key words: Crowd counting
KW  - Precision agriculture
ER  - 

TY  - CONF
TI  - Individualization Of Head Related Transfer Function Based On PCA And RBF Network
AU  - Chen, Wei
AU  - Zhang, Hongxu
AU  - Yu, Jinxia
AU  - Luo, Fen
T3  - ICNCC '22
AB  - Head-Related Transfer Function (HRTF) describes the acoustic reflection and diffraction effect caused by the influence of the human body (head, torso, etc.) in the transmission of sound waves to the human ear. In Virtual Reality(VR) / Augmented Reality(AR), HRTF is often used to generate virtual 3D audio due to its ability to recreate perceptions of natural sound scenes realistically. However, HRTF varies from person to person due to the differences in anthropometric features. Using non-individualized HRTF to produce 3D sounds may lead to hearing localization bias in users. Therefore, how to obtain individualized HRTF is a hot topic in the field of VR / AR. This paper proposes an effective method to establish the relationship between anthropometric features and HRTF. At first, a method based on multimodal principal component analysis is proposed for the representation of HRTF models with low dimensions. Then a nonlinear mapping representation model between the low-dimensional features of HRTF and anthropometric features is established using Radial Basis Function Neural Network (RBFNN). Objective experiments show that the proposed HRTF Individualization method can reduce the spectral distortion as low as 4.48 dB. The subjective listening experiments based on the principal sagittal plane show that the individualized HRTF obtained using this method can effectively improve the accuracy of subjective listening (about 33%).
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579912
SP  - 109
EP  - 116
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579912
KW  - HRTF
KW  - Individualization
KW  - PCA
KW  - RBFNN
ER  - 

TY  - CONF
TI  - Object pest detection method based on lightweight SSD_RA algorithm
AU  - Li, Shixuan
AU  - Peng, Hongxing
AU  - Yuan, Jingqi
T3  - ICNCC '22
AB  - In order to detect the types and quantities of pests in rice fields quickly and accurately, a lightweight target pest detection method SSD_RA based on SSD algorithm is proposed. In order to deal with the problems of high missed detection rate, inaccurate positioning, slow detection speed, large number of model parameters and low accuracy of the detection model, the ResNet feature extraction network was introduced and optimized. The first prediction feature layer of SSD was connected to the Conv3_x module of the ResNet network, and all network layers after the Conv3_x module were dropped. The number of parameters of the model is reduced, so that the model is more lightweight, the detection speed is improved, and the redundant features are reduced to ensure the accuracy of the model. In addition, aiming at the characteristics of small target, the structure of prediction feature layer of SSD algorithm is improved, the number of prediction feature layers is adjusted, and the output of underlying feature Conv2_x is connected to the prediction feature layer. The candidate box of each cell in the new prediction feature layer is 6, which accurately divides the boundaries of large, medium and small target boxes. The experimental results show that the mAP of SSD_RA of the improved algorithm in this paper is 84.1%, which is 23.4 percentage points higher than that of the original SSD model. The reasoning time in CPU and GPU environment is 0.056s and 0.009s, which is 0.101s and 0.005s faster than that of the original SSD model, and the model size is 51.9MB. It is reduced to about 7/100 of the original SSD model. Compared with other models, the mAP of SSD_RA is 7.8 and 4.2 percentage points higher than that of EfficientDet and RFCN, respectively. The SSD_RA model is more effective and faster to detecting insect pests and reduces the missed detection rate.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579911
SP  - 102
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579911
KW  - Insect pest
KW  - ResNet
KW  - SSD_RA
ER  - 

TY  - CONF
TI  - Realistic Nighttime Haze Image Generation with Glow Effect
AU  - Zheng, Yading
AU  - Mi, Aizhong
AU  - Qiao, Yingxu
AU  - Wang, Yijiang
T3  - ICNCC '22
AB  - Abstract: Haze rendering aims to generate realistic nighttime haze images from clear images. The results can be applied to various practical applications, such as nighttime image dehazing algorithms, game scene rendering, shooting filters, etc. We investigate two smaller but challenging problems in nighttime haze rendering, namely 1) how to accurately estimate the transmission map and air light from clear and haze images, respectively, in the absence of paired datasets? 2) How to render the characteristics of a realistic nighttime haze image: glow effect? For this purpose, we propose an unsupervised nighttime haze image rendering method called NHRM (Nighttime Haze Rendering Module). Precisely, the NHRM consists of three modules: 1) an illumination retention module based on Retinex theory. 2) a transmission map estimation network using multi-scale feature fusion and attention mechanism. 3) a glow generation module using tone mapping and convolution bloom technique. Compared with existing haze generation methods, NHRM can render realistic and controllable nighttime haze images by simulating the main features of nighttime haze scenes in an unsupervised manner. Numerous experimental results show that our method outperforms existing rendering methods with better visual effects and quantitative metrics.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579910
SP  - 96
EP  - 101
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579910
KW  - Atmospheric Scattering Model
KW  - Glow Effect
KW  - Image Hazing
KW  - Image Rendering
ER  - 

TY  - CONF
TI  - A Chromosome Enumeration Method Based On Morphology
AU  - Zhao, Zhe
AU  - Zhang, Feng Zhi
AU  - Cui, Xiao
AU  - Sun, Tong
T3  - ICNCC '22
AB  - Chromosome enumeration is a tedious and necessary step in karyotype analysis. Abnormal detection usually starts with enumeration of chromosome number. Chromosome images have the characteristics of high cohesion, overlap and nesting, which is a difficulty in chromosome enumeration at this stage. In this work, tandem rule is used to remove redundant and irrelevant objects from the preprocessed karyotype image; A chromosome enumeration method based on morphology is proposed. Starting from overlapping features, the relationship between intersection points and curves is solved to complete enumeration. This work is verified on 200 images, and the results show that the recognition rate of overlapping chromosome clusters is 98.5%, and the recognition rate of complex chromosome clusters is 90.5%. This shows the effectiveness of the algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579913
SP  - 117
EP  - 122
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579913
KW  - Enumeration
KW  - Morphology
KW  - Overlapping Chromosomes
ER  - 

TY  - CONF
TI  - Global-Local Feature Alignment Loss for Photorealistic Style Transfer
AU  - Jing, Yuchao
AU  - Jiang, Guoquan
AU  - Huo, Zhanqiang
AU  - Wang, Yijiang
AU  - Wu, Lili
T3  - ICNCC '22
AB  - The problem that needs to be solved for photorealistic style transfer lies in limiting the distortion of texture details of the generated image based on the typical style transfer network. Although the existing methods achieve better stylization results, they lack sufficient style information because they do not consider the feature map comprehensively enough, leading to exposure or artifacts. This article proposes a loss function based on the contrast learning method to constrain the network to extract local and global information effectively. It ensures the consistency of distribution among regional blocks generated based on anchor points and the consistency of comparison between anchor points of the resulting image and content image in their neighborhood. This ensures consistency between local and global information comparisons. To ensure that the network is simple and effective and that enough information is extracted, this article proposes a linear covariance transformation network to achieve faithful stylization by effectively fusing feature first-order statistics with second-order statistics. Experiments show that the proposed method can faithfully achieve realistic stylization and satisfying visual effects.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579909
SP  - 90
EP  - 95
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579909
KW  - Contrast learning
KW  - Feature fusion
KW  - Image statistics
KW  - Realistic stylization
ER  - 

TY  - CONF
TI  - Detail Recovery and Color Enhancement for Single Image Dehazing
AU  - Fang, Wangming
AU  - Huo, Zhanqiang
AU  - Qiao, Yingxu
T3  - ICNCC '22
AB  - Due to the complexity of taking photos on foggy days, images captured in the real world are prone to problems of detail loss, color dimness, and low saturation. Considering image dehazing as a problem of detail recovery and color enhancement, a two-stage progressive fusion method of single image dehazing is proposed, which consists of a detail recovery branch, a color enhancement branch, and a wavelet fusion module. Firstly, to solve the problem of hazy image details and detail loss after image defogging, we introduce gamma transform, block homomorphic filtering, and multi-scale exposure fusion in the detail recovery branch for the first fusion stage to restore image details. Secondly, aiming at the problem that the overall color of the image is dark and the image saturation is poor after defogging, the color-preserving CLAHE(limited contrast adaptive histogram equalization) of contrast enhancement method is applied in the color enhancement branch to enhance the color. Finally, to fully use the complementary information between the two enhanced images, a wavelet fusion module is designed for pixel-level fusion in the second stage, which can recover the details and improve color information while removing the fog to the greatest extent. The experimental results show that the image's color can be restored naturally, and the details can be preserved completely. The experimental results show that the image's color can be restored naturally and the details can be fully preserved.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579906
SP  - 67
EP  - 75
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579906
KW  - Contrast enhancement
KW  - Image dehazing
KW  - Multi-scale fusion
KW  - Wavelet transform
ER  - 

TY  - CONF
TI  - Low-light Image Enhancement via Unsupervised Progressive Fusion Network
AU  - Li, Hengxuan
AU  - Huo, Zhanqiang
AU  - Qiao, Yingxu
T3  - ICNCC '22
AB  - To address the issue that unsupervised low-light image enhancement methods rely on finely selected training sets or contrast exposure stacks, this paper proposes a low-light image enhancement network with unsupervised progressive fusion driven jointly by knowledge and data. The network consists of low-light image pre-processing stage and progressive fusion stage. In the pre-processing stage, the input low-light image is first inverted. Next, we perform three methods of fixed-value gamma correction, adaptive gamma correction, and color-preserving adaptive histgram equalization (color-preserving AHE) to generate three images with different degrees of contrast enhancement. The progressive fusion stage performs a progressive fusion of the three images generated in the preprocessing stage and the inverted input image. The contrast and brightness of the fused result are improved by fusion while suppressing overexposure in the bright regions. It is shown experimentally that the proposed method outperforms the current state-of-the-art unsupervised low-light image enhancement networks in terms of both visual quality and technical specifications. In some low-light scenes, our method even outperforms the supervised learning-based low-light image enhancement network.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579908
SP  - 83
EP  - 89
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579908
KW  - Image fusion
KW  - Low-light image enhancement
KW  - Unsupervised learning
ER  - 

TY  - CONF
TI  - Low-light Image Enhancement via Zero-Reference Dynamic Curve Estimation
AU  - Luo, Wenhui
AU  - Mi, Aizhong
AU  - Huo, Zhanqiang
T3  - ICNCC '22
AB  - Abstract: Most low-light enhancement methods based on curve estimation do not have the ability of multi-illumination processing. They cannot use one model to process images with different exposure levels. This paper proposes to process multi-illumination images by dynamic curve estimation. The curve is a new dynamic light enhancement curve that allows appropriate enhancement, suppression, and hold operations depending on the light level of the input image. Therefore, the model can process images in different lighting environments. In addition, to further improve the model's ability to process different illumination images, the illumination discriminator is designed. It can further adjust the image to avoid overexposure and underexposure problems. Many qualitative and quantitative experiments show that this method is superior to the existing methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579907
SP  - 76
EP  - 82
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579907
KW  - Key words: Curve estimation
KW  - Low-light image enhancement
KW  - Zero-shot learning
ER  - 

TY  - CONF
TI  - A Region-Based Point Cloud Down Sampling Technique for Scene Rendering Augmentation of Synthetic 3D-Modeled Objects
AU  - Jayoma, Jaymer M.
AU  - Pacot, Mark Phil B.
AU  - Moyon, Elbert S.
T3  - ICNCC '22
AB  - 3D modeling is the process of creating and designing 3-dimensional objects used to represent real objects or physical environments. It is used for game development, information, educational and communication materials that are developed and deployed efficiently in PCs or Mobile devices with at least 8GB of RAM, 4 Cores CPU, etc. To increase efficiency in development and deployment, point cloud downsampling is developed without sacrificing accuracy or quality of object classification of 3D objects created through 3D modeling softwares. The combination of native voxel approaches with the region-based adaptation of down-sampling unordered point clouds for potential augmentation was successfully done in rendering scenes using synthetic 3D Model Objects.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579905
SP  - 62
EP  - 66
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579905
KW  - 3D-modeled objects
KW  - down sampling
KW  - point cloud
KW  - region-based
KW  - scene rendering augmentation
ER  - 

TY  - CONF
TI  - HybridCANet:UNet-like network Bridging CNN and Attention for Multimodal Brain Image Segmentation
AU  - Tang, Chaosheng
AU  - Dai, Chendi
AU  - Sun, Junding
T3  - ICNCC '22
AB  - Brain tumor is one of the diseases that seriously threaten human life and health. Accurate segmentation of tumor lesion region is an important step in image-guided radiotherapy, and also a key part in planning effective treatment strategies and preventing other diseases. In order to solve the problems of low contrast and high Imaging redundancy between adjacent organs in Magnetic Resonance Imaging images (MRI) segmentation of brain tumor. In this paper, we propose a hybrid efficient segmentation network based on a deep learning approach to extract MRI brain tumor volume feature maps using 2D convolution at the encoder, and design an Efficient Self-Attention Module (ESAM) to focus on robust feature map parameters while narrowing the parameter weights of irrelevant features. The Hybrid Cross-Attention Module (HCAM) explicitly models the correlation between the two stage feature maps in the decoder stage, and dynamically recalibrates the feature maps according to the input context features. We introduce spatial information of 3D images by fusing multi-view fusion training model. The accurate segmentation and lightweight design of MRI segmentation network will provide a powerful reference for clinicians in the diagnosis and treatment of brain tumors.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579904
SP  - 56
EP  - 61
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579904
KW  - Deep Learning
KW  - Efficient Self-Attention
KW  - Hybrid Cross-Attention
KW  - Multi-view Fusion
ER  - 

TY  - CONF
TI  - Weakly Supervised Semantic Segmentation Based on Image-level Class Labels with Deep Learning: A Survey
AU  - Wang, Yijiang
AU  - Luo, Fen
AU  - Zhang, Hongxu
AU  - Huo, Zhanqiang
T3  - ICNCC '22
AB  - The training of fully supervised semantic segmentation (FSSS) networks relies on a large amount of data with pixel-level class labels, which limits semantic segmentation's application in practical scenarios. Weakly supervised semantic segmentation (WSSS) based on image-level class labels has become a new research hotspot in the field of image semantic segmentation. In this paper, the WSSS algorithms with image-level class labels are classified and sorted out according to two critical steps of the generic pipeline: seed generation and mask refinement. Different ways of seed generation can be divided into three categories: Multiple-Instance Learning-based methods, Class Activation Maps-based methods, and other generation methods. Different seed mask refinement methods can be divided into affinity-based mask refinement methods, additional supervision-based mask refinement methods, and other mask refinement methods. In addition, this paper analyzes the principles, key ideas, primary contributions, and advantages and disadvantages of various methods. Then, the segmentation performance of different WSSS algorithms on different datasets are compared, and the current state-of-the-art segmentation algorithms are labeled. Finally, the main challenges currently faced in the field and possible future directions have been prospected.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579903
SP  - 45
EP  - 55
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579903
KW  - Image-level
KW  - Seed generation
KW  - Seed mask refinement
KW  - WSSS
ER  - 

TY  - CONF
TI  - Real-time semantic segmentation network based on improved BiSeNet V1
AU  - Zhao, Shan
AU  - Wu, Xuan
AU  - Tian, Kaiwen
T3  - ICNCC '22
AB  - Aiming at the problems of unclear boundaries and low segmentation accuracy in general real-time semantic segmentation networks, a real-time semantic segmentation network based on improved BiSeNet V1 was proposed. Based on the BiSeNetV1 network, a spatial enhancement module (SRM) is introduced into the spatial path to enhance the spatial information and improve the detection ability of target boundaries and small targets. At the same time, when the spatial path and context path feature information are fused, the Feature Aggregation Module (FAM) is proposed to solve the difference in feature representation between the two paths in feature fusion and improve the fusion efficiency. We experiment on Cityscapes that reach 69.6% MIoU and 100.4 FPS. The experimental results show that the proposed algorithm can improve the efficiency of segmentation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579902
SP  - 38
EP  - 44
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579902
KW  - Bilateral Segmentation Network
KW  - Real-time image semantic segmentation
KW  - Spatial attention
ER  - 

TY  - CONF
TI  - A Person Re-identification Method Fusing Bottleneck Transformer andRelation-aware Global Attention
AU  - Huang, Min
AU  - Niu, Huiyang
AU  - Zhang, Shizheng
AU  - Ren, Guanyu
T3  - ICNCC '22
AB  - Person re-identification can quickly locate and find all the specified targets in complex scenes with multiple cameras, which has been widely applied in intelligent video surveillance and security system. As a state-of-art method proposed recently, ResNet exhibits promising performances on person re-identification. However, without intermediate fully connected layer, ResNet fails to fully grasp the global information in the detection process. To overcome the above problem, this paper proposes a person re-identification method named RG-BoTNet by fusing the Relation-aware Global Attention mechanism into BoTNet. Since relation-aware global attention is good at grasping the global information of the image, RG-BoTNet is powerful in extracting personal features. The good performances conducted on cuhk03 dataset in terms of Mean Average Precision (MAP) and Rank-1demonstrate the effectiveness of RG-BoTNet for person re-identification task.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579901
SP  - 31
EP  - 37
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579901
ER  - 

TY  - CONF
TI  - MediaPipe based Gesture Recognition System for English Letters
AU  - Zhu, Huaizhong
AU  - Deng, Chao
AU  - Zhu, Yuguang
T3  - ICNCC '22
AB  - Gesture recognition is widely used in communication, virtual reality, smart cockpit, smart home, etc. This paper proposes an application system based on MediaPipe for intelligent recognition of 26 letter gestures in English. The system uses images captured by a monocular camera, reads images using OpenCV, creates a hand detection model, uses MediaPipe to identify 21 key points of the hand, constructs a gesture recognition module for English letters, and recognizes letters through rough gesture recognition algorithm and fine gesture recognition algorithm. The experimental results show that the recognition accuracy of all English letters in this system is more than 81%, and the recall rate is more than 83%, which can be applied to gesture recognition related applications of English letters.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579900
SP  - 24
EP  - 30
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579900
KW  - English letter recognition
KW  - Gesture recognition
KW  - MediaPipe
KW  - OpenCV
ER  - 

TY  - CONF
TI  - Identify VPN Traffic Under HTTPS Tunnel Using Three-Dimensional Sequence Features
AU  - Zhang, Yaning
AU  - Sun, Weishi
AU  - Zhang, Shuzhuang
T3  - ICNCC '22
AB  - VPN traffic identification under HTTPS tunnel is an urgent problem in the field of network security and network management. In the research scenario of TLS encrypted VPN traffic, the existing work mainly focuses on the classification of traffic application types, and there is no specific research on VPN traffic identification under HTTPS tunnel, this makes the existing methods in the VPN traffic identification scenario under HTTPS tunnel subject to the impact of different application type traffic patterns and different network conditions, resulting in reduced identification accuracy and robustness of the model. At the same time, the existing work also lacks the analysis of the TPR and FPR indicators of the model, which results in that the practicability of the existing results cannot be guaranteed. To solve these problems, this paper has confirmed the simulation scenario of VPN traffic identification under HTTPS tunnel. In order to better mine the network behavior characteristics of VPN services, we propose three-dimensional sequence features (TSF) from three aspects: changes in the number of packets, changes in the payload length of packets, and changes in the interaction rules of uplink and downlink packets. Then we convert the features into RGB images to build a CNN based VPN traffic identification framework under HTTPS tunnel. Experiments on the ISCX-TOR dataset show that the Accuracy of the TSF method is 100%, the TPR and F1-Score are more than 99%, and the FPR is only 0.03%. This means that the TSF method has excellent identification accuracy in the VPN traffic identification scenario under the HTTPS tunnel, and can meet the requirements of actual use to a certain extent.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579899
SP  - 18
EP  - 23
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579899
ER  - 

TY  - CONF
TI  - A Multi-view Fuzzy Compactness and Separation Co-clustering Algorithm
AU  - Gao, Yan
AU  - Cao, Ziqi
AU  - Ma, Shengyu
T3  - ICNCC '22
AB  - With the advent of the era of big data, although the relationship between samples can be found from individual clustering of each view, data in the real world generally has multiple representations, and different data representations can complement each other. Clustering performance can be made more accurate by mining the information hidden between various multi-view data, making real-word data more interpretable. In view of the above problems, the multi-view clustering is studied, and a multi-view fuzzy compactness and separation co-clustering(MvFCSCC)algorithm is proposed. Based on the fuzzy compactness and separation co-clustering (FCSCC), the algorithm clusters the two dimensions of data objects and features for each view, and then optimizes and assigns different weights to different views by iterating the weight vectors, and finally performs collaborative clustering according to the importance of different views. In order to evaluate clustering effectiveness, experiments were carried out on four multi-view datasets to compare the MvFCSCC with the other three clustering algorithms. The experimental results show that this algorithm not only effectively improves the clustering effect, but also has a stronger robustness to noisy data.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579897
SP  - 6
EP  - 11
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579897
KW  - co-clustering algorithm
KW  - compactness
KW  - data mining
KW  - multi-view clustering
KW  - objective function
KW  - separation
ER  - 

TY  - CONF
TI  - BraDect: A Novel Brain Tumor Image Classification Algorithm
AU  - Tang, Chaosheng
AU  - Li, Bin
AU  - Sun, Junding
T3  - ICNCC '22
AB  - Brain tumor is one of the common diseases of the central nervous system, and the incidence and death of brain tumors are among the highest in the world. Although the incidence of brain tumors is lower than that of other systemic tumors, due to the wide range of types and pathological types, the same pathological type is divided into different sub-grades, and has complex imaging manifestations, which makes clinical diagnosis and treatment difficult. In this paper, a new CAD model named BraDect is proposed based on the inducible bias of convolution and the high capacity of Transformer, and the fully connected layer and attention mechanism are improved, which effectively solves the problem of large amount of parameters and low efficiency in the current model. The proposed method had performed SOTA as specificity=99.83%, precision=99.84%, Recall=99.83%, F1 score=99.84%, area under the ROC curve=99%, accuracy=99.28%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579898
SP  - 12
EP  - 17
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579898
ER  - 

TY  - CONF
TI  - A fine-grained image classification method combining YOLOv7 and bilinear multi-level feature fusion
AU  - Huang, Min
AU  - Wang, Zehua
AU  - Zhu, Saixing
T3  - ICNCC '22
AB  - Fine grain image is an important research field of image recognition, which can classify objects in more detail. Image feature extraction is usually implemented by bilinear network, which can meet the desired effect of feature extraction, but also discard some detailed feature information. In this study, a fine-grained classification optimization algorithm that combines the target detection method YOLOv7 and multi-feature fusion bilinear network is proposed to achieve fine-grained image classification. In the method, YOLOv7 is used to locate the target, and the recognition content is extracted according to the image detection frame; Then, the improved bilinear convolutional neural network structure is used to fuse the features of different channels and different levels of convolutional layers in the bilinear network, so as to obtain more feature information and improve the precision of fine-grained classification. Experimental results show that the classification results of this algorithm are better.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 11th International Conference on Networks, Communication and Computing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579895.3579950
SP  - 1
EP  - 5
PB  - Association for Computing Machinery
SN  - 978-1-4503-9803-9
UR  - https://doi.org/10.1145/3579895.3579950
KW  - bilinear convolutional neural network
KW  - fine-grained image classification
KW  - multi-channel fusion
KW  - multi-feature fusion
KW  - object detection
ER  - 

TY  - CONF
TI  - Engaging the Discourse of Empowerment for Marginalized Communities Through Research and Design Participation
AU  - Anuyah, Oghenemaro
AU  - Badillo-Urquiola, Karla
AU  - Metoyer, Ronald
T3  - CHI EA '23
AB  - This paper goes beyond the current empowerment discourse in the SIGCHI community to address how we primarily focus on research and design contexts and technological contributions. It argues that existing literature on empowerment does not fully account for the complexity of marginalized communities, including factors such as poverty, lack of digital literacy, or access to technology, which can affect a community’s decision to participate in research and their effectiveness during participation. The paper presents two provocations: 1) research must adopt methods of partnership that empower the community, and 2) researchers must consider how empowerment is sustained both within and outside of research and design settings and technological contributions. The paper concludes with a call to action for a holistic empowerment strategy within HCI to stimulate further discussion on empowering marginalized communities beyond research and design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585678
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585678
KW  - Empowerment
KW  - Marginalized Communities
KW  - Research and Design
ER  - 

TY  - CONF
TI  - Embodied Telepresent Connection (ETC): Exploring Virtual Social Touch Through Pseudohaptics
AU  - Desnoyers-Stewart, John
AU  - Stepanova, Ekaterina R.
AU  - Liu, Pinyao
AU  - Kitson, Alexandra
AU  - Pennefather, Patrick Parra
AU  - Ryzhov, Vladislav
AU  - Riecke, Bernhard E.
T3  - CHI EA '23
AB  - In search of missing tactile sensations in telepresent virtual reality (VR), we set off to explore how we might be able to apply pseudo-haptics to elicit an embodied illusion of social touch. We developed ETC (Embodied Telepresent Connection), a prototype that allows two participants to interact remotely through pseudo-haptic touch via their abstract aura avatars. ETC consists of a set of interaction patterns aimed to elicit an illusion of interpersonal touch using embodied metaphors, simulated physics, integration of visuals and sounds, biosignal representation, and embedded social connotations. We showed ETC at 5 events and 3 workshops, observing participants and gathering feedback from them. Here, we report on our design process and initial observations relating to the experience of virtual social touch. We observed that pseudo-haptics applied to social interaction afford a subtle and somewhat uncanny experience of virtual touch with the potential for intimate embodied connection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585843
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585843
KW  - embodiment
KW  - pseudo-haptics
KW  - social connection
KW  - social touch
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Effect of a Cursor Warping Left and Right of the Notch
AU  - Oba, Yosuke
AU  - Miyashita, Homei
T3  - CHI EA '23
AB  - Although the mouse cursor can enter the notch of the MacBook Pro (2021), it is partially or entirely hidden by the notch. Moving the cursor around the notch or avoiding it entirely can increase the movement time. This study investigated the possibility of using a cursor warping to the left and right of the notch to shorten the path to the target and restrain the movement time increased by the notch. We conducted an experiment to compare the performance of a default cursor, a cursor twice the default size, and a cursor warping to the left and right of the notch. The results showed that a cursor warping left and right of the notch was not effective in terms of the movement time.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585766
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585766
KW  - cursor warping
KW  - edge target
KW  - Fitts’ law
KW  - human motor performance
KW  - Mouse pointing
KW  - notch
ER  - 

TY  - CONF
TI  - Engage AI and Child in Explanatory Dialogue on Commonsense Reasoning
AU  - Xu, Erqian
AU  - Wang, Hecong
AU  - Bai, Zhen
T3  - CHI EA '23
AB  - Human-level commonsense reasoning capability is vital for human-AI interaction, enabling AI to understand, anticipate, and respond to human’s thoughts, feelings, and behaviors. Despite the recent advancements in AI commonsense reasoning due to generative language models, a young child is often more rational than state-of-the-art AIs in terms of commonsense reasoning. The field of cognitive science, child development, and explainable AI have long recognized the importance of explanations for sharing knowledge and resolving contradictions. We, therefore, raise the question: can AIs leverage the power of explanations to learn human-level commonsense reasoning? More specifically, can explanatory dialogue with children help AIs to develop commonsense reasoning capabilities? As a first step in this line of research, we aim to engage children in explanatory dialogue with AIs during story reading. We present our novel explanatory dialogue interface based on a state-of-the-art multi-step commonsense reasoning engine and discuss our upcoming pilot study.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585699
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585699
KW  - Commonsense Reasoning
KW  - Explainable AI
KW  - Human-AI Collaboration
ER  - 

TY  - CONF
TI  - Empowering Students as Leaders of Co-Design for Block-Based Programming
AU  - Limke, Ally
AU  - Lytle, Nicholas
AU  - Lin, Maggie
AU  - Mahmoud, Sana
AU  - Hill, Marnie
AU  - Cateté, Veronica
AU  - Barnes, Tiffany
T3  - CHI EA '23
AB  - Educational software is rarely co-designed with teachers and students. We have created a novel co-design process that can help both teachers and students learn about human-computer interaction (HCI) and research methods while contributing to the design of educational systems that will benefit future students and teachers. We investigated the results of our process of mentoring two undergraduate students to lead participatory design (PD) sessions with three K-12 teachers. We found that this process exposed teachers and undergraduates to HCI research and design techniques, empowered undergraduates to lead design sessions, and encouraged knowledge transfer between the groups. Our lessons learned include ways to prepare students inexperienced with HCI to lead PD, with training in the participants’ domain, practice sessions, and predefined PD methods to adapt for their context. Our recommendations for future design collaborations can also provide insights to empower undergraduate students or less experienced teams and participants to benefit from participatory design efforts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585775
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585775
KW  - HCI Teaching Methods
KW  - K-12 computing
KW  - Participatory Design
KW  - Undergraduate Research
ER  - 

TY  - CONF
TI  - Effects of Delivery Time and Delivery Distance of Indoor Robot Delivery Service on User Satisfaction and Reuse Intention
AU  - Cho, Yohan
AU  - Kwon, Gyu Hyun
T3  - CHI EA '23
AB  - The indoor robot service industry has been growing rapidly, industrial and academic research has been actively conducted. However, several previous studies have focused on the acceptance of robots, and there is a lack of research on delivery robot services. Moreover, research cases targeting users who have experienced actual robot delivery services are rare. Therefore, we conducted this study targeting employees who have used actual robot delivery services in a large office space with a total floor area of 165,000 m2 built as a robot-friendly building. Providing delivery services with approximately 100 robots in a large building is a rare case in the world. This study expanded the technology acceptance model and analyzed how delivery time and distance, which are the characteristics of robot delivery services, affect the robot acceptance intention.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585720
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585720
ER  - 

TY  - CONF
TI  - Driving Next to Automated Vehicles: Emergent Human-machine Cooperation in Mixed Traffic
AU  - Zhang, Yutong
AU  - Ling, Shihong
AU  - Awad, Edmond
AU  - Frank, Morgan R.
AU  - Du, Na
T3  - CHI EA '23
AB  - Introducing automated vehicles (AVs) on public roads may challenge established norms as drivers in human-driven vehicles (HVs) learn to interact with AVs. Our study utilizes a game theory framework to investigate how driver and vehicle driving styles (aggressive vs. conservative), interaction types (HV-HV vs. HV-AV), scenario types (chicken game vs. public goods game scenarios), and time constraints (high vs. low) influence human drivers’ decision-making in mixed-traffic environments. According to an online survey study, drivers with aggressive driving styles and high time constraints were more likely to take aggressive actions. More importantly, there were significant interaction effects between vehicle driving styles and scenario types, between scenario types and time constraints, and between driver driving styles and interaction types on driver decision-making. Our findings provide essential insights into the design of AVs and promote the development of related laws and policies to facilitate human-machine cooperation in mixed-traffic environments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585690
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585690
KW  - automated vehicles
KW  - game theory
KW  - human-machine cooperation
KW  - mixed-traffic environment
ER  - 

TY  - CONF
TI  - Dream Garden: Exploring Location-Based, Collaboratively-Created Augmented Reality Spaces
AU  - Petrov, Elizabeth
AU  - Monroy-Hernández, Andrés
T3  - CHI EA '23
AB  - We introduce Dream Garden, an augmented reality application (AR) that lets people place 3D flowers into the physical world to build a collaborative location-based garden. Despite the potential for connecting strangers in the digital realm, current research has not explored location-based augmented reality experiences that enable strangers to connect by building artifacts collaboratively. We explore this by creating an AR digital community garden deployed in a specific location. Anyone with the proper app can access and see the flowers previously planted by strangers, as well as plant their own flowers to grow the garden. We evaluated this app with 10 participants, with 5 visiting the digital garden more than once, to evaluate their sense of connection to the other participants as each participant added one digital flower to the garden. We found that participants were joyful about building a shared space, were excited about the dynamic nature of the garden, felt a connection to the physical location of the digital garden, and expressed a sense of belonging to a community of strangers but not necessarily an emotional connection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585810
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585810
KW  - augmented reality
KW  - collaboration
KW  - connection
KW  - location-based
KW  - loneliness
KW  - strangers
ER  - 

TY  - CONF
TI  - Double Empathy as a Lens to Understand the Design Space for Inclusive Social Play Between Autistic and Neurotypical Children
AU  - Morris, Brooke Ayers
AU  - Havlucu, Hayati
AU  - Oldfield, Alison
AU  - Metatla, Oussama
T3  - CHI EA '23
AB  - Social play (SP) is a play activity that involves social interaction between children. Research has shown mixed groups (MG)1, which include autistic and neurotypical children, benefit more from mutual social interactions. However, inclusive SP in MG reveals challenges in terms of the differences between groups, by which autism is typically characterized. Previous research addressing these issues either only includes one group or only concerns the barriers for autistic children. Addressing this, we aim to understand the design space to support inclusive SP for MG. For this, we utilize the ‘double empathy problem’ that aims to focus on interpersonal issues rather than problems of one group. In this preliminary work, we conducted interviews with 6 professionals who support MG during SP and examined barriers and design insights. We argue our findings could assist in developing the design space and methods that aim to promote mutual understanding in SP research for MG.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585828
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585828
KW  - Autism
KW  - Double Empathy Problem
KW  - Mixed Groups
KW  - Social Play
ER  - 

TY  - CONF
TI  - EarCough: Enabling Continuous Subject Cough Event Detection on Hearables
AU  - Zhang, Xiyuxing
AU  - Wang, Yuntao
AU  - Zhang, Jingru
AU  - Yang, Yaqing
AU  - Patel, Shwetak
AU  - Shi, Yuanchun
T3  - CHI EA '23
AB  - Cough monitoring can enable new individual pulmonary health applications. Subject cough event detection is the foundation for continuous cough monitoring. Recently, the rapid growth in smart hearables has opened new opportunities for such needs. This paper proposes EarCough, which enables continuous subject cough event detection on edge computing hearables, by leveraging the always-on active noise cancellation (ANC) microphones. Specifically, we proposed a lightweight end-to-end neural network model — EarCoughNet. To evaluate the effectiveness of our method, we constructed a synchronous motion and audio dataset through a user study. Results show that EarCough achieved an accuracy of 95.4% and an F1-score of 92.9% with a space requirement of only 385 kB. We envision EarCough as a low-cost add-on for future hearables to enable continuous subject cough event detection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585903
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585903
KW  - Cough event detection
KW  - Deep learning
KW  - Feedforward and feedback microphones
KW  - Hybrid active noise cancelling
KW  - Subject cough detection
ER  - 

TY  - CONF
TI  - Does Repeatedly Typing the Same Phrase Provide a Good Estimate of Expert Text Entry Performance?
AU  - Mutasim, Aunnoy K
AU  - Batmaz, Anil Ufuk
AU  - Hudhud Mughrabi, Moaaz
AU  - Stuerzlinger, Wolfgang
T3  - CHI EA '23
AB  - To identify if novel/unfamiliar keyboard layouts like OPTI can outperform QWERTY, lengthy training through longitudinal studies is typically required. To reduce this logistical bottleneck, a popular approach in the literature requires participants to type the same phrase repeatedly. However, it is still unknown whether this approach provides a good estimate of expert performance. To validate this method, we set up a study where participants were tasked with typing the same phrase 96 times for both OPTI and QWERTY. Results showed that this approach has the potential to estimate expert performance for novel/unfamiliar keyboards faster than the traditional approach with different phrases. Yet, we also found that accurate estimates still require training over several days and, therefore, do not eliminate the need for a longitudinal study. Our findings thus show the need for research on faster, easier, and more reliable empirical approaches to evaluate text entry systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585647
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585647
KW  - OPTI
KW  - QWERTY
KW  - Soft Keyboards
KW  - Tap Typing
KW  - Text Entry
KW  - Touch Typing
ER  - 

TY  - CONF
TI  - “Do you get déjà vu”: Persuasiveness Effects of Communicating with an Avatar of Similar Appearance in Social Virtual Reality
AU  - Shih, Meng Ting
AU  - Lee, Yi-Chieh
AU  - Huang, Chih-Mao
AU  - Chan, Liwei
T3  - CHI EA '23
AB  - The similarity effect is a phenomenon whereby people tend to be more influenced by others who resemble them in appearance. It has been found to have many positive impacts, including building trust and promoting collaboration performance. While empirical evidence confirmed that similarity effect operates on screen-based communication platforms, it remains unclear how this phenomenon impacts user perceptions and others’ persuasiveness in immersive virtual reality (VR) environments. In this study, we adopted a mixed-methods approach to investigating how interaction with avatars of similar appearance to one’s own avatar influences conversations. We operationalized similarity as identicality, moderate similarity, and dissimilarity. Avatars of moderate similarity were found to have the greatest persuasiveness; however, in both identicality and moderate similarity conditions, participants felt it was easier to communicate with and lower eeriness rating to avatars than in the dissimilarity condition. We conclude that similarity effect could be leveraged to support persuasiveness in VR-based communication.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585839
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585839
KW  - Appearance
KW  - Avatar
KW  - Computer Mediated Communication
KW  - Similarity Effect
KW  - Social Virtual Reality
ER  - 

TY  - CONF
TI  - Dis/Immersion in Mindfulness Meditation with a Wandering Voice Assistant
AU  - Ku, Bonhee
AU  - Itagaki, Tatsuya
AU  - Seaborn, Katie
T3  - CHI EA '23
AB  - Mindfulness meditation is a validated means of helping people manage stress. Voice-based virtual assistants (VAs) in smart speakers, smartphones, and smart environments can assist people in carrying out mindfulness meditation through guided experiences. However, the common fixed location embodiment of VAs makes it difficult to provide intuitive support. In this work, we explored the novel embodiment of a "wandering voice" that is co-located with the user and “moves” with the task. We developed a multi-speaker VA embedded in a yoga mat that changes location along the body according to the meditation experience. We conducted a qualitative user study in two sessions, comparing a typical fixed smart speaker to the wandering VA embodiment. Thick descriptions from interviews with twelve people revealed sometimes simultaneous experiences of immersion and dis-immersion. We offer design implications for "wandering voices" and a new paradigm for VA embodiment that may extend to guidance tasks in other contexts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585627
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585627
KW  - Mindfulness Meditation
KW  - User Experience
KW  - Voice Assistant
KW  - Voice Embodiment
KW  - Voice Interaction
KW  - Wandering Voice
ER  - 

TY  - CONF
TI  - Dimensional alt text: Enhancing Spatial Understanding through Dimensional Layering of Image Descriptions for Screen Reader Users
AU  - Cho, Jaemin
AU  - Kim, Hee Jae
T3  - CHI EA '23
AB  - Over the past decade, there has been a significant improvement in the quality of images we see on the web, and image processing technologies such as monocular depth estimation are opening up new possibilities for various applications. However, despite these developments, how we utilize image descriptions for image accessibility has remained stagnant since alt text was introduced with HTML 2.0 in 1995. This paper presents the concept of Dimensional alt text, which enables users to navigate image descriptions through three-dimensional layers: the foreground, middle ground, and background. Our research findings suggest that providing space for image descriptions on each dimensional layer can assist users in building a mental image of the photo, resulting in better spatial understanding. Our discussion for future work is to extend the use case of the prototype to a broader range of users and investigate a hybrid authoring model that combines human authorship with AI assistance.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585706
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585706
KW  - Accessibility
KW  - Alt Text
KW  - Alt Text Authoring
KW  - Depth Map
KW  - Dimensional Alt Text
KW  - Image Description
KW  - Inclusive Design
KW  - Screen Readers
KW  - Visual Impairment
ER  - 

TY  - CONF
TI  - Digital Sovereignty: What it is and why it matters for HCI
AU  - Lawo, Dennis
AU  - Neifer, Thomas
AU  - Esau-Held, Margarita
AU  - Stevens, Gunnar
T3  - CHI EA '23
AB  - In recent years, digital sovereignty has become a central term in digital policy discourses. Both authoritarian and democratic states use digital sovereignty as a base for their digital policy, although, the individual interpretation and resulting policy and power balance might be quite different. Given the importance of this term, the HCI community and the users as the core of our research would benefit from taking up the discussion by finding own definitions of human-centred digital sovereignty, contributing to policy discourses, and to strengthening the position of users under non-sovereign conditions. This paper aims to initiate and provoke such discourse within the community by (1) introducing the policy term to HCI and providing an overview of how it is used, (2) arguing for the relevancy of the term, and (3) proposing possible ways forward.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585834
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585834
KW  - Consumer Protection
KW  - Digital Sovereignty
KW  - Individual Empowerment
KW  - Policy
KW  - Privacy
ER  - 

TY  - CONF
TI  - Detecting Email Components with Constraints: Expressive and Extensible Models in Answer Set Programming
AU  - Chan, Gromit Yeuk-Yin
AU  - Guo, Shunan
AU  - Kim, Caroline
AU  - Connelly, Cole
AU  - Lee, Michelle
AU  - Thomson, Andrew
AU  - Koh, Eunyee
T3  - CHI EA '23
AB  - Detecting structures and components in business emails is vital for editor software to convert third-party emails so that designers can edit them without needing to know how HTML works. In a production environment, the challenge is to make the model easy to be understood and maintained by different stakeholders. We propose detecting email components with a collection of constraints written in Answer Set Programming (ASP). Hard constraints can detect well-defined components like email layouts, and soft constraints can incorporate ML to detect custom components like buttons and titles in emails. Using constraints, developers can apply their domain knowledge to the model and express them in a concrete, extensible, and deterministic form. We demonstrate the effectiveness with a prototype and evaluations from real datasets.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585714
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585714
KW  - Answer Set Programming
KW  - Constraints
KW  - Email Component Detection
ER  - 

TY  - CONF
TI  - Disagreement, Agreement, and Elaboration in Crowdsourced Deliberation: Ideation Through Elaborated Perspectives
AU  - Aitamurto, Tanja
AU  - Royal, Peter G
AU  - Saldivar, Jorge
T3  - CHI EA '23
AB  - In this study, we examined disagreement, agreement, and elaboration (rationale sharing) and their association with idea generation in a crowdsourced deliberation that took place within a crowdsourced policymaking process led by a national government. We analyzed the comments posted to the crowdsourced deliberation process and found that the elaboration of perspectives was a key element in idea generation. Disagreement contributed to ideation most when it was elaborated—i.e., when the participants justified their stances—and when it was accompanied by elaborated agreement. The findings suggest that in the design of the technologies and processes facilitating crowdsourced policymaking and other applications for civic engagement, there should be a particular focus on encouraging elaboration because elaboration can contribute to productive ideation as well as constructive argumentation. Elaboration could be fostered by deploying features from deliberation and argumentation technologies, which are designed to encourage participants to elaborate on their stances.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585708
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585708
KW  - civic engagement
KW  - civic participation
KW  - civic technology
KW  - crowdsourced policymaking
KW  - deliberation
KW  - democratic innovations
KW  - participatory democracy
KW  - policy-making
ER  - 

TY  - CONF
TI  - Designing Participatory AI: Creative Professionals’ Worries and Expectations about Generative AI
AU  - Inie, Nanna
AU  - Falk, Jeanette
AU  - Tanimoto, Steve
T3  - CHI EA '23
AB  - Generative AI, i.e., the group of technologies that automatically generate visual or written content based on text prompts, has undergone a leap in complexity and become widely available within just a few years. Such technologies potentially introduce a massive disruption to creative fields. This paper presents the results of a qualitative survey (N = 23) investigating how creative professionals think about generative AI. The results show that the advancement of these AI models prompts important reflections on what defines creativity and how creatives imagine using AI to support their workflows. Based on these reflections, we discuss how we might design participatory AI in the domain of creative expertise with the goal of empowering creative professionals in their present and future coexistence with AI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585657
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585657
KW  - creative professionals
KW  - creativity support
KW  - generative AI
KW  - participatory AI
KW  - participatory design
ER  - 

TY  - CONF
TI  - Designing an Algal Relay Computer: A Critical Orientation in Exploring More-than-Human Temporality
AU  - Ikeya, Yuta
AU  - Barati, Bahareh
T3  - CHI EA '23
AB  - The re-evaluation of our industrial, anthropocentric relationships with time has led to the emergence of new conceptualizations of temporality beyond clock time in design-oriented HCI research. In order to provoke discussions on how design may (or may not) account for temporality of nonhumans, we conceptualized and prototyped Algal Relay Computer (ARC), a "slow" computer that incorporates the growth of algae in its calculation process. The paper presents theoretical groundings and technical details of ARC and offers preliminary insights into multiplicity of more-than-human temporality uncovered through the design process and exhibition of this artefact.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585874
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585874
KW  - critical design
KW  - hardware
KW  - micro-algae
KW  - more-than-human design
KW  - temporality
ER  - 

TY  - CONF
TI  - Detecting an Offset-Adjusted Similarity Score based on Duchenne Smiles
AU  - Henneberg, Maximilian
AU  - Eghtebas, Chloe
AU  - De Candido, Oliver
AU  - Kunze, Kai
AU  - Ward, Jamie A
T3  - CHI EA '23
AB  - Detecting interpersonal synchrony in the wild through ubiquitous wearable sensing invites promising new social insights as well as the possibility of new interactions between humans-humans and humans-agents. We present the Offset-Adjusted SImilarity Score (OASIS), a real-time method of detecting similarity which we show working on visual detection of Duchenne smile between a pair of users. We conduct a user study survey (N = 27) to measure a user-based interoperability score on smile similarity and compare the user score with OASIS as well as the rolling window Pearson correlation and the Dynamic Time Warping (DTW) method. Ultimately, our results indicate that our algorithm has intrinsic qualities comparable to the user score and measures well to the statistical correlation methods. It takes the temporal offset between the input signals into account with the added benefit of being an algorithm which can be adapted to run in real-time will less computational intensity than traditional time series correlation methods.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585709
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585709
KW  - Interpersonal synchrony
KW  - Time Series Similarity
ER  - 

TY  - CONF
TI  - Design to Improve Social Presence among University Students in Asynchronous Online Learning Environment
AU  - Lee, Wonjin
AU  - Park, Kayoung
AU  - Yoo, Jiyoung
AU  - Lim, Hajin
T3  - CHI EA '23
AB  - Since the COVID-19 pandemic, online lectures are becoming more common in higher education. Specifically, asynchronous online classes have become increasingly popular because of their flexibility. Asynchronous online courses, however, may negatively impact students’ academic performance and social development due to the diminished sense of social presence. To explore ways to enhance social presence among students in asynchronous online classes, this paper used a co-design methodology that involved 12 undergraduate students as primary stakeholders. As a result, we developed a design framework for designing in-class interaction to promote social presence in asynchronous online lectures. This framework consists of four high-level elements and sub-categories: interaction topic (direct or peripheral topics related to learning), interaction size (small or entire group), interaction mode (anonymity, synchronicity, instructor involvement), and interaction motivator (lightweightness and entertainment). Our design framework may serve as a guide to future technology for improving asynchronous online classes.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585593
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585593
KW  - asynchronous learning
KW  - asynchronous online class
KW  - co-design
KW  - higher education
KW  - online learning
KW  - Social presence
KW  - university education
ER  - 

TY  - CONF
TI  - DAOing It as a Collective: Designing the Future of Decentralised Personal Health Data Sharing
AU  - Neumann, Victoria
AU  - Harding, Mike
AU  - Davies, Nigel
T3  - CHI EA '23
AB  - The public depends on healthcare institutions to protect and govern medical-related information. However, with increasing security breaches and compliance failures with data protection law, researchers have begun to explore the feasibility of Decentralised Autonomous Organisations (DAOs) as a way of reimagining traditional forms of top-down data governance. In this paper, we describe early findings from the development of a card-based approach for engaging the public in the design of DAOs for collectively governing health data. Following a public workshop, we reflect on how our methodological approach involved laypeople in practical discussions about DAO design elements, such as voting mechanisms. Through group conversations, we observed how values affected the kinds of decentralised organisational structures participants wished to engage in. In particular, our analysis has implications for the future directions of DAO design, by pointing towards flexibility and modularity for voting and proposal interfaces, scalability and balancing power in tokenised communities.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585645
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585645
KW  - Decentralised Autonomous Organisations
KW  - Distributed Ledger Technology
KW  - Healthcare
KW  - Interaction Design
ER  - 

TY  - CONF
TI  - COVID-19 as an Energy Intervention: Lockdown Insights for HCI
AU  - Bremer, Christina
AU  - Bates, Oliver
AU  - Remy, Christian
AU  - Gormally-Sutton, Alexandra
AU  - Knowles, Bran
AU  - Friday, Adrian
T3  - CHI EA '23
AB  - As the operation of buildings accounts for around 30% of global CO2 emissions, reducing their energy consumption is considered crucial for climate change mitigation. Aware of this significance, the sustainable HCI (SHCI) community has conducted research on energy consumption for over 15 years. However, compared with domestic environments, commercial organisations are comprised of complex mixed-use buildings, and the socio-technical understanding of space and resulting energy use are relatively under-explored. In this late-breaking work, we present the initial findings of a longitudinal analysis that uses building energy data from a period covering the COVID-19 lockdown measures to help identify the energy associated with these buildings and their users. Viewing the pandemic as a unique, grand-scale ‘energy intervention’, the resulting consumption patterns are used to inform questions about leverage points for achieving change, stakeholder agency vs. infrastructure demand; and highlight the importance of putting energy data in context.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585896
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585896
KW  - COVID-19 pandemic
KW  - energy data
KW  - rebound effect
KW  - Sustainable HCI
ER  - 

TY  - CONF
TI  - CoRoot: A Collaborative Planting System to Strengthen Intergenerational Relationships
AU  - Qiu, Rou
AU  - Xu, Ziang
AU  - Xu, Wenjie
T3  - CHI EA '23
AB  - The grandparent-grandchild relationship plays an essential and irreplaceable role in life. Strong intergenerational relationships benefit both grandparents and grandchildren. However, social conditions and geographical isolation make it difficult for young people to develop close relationships with their grandparents. In this paper, we explore the collaborative planting system, CoRoot, which is designed to facilitate intergenerational relationships. CoRoot allows young people and their grandparents to water each other’s vegetables at a distance and to harvest ripe vegetables through collaborative watering. This paper presents the system design of CoRoot, the interactive mode of the system, and a user study of its usability. We found that collaborative planting can create a link between generations. Our design is expected to provide opportunities for intergenerational communication and promote the emotional bond between grandparents and young people.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585621
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585621
KW  - collaborative watering
KW  - communication
KW  - connection
KW  - grow vegetables
KW  - Intergenerational relationship
ER  - 

TY  - CONF
TI  - Design and Development of a Training and Immediate Feedback Tool to Support Healthcare Apprenticeship
AU  - Yarmand, Matin
AU  - Wang, Borui
AU  - Chen, Chen
AU  - Sherer, Michael
AU  - Hernandez, Larry
AU  - Murphy, James
AU  - Weibel, Nadir
T3  - CHI EA '23
AB  - The apprenticeship model of learning, while valuable in facilitating direct expert supervision, lacks flexibility, timeliness, and feedback diversity, especially in high-stakes healthcare training (e.g., residency programs) where teaching resources are limited. An example healthcare domain is radiation oncology, where residents learn from attending physicians how to contour tumors that require radiotherapy treatment. This paper explores the current apprenticeship strategies in radiation oncology, proposes designs, and develops a prototype to enhance the transfer of knowledge from experts to residents. We introduce three feedback mechanisms comprising visual and text-based elements that outline the degree of overlap with expert contour, specific guidance on over- and under-contoured regions, and long-term toxicity for tumors and nearby organs at risk. The design strategies of this work can inform the design of other learning platforms (in healthcare and beyond) to improve the delivery and access of expert feedback in apprenticeship models.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585894
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585894
KW  - Apprenticeship Learning Models
KW  - Contouring
KW  - Healthcare Training
ER  - 

TY  - CONF
TI  - Defining Embodied Provenance for Immersive Sensemaking
AU  - Zhang, Yidan
AU  - Ens, Barrett
AU  - Satriadi, Kadek Ananta
AU  - Yang, Ying
AU  - Goodwin, Sarah
T3  - CHI EA '23
AB  - Immersive analytics research has explored how embodied data representations and interactions can be used to engage users in sensemaking. Prior research has broadly overlooked the potential of immersive space for supporting analytic provenance, the understanding of sensemaking processes through users’ interaction histories. We propose a concept of embodied provenance, the use of three-dimensional space and embodiment in supporting recalling, reproducing, annotating and sharing analysis history in immersive environments. We highlight a set of design criteria for analytic provenance drawn from prior work and propose a conceptual framework for embodied provenance. We develop a prototype system in virtual reality to demonstrate the concept and support the conceptual framework by providing multiple data views and embodied interaction metaphors in a large space. We present a use case scenario of energy consumption analysis, which shows the system’s potential for assisting analytic provenance using embodiment.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585691
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585691
KW  - analytic provenance
KW  - embodied provenance
KW  - immersive analytics
KW  - sensemaking
KW  - spatial memory
ER  - 

TY  - CONF
TI  - Comparing the Impact of Professional and Automatic Closed Captions on Video-Watching Experience
AU  - Kim, Hyunju
AU  - Tao, Yan
AU  - Liu, Chuanrui
AU  - Zhang, Yuzhuo
AU  - Li, Yuxin
T3  - CHI EA '23
AB  - Closed captions (CC) have gained popularity in recent years. While professional subtitles are commonly used, there has been a trend toward using automatic speech recognition technology to generate closed captions. However, there is limited research on the impact of these subtitles on viewers. To address this gap, we conducted an experiment to investigate how professional and automatic CC influence people’s video-watching experiences. We developed to measure viewers’ narrative engagement. We found that people showed better narrative understanding with the professional compared to the automatic one, while no significant difference in their emotional engagement and narrative presence. These findings suggest that automatic CC has the potential to be a rival professional one, but more research is needed to improve its effectiveness. Additionally, it provides insight into the motivations of viewers without hearing impairments or language translation needs, who use CC to enhance their video-watching experiences.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585634
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585634
KW  - automatic speech recognition
KW  - closed captions
KW  - narrative engagement
KW  - video-watching experience
ER  - 

TY  - CONF
TI  - Collaborative Diffusion: Boosting Designerly Co-Creation with Generative AI
AU  - Verheijden, Mathias Peter
AU  - Funk, Mathias
T3  - CHI EA '23
AB  - Visual communication in collaborative design provides common ground and a tangible trace of thoughts. Yet, it is often underused due to a lack of visualization skills and time needed to sketch and detail. Current visual co-creation tools can support this with existing images, whereas generative AI can produce entirely new images from textual prompts, allowing for highly specific, personalized results. In this paper, we explore how AI image generation can be used to enhance inspiration and communication throughout collaborative design. We introduce BrainFax, a tool that facilitates generating, editing, and sharing images with AI through a chat bot and online whiteboard. Through co-creation with designers in the field, we found that AI image generation can boost designerly co-creation, yet needs careful embedding into a workflow to leverage inspirational and communicative creations. We close with a critical perspective on the implications of this technology for design and discuss limitations and future work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585680
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585680
KW  - AI Image Generation
KW  - Co-Creation Tool
KW  - Design Process
KW  - Generative AI
KW  - Human-AI Collaboration
ER  - 

TY  - CONF
TI  - Collaboration in Co-located Collaborative Digital Games - Towards a Quadripartite Taxonomy
AU  - Baykal, Gökçe Elif
AU  - Eriksson, Eva
AU  - Torgersson, Olof
T3  - CHI EA '23
AB  - In this paper, we propose a taxonomy for the classification of collaborative interaction situations derived from studying a set of co-located collaborative gameplay sessions. The taxonomy builds on the MDA framework and Activity Theory (AT) as top-level attributes, and offers the analytical dimensions WHAT, WHO, WHEN and HOW, each containing a number of sub-categories, for evaluating different levels of collaborative interaction mediated by games. The work is based on a three stage process: design of game instances, data collection, and analysis of play sessions. This taxonomy is an initial step towards capturing the complexity of collaboration mediated by games, and helps in understanding and studying collaboration as a phenomena in game design. Our preliminary work provides a characterization of multiple dimensions of collaborative interaction, providing game designers a starting point for deeper understanding into collaborative interaction mediated by a collocated gameplay.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585760
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585760
KW  - Collaboration
KW  - design
KW  - games
KW  - HCI
ER  - 

TY  - CONF
TI  - CodeML: A Machine Learning-Assisted User Interface for Code Identification and Labeling
AU  - Chen, Francine
AU  - Hong, Matthew K.
AU  - Denoue, Laurent
AU  - Glazko, Kate
AU  - Sumner, Emily Sarah
AU  - Chen, Yan-Ying
AU  - Klenk, Matthew
T3  - CHI EA '23
AB  - Labeling short, unstructured texts is generally performed by sequentially identifying codes and assigning them to segments of text based on viewing a small sample of data. In this greedy approach, coders risk overlooking important code ideas and must perform the tedious task of iteratively revising the initial code set, and sometimes response code assignments, as new themes emerge. To address this, we propose CodeML, a machine learning-assisted (ML) coding interface that identifies multiple ideas in a response, which are displayed to support interactive data exploration, code identification, and refinement of snippet code assignments. By surfacing themes and snippets early, coders can consider a broader range of potential codes to reduce chances of omitting codes that surface later. A comparative study against search-style coding shows the potential for CodeML to facilitate initial exploration and discovery of finer-grained code sets while not adding significant cognitive load to organize codes and underlying text snippets.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585587
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585587
KW  - interactive machine learning
KW  - qualitative coding
KW  - text annotation
ER  - 

TY  - CONF
TI  - Code Will Tell: Visual Identification of Ponzi Schemes on Ethereum
AU  - Wen, Xiaolin
AU  - Yeo, Kim Siang
AU  - Wang, Yong
AU  - Cheng, Ling
AU  - Zhu, Feida
AU  - Zhu, Min
T3  - CHI EA '23
AB  - Ethereum has become a popular blockchain with smart contracts for investors nowadays. Due to the decentralization and anonymity of Ethereum, Ponzi schemes have been easily deployed and caused significant losses to investors. However, there are still no explainable and effective methods to help investors easily identify Ponzi schemes and validate whether a smart contract is actually a Ponzi scheme. To fill the research gap, we propose PonziLens, a novel visualization approach to help investors achieve early identification of Ponzi schemes by investigating the operation codes of smart contracts. Specifically, we conduct symbolic execution of opcode and extract the control flow for investing and rewarding with critical opcode instructions. Then, an intuitive directed-graph based visualization is proposed to display the investing and rewarding flows and the crucial execution paths, enabling easy identification of Ponzi schemes on Ethereum. Two usage scenarios involving both Ponzi and non-Ponzi schemes demonstrate the effectiveness of PonziLens.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585861
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585861
KW  - Ethereum
KW  - Ponzi scheme
KW  - visual analytics
KW  - visual identification
ER  - 

TY  - CONF
TI  - Co-Design with Myself: A Brain-Computer Interface Design Tool that Predicts Live Emotion to Enhance Metacognitive Monitoring of Designers
AU  - Yang, Qi
AU  - Feng, Shuo
AU  - Zhao, Tianlin
AU  - Kalantari, Saleh
T3  - CHI EA '23
AB  - Modulating the feelings of confidence toward design options and metacognitive monitoring are important components of design intuition. We find not many creativity support tools explored the potential of biofeedback to aid design processes in this regard. In the current study, we present “Multi-Self,” a BCI-VR design tool that aims to enhance metacognitive monitoring during architectural design. It evaluates designers’ own valence and arousal to their design work and presents designers with their biofeedback visually in real time. A pilot proof-of-concept study with 24 participants was conducted to evaluate the feasibility of the tool. Interview responses regarding the accuracy of the feedback were mixed. The majority of the participants found the feedback mechanism useful and the tool elicited metacognitive feelings and stimulated explorations of the design space while modulating subjective feelings of uncertainty.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585701
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585701
KW  - Affective Computing
KW  - Biofeedback
KW  - Brain-Computer Interface
KW  - Creativity Support Tool
KW  - Metacognition
ER  - 

TY  - CONF
TI  - Closer Worlds: Using Generative AI to Facilitate Intimate Conversations
AU  - Chen, Tiffany
AU  - Lee, Cassandra
AU  - Mindel, Jessica R
AU  - Elhaouij, Neska
AU  - Picard, Rosalind
T3  - CHI EA '23
AB  - Deep emotional intimacy is a foundational aspect of strong relationships, but the digital tools we use to communicate often limit rather than empower our feelings of connection. Two compelling strategies technologists have used to counteract such trends include games and generative AI art. In this paper, we design and test Closer Worlds, an ML-assisted 2-person game that fosters emotionally intimate conversations through co-creative world-building. We explore design principles inspired by facilitation methods and assess their effectiveness in a pilot study. We find that Closer Worlds elicits some self-disclosure behavior, but less than a social game without generative AI. However, participants clearly enjoy the unique affordances offered by visualizing shared values, which suggests that this method offers a comfortable and novel avenue for meaningful conversations. We conclude by discussing future ways in which co-creative games might leverage generative techniques to foster pro-social environments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585651
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585651
KW  - Co-creation
KW  - Conversation Games
KW  - Generative AI
KW  - Intimacy
KW  - Self-disclosure
KW  - World-building
ER  - 

TY  - CONF
TI  - Challenges and Requirements in Multi-Drone Interfaces
AU  - Hoang, Maria-Theresa Oanh
AU  - van Berkel, Niels
AU  - Skov, Mikael B.
AU  - Merritt, Timothy R.
T3  - CHI EA '23
AB  - Unmanned aerial vehicles (UAVs), commonly known as drones, have been deployed across various applications. These applications range from entertainment to critical situations, such as search and rescue (SAR) operations. The use of single drones is most common–one pilot controls one individual drone. Research has begun to explore the benefits of deploying a group of drones as a coordinated swarm. It is, however, uncertain how a multi-drone system should be designed to facilitate interaction in real-world contexts. We report initial findings from three study sessions involving prototype evaluations and co-design sessions we conducted in collaboration with the emergency services of Denmark. The results of our study open new questions and provide input on the features and functions that impact the future adoption of multi-drone systems, including interactions with multiple video feeds, ecology of screens, team communication, and flight control methods.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585673
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585673
KW  - multi-drone system
KW  - search and rescue
KW  - user-interface evaluation
ER  - 

TY  - CONF
TI  - Clinician Attitudes Towards Telemonitoring for Heart Failure Care: Opportunities for Design Research
AU  - Vugs, Suzanne
AU  - Scholte, Niels Tjeerd Benjamin
AU  - Markopoulos, Panos
AU  - Ronner, Eelko
T3  - CHI EA '23
AB  - Telemonitoring (TM) systems are not widely used by Dutch Heart Failure (HF) clinics and previous research provides inconclusive evidence for their effectiveness in HF care. To understand the underlying causes, we conducted an interview study with a purposive sample of eight medical professionals regarding their expectations and experiences towards TM systems. A qualitative analysis of the interviews showed that the expectation of HF clinicians that TM reduces their workload is not met. From the interviews, relatively unknown and understudied design implications were defined to serve as opportunities for research through design to improve TM systems for HF care. The design implications were categorized by the themes ‘ineffective user interaction’, ‘one size does not fit all’, and ‘sharing the load’.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585723
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585723
KW  - clinicians
KW  - design implications
KW  - heart failure
KW  - telemonitoring
ER  - 

TY  - CONF
TI  - Children’s Trust in Robots and the Information They Provide
AU  - Beelen, Thomas
AU  - Velner, Ella
AU  - Truong, Khiet P.
AU  - Ordelman, Roeland
AU  - Huibers, Theo
AU  - Evers, Vanessa
T3  - CHI EA '23
AB  - Previous work has shown that children tend to trust embodied conversational agents such as social robots. Also, that children have difficulty assessing the credibility of information. The study reported in this paper addresses how children’s attitudes toward and trust in a robot affect their acceptance of information provided by the robot. We conducted a within-subjects study (N=30) where children engaged with a ‘trustworthy’ versus an ‘untrustworthy’ robot. Due to the pandemic period, this interaction was carried out via video call. The children played a quiz with the robot where we measured whether they accepted the information provided by the robot. Results show that the manipulation of trustworthiness was successful. We did not find evidence for a causal relationship between trust in the robot and acceptance of the information. Furthermore, semi-structured interviews offered a more in-depth understanding of how children perceived the two different robots and their preference for the trustworthy robot.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585801
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585801
KW  - children
KW  - information assessment
KW  - robots
KW  - trust
ER  - 

TY  - CONF
TI  - Can Cross-Reality Help Nonspeaking Autistic People Transition to AR Typing?
AU  - Alabood, Lorans
AU  - Dow, Travis
AU  - Kaufman, Kate M.
AU  - Jaswal, Vikram K.
AU  - Krishnamurthy, Diwakar
T3  - CHI EA '23
AB  - About 30% of autistic people are nonspeakers; they cannot use speech to communicate effectively. Pointing to letters on a letterboard held by a Communication and Regulation Partner (CRP) is one alternative method of expressive communication that some members of this population use. In the training of this method, a CRP delivers engaging and customized lessons. Additionally, the CRP provides regulatory, sensory, and attentional support and also works to strengthen the subject’s pointing skills. The goal of this training is to equip individuals with the required skills to be able to type independently. Recent studies have proposed using AR to provide opportunities for nonspeakers to practice the motor skills involved in typing. To use such systems, however, there needs to be a transition phase where a CRP teaches their subject how to interact with a virtual letterboard. In this paper, we explore the feasibility of using cross-reality, in which a CRP and nonspeaker can interact with the same virtual objects simultaneously, as a possible means of fostering this transition. We report a study involving 5 nonspeaking autistic subjects with diverse motor skills interacting using a virtual HoloLens 2 letterboard system we developed called HoloBoard. All subjects succeeded in pointing to letters correctly or spelling on the virtual board. We report process and design recommendations based on feedback obtained from subjects and their CRPs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585859
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585859
KW  - assistive technology
KW  - augmented reality
KW  - cross-reality
KW  - Nonspeaking autistic people
ER  - 

TY  - CONF
TI  - CatHill: Emotion-Based Interactive Storytelling Game as a Digital Mental Health Intervention
AU  - Cai, Jinghe
AU  - Li, Xiaohan
AU  - Chen, Bohan
AU  - Wang, Zhigang
AU  - Jia, Jia
T3  - CHI EA '23
AB  - In this paper, we introduce CatHill, an emotion-based interactive storytelling game leveraging Cognitive Behavioral Therapy (CBT) to help college students with chronic mental health conditions. The game utilizes evidence-based stories to integrate three CBT techniques: exposure therapy, cognitive restructuring, and relaxation training. We propose a novel interface only controlled by players’ mouths to engage players better. The game allows players to chat with non-player characters (NPCs) and their speech emotions will deeply influence NPCs’ actions and story progression. Besides, players can also conduct mindful breathing exercises by breath control. Such fun and impressive interaction modes teach young people to understand the correlation among thoughts, emotions, and behaviors and change irrational automatic thoughts, and overcome anxiety or distress. Through our practice, we show that popular game elements and new interaction technologies have the potential to expand the impact of digital mental health interventions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585639
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585639
KW  - CBT
KW  - emotion-based game
KW  - mental health
ER  - 

TY  - CONF
TI  - Can Voice Assistants Sound Cute? Towards a Model of Kawaii Vocalics
AU  - Seaborn, Katie
AU  - Nam, Somang
AU  - Keckeis, Julia
AU  - Itagaki, Tatsuya
T3  - CHI EA '23
AB  - The Japanese notion of “kawaii” or expressions of cuteness, vulnerability, and/or charm is a global cultural export. Work has explored kawaii-ness as a design feature and factor of user experience in the visual appearance, nonverbal behaviour, and sound of robots and virtual characters. In this initial work, we consider whether voices can be kawaii by exploring the vocal qualities of voice assistant speech, i.e., kawaii vocalics. Drawing from an age-inclusive model of kawaii, we ran a user perceptions study on the kawaii-ness of younger- and older-sounding Japanese computer voices. We found that kawaii-ness intersected with perceptions of gender and age, i.e., gender ambiguous and girlish, as well as VA features, i.e., fluency and artificiality. We propose an initial model of kawaii vocalics to be validated through the identification and study of vocal qualities, cognitive appraisals, behavioural responses, and affective reports.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585656
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585656
KW  - cuteness
KW  - Kawaii
KW  - kawaii vocalics
KW  - user experience
KW  - vocalics
KW  - voice assistants
KW  - voice UX
ER  - 

TY  - CONF
TI  - “Briefly Entertaining but Pointless”: Perceived Benefits & Risks of Social Robots in the Home
AU  - Schneiders, Eike
AU  - Papachristos, Eleftheris
AU  - van Berkel, Niels
AU  - Jacobsen, Rune Møberg
T3  - CHI EA '23
AB  - In contrast to the adoption of personal assistants, social robots have yet to break into the domestic market. Several manufacturers have introduced and quickly retracted their social robots for the home. We report on a survey study (N&nbsp;=&nbsp;50) to understand potential users’ perceptions towards these social robots. Participants were presented with videos of three domestic social robots and subsequently provided their perception of these in terms of perceived benefits, attraction, privacy risk, usage intention, and capabilities. While participants perceived hedonic and utilitarian benefits, we found a low intention of future adoption of these devices. Further, our findings showed that owners of personal assistants perceived significantly higher hedonic benefits, fewer privacy risks, and higher intention to use domestic social robots. Our work provides an initial step towards understanding perceptions towards social robots and how previous exposure to domestic AI shapes users’ perceptions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585696
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585696
KW  - domestic robots
KW  - personal assistants
KW  - robot assistants
KW  - Social robots
ER  - 

TY  - CONF
TI  - BREATHTURES: A First Step Towards Breathing Gestures as Distinct Input Modality
AU  - Burr, Lisa Anneke
AU  - Šula, Julius
AU  - Mayrhauser, Julia
AU  - Meschtscherjakov, Alexander
T3  - CHI EA '23
AB  - The use of breath as interaction modality has sparked some interest recently in HCI. Research in this field actively explored breathing interaction (e.g., guidance and feedback) in different contexts. So far, very little systems can be found that systematically use defined breathing gestures as distinct input modality. In this work, we describe the design, development and implementation of five distinct breathing gestures (BREATHTURES), that can be applied as defined input modality to interact with an application. We present a qualitative user study (n=7) focusing on usability and user experience of the developed BREATHTURES when applied in a game-like application. Results indicate an overall positive rating in terms of fun and usability. Some BREATHTURES were perceived harder to perform and to detect than others. Further iterations of our work will require refined BREATHTURE detection. Overall, our work demonstrates the design, implementation and application of pre-defined breathing gestures as distinct input modality.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585787
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585787
KW  - breath detection
KW  - breathing pattern
KW  - distinct input modality
KW  - interaction
KW  - modular environment
ER  - 

TY  - CONF
TI  - Breathing based immersive interactions for enhanced agency and body awareness: a claustrophobia motivated study
AU  - Wald, Iddo Yehoshua
AU  - Maimon, Amber
AU  - Keniger De Andrade Gensas, Lucas
AU  - Guiot, Noemi
AU  - Ben Oz, Meshi
AU  - Corn, Benjamin W.
AU  - Amedi, Amir
T3  - CHI EA '23
AB  - This work explores utilizing representations of one’s physiological breath (embreathment) in immersive experiences, for enhancing presence and body awareness. Particularly, embreathment is proposed for reducing claustrophobia and associated negative cognitions such as feelings of restriction, loss of agency, and sense of suffocation, by enhancing agency and interoception in circumstances where one’s ability to act is restricted. The informed design process of an experience designed for this purpose is presented, alongside an experiment employing the experience, evaluating embodiment, presence, and interoception. The results indicate that embreathment leads to significantly greater levels of embodiment and presence than either an entrainment or control condition. In addition, a modest trend was observed in a heartbeat detection task implying better interoception in the intervention conditions than the control. These findings support the initial assumptions regarding presence and body awareness, paving the way for further evaluation with individuals and situations related to the claustrophobia use case.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585897
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585897
KW  - agency
KW  - breathing
KW  - claustrophobia
KW  - embodiment
KW  - embreathment
KW  - negative cognitions
KW  - presence
KW  - respiation
KW  - sense of control
ER  - 

TY  - CONF
TI  - BreatheWithMe: Exploring Visual and Vibrotactile Displays for Social Breath Awareness during Colocated, Collaborative Tasks
AU  - El Ali, Abdallah
AU  - Stepanova, Ekaterina R.
AU  - Palande, Shalvi
AU  - Mader, Angelika
AU  - Cesar, Pablo
AU  - Jansen, Kaspar
T3  - CHI EA '23
AB  - Sharing breathing signals has the capacity to provide insights into hidden experiences and enhance interpersonal communication. However, it remains unclear how the modality of breath signals (visual, haptic) is socially interpreted during collaborative tasks. In this mixed-methods study, we design and evaluate BreatheWithMe, a prototype for real-time sharing and receiving of breathing signals through visual, vibrotactile, or visual-vibrotactile modalities. In a within-subjects study (15 pairs), we investigated the effects of modality on breathing synchrony, social presence, and overall user experience. Key findings showed: (a) there were no significant effects of visualization modality on breathing synchrony, only on deliberate music-driven synchronization; (b) visual modality was preferred over vibrotactile feedback, despite no differences across social presence dimensions; (c) BreatheWithMe was perceived to be an insightful window into others, however included data exposure and social acceptability concerns. We contribute insights into the design of multi-modal real-time breathing visualization systems for colocated, collaborative tasks.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585589
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585589
KW  - awareness
KW  - Breathing
KW  - collaborative
KW  - dyadic
KW  - haptics
KW  - LED
KW  - mutltimodal
KW  - respiration
KW  - social interactions
KW  - visual
ER  - 

TY  - CONF
TI  - Breath Tools: Exploring the Effects on Adherence and User Experience of 4 Sounds Assisting Runners with Coupling Breath to Steps
AU  - van Rheden, Vincent
AU  - Harbour, Eric
AU  - Finkenzeller, Thomas
AU  - Meschtscherjakov, Alexander
T3  - CHI EA '23
AB  - Running is a popular sport worldwide. Locomotor-Respiratory Coupling (LRC), a breathing technique in which the breath is coupled to steps, can positively impact running experience and economy. LRC may be difficult to learn and maintain during a run. Sound cues are a promising method to guide LRC while running. We designed four guiding sounds and evaluated these in a preliminary study (N=9). All sounds supported participants with LRC (on average 74.9±16.2% of time attached to the LRC rhythm). Based on our findings we advocate sound guidance for LRC and present directions to improve adherence and run experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585736
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585736
KW  - Auditory interface
KW  - breathing
KW  - coupling
KW  - human-computer interaction
KW  - running
KW  - sports
KW  - user experience
ER  - 

TY  - CONF
TI  - Blended Collaboration: Communication and Cooperation Between Two Users Across the Reality-Virtuality Continuum
AU  - Kruse, Lucie
AU  - Wittig, Joel
AU  - Finnern, Sebastian
AU  - Gundlach, Melvin
AU  - Iserlohe, Niclas
AU  - Ariza, Oscar
AU  - Steinicke, Frank
T3  - CHI EA '23
AB  - Mixed reality (MR) technologies provide enormous potential for collaboration between multiple users across the Reality–Virtuality continuum. We evaluate communication in a MR-based two-user collaboration task, in which the users have to move an object through an obstacle without collision. We used a blended reality environment, in which one user is immersed in virtual reality, whereas the other uses mobile augmented reality. Both users have different abilities and information and mutually depend on each other for successful completion of the task. Communication consensus can either be achieved by using speech, visual widgets, or a combination of both. The results indicate that speech plays a fundamental role. The usage of widgets served as an extension rather than a replacement of language. However, the combination of speech and widgets improved the clearness of communication with less miscommunication. These results provide important indications about how to design blended collaboration across the Reality–Virtuality continuum.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585881
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585881
KW  - 3D interaction
KW  - augmented reality
KW  - collaboration
KW  - communication
KW  - cooperation
KW  - multi-user XR
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Big Buddy: A Simulated Embodied Moderating System to Mitigate Children’s Reaction to Provocative Situations within Social Virtual Reality
AU  - Fiani, Cristina
AU  - Bretin, Robin
AU  - McGill, Mark
AU  - Khamis, Mohamed
T3  - CHI EA '23
AB  - The use of social Virtual Reality (VR) among children is increasing, but with it comes new forms of harassment that can be difficult for parents to monitor. To address this issue, we have developed "Big Buddy", a prototype AI-moderator that aims to safeguard children from potential harassment in social VR. We conducted a study in which 43 children (aged 8-16) participated in a simulated social VR classroom, with fictitious competitors disrupting their game. When Big Buddy intervened, the children reported feeling significantly less negative emotions and felt safer. This is the first study to empirically examine the use of an embodied AI-moderator in social VR from the perspective of children, and it provides important insights for designing AI-moderators in social VR.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585840
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585840
KW  - artificial moderator
KW  - children
KW  - embodied moderating system
KW  - online harassment
KW  - social virtual reality
ER  - 

TY  - CONF
TI  - "Begin with the End in Mind": Incorporating UX Evaluation Metrics into Design Materials of Participatory Design
AU  - Zheng, Qingxiao
AU  - Huang, Yun
T3  - CHI EA '23
AB  - Participatory Design (PD) aims to empower users by involving them in various design decisions. However, it was found that the PD’s evaluation criteria are usually set by the product team and used only at the end of a design process, without adequate user participation. To address this issue, we proposed introducing UX evaluation metrics into design materials at the participatory design INPUT phase. Using a case study of designing a chatbot for community members to report safety incidents, we studied the impact of this approach with 58 participants from two workshops. Our results showed that the integration of UX evaluation metrics efficiently rationalized participants’ contributions and helped identify key evaluation metrics when setting values for new AI systems, enhancing PD workshop insights. In addition to examining the use of the Program Theory Model to explain PD, our empirical investigation added a new dimension to this model.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585664
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585664
KW  - design material
KW  - evaluation metrics
KW  - Participatory design
KW  - program theory
KW  - UX
ER  - 

TY  - CONF
TI  - BrainiBeats: A dual brain-computer interface for musical composition using inter-brain synchrony and emotional valence
AU  - Ceccato, Caterina
AU  - Pruss, Ethel
AU  - Vrins, Anita
AU  - Prinsen, Jos
AU  - Alimardani, Maryam
T3  - CHI EA '23
AB  - A dual brain-computer interface (BCI) was developed to translate emotions and synchrony between two users into music. Using EEG signals of two individuals, the system generates live music note-by-note and controls musical parameters, such as pitch, intensity and interval. The users’ mean EEG amplitude determines the notes, and their emotional valence modulates the intensity (i.e. volume of music). Additionally, inter-brain synchrony is used to manipulate the interval between notes, with higher synchrony producing more pleasant music and lower synchrony producing less pleasant music. Further research is needed to test the system in an experimental setting, however, literature suggests that neurofeedback based on inter-brain synchrony and emotional valence could be used to promote positive aspects of group dynamics and mutual emotional understanding.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585910
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585910
KW  - brain-computer interface (BCI)
KW  - emotion
KW  - inter-brain synchrony
KW  - music
KW  - neurofeedback
ER  - 

TY  - CONF
TI  - Blockchain (not) for Everyone: Design Challenges of Blockchain-based Applications
AU  - Saldivar, Jorge
AU  - Martínez-Vicente, Elena
AU  - Rozas, David
AU  - Valiente, Maria-Cruz
AU  - Hassan, Samer
T3  - CHI EA '23
AB  - Upon its arrival, the Ethereum blockchain promised to introduce a new paradigm of Internet-based applications that would revolutionize multiple fields, from finance to IoT to the public sector. Until now, scientific efforts have been primarily focused on theoretical discussions about the implications of the technology and on technical proposals to improve and consolidate the underlying infrastructure, neglecting the experience of people using blockchain-based systems. However, for this technology to permeate the mainstream, blockchain technology should be easily accessible to the general public. This paper reports on evaluations conducted with first-time blockchain users of two Internet-mediated communities using prototype applications built on Ethereum. Results unveil that even users familiar with technology experienced severe difficulties using blockchain-based apps. Also, we saw how blockchain metaphors and transaction-mediated interactions challenge established mental models for modern applications, imposing heavy workloads on users. We conclude the paper by discussing design implications resulting from blockchain’s paradigm change.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585825
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585825
KW  - blockchain
KW  - decentralized applications
KW  - user experience
ER  - 

TY  - CONF
TI  - Bees, Birds and Butterflies: Investigating the Influence of Distractors on Visual Attention Guidance Techniques
AU  - Doerr, Nina
AU  - Angerbauer, Katrin
AU  - Reinelt, Melissa
AU  - Sedlmair, Michael
T3  - CHI EA '23
AB  - Visual attention guidance methods direct the viewer’s gaze in immersive environments by visually highlighting elements of interest. The highlighting can be done, for instance, by adding a colored circle around elements, adding animated swarms (HiveFive), or removing objects from one eye in a stereoscopic display (Deadeye). We contribute a controlled user experiment (N=30) comparing these three techniques under the influence of visual distractors, such as bees flying by. Our results show that Circle and HiveFive performed best in terms of task performance and qualitative feedback, and were largely robust against different levels of distractions. Furthermore, we discovered a high mental demand for Deadeye.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585816
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585816
KW  - attention guidance
KW  - perception
KW  - virtual reality
KW  - visual attention
ER  - 

TY  - CONF
TI  - AVOCUS: A Voice Customization System for Online Personas
AU  - Byeon, Hyeon Jeong
AU  - Ha, Seungjin
AU  - Oh, Uran
T3  - CHI EA '23
AB  - Many digital applications offer avatar customization options, positively affecting user experience. However, the adoption of auditory aspects in avatar customization has often been neglected and may have been understudied for its potential. Inspired by prior research that uncovers end-user’s demands for voice customization, we seek to apply the identified implications into practice and discover end-user’s voice preferences and behavior towards voice customization systems. To this end, we designed and deployed AVOCUS, a web application that enables users to search for specific voices or manipulate voice-related parameters to generate a voice similar to a target voice. Our findings suggest that (1) searching for specific voice using hashtags were perceived to be easy, (2) customized voices generated from voice reflection and voice parameter control functions had high satisfaction, and (3) participants tend to reflect the features of their desired voices when customizing their own voice.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585892
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585892
KW  - online communication
KW  - user evaluation
KW  - voice customization
KW  - voice perception
KW  - voice quality
ER  - 

TY  - CONF
TI  - AUTOMATE - AN EMPATHIC FIRST-AID COMMUNICATION SYSTEM TO REDUCE THE BYSTANDER EFFECT IN CAR ACCIDENTS
AU  - Demir, Cansu
AU  - Lang, Sonja
AU  - Melibeu, Isabel
AU  - Meschtscherjakov, Alexander
T3  - CHI EA '23
AB  - The bystander effect (i.e. theory that individuals are less likely to offer help in presence of others) is a common problem especially, when in cases of car accidents. In this paper, we present a first-aid communication system (AutoMate) that shall increase empathy of nearby drivers and support them in helping a car accident victim. Based on expert interviews, we designed and implemented a prototypical AutoMate system and evaluated it in a user study (N=8) in a car simulator. Results show the potential of such a system towards a more empathic behavior. We discuss challenges and opportunities for the design of in-vehicle information systems addressing bystander effects.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585777
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585777
KW  - Bystander Effect
KW  - Emergency
KW  - Empathy
KW  - First-Aid
KW  - Interaction Design
KW  - UCD
KW  - Voice Assistance
ER  - 

TY  - CONF
TI  - Authentication Challenges in Customer Service Settings Experienced by Deaf and Hard of Hearing People
AU  - Andrew, Sarah
AU  - Watson, Stacey L
AU  - Oh, Tae
AU  - Tigwell, Garreth W.
T3  - CHI EA '23
AB  - Customer services are important for answering questions, providing information, and handling issues. Often people want to connect with a customer service representative, yet, this can be an accessibility barrier for Deaf and Hard of Hearing People (DHH) when voice calls are the only method. However, little is known about the challenges experienced by DHH people in solely voice-based customer service settings (e.g., authenticating themselves over the phone to their banks). To address this, we interviewed 18 DHH people to understand the challenges when remotely authenticating themselves with customer service. Though DHH people are not unique in their attitudes and behaviors toward mobile authentication, we found that voice-based authentication and services are challenging. Furthermore, DHH people can often be put in positions where they must trust third-party support (e.g., human interpreters) when discussing sensitive information to authenticate themselves through voice-based authentication and services. We present several avenues of future work needed to address these challenges.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585707
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585707
KW  - Customer Service
KW  - Deaf
KW  - Hard of Hearing
KW  - Video Relay Services
ER  - 

TY  - CONF
TI  - Balancing Power Relations in Participatory Design: The Importance of Initiative and External Factors
AU  - Volkmann, Torben
AU  - Dresel, Markus
AU  - Jochems, Nicole
T3  - CHI EA '23
AB  - Power imbalances between users and designers impede the intent to equal contributions in a participatory process. Recent years have shown that unforeseen external factors pose a risk of exacerbating this power imbalance by limiting in-person meetings and communication in general. This study evaluated a projects’ power relations using a three-part reflection-on-action approach. Results show, that external factors can act as an actor in the power relationship model and that the change of initiative can change the power relations. Thus, we propose a power relation triangle for Participatory Design processes, including participants, designers and external conditions as actors and the decision-making at the center based on the combination of the actor’s relations. This framework can help to better understand and address power imbalances in Participatory Design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585864
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585864
KW  - decision-making
KW  - gerontechnology
KW  - older adults
KW  - participatory design
KW  - power
KW  - user-collaboration
ER  - 

TY  - CONF
TI  - Autonomy and Safety: A Quantitative Study with Control Room Operators on Affinity for Technology Interaction and Wish for Pervasive Computing Solutions
AU  - Flegel, Nadine
AU  - Wessel, Daniel
AU  - Pöhler, Jonas
AU  - Van Laerhoven, Kristof
AU  - Mentler, Tilo
T3  - CHI EA '23
AB  - Control rooms are central to the well-being of many people. In terms of human computer interaction (HCI), they are characterized by complex IT infrastructures providing numerous graphical user interfaces. More modern approaches have been researched for decades. However, they are rarely used. What role does the attitude of operators towards novel solutions play? In one of the first quantitative cross-domain studies in safety-related HCI research (N = 155), we gained insight into affinity for technology interaction (ATI) and wish for pervasive computing solutions of operators in three domains (emergency response, public utilities, maritime traffic). Results show that ATI values were rather high, with broader range only in maritime traffic operators. Furthermore, the assessment of autonomy is more strongly related to the desire for novel solutions than perceived added safety value. These findings can provide guidance for the design of pervasive computing solutions, not only but especially for users in safety-critical contexts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585822
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585822
KW  - Affinity for Technology Interaction
KW  - Autonomy
KW  - Control Room
KW  - Pervasive Computing
KW  - Safety
ER  - 

TY  - CONF
TI  - Augmenting Auditory Attention and Memory to Reduce Cognitive Load in Dual Tasks: A wearable device to augment auditory attention and memory to improve performance in a duals task
AU  - Urakami, Jacqueline
AU  - Moriwaki, Akito
AU  - Nagao, Shotaro
AU  - Osumi, Kousuke
AU  - Yamamoto, Erika
AU  - Kanaoka, Toshikazu
T3  - CHI EA '23
AB  - We present a wearable device that enhances auditory attention and memory by monitoring the environment for relevant auditory information, storing it, alerting the user to it, and playing back the information. This paper presents the design concept of the wearable device and its empirical evaluation. Using a within-subject design, participants’ cognitive and perceptual performance was compared with and without auditory augmentation. Participants were presented with a dual task in which they had to monitor an auditory message for a specific keyword while completing a reading comprehension task. Results showed that the wearable device successfully enhanced auditory attention and memory by taking over the listening task, thereby freeing up cognitive resources for the reading task. In addition, participants' self-assessment indicated that the auditory augmentation was successfully integrated into cognitive and perceptual processes, reducing distraction, and increasing perceived calmness.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585584
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585584
KW  - Auditory memory
KW  - Divided attention
KW  - Human augmentation
KW  - User-centered design
KW  - Wearable device
ER  - 

TY  - CONF
TI  - Augmented Reality-based Indoor Positioning for Smart Home Automations
AU  - Schenkluhn, Marius
AU  - Peukert, Christian
AU  - Weinhardt, Christof
T3  - CHI EA '23
AB  - Ambient Assisted Living (AAL) has been discussed for some time; however, many systems are not considered as interoperable or user-friendly. This fact is an even more important issue as every interaction is more costly in terms of time and effort for people with disabilities or senior citizens. Therefore, this paper examines the potential of automations that can substitute typical daily interactions in AAL or Smart Home settings in general based on the users’ location. Particularly, we suggest the novel approach of using the indoor positioning capabilities of Augmented Reality (AR) head-mounted displays (HMD) to detect, track, and identify residents for the purpose of automatically controlling various Internet of Things (IoT) devices in Smart Homes. An implementation of this feature on an off-the-shelf AR HMD without additional external trackers is demonstrated and the results of an initial feasibility study are presented.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585745
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585745
KW  - Augmented Reality
KW  - Indoor Positioning
ER  - 

TY  - CONF
TI  - Augmented Reality in Service of Human Operations on the Moon: Insights from a Virtual Testbed
AU  - Becker, Leonie
AU  - Nilsson, Tommy
AU  - Demedeiros, Paul
AU  - Rometsch, Flavie
T3  - CHI EA '23
AB  - Future astronauts living and working on the Moon will face extreme environmental conditions impeding their operational safety and performance. While it has been suggested that Augmented Reality (AR) Head-Up Displays (HUDs) could potentially help mitigate some of these adversities, the applicability of AR in the unique lunar context remains underexplored. To address this limitation, we have produced an accurate representation of the lunar setting in virtual reality (VR) which then formed our testbed for the exploration of prospective operational scenarios with aerospace experts. Herein we present findings based on qualitative reflections made by the first 6 study participants. AR was found instrumental in several use cases, including the support of navigation and risk awareness. Major design challenges were likewise identified, including the importance of redundancy and contextual appropriateness. Drawing on these findings, we conclude by outlining directions for future research aimed at developing AR-based assistive solutions tailored to the lunar setting.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585860
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585860
KW  - astronaut
KW  - augmented reality
KW  - head-up display
KW  - human factors
KW  - human space flight
KW  - lunar exploration
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Atmospheror: Towards an Olfactory Interactive System for Enhancing Social Presence and Interaction in Synchronous Online Classes
AU  - Lu, Qi
AU  - Zhang, Yuewei
AU  - Zhang, Yuxin
AU  - Ma, Shao-En
AU  - Zhang, Yunfan
AU  - Qin, Yuou
AU  - Gao, Peizhong
AU  - Zhang, Qiwei
AU  - Xu, Yingqing
T3  - CHI EA '23
AB  - Synchronous online classes have become increasingly common in recent years. However, students and instructors often face challenges when giving and receiving reactions and feedback. Existing solutions include audio and visual cues, which often act as distractions. A potential alternative is olfactory cues. This paper proposes Atmospheror, an interactive system that supports interaction and feedback between students and instructors through an ambient olfactory display. We performed a pilot study with two instructors and 13 students to evaluate the effectiveness of Atmospheror and its design and implementation, applying both quantitative and qualitative methods. Preliminary results indicate that Atmospheror can promote students’ concentration and increase interactivity in online classes. User interviews provided suggestions for future enhancements of the selection and treatment of odor, hardware implementation, and interface system mechanisms.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585832
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585832
KW  - olfactory interface
KW  - remote communication
KW  - scent atmosphere
KW  - social presence and interaction
KW  - synchronous online class
ER  - 

TY  - CONF
TI  - Assessing Superhuman Speed as a Gamified Reward in a Virtual Reality Bike Exergame
AU  - McDade, Jeremy
AU  - Jing, Allison
AU  - Stanton, Tasha
AU  - Smith, Ross
T3  - CHI EA '23
AB  - This research presents a Virtual Reality (VR) bike exergame system consisting of a stationed road bike, four novel virtual steering methods, two in-game superhuman speed reward ideas, and a pedalling system simulating real-life resistance. A study is conducted to understand how virtual speed can be used as a reward to encourage enjoyment in physical activities. The result suggests that adding reward-based superhuman speed positively impacts user enjoyment. Adding steering control and increasing speed potentially do not inhibit greater motion sickness symptoms using well-aligned physical-to-virtual input and output representations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585730
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585730
ER  - 

TY  - CONF
TI  - Are robots vegan? Unexpected behaviours in child-robot interactions and their design implications
AU  - Wróbel, Alicja
AU  - Źróbek, Karolina
AU  - Indurkhya, Bipin
AU  - Schaper, Marie-Monique
AU  - Gunia, Artur
AU  - Zguda, Paulina Maria
T3  - CHI EA '23
AB  - A robot’s unexpected behaviors, such as a social faux pas or system errors, affect how a child perceives or interacts with the robot. In this study, we conducted two child-robot interaction workshops on active reading in a museum of modern art, and observed the behavior and attitudes of 18 children from two age groups (6-7 yrs and 10-12 yrs). The video and audio data from this event was analyzed to observe how children in a group respond to the robot’s unexpected behaviors. We extracted six different types of robot’s surprising behaviors: robot’s personality, movement malfunctions, inconsistent behavior, mispronunciation, delays and freezing. We analyzed how children in the younger and the older age groups respond to each of these behaviours, and what are the similarities and differences between the two groups. Based on this analysis, we suggest guidelines for designing age-appropriate learning interactions with social robots.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585666
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585666
KW  - Age-Appropriate Learning Experience
KW  - Child-Robot Interaction
KW  - Child-Robot Interaction Design
KW  - Robot Unexpected Behaviors
KW  - Social Robots
ER  - 

TY  - CONF
TI  - ARephotography: Revisiting Historical Photographs using Augmented Reality
AU  - Hasselman, Tommy
AU  - Lo, Wei Hong
AU  - Langlotz, Tobias
AU  - Zollmann, Stefanie
T3  - CHI EA '23
AB  - Augmented Reality (AR) opens up new possibilities for interactive experiences which can be used in a variety of circumstances. Rephotography is a photo technique commonly presented on dedicated internet pages that align a past view with a current photo, allowing you to have a comparative view of the past with the present. This project aims to combine these two concepts to create AR experiences where you can view buildings and street views from historical photography seamlessly embedded in the present environment. We report on our automated pipeline that can take a historical photograph of a building and produces a textured 3D model that can be placed in AR over the current view of the building using techniques from machine learning while also reporting on first feedback from a preliminary user study.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585646
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585646
KW  - 3D reconstruction
KW  - Augmented Reality
KW  - Inpainting
KW  - Instance Segmentation
KW  - Rephotography
ER  - 

TY  - CONF
TI  - ARctic Escape: Promoting Social Connection, Teamwork, and Collaboration Using a Co-Located Augmented Reality Escape Room
AU  - Knoll, Theodore
AU  - Liaqat, Amna
AU  - Monroy-Hernández, Andrés
T3  - CHI EA '23
AB  - We present ARctic Escape, a co-located augmented reality (AR) escape room designed to promote collaboration between dyads through play. While physical escape rooms provide groups with fun, social experiences, they require a gameplay venue, props, and a game master, all of which detract from their ease of access. Existing AR escape rooms demonstrate that AR can make escape room experiences easier to access. Still, many AR escape rooms are single-player and therefore fail to maintain the social and collaborative elements of their physical counterparts. This paper presents ARctic Escape, a two-person AR escape room with clues emphasizing player interaction and teamwork. We evaluated ARctic Escape by conducting semi-structured interviews with four dyads to learn about participants’ interpersonal dynamics and experiences during gameplay. We found that participants thought the experience was fun, collaborative, promoted discussion, and inspired new social dynamics, but sometimes the escape room’s reliance on virtual content was disorienting.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585841
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585841
KW  - Asymmetric Visual Information
KW  - Augmented Reality
KW  - Co-Located
KW  - Collaboration
KW  - Escape Room
KW  - Games
KW  - Mobile AR
KW  - Playful
KW  - Social
ER  - 

TY  - CONF
TI  - Another Recipe App: A Design Case with Motive Disposition Theory
AU  - Yu, Tong
T3  - CHI EA '23
AB  - As an interdisciplinary field, HCI studies are often built upon findings from other disciplines, such as the prevalent application of self-determination theory in HCI. Besides self-determination theory, motive disposition theory (MDT) is another prominent motivation theory that addresses human needs. However, the application of MDT is barely seen in HCI studies. MDT emphasizes individual differences in motives, differentiates implicit and explicit motives, and takes fear motives into account. We demonstrate a design case where MDT is applied to the design of a recipe app in order to motivate user engagement and deliver positive experiences. We then discuss our reflections from designing with MDT and identify concerns that could be addressed in the future. We hope that through our design case, the possibility and potential benefits of utilizing MDT in HCI design could be seen, and more discussions and studies with MDT in HCI could be sparked.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585591
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585591
KW  - design
KW  - motivation
KW  - motive disposition theory
KW  - user experience
ER  - 

TY  - CONF
TI  - An Immersive Layout Framework for Web Design in Virtual Reality
AU  - Lu, Yu
AU  - Hu, Yong
AU  - Shen, Xukun
AU  - Chen, Zhaojia
T3  - CHI EA '23
AB  - In recent years, many consumer-grade VR devices have emerged, and VR devices have the potential to become the next generation of terminals for visiting websites. Compared to traditional PC and mobile devices, VR moves away from the desktop concept and can show information in a 3D environment. This two-dimensional to three-dimensional transformation means that website layouts, media content, and interactions can make the user experience more immersive. Currently, VR users can visit websites through built-in or third-party browsers, but most website content and UI visuals are consistent with the desktop version instead of the VR version. The website has no separate visual and interactive designs for VR devices. Therefore, this paper analyzes the design elements from three aspects: spatial layout design of website hierarchical structures, presentation of multimedia contents, and interaction modes, and proposes a VR website design framework based on the fan-shaped layout using the spatial depth cue. Based on this design framework, we built a prototype of the VR version of the website in the context of the online museum website of intangible cultural heritage in Yunnan Province. We provided a reference for spatial layout and visual style design for developing the VR website.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585889
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585889
KW  - 3D Layout Framework
KW  - Virtual Reality
KW  - Web Design
KW  - web XR
ER  - 

TY  - CONF
TI  - An Expressivity-Complexity Tradeoff?: User-Defined Gestures from the Wheelchair Space are Mostly Deictic
AU  - Bilius, Laura-Bianca
AU  - Ungurean, Ovidiu-Ciprian
AU  - Vatavu, Radu-Daniel
T3  - CHI EA '23
AB  - We present empirical results about gesture expressivity and articulation complexity from an analysis of 231 gestures elicited from eleven wheelchair users, for which we employ a combination of McNeill’s gesture theory from psycholinguistics and a taxonomy used in Human-Computer Interaction for the analysis of gestures elicited from end users. We report that 53.7% of the gestures that we analyzed were deictic in nature, and 50.7% were performed toward the body. These findings suggest a potential tradeoff between the expressivity of iconic and metaphoric gestures, less represented in the gesture set analyzed in this work, for the low complexity of simple pointing movements performed from the wheelchair space. Our results complement findings of previous gesture elicitation studies conducted with users with motor and/or mobility impairments, and suggest future work opportunities for gesture input performed from the wheelchair space, including mixed-nature gestures that feature both low complexity and rich expressivity.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585695
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585695
KW  - deictic gestures
KW  - gesture elicitation
KW  - Gesture input
KW  - iconic gestures
KW  - mobility impairments
KW  - motor impairments
KW  - wheelchair users
ER  - 

TY  - CONF
TI  - An Exploration of Theatre Rehearsals in Social Virtual Reality
AU  - Levordashka, Ana
AU  - Eastman, Jamie
AU  - Skoulikari, Eleni Anna
AU  - Salagean, Anca
AU  - Cosker, Darren
AU  - Stanton Fraser, Danaë
T3  - CHI EA '23
AB  - Virtual Reality (VR) offers potential for theatre makers to rehearse remotely in settings which are uniquely immersive. In collaboration with a major drama school in the United Kingdom, a longitudinal diary study was completed to examine the utility of consumer-grade VR for theatre rehearsals. Utilising commonly affordable headsets and general-purpose Social VR applications, 10 experienced students (2 directors, 8 actors) rehearsed scenes in VR over 3 weeks, before performing them in person. Participants detailed their experiences in diary logs and interviews, expressing the ability to work through spatial arrangements (blocking) as a full body avatar to be positively beneficial. Limitations included the absence of facial expressions and gestural nuance. Our overarching conclusion is that low-tech VR can be a useful aid in theatre rehearsals and early stages of production. In conclusion we outline design recommendations for a) using VR in theatre production and b) research and development of Social VR.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585685
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585685
KW  - acting
KW  - avatars
KW  - presence
KW  - remote rehearsals
KW  - social interaction
KW  - theatre rehearsals
ER  - 

TY  - CONF
TI  - An Evaluation of Other-Avatar Facial Animation Methods for Social VR
AU  - Kullmann, Peter
AU  - Menzel, Timo
AU  - Botsch, Mario
AU  - Latoschik, Marc Erich
T3  - CHI EA '23
AB  - We report a mixed-design study on the effect of facial animation method (static, synthesized, or tracked expressions) and its synchronization to speaker audio (in sync or delayed by the method’s inherent latency) on an avatar’s perceived naturalness and plausibility. We created a virtual human for an actor and recorded his spontaneous half-minute responses to conversation prompts. As a simulated immersive interaction, 44 participants unfamiliar with the actor observed and rated performances rendered with the avatar, each with the different facial animation methods. Half of them observed performances in sync and the others with the animation method’s latency. Results show audio synchronization did not influence ratings and static faces were rated less natural and less plausible than animated faces. Notably, synthesized expressions were rated as more natural and more plausible than tracked expressions. Moreover, ratings of verbal behavior naturalness differed in the same way. We discuss implications of these results for avatar-mediated communication.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585617
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585617
KW  - Facial Animation
KW  - Facial Expression Synthesis
KW  - Facial Expression Tracking
KW  - Naturalness
KW  - Observation Study
KW  - Performance Capture
KW  - Plausibility
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - AmBiDiguity does exist: UI item Direction Interpretation by Bidirectional Users
AU  - Goldenberg, Yulia
AU  - Tractinsky, Noam
T3  - CHI EA '23
AB  - Bidirectional user interfaces serve more than half a billion users worldwide. Despite increasing diversity-driven approaches to interface development, bidirectional interfaces still use UI items’ directionality inconsistently and incorrectly. Designers should pay special attention to UI items containing ambiguous information that can be processed both from right to left and from left to right by bidirectional users. Such items are susceptible to ineffective use.This paper reports preliminary results from a study with 1705 Arabic and Hebrew users. We investigated the directional interpretation of 16 UI items, empirically demonstrating the ambiguity problem in bidirectional interfaces and the potential influence of UI factors on how users interpret the items’ directionality. While the study indicates that preventing all interpretation errors is unlikely, a large portion of those errors can be addressed by proper design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585598
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585598
ER  - 

TY  - CONF
TI  - All it Takes is a Slight Rotation: Robotic Bar-stools Enhance Intimacy in Couples’ Conflict
AU  - Sadka, Ofir
AU  - Parush, Avi
AU  - Zuckerman, Oren
AU  - Erel, Hadas
T3  - CHI EA '23
AB  - Couples’ ability to manage conflicts is fundamental in the discourse of romantic relationships. A supportive environment for conflict management highly depends on non-verbal communication cues. We explored the possibility to facilitate positive non-verbal cues by using autonomous furniture that do not alter the dyadic nature of the interaction. Couples discussed a subject of disagreement while seated on autonomous bar-stools. During the discussion, the stools rotated inward, directing partners toward one another. In the baseline condition, the bar-stools were inactive. Our findings showed that the inward rotation facilitated couples’ non-verbal cues (e.g., eye-gaze, body-orientation), which highly contributed to their communication and decreased conflict intensity. The positive effect was also evident in the number of intimate touch occurrences. The bar-stools’ movement led to a significant increase in hand-holding, kisses, and hugs. This work highlights the great potential of leveraging autonomous furniture for enhancing romantic interactions while preserving their intimate and emotional nature.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585620
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585620
KW  - conflict
KW  - Human-Human-Robot Interaction
KW  - Robotic Furniture.
KW  - Romantic-relationships
ER  - 

TY  - CONF
TI  - Algorithmic appreciation or aversion? The moderating effects of uncertainty on algorithmic decision making
AU  - Schecter, Aaron
AU  - Bogert, Eric
AU  - Lauharatanahirun, Nina
T3  - CHI EA '23
AB  - Humans are increasingly making decisions with the aid of algorithms. In some cases, people have exhibited algorithmic aversion, or a tendency to disregard potentially accurate advice from an algorithm. In other cases, the reverse is true, and humans display algorithmic appreciation. Prior work has focused on the role of task type in determining aversion or appreciation, or has considered an individual’s agency in the decision making process. In this paper, we posit that certain latent preferences can explain these decisions. We introduce two constructs related to individuals’ tolerance for uncertainty and sensitivity to the source of uncertainty and measure them across three different preregistered experimental tasks (N = 451 participants total). We find an overall robust tendency towards algorithmic appreciation and find that the measures we introduced significantly moderate the propensity to accept algorithmic advice. We find some heterogeneity across task types and identify circumstances where individuals express aversion instead of appreciation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585908
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585908
KW  - algorithmic advice
KW  - Decision making
KW  - human computer interaction
KW  - risk preferences
KW  - uncertainty
ER  - 

TY  - CONF
TI  - AI in the Shell: Towards an Understanding of Integrated Embodiment
AU  - Li, Zhuying
AU  - Huang, Tianze
AU  - Patibanda, Rakesh
AU  - Mueller, Florian
T3  - CHI EA '23
AB  - With technologies becoming increasingly intelligent, the interaction paradigm of Human-Computer Integration where computers and human form a partnership emerged. Most of these works considered computers as separate from users’ embodiment. However, in recent years, technologies are becoming increasingly closer and even interwoven with the human body. Our work asks whether computers can incorporate into one’s embodiment and form a partnership. We call this integrated embodiment. Such a paradigm might facilitate a more direct and intimate partnership between humans and computers. To exemplify the paradigm, we present AI-in-the-Shell, an exoskeleton-based system that enables users to experience having an AI residing in their body. The AI-powered system can make independent decisions and actuate the user’s body to better support their daily tasks and experiences, e.g., to enhance their game performance. We hope this work can extend the current understanding of Human-Computer Integration, and step towards a more complete understanding of integrated embodiment.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585867
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585867
KW  - augmented human
KW  - exoskeleton
KW  - human-computer integration
KW  - Integrated embodiment
ER  - 

TY  - CONF
TI  - AI Writing Assistants Influence Topic Choice in Self-Presentation
AU  - Poddar, Ritika
AU  - Sinha, Rashmi
AU  - Naaman, Mor
AU  - Jakesch, Maurice
T3  - CHI EA '23
AB  - AI language technologies increasingly assist and expand human communication. While AI-mediated communication reduces human effort, its societal consequences are poorly understood. In this study, we investigate whether using an AI writing assistant in personal self-presentation changes how people talk about themselves. In an online experiment, we asked participants (N=200) to introduce themselves to others. An AI language assistant supported their writing by suggesting sentence completions. The language model generating suggestions was fine-tuned to preferably suggest either interest, work, or hospitality topics. We evaluate how the topic preference of a language model affected users’ topic choice by analyzing the topics participants discussed in their self-presentations. Our results suggest that AI language technologies may change the topics their users talk about. We discuss the need for a careful debate and evaluation of the topic priors built into AI language technologies.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585893
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585893
KW  - Co-writing
KW  - GPT-3
KW  - risks of large language models
ER  - 

TY  - CONF
TI  - AI Education from the Educator’s Perspective: Best Practices for an Inclusive AI Curriculum for Middle School
AU  - Gibellini, Giorgia
AU  - Fabretti, Valeria
AU  - Schiavo, Gianluca
T3  - CHI EA '23
AB  - Artificial Intelligence (AI) and its applications have a strong impact on people’s lives worldwide. Therefore, an increasing number of professionals and academics are focusing on the development of AI education programs for K-12. Part of these programs is developed for formal educational settings, such as school classrooms, which are complex systems with several variables interwoven. The current study concentrates on the teachers’ perspective on the implementation of an AI education curriculum for middle schools located in disadvantaged areas of Europe. Given these premises, a particular focus is devoted to how AI education can foster inclusion and be more accessible. Feedback was gathered through 582 logbooks provided by educators, and an international focus group conducted at the end of the curriculum implementation. This information helped to understand educators’ points of view on the AI curriculum, investigating how these topics can stimulate reflections around inclusion and diversity.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585747
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585747
KW  - AI Education
KW  - Digital Competencies
KW  - Inclusive Education
ER  - 

TY  - CONF
TI  - Affective Typography: The Effect of AI-Driven Font Design on Empathetic Story Reading
AU  - Shen, Jocelyn J
AU  - Jin, Kathryn
AU  - Zhang, Ann
AU  - Breazeal, Cynthia
AU  - Park, Hae Won
T3  - CHI EA '23
AB  - When people listen to stories, the words are colored with emotions conveyed through prosodic features beyond the text alone. Visual font design provides an opportunity to enhance the empathic quality of a story compared to plain text. In this paper, we present the design, implementation, and evaluation of Affective Typography (AffType), an AI-driven system that extracts prosodic information and sentiment from speech and maps these properties to typographic styles.1 We conduct a crowdsourced study (N = 140) to assess how different font design elements impact readers’ empathy with personal stories. While our empathy survey results were not statistically significant, we found that participants had a preference for color to express emotion and saw an increase in average empathy for stories with color-based text alterations. In addition, we offer design insights as to what display features best convey emotional qualities of personal stories for future applications that use affective fonts to create more expressive digital text.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585625
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585625
KW  - emotional communication
KW  - empathy
KW  - speech representation
KW  - typography
KW  - voice input
ER  - 

TY  - CONF
TI  - Active Proxy Dashboard: Binding Physical Referents and Abstract Data Representations in Situated Visualization through Tangible Interaction
AU  - Satriadi, Kadek Ananta
AU  - Ens, Barrett
AU  - Goodwin, Sarah
AU  - Dwyer, Tim
T3  - CHI EA '23
AB  - Myriad systems have been proposed in recent years involving situated visualization with tangible scale models as proxies for physical referents. Most of these focus on static placements of scale models that mimic their real-world arrangement. While such static placement is useful to show the spatial context of referents, it does not take full advantage of the potential interaction affordances of the proxies. Our approach, Active Proxy, binds the data representation and referent through physical manipulations of scale models. We introduce a conceptual design space defining four quadrants as combinations of two dimensions: spatial to abstract representation; and passive to active proxy. Our focus is the novel quadrant defined by active proxies and abstract representations. Designing active proxy techniques is non-trivial as users are accustomed to common interaction modalities. This paper presents an initial exploration toward a better understanding of the active proxy concept, and designs of active proxy systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585797
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585797
KW  - active proxy
KW  - data exploration
KW  - proxsituated visualization
KW  - situated visualization
KW  - tangible interaction
ER  - 

TY  - CONF
TI  - Accuracy of AI-generated Captions With Collaborative Manual Corrections in Real-Time
AU  - Kuhn, Korbinian
AU  - Kersken, Verena
AU  - Zimmermann, Gottfried
T3  - CHI EA '23
AB  - Automatic Speech Recognition (ASR) is a cost-efficient and scalable tool to automate real-time captioning. Even though its overall quality has improved rapidly, generated transcripts can be inaccurate. While manual correction helps to increase transcription accuracy, this causes new real-time challenges, especially for live-streaming. Crowd-sourcing can make the high workload more manageable by distributing the work across multiple individuals. In this paper, we developed a prototype that enables humans to collaboratively correct AI-generated captions in real-time. We conducted an experiment with 40 participants to measure the accuracy of the created and manually corrected captions. The results show that manual corrections improved the overall text accuracy according to multiple metrics as well as overall qualitative analysis.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585724
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585724
KW  - automatic speech recognition
KW  - captioning
KW  - crowd-sourcing
KW  - real-time
KW  - subtitles
ER  - 

TY  - CONF
TI  - AEDLE: Designing Drama Therapy Interface for Improving Pragmatic Language Skills of Children with Autism Spectrum Disorder Using AR
AU  - Park, Jungin
AU  - Bae, Gahyeon
AU  - Park, Jueon
AU  - Park, Seo Kyoung
AU  - Kim, Yeon Soo
AU  - Lee, Sangsu
T3  - CHI EA '23
AB  - This research proposes AEDLE, a new interface combining AR with drama therapy — an approved method of improving pragmatic language skills — to offer effective, universal, and accessible language therapy for children with Autism Spectrum Disorder (ASD). People with ASD commonly have a disability in pragmatic language and experience difficulty speaking. However, although therapy in childhood is necessary to prevent long-term social isolation due to such constraints, the limited number of therapists forbids doing so. Technology-based therapy can be a solution, but studies on utilizing digital therapy to improve pragmatic language are still insufficient. We conducted a preliminary user study with an ASD child and a therapist to investigate how the child with ASD reacts to drama therapy using AEDLE. We observed that our ASD child actively participated in AEDLE-mediated drama therapy, used our insights to recommend design suggestions for AR-based drama therapy, and explored various ways to utilize AEDLE.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585809
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585809
KW  - Augmented Reality
KW  - Autism Spectrum Disorder
KW  - Drama Therapy Tool
KW  - Pragmatic Language
ER  - 

TY  - CONF
TI  - ACTIVE4: A Conceptual Framework for Gathering Empathetic Insights toward Office Workers’ Vitality Ecosystem Design
AU  - Yu, Xiang
AU  - Li, Jie
AU  - Vos, Steven
AU  - Brombacher, Aarnout
T3  - CHI EA '23
AB  - Sedentary behavior (SB) is prevalent in workplaces, putting office workers at an increased risk of severe health problems. To help designers and researchers gain a better understanding of office workers’ contextual concerns for physical inactivity (reducing SB and enhancing physical activity (PA)), we have proposed a conceptual framework ACTIVE4. This framework advises designers and researchers to consider four key factors that influence office workers’ physical inactivity: active mind, active behavior, active support, and active environment. We conducted three workshops (N=28 design students) to evaluate the framework. The participants found ACTIVE4 helpful in guiding them towards a more systematic understanding of the environmental influences and office workers’ personal needs for reducing physical inactivity. In future work, we will optimize the ACTIVE4 framework’s learning curve as suggested by participants and conduct an expert study to further discuss design opportunities and requirements for the ACTIVE4-related vitality toolkit.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585844
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585844
KW  - behavior change
KW  - conceptual framework
KW  - design guideline
KW  - hybrid workshops
KW  - sedentary behavior
ER  - 

TY  - CONF
TI  - Accomplishing More With Less: The Practice of Cybersecure Health Technology Design Among Danish Startups
AU  - Li, Ziru
AU  - Vu, Simon Nam Thanh
AU  - Dragoni, Nicola
AU  - Doherty, Kevin
T3  - CHI EA '23
AB  - While innovative health technologies have the capacity to better lives, their success hinges, increasingly, on their cybersecurity. Recent years have seen growing awareness of cybersecurity as not only technical but cultural in nature. And yet, how health technologies are developed is also changing — innovation today often led by startups, about whose cybersecurity efforts we know less, and whom might be most at risk. Striving to address this essential gap in knowledge, we present findings from a mixed-methods, design-led study of nine Danish health technology startups and six cybersecurity experts’ experiences. Through analysis of interviews and workshops, we contribute insight into startups’ perceptions of cybersecurity as essential yet often elusive, one amongst many priorities, and often a self-taught discipline. Drawing on this knowledge, we describe the co-design of a self-assessment platform to support increased awareness and preparedness among health technology startups, concluding with implications for future cybersecurity initiatives.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585597
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585597
KW  - Cybersecurity
KW  - design
KW  - development
KW  - enterprise software
KW  - health technology
KW  - Human-Computer Interaction (HCI)
KW  - startups
ER  - 

TY  - CONF
TI  - Accessibility Evaluation of IoT Android Mobile Companion Apps
AU  - Tazi, Faiza
AU  - Saka, Suleiman
AU  - Opp, Griffin
AU  - Neupane, Shradha
AU  - Das, Sanchari
AU  - De Carli, Lorenzo
AU  - Ray, Indrakshi
T3  - CHI EA '23
AB  - Internet of Things (IoT) devices use mobile companion apps to configure, update, and proxy communications between devices, cloud endpoints, and users. However, to the best of our knowledge, their accessibility characteristics have received little study. Thus, we report the analysis results of 248 IoT companion apps. Our approach involves manual analysis based on the Accessibility Insights tool and reports on: the presence of contextual information (descriptions of controls, images, and text input), size of touch elements, and color contrast. Our primary findings are: (i) most apps have reasonable accessibility posture, but there exists a long tail of apps with significant problems, (ii) only two apps do not present any accessibility errors, and (iii) nearly 87% of apps in the corpus exhibit errors involving a lack of names and descriptions of elements and/or images. We further provide actionable recommendations to enhance the accessibility posture of the IoT android apps.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585652
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585652
KW  - Accessibility Evaluation.
KW  - Internet of Things
KW  - IoT Devices
KW  - Mobile Apps
ER  - 

TY  - CONF
TI  - Above-Screen Fingertip Tracking with a Phone in Virtual Reality
AU  - Matulic, Fabrice
AU  - Kashima, Taiga
AU  - Beker, Deniz
AU  - Suzuo, Daichi
AU  - Fujiwara, Hiroshi
AU  - Vogel, Daniel
T3  - CHI EA '23
AB  - Using a phone as a VR controller is challenging because users cannot see their fingers when aiming for targets on the touchscreen. We propose using two mirrors mounted above the screen that reflect the front camera and a purpose-built deep neural network to robustly infer the 3D position of fingertips manipulating the phone. Network training is self-supervised after only a few initial labelled images and does not require any external sensor. We present a few example scenarios showing potential applications that use our phone-based fingertip tracker for precise touch input and above-screen interaction.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585728
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585728
KW  - hand pose estimation
KW  - virtual reality
ER  - 

TY  - CONF
TI  - A Wearable Haptic Interface for Assisting Blind and Visually Impaired Students in Learning Algebraic Equations
AU  - Kim, Sunhee
AU  - Cherian, Josh
AU  - Ray, Samantha
AU  - Lacy, Amanda
AU  - Taele, Paul
AU  - Koh, Jung In
AU  - Hammond, Tracy
T3  - CHI EA '23
AB  - BVI (blind and visually impaired) persons do not have the same degree of access to concepts and procedures in learning algebraic equations as sighted persons. As tactile resources are uncommon, most rely on auditory-based methods that place heavy stress on working memory. We propose a novel approach that leverages haptic technology to communicate mathematical symbols via vibrotactile patterns; this design addresses open challenges found in existing resources for BVI people and explores the potential utility of this medium for all users. We conducted three separate studies to evaluate the feasibility of our gloves that included BVI participants. The outcomes of our studies yielded insightful design discussions, including a blind participant who found the device immediately intuitive and exciting in potential.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585815
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585815
KW  - haptic feedback
KW  - haptic glove
KW  - math notation
KW  - tactile feedback
KW  - visually impaired
KW  - wearables
ER  - 

TY  - CONF
TI  - Accessible Text Tools: Where They Are Needed & What They Should Look Like
AU  - Heuer, Hendrik
AU  - Glassman, Elena Leah
T3  - CHI EA '23
AB  - Many people have problems with reading, which limits their ability to participate in society. This paper explores tools that make text more accessible. For this, we interviewed experts who proposed scenarios and tools. Frequently mentioned scenarios are public administration, the medical domain, and everyday life. The accessible text tools proposed by experts support readers by improving how text is compressed, expanded, reviewed, and experienced. We provide the Accessible Text Framework to help researchers understand how the different software tools can be combined and discuss how individual tools can be implemented.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585749
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585749
KW  - Accessibility
KW  - Easy Language
KW  - Non-Native Readers
KW  - People With Intellectual Disabilities
KW  - Plain Language
KW  - Text Summarization
ER  - 

TY  - CONF
TI  - A User Interface for Sense-making of the Reasoning Process while Interacting with Robots
AU  - Wang, Chao
AU  - Deigmoeller, Joerg
AU  - An, Pengcheng
AU  - Eggert, Julian
T3  - CHI EA '23
AB  - This paper describes an interface that enables experts to communicate with a virtual robot in a simulated environment via natural language, and to visualize the robot’s knowledge representation for them for inspection and correction. The interface visually links the robot’s internal reasoning processes and knowledge with the simulated instances in the form of a 3D isometric visualization as well as the robot’s first-person view. After 3 weeks of using the system by the roboticists in their daily development, some feedback was collected that provided insights for designing such systems in the future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585886
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585886
KW  - data visualization
KW  - explainable AI
KW  - graph representation
KW  - human-robot interaction
ER  - 

TY  - CONF
TI  - “A Switch Went off in my Whole Body”: Lived Experiences of Fatigue and Post-Exertional Malaise in Long Covid
AU  - Sas, Corina
AU  - Lotankar, Yojana
AU  - Adam, Rosalind
AU  - Bradbury, Katherine J
AU  - Cooper, Jonathan
AU  - Hill, Derek L
AU  - Martinez, Veronica
AU  - Powell, Daniel
T3  - CHI EA '23
AB  - The growing HCI agenda on health has focused on different chronic conditions but less so on Long Covid, despite its severe impact on the quality of life. We report findings from 2 workshops with 13 people living with Long Covid, indicating the challenges of making sense of their physical, cognitive, and emotional symptoms, and of monitoring the triggers of post-exertional malaise. While most participants engage in pacing activities for the self-management of fatigue, only a few are aware of the importance of planning all their daily activities and routines in order to avoid post-exertional malaise. We conclude with design implications to support lightweight tracking and sensemaking of fatigue symptoms, novel data analytics for monitoring the triggers of post-exertional malaise and the worsening of symptoms, and support for self-management in order to prevent post-exertional malaise.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585846
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585846
KW  - Body awareness
KW  - Cognitive Exertion
KW  - Fatigue
KW  - Lived experiences
KW  - Long Covid
KW  - Overstimulation
KW  - PEM
KW  - Post-Covid Syndrome
KW  - Post-exertional malaise
KW  - Stress
KW  - Triggers
ER  - 

TY  - CONF
TI  - A Sensory Autoethnography of Energy Practices in the Home: An Exploration of Combining Smart Meter Data with Situated accounts of What Energy is For
AU  - De Koning, Piet
AU  - Kuijer, Lenneke
AU  - Frens, Joep
T3  - CHI EA '23
AB  - Energy providers and government institutions encourage residents to adopt (retrofit) smart solutions. This creates a form of smart-paternalism that shifts agency over everyday decisions from residents to algorithms, deciding what is good for them based on averages. The aim of this paper is to formulate design guidelines for future research that takes inclusion of marginalized groups as a starting point for a just energy transition. Based on the observation that quantitative energy data misses important information to understand what energy is used for, while ethnographic approaches tend to brush over relevant technological details, we performed a sensory auto-ethnography that links sensorial and situated accounts of what energy is (not) for to smart meter data. We use the findings to argue for enabling residents’ situated understanding of how their everyday practices relate to their actual consumption and formulate guidelines on what both residents and designers need to do so.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585710
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585710
KW  - Auto-ethnography
KW  - Discourse
KW  - Energy transition
KW  - Fieldwork
KW  - Situated
KW  - Smart Home
KW  - Social Practices
ER  - 

TY  - CONF
TI  - A Preliminary Study of World Customizability for Virtual Reality Co-Play
AU  - Lao, Cheryl
AU  - Zhang, Yanting
AU  - Vogel, Daniel
AU  - Kaplan, Craig S.
AU  - McGuire, Morgan
AU  - Zordan, Victor B.
T3  - CHI EA '23
AB  - Cooperative play, or “co-play”, is the act of playing with others in a co-located setting, including co-location of avatars in virtual reality (VR). Customizability is the degree to which play artifacts like props can be changed to suit different needs, a factor of co-play which is easier to support in VR than in the real world. We present the results of a preliminary user study that explores how different levels of customization affect creativity in a two-person VR co-play setting. Using the Creativity Support Index, system logs, and observations, we found that increasing customizability of props used to improvise a story trended toward higher levels of perceived creativity. Our work introduces a new topic of investigation for social VR together with a study methodology and initial results to motivate further investigation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585605
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585605
KW  - Co-Play
KW  - Social VR
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - A Study on User Perception and Experience Differences in Recommendation Results by Domain Expertise: The Case of Fashion Domains
AU  - Noh, Taehyung
AU  - Yeo, Haein
AU  - Kim, Myungjin
AU  - Han, Kyungsik
T3  - CHI EA '23
AB  - To improve user satisfaction to the recommender systems (RS), it is essential to identify how users would perceive the system and what recommendation results they would prefer. Domain experts also use RS that relate to their work and decision-making, but existing studies have primarily focused on user experience from the general public and somewhat neglected the degree of user perception, understanding, and preference to the RS according to domain knowledge and interest and recommendation algorithm types. In this paper, we present My Own Style (MOS), a dashboard tool designed to analyze a given input fashion image and recommend outfit based on three recommendation algorithms that have different degrees of similarity and diversity. Based on the results from a large-scale user study with 166 participants, our results showed that the participants who have high fashion knowledge and interest (i.e., domain experts) well understood the results of RS and preferred the recommendation algorithm that provides similar outfit, while those who have low fashion knowledge and interest did not well understand the recommendation results as much as the expert group and preferred the algorithm that suggests diverse outfit. Our work is meaningful in providing empirical evidence on how to develop, select, and utilize recommendation algorithms according to domain expertise.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585641
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585641
KW  - Domain knowledge
KW  - Fashion recommendation
KW  - User perception
ER  - 

TY  - CONF
TI  - A Patient Centred Approach to Rare Disease Technology
AU  - Nielsen, Emily Esther
AU  - Owen, Tom
AU  - Roach, Matthew
AU  - Dix, Alan
T3  - CHI EA '23
AB  - Rare disease patients face a long, arduous process to obtain a correct diagnosis. This often involves multiple misdiagnoses, leading to undue treatments and surgeries; patients are left feeling unheard by their healthcare providers and are even isolated from their peers who ‘just don’t understand’. Research to support clinicians in diagnosing rare disease patients has made great strides. However, little research aims to support the patients through this challenging time; and those that do, demonstrate minimal patient input in the design process. This is the first paper that uses methodologically robust patient driven design of pre-diagnostic technologies for rare disease patients. We conducted two workshops with rare disease patients to design a probe technology and subsequently evaluated the probe using a questionnaire. This revealed that rare disease patients predominantly wanted clinician communication aids (90.5%) and social support (61.9%) from technology, rather than the informational support that is typical with patient technology.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585826
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585826
KW  - co-design
KW  - participatory design
KW  - patient centred design
KW  - rare disease
ER  - 

TY  - CONF
TI  - A Low-Cost Grip Pen Sensing Tool to Detect Handwriting Disorders
AU  - Phelippeau, Ana
AU  - Poignon, Wim
AU  - Husson, Adrien
AU  - Duhart, Clément
AU  - Teyssier, Marc
AU  - Chevrier, Joel
T3  - CHI EA '23
AB  - Handwriting is a complex motor activity. Neurodevelopmental disorders, such as dysgraphia can lead to severe handwriting difficulties. These dysfunctions could be predicted by measuring the pen’s motion, the pressure of the tip and the grip force while handwriting. Various hardware platforms have been proposed to sense pen movement. However, the grip force sensing is more challenging and often requires high-end sensing devices. In this paper, we propose a low-cost pen grip sensing tool to detect pressures and positions of fingers on the pen. It consists of a flexible, mutual-capacitive sensor rolled around the pen and connected to an inexpensive microcontroller. We provide initial tests of our grip sensing tool on multiple single-touch conditions. The results show a homogeneity over the flexible sensor and a linearity of the response with several curvatures. Such novel device open new opportunities for neurodevelopemental disorders research and new possibilities for clinical purposes.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585599
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585599
KW  - Digital pen
KW  - Flexible printed circuit
KW  - Grip force
KW  - Handwriting disorders
KW  - Multi-point input
KW  - Sensitive matrix
ER  - 

TY  - CONF
TI  - A Parametric 3D Knitting Workflow for Punchcard Knitting Machines
AU  - Asor, Shahar
AU  - Sterman, Yoav
T3  - CHI EA '23
AB  - Punchcard knitting machines allow automatic needle selection based on a punched pattern. The machine reads the card and translates a punched hole to specific knitting actions. Punchcards are usually purchased ready to use or manually punched by the user. Current tools allow the digital fabrication of punchcards, however those tools focus on two-dimensional graphic patterns. This work introduces a parametric workflow for designing and fabricating custom-made punchcards that enable 3D knitting and shaping. We demonstrate our workflow using two case studies that implement short-row knitting to obtain 3D surfaces and non-rectangular shapes. In the first, we generate parametric spike 3D textures, and in the second, we demonstrate long curved shapes and 3D cones. A DXF file is saved and used for cutting the punchcard using a digital desktop cutting machine. Our workflow broadens the design opportunities when using punchcard-driven domestic knitting machines.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585721
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585721
KW  - Parametric Design
KW  - Partial knitting
KW  - Punchcards
KW  - Shaping
ER  - 

TY  - CONF
TI  - A Field Study on Pedestrians’ Thoughts toward a Car with Gazing Eyes
AU  - Gui, Xinyue
AU  - Toda, Koki
AU  - Seo, Stela Hanbyeol
AU  - Eckert, Felix Martin
AU  - Chang, Chia-Ming
AU  - Chen, Xiang 'Anthony
AU  - Igarashi, Takeo
T3  - CHI EA '23
AB  - It is promising to apply eye-gaze techniques in designing an external human-machine interface (eHMI) for a self-driving car. We can find several prior "eye" studies; however, due to the difficulty of running a study in a real environment, prior research was often evaluated in a controlled VR environment. It is unclear how physical eyes on the car affect pedestrians’ thoughts in the real-world outdoor environment. To answer the question, we built and mounted a set of physical eyes of suitable size for a real car, drove the car in a public open space, activated the physical eyes, and performed the eye-gaze interaction with pedestrians without providing them any prior explanation. We administered a questionnaire to collect pedestrians’ thoughts and conducted a thematic (inductive) analysis. By comparing our findings to the previous results through a literature review, we highlighted the significance of physical implementation of the "eye concept" for future research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585629
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585629
KW  - Physical anthropomorphic eHMI design
KW  - Uncontrolled field study
ER  - 

TY  - CONF
TI  - A Field Study of Developer Documentation Format
AU  - Nassif, Mathieu
AU  - Robillard, Martin P.
T3  - CHI EA '23
AB  - Documentation facilitates the transfer of knowledge among programmers and helps them become familiar with new technologies. However, the effectiveness with which a reader can find information in a document depends on its presentation format. In a prior publication, we presented Casdoc, a novel dynamic format for code examples. In this work, we synthesized five documentation presentation guidelines from prior research on programmer information needs and search behaviors. We then used Casdoc as an instrument to evaluate the impact of these guidelines in a field study with 326 students who used 126 documents over several months. Participants overwhelmingly chose to use Casdoc instead of a static baseline format. We observed that interactive documents can contain more information without distracting its readers. We also found some limitations that authors should consider when applying the guidelines, such as the large impact of small differences in visual cues to help readers navigate a document.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585767
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585767
KW  - code examples
KW  - documentation format
KW  - dynamic documentation
KW  - field study
KW  - softare documentation
ER  - 

TY  - CONF
TI  - A Database for Kitchen Objects: Investigating Danger Perception in the Context of Human-Robot Interaction
AU  - Leusmann, Jan
AU  - Oechsner, Carl
AU  - Prinz, Johanna
AU  - Welsch, Robin
AU  - Mayer, Sven
T3  - CHI EA '23
AB  - In the future, humans collaborating closely with cobots in everyday tasks will require handing each other objects. So far, researchers have optimized human-robot collaboration concerning measures such as trust, safety, and enjoyment. However, as the objects themselves influence these measures, we need to investigate how humans perceive the danger level of objects. Thus, we created a database of 153 kitchen objects and conducted an online survey (N=300) investigating their perceived danger level. We found that (1) humans perceive kitchen objects vastly differently, (2) the object-holder has a strong effect on the danger perception, and (3) prior user knowledge increases the perceived danger of robots handling those objects. This shows that future human-robot collaboration studies must investigate different objects for a holistic image. We contribute a wiki-like open-source database to allow others to study predefined danger scenarios and eventually build object-aware systems: https://hri-objects.leusmann.io/.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585884
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585884
KW  - bayesian mixed models
KW  - dataset
KW  - human-computer interaction
KW  - human-robot interaction
KW  - kitchen
KW  - robots
ER  - 

TY  - CONF
TI  - A Cross-Cultural Study of Relational Maintenance in Tech Caregiving
AU  - Sharifi, Hasti
AU  - Chattopadhyay, Debaleena
T3  - CHI EA '23
AB  - In day-to-day life, older adults prefer getting tech support from loved ones, rather than relying on instruction manuals or institutional support. But asking for help, frequently or repeatedly for similar issues, can strain relations between older adults and their helpers. This paper examines how relationships are maintained when younger helpers give and older adults get tech support—across three different cultures: North American, South Asian, and Middle Eastern. Our deductive application of the relational maintenance strategies framework to 40 in-depth, semi-structured, and cross-cultural interviews identify challenges in tech caregiving, like avoiding the topic or interaction, and mitigation efforts, like directly or indirectly assuring each other of their skills and abilities. We discuss how social interactions are managed around tech support, how individual constraints, like time, place, or abilities are respected, and how self-conscious emotions, like guilt, embarrassment, or empathy are handled.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585697
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585697
KW  - accessibility
KW  - older adults
KW  - relational maintenance
KW  - tech caregiving
KW  - tech support
ER  - 

TY  - CONF
TI  - A Collective Approach to Providing Digital Skills Training Among U.S. Public Housing Residents
AU  - Lee, Soyoung
AU  - Hui, Julie
AU  - Rowe, Zachary
AU  - Dillahunt, Tawanna R
T3  - CHI EA '23
AB  - Addressing the digital divide would support access to essential activities such as healthcare, employment, and education among under-resourced communities in the United States (U.S.). However, half of the adults in the U.S. lack confidence and preparedness to use digital tools for learning. We developed and piloted an intervention to train public housing residents as intermediaries to provide digital support to their community members to address this gap. Collaborating with community partners, we developed a cohort-based basic digital skills training program consisting of online courses and offline social learning support. We trained nine public housing residents and present best practices of collective training and the challenges the trainees faced. Preliminary results suggest an increase in trainees’ self-efficacy in basic digital skills. Our approach aims to increase digital literacy and minimize barriers to online learning among traditionally-excluded populations. Our work extends prior interventions that only provide device and Internet access.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585712
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585712
KW  - Community-based participatory research
KW  - Digital divide
KW  - Digital literacy
KW  - Online learning
KW  - Social learning
KW  - Social support
ER  - 

TY  - CONF
TI  - 3DMovieMap: an Interactive Route Viewer for Multi-Level Buildings
AU  - Kayukawa, Seita
AU  - Higuchi, Keita
AU  - Morishima, Shigeo
AU  - Sakurada, Ken
T3  - CHI EA '23
AB  - We present an interactive route viewer system, 3DMovieMap, which generates and shows navigation movies walking through multi-level buildings, such as a science museum, airport, and university building. Movie map systems can provide users with visual cues by synthesizing navigation movies based on their inputs of routes. However, existing systems are limited to flat areas such as city areas. We aim to extend Movie Map to generate navigation movies for multi-level buildings. The 3DMovieMap system generates a movie map from an equirectangular movie via a visual Simultaneous Localization and Mapping technology. Users select waypoints on the floor maps. 3DMovieMap calculates the shortest path that visits these points and generates a navigation movie along the route. We created four movie maps of buildings and asked two participants to use our system and provide feedback for further improvements. We will be releasing an open dataset of equirectangular movies captured in a science museum.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585885
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585885
KW  - equirectangular movie dataset
KW  - indoor environment
KW  - movie map
KW  - navigation
ER  - 

TY  - CONF
TI  - 4DCurve: A Shape-Changing Fabrication Method Based on Curved Paths with a 3D Printing Pen
AU  - Wang, Zhiqi
AU  - Cai, Linlin
AU  - Jiang, Xinbei
AU  - Li, Jiaji
AU  - Ji, Junzhe
AU  - Zhang, Ting
AU  - Tao, Ye
AU  - Wang, Guanyun
T3  - CHI EA '23
AB  - In recent years, 4D printing is of continuous interest and attention in the field of Human-Computer Interaction. However, the advanced settings and complex g-code controls are still raising barriers for newcomers. 3D printing pen, in contrast, provides maximum versatility and accessibility for novices and even children. In this paper, we propose 4DCurve as a low-cost and easy-accessible 4D printing method to create curves with 3D printing pens. Compared with the strictly flat and layer-by-layer printing strategy of machines, the manual use of 3D printing pens enables freely curved and non-planar printing paths for spatial creativity and constant combination with daily objects. In addition, a guidance system has been built up for proposing curve path guidance based on the users' deformation needs, we also demonstrate various application cases on explosive design space for fashion designers, craft enthusiasts and designers in the field of personal fabrication.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585831
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585831
KW  - 3D pen
KW  - 4D printing
KW  - personal fabrication
KW  - shape-changing interface
ER  - 

TY  - CONF
TI  - 3D Printing and Design in Isolation: A Case from a Simulated Lunar Mission
AU  - Stawski, Wiktor
AU  - Skorupska, Kinga H.
AU  - Kopec, Wieslaw
T3  - CHI EA '23
AB  - Despite the decades-long history of 3D printing, it is not used to its full potential. Yet 3D printing holds promise for isolated communities, aiming for self-sufficiency. In this experiential study conducted in an analog space habitat we evaluated challenges and opportunities of using 3D printing. Our study revealed barriers such as: 1) setting up and maintaining the 3D printing equipment while minding different kinds of pollution, that is air, temperature and sound, 2) design skill and familiarity with specialized software as well as materials and 3) the awareness of what can be achieved to meet community needs. We observed that in-community experience and know-how are reliable sources of 3D print ideas, that improve quality of life of community members if they are encouraged and supported by participatory design. Co-design of 3D prints in small, specialized communities is a promising area of study, that can bring new applications of 3D print technology.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585741
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585741
KW  - 3D print lab setup
KW  - 3D printing
KW  - analog astronauts
KW  - barriers to design
KW  - co-design
KW  - experiential study
KW  - isolated communities
KW  - participatory design
ER  - 

TY  - CONF
TI  - Making Smart Cities Explainable: What XAI Can Learn from the “Ghost Map”
AU  - Gupta, Shubhangi
AU  - Loukissas, Yanni Alexander
T3  - CHI EA '23
AB  - How can we visualize civic algorithms in ways that illuminate both their positive and negative spatial impacts? Civic algorithms guide everyday decisions that cumulatively create city life. Yet, their broader effects remain invisible to their creators and city inhabitants. Recent scholarship on “algorithmic harms” presents an urgent need to make smart cities explainable. We argue that existing Explainable AI (XAI) approaches are limited across four important dimensions: accessibility, cultural reflexivity, situatedness, and visibility into internal representations. Our research explores the potential of conventional maps in addressing these limits and providing what we call “grounded explanations”. As a salient example, we harness the historical case of the “Ghost Map”, designed by John Snow to visualize and resolve the 1854 London Cholera epidemic. We believe that such examples can help the XAI community learn from the cultural history of city representations, as they seek to establish public processes for explaining and evaluating “smart cities”.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585847
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585847
KW  - Algorithmic audits
KW  - Explainable AI
KW  - Maps
KW  - Smart city
KW  - Transparency
KW  - Visualization
ER  - 

TY  - CONF
TI  - Making Usability Test Data Actionable! A Quantitative Test-Driven Prototyping Approach
AU  - Kretzer, Felix
AU  - Maedche, Alexander
T3  - CHI EA '23
AB  - In recent years, the availability and use of prototyping and usability testing tools has increased massively in practice. In parallel, research introduced multiple novel approaches and tools to assist novice and expert designers in prototyping. However, existing research has not looked into how to assist designers in conducting usability tests and making the collected quantitative data directly available in prototyping tools. In this paper, we distill three design goals from literature and propose a novel quantitative test-driven prototyping approach. The approach in its current form consists of a process and two user interface artifacts supporting selected actions of our process. We conducted a formative study to gather feedback from potential users on our approach. We use the collected feedback to refine our approach, identify trade-offs, and propose future research directions. We contribute by providing a novel quantitative test-driving prototyping approach that tightly connects prototyping with asynchronous usability testing.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585659
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585659
KW  - Data-Driven
KW  - GUI
KW  - Prototyping
KW  - Usability Testing
ER  - 

TY  - CONF
TI  - Lullaland: A Multisensory Virtual Reality Experience to Reduce Stress
AU  - Liu, Bo
AU  - Wang, Wenyu
AU  - Zhang, Yuqing
AU  - Huang, Rui
AU  - Raiti, John
T3  - CHI EA '23
AB  - People with health anxiety often experience feelings of nervousness or panic while in high-stress environments. While various techniques such as aromatherapy, and therapeutic video games have been shown to be effective in reducing anxiety, few studies have explored the use of a combination of these techniques in a multisensory approach. In this paper, we propose "Lullaland", a therapeutic virtual reality game that incorporates a wireless diffuser to provide an immersive, multisensory experience designed to help reduce anxiety in medical waiting rooms.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585636
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585636
KW  - aromatherapy
KW  - HCI
KW  - virtual reality
KW  - wearable
ER  - 

TY  - CONF
TI  - Let warnings interrupt the interaction and explain: designing and evaluating phishing email warnings
AU  - Buono, Paolo
AU  - Desolda, Giuseppe
AU  - Greco, Francesco
AU  - Piccinno, Antonio
T3  - CHI EA '23
AB  - Phishing represents one of the most spread and effective cyber-attacks of our times. Warning messages are commonly employed in email clients to notify users about the possible danger and let them decide on their own. However, the high success rate of phishing attacks shows that the existing warnings are not yet adequate. This study contributes by proposing two novel warning dialogs for email clients that prevent users from immediately accessing the content of phishing emails. Specifically, the first one alerts the users against the potential scam, and the second one also reports explanations about the possible causes of the scam. A comparative between-subjects experiment with 300 participants has been performed. Results show that the proposed warnings better defend users from phishing emails than the warnings at the state-of-the-art. In addition, explanations resulted useful in preventing users from discarding genuine emails where warnings are displayed incorrectly due to misclassification of the email.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585802
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585802
KW  - Explanations
KW  - Phishing
KW  - Warnings
ER  - 

TY  - CONF
TI  - “Just Like Blooming Fireworks, And Match With Function Perfectly”: Explore and Evaluate User-Defined One-Handed Gestures of Smartwatch
AU  - Ye, Lyumanshan
AU  - Yue, Jiatong
AU  - Wei, Yiwen
AU  - Liang, Shuai
AU  - Chang, Danni
T3  - CHI EA '23
AB  - One-handed gesture interaction is a more convenient input interaction method on smartwatches for some special scenarios, e.g. wearing a smartwatch when running or biking. To explore user-friendly one-handed gestures, what users are thinking when using the gesture, and what characteristic would make the user feel this one-handed gesture is friendly, we developed a series of one-handed gestures for 6 basic functions of the smartwatch. The end-user elicitation method resulted in 12 new one-hand gestures. We compared these 12 user-defined one-handed gestures with the Apple Watch one-handed gestures. We developed a Wizard of Oz model and evaluated these gestures by using qualitative and quantitative approaches. The results show that we generated a set of one-handed gestures that are more friendly than the existing Apple Watch one-handed gestures. Also, during the evaluation process, we collected quantitative data and interesting user perspectives. We also gave some design recommendations for one-handed gestures.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585914
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585914
KW  - Gesture generation
KW  - One-handed gestures
KW  - User-defined gestures
ER  - 

TY  - CONF
TI  - Is “Categorical Imperative” Metaversal?: A Kantian Ethical Framework for Social Virtual Reality
AU  - Kucuk, Eyup Engin
AU  - Yildirim, Caglar
T3  - CHI EA '23
AB  - The increasing adoption of social virtual reality (VR) environments for socializing and collaborating with others has led to a growing concern about ethical issues in these immersive environments. Beyond the introduction of some practical guidelines, theoretical work on this topic has been scant. In this paper, we propose an ethical framework for social VR based on Kant’s Theory of Morality. In so doing, we argue that the Kantian concept of categorical imperative does apply to social VR, that the reality of VR is not different from the reality of real life, and that what is morally unacceptable in real life is and should be unacceptable in social VR. In our framework, we provide three principles that can aid users and developers of social VR environments in reasoning about ethical issues in social VR, while advocating for more theoretical approaches to addressing the issue of VR ethics in human-computer interaction circles.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585911
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585911
KW  - Kantian ethics
KW  - social VR
KW  - VR ethics
ER  - 

TY  - CONF
TI  - Investigation of a Pitch Function for Motion-Based VR Bicycle Simulators
AU  - Wang, Yu
AU  - Steinmetz, Martin
AU  - Dorfbauer, Sonja
AU  - Michahelles, Florian
AU  - Wintersberger, Philipp
T3  - CHI EA '23
AB  - Research on cycling safety and comfort is becoming increasingly relevant in the domain of human-computer interaction. Many studies presented so far have been conducted on static bicycle simulators, which suffer problems of immersion and simulator sickness. Since previous publications on simulator design have suggested a positive effect of simulator tilt (lateral motion), we investigated the potential of simulator pitch (longitudinal motion). N=31 participants completed a test track with multiple flat, up-, and downhill sections while being supported with different pitch modes and a baseline without any motion. Our results suggest only a small impact of simulator pitch on simulator sickness and perceived immersion. However, we found out that study participants adjusted their pedaling strength based on the inclination of the test track, which we attribute to the plausibility illusion in virtual reality. The experiment contributes to the design of virtual reality bicycle simulators at different degrees of fidelity.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585623
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585623
KW  - Cycling simulation
KW  - immersion
KW  - physical simulator
KW  - presence
KW  - simulator sickness
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Keep it simple? Evaluation of Transitions in Virtual Reality
AU  - Feld, Nico
AU  - Bimberg, Pauline
AU  - Weyers, Benjamin
AU  - Zielasko, Daniel
T3  - CHI EA '23
AB  - The impact of different transitions between two virtual reality (VR) environments is still an open research question, and related work often serves only an isolated view on different techniques, i.e., with low ecological validity. The purpose of this study was to start closing this gap and evaluate the impact of six transitions while the user is solving a task that keeps them engaged. Therefore, we first propose a suitable and reproducible task design. Then we evaluate the six transitions in a user study. The results show that in contrast to prior work, the users preferred a short and efficient transition against a transition that was designed to achieve higher interactivity and continuity but was perceived as more cumbersome to use.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585811
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585811
KW  - cross reality
KW  - task load
KW  - task performance
KW  - transitions
KW  - usability
KW  - virtual reality
ER  - 

TY  - CONF
TI  - It Takes a Village: A Case for Including Extended Family Members in the Joint Oversight of Family-based Privacy and Security for Mobile Smartphones
AU  - Akter, Mamtaj
AU  - Alghamdi, Leena
AU  - Kropczynski, Jess
AU  - Lipford, Heather Richter
AU  - Wisniewski, Pamela J.
T3  - CHI EA '23
AB  - We conducted a user study with 19 parent-teen dyads to understand the perceived benefits and drawbacks of using a mobile app that allows them to co-manage mobile privacy, safety, and security within their families. While the primary goal of the study was to understand the use case as it pertained to parents and teens, an emerging finding from our study was that participants found value in extending app use to other family members (siblings, cousins, and grandparents). Participants felt that it would help bring the necessary expertise into their immediate family network and help protect the older adults and children of the family from privacy and security risks. However, participants expressed that co-monitoring by extended family members might cause tensions in their families, creating interpersonal conflicts. To alleviate these concerns, participants suggested more control over the privacy features to facilitate sharing their installed apps with only trusted family members.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585904
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585904
KW  - Collaborative Approach
KW  - Community Oversight
KW  - Digital Privacy
KW  - Family Online Safety
KW  - Joint Oversight
KW  - Mobile Privacy
KW  - Security
ER  - 

TY  - CONF
TI  - Is cartoonized life-vlogging the key to increasing adoption of activity-oriented wearable camera systems?
AU  - Fernandes, Glenn
AU  - Zhu, Helen
AU  - Pedram, Mahdi
AU  - Schauer, Jacob
AU  - Shahi, Soroush
AU  - Romano, Christopher
AU  - Gergle, Darren
AU  - Alshurafa, Nabil
T3  - CHI EA '23
AB  - Health science researchers studying human behavior rely on wearable cameras to visually confirm behaviors in real-world settings. However, privacy concerns significantly impede their adoption. Lens orientation and activity-oriented cameras have potential in balancing the need to visually validate the wearers’ activities while reducing privacy concerns. To increase adoption and further alleviate privacy concerns while maintaining utility, generative stylizing approaches, like cartooning using generative adversarial networks (GANs), have recently shown promise. We investigate different cartoon-based obfuscation of activity-oriented footage through two studies. The first deploys crowdsourcing methods (n=60), while the second is experiential, where participants (n=49) don the device for an entire day and report concerns on their footage. Our findings support that cartoonization of activity-oriented data significantly reduces privacy concerns, particularly among bystanders in high privacy-concerning scenarios, while maintaining context verification (90% of participants). Through thematic analysis, we provide further insight for the community on best practices for cartoonization of activity-oriented videos.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585812
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585812
KW  - activity-oriented wearable cameras
KW  - generative adversarial networks
KW  - obfuscation techniques
KW  - privacy concerns
KW  - qualtrics survey
ER  - 

TY  - CONF
TI  - Investigating the Synonyms of Conversational Agents to Aid Cross-Disciplinary CA Research
AU  - Wang, Lu
AU  - Chen, Chaomei
AU  - Huh-Yoo, Jina
T3  - CHI EA '23
AB  - With the advent of artificial intelligence, the CHI community has regained a large interest in Conversational Agents (CAs). Designing CAs involves cross-disciplinary efforts, such as that of computer science (e.g., language models), psychology (e.g., cognition and emotions), linguistics (e.g., conversation design), or communication (e.g., trust, communication theory). However, CAs are named differently depending on the discipline and purpose (e.g., chatbot, embodied avatar, virtual butler). This divergence of vocabulary on CA brings challenges to researchers and designers in researching the full landscape of CA literature and sharing cross-disciplinary knowledge. We performed bibliometric and qualitative analyses to systematically assess divergent terms used for CA nomenclatures. We present 54 CA-terms and how these terms are used differently depending on the discipline and design characteristics (e.g., voice vs. non-verbal vs. text-based). Our work contributes to helping CA researchers effectively review the CA literature and build on each other’s work for novel cross-disciplinary CA research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585640
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585640
KW  - bibliometric analysis
KW  - chatbot
KW  - co-citation analysis
KW  - conversational agent
ER  - 

TY  - CONF
TI  - Investigating the Physiological and Psychological Effect of an Interactive Musical Interface for Stress and Anxiety Reduction
AU  - Lecamwasam, Kimaya
AU  - Gutierrez Arango, Samantha
AU  - Singh, Nikhil
AU  - Elhaouij, Neska
AU  - Addae, Max
AU  - Picard, Rosalind
T3  - CHI EA '23
AB  - Music is a powerful tool for managing negative affect, due to its portability, accessibility, and unique ability to impact mood. In an effort to explore uses of personalized music as an anxiety management intervention, we designed an interface featuring 14 novel musical fragments with adjusted tempo, instrumentation, and rhythm and allowed users to navigate freely. We conducted a pilot study to test the efficacy of this approach for reducing stress and anxiety. Through survey and biometric data, we found that our approach can effectively reduce stress when enabling participants to personalize their musical stimuli. This suggests significant value for conducting larger-scale studies, prompting us to present our findings to support future work toward building personalized musical interventions that alleviate symptoms of stress and anxiety.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585778
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585778
KW  - affective computing
KW  - anxiety
KW  - interface
KW  - mental health
KW  - music
KW  - physiology
KW  - stress
ER  - 

TY  - CONF
TI  - Investigating Semantically-enhanced Exploration of GAN Latent Space via a Digital Mood Board
AU  - Wan, Qian
AU  - Lu, Zhicong
T3  - CHI EA '23
AB  - During past decades, Artificial Intelligence (AI) has been consistently used in Creativity Support Tools (CSTs). Recently, with the development of generative AI models, particularly Generative Adversarial Nets (GAN) in Computer Vision, it became possible that AI directly generates visual ideas. However, there were rarely any work in creativity research that harnessed the design ideas generated by such models directly for design space exploration. To that end we designed a digital mood board as a technology probe to support semantically-enhanced exploration of the StyleGAN latent space. We compared the mood board with traditional gallery display. Preliminary results showed that such design offered a more enjoyable and explicit way of exploring AI generated visual ideas, but gallery display was found to be more straightforward and less demanding.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585740
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585740
KW  - creativity support
KW  - digital mood board
KW  - human-AI interaction
KW  - ideation
ER  - 

TY  - CONF
TI  - Investigating Perceived Message Credibility and Detection Accuracy of Fake and Real Information Across Information Types and Modalities.
AU  - Tseng, Yu-Chia
AU  - Yuan, Chien Wen (Tina)
T3  - CHI EA '23
AB  - (Mis-)information thrives on social media, so it has become increasingly important for users to tell real from misleading content because erroneously following misinformation can cause serious consequences. In this study, we investigated users’ subjective perceived information credibility and objective detection accuracy of fake and real information across three topics, each of which was delivered via two modalities. We conducted an online within-subject experiment (n = 293) with a three (information topics: health, science, and life) by two (modalities: text and image) by two (veracity: real and fake) design. Overall, our participants were better at identifying fake information from real information. Results also found that information types significantly mediated information modality and veracity. For real information, the text mode helped people perceive credibility in health, life, and science topics. However, for false information, the image mode helped raised the perceived credibility of life information than the text mode.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585719
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585719
KW  - detection accuracy
KW  - Information modality
KW  - information topics
KW  - information veracity
KW  - perceived message credibility
ER  - 

TY  - CONF
TI  - Interplay of Security, Privacy and Usability in Videoconferencing
AU  - Weinberger, Lydia
AU  - Eichenmüller, Christian
AU  - Benenson, Zinaida
T3  - CHI EA '23
AB  - In the period from August to October 2022, we conducted an online survey concerning users’ perception and use of videoconferencing systems. We collected and analyzed a total of 245 responses from German-speaking participants. Each participant reported general use and case-specific use scenarios. We present usage trends and perceptions with respect to security, privacy and usability of various unified communications and collaboration (UCC) applications. The most frequently used tools, such as Zoom and Microsoft Teams, were rated lower in terms of security and privacy, but their usability ratings were above average. Tools tend to be avoided because of a lack of usability rather than security and privacy concerns. Nevertheless, almost 12% (29/245) of all participants reported using applications which were subject to security and privacy issues and which study participants would therefore personally prefer to avoid.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585683
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585683
KW  - online meetings
KW  - privacy
KW  - security
KW  - UCC
KW  - unified communication
KW  - usability
KW  - videoconferencing
ER  - 

TY  - CONF
TI  - InterFlowCeption: Foundations for Technological Enhancement of Interoception to Foster Flow States during Mental Work: About the potential of technologically supported body awareness to promote flow experiences during mental work
AU  - Berger, Christoph
AU  - Knierim, Michael Thomas
AU  - Benke, Ivo
AU  - Bartholomeyczik, Karen
AU  - Weinhardt, Christof
T3  - CHI EA '23
AB  - Conducting mental work by interacting with digital technology increases productivity, but strains attentional capacities and mental well-being. In consequence, many mental workers try to cultivate their flow experience. However, this is complex and difficult to achieve. Nevertheless, current technological systems do not yet provide this support in mental work. As interoception, the individual bodily awareness is an underlying mechanism of numerous flow correlates, it might offer a new approach for flow-supporting systems in these scenarios. Results from a survey study with 176 digital workers show that adaptive regulation of interoceptive sensations correlates with higher levels of flow and engagement. Additionally, regular mindfulness practices improved workers' adaptive regulation of bodily signals. Based on these results and integrating the current literature, this work conceptualizes three future technological support systems, such as interoceptive biofeedback, and electrical or auditory stimulation to enhance interoceptive awareness and foster flow in mental work.CCS CONCEPTS • Human-centered computing • Human computer interaction (HCI) • Empirical studies in HCI
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585833
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585833
KW  - Body Awareness
KW  - Flow Experience
KW  - Interoception
KW  - Mental Work
KW  - Technological Support Systems
KW  - Work Engagement
ER  - 

TY  - CONF
TI  - Interpretable Time-Dependent Convolutional Emotion Recognition with Contextual Data Streams
AU  - Bethge, David
AU  - Patsch, Constantin
AU  - Hallgarten, Philipp
AU  - Kosch, Thomas
T3  - CHI EA '23
AB  - Emotion prediction is important when interacting with computers. However, emotions are complex, difficult to assess, understand, and hard to classify. Current emotion classification strategies skip why a specific emotion was predicted, complicating the user’s understanding of affective and empathic interface behaviors. Advances in deep learning showed that convolutional networks can learn powerful time-series patterns while showing classification decisions and feature importances. We present a novel convolution-based model that classifies emotions robustly. Our model not only offers high emotion-prediction performance but also enables transparency on the model decisions. Our solution thereby provides a time-aware feature interpretation of classification decisions using saliency maps. We evaluate the system on a contextual, real-world driving dataset involving twelve participants. Our model achieves a mean accuracy of in 5-class emotion classification on unknown roads and outperforms in-car facial expression recognition by . We conclude how emotion prediction can be improved by incorporating emotion sensing into interactive computing systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585672
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585672
KW  - Affective Computing
KW  - Emotion Classification
KW  - Explainable AI
KW  - Time-Series Classification
ER  - 

TY  - CONF
TI  - Interactive Visual Exploration of Knowledge Graphs with Embedding-based Guidance
AU  - Hsuan Yuan, Chao-Wen
AU  - Yu, Tzu-Wei
AU  - Pan, Jia-Yu
AU  - Lin, Wen-Chieh
T3  - CHI EA '23
AB  - Knowledge graphs have been commonly used to represent relationships between entities and utilized in the industry to enhance service qualities. As knowledge graphs integrate data from a variety of sources, they can also be useful references for human users. However, there is a lack of effective tools for data analysts to make the most of the rich information in knowledge graphs. Existing knowledge graph exploration systems are ineffective because they didn’t consider various users’ needs and the characteristics of knowledge graphs. Exploratory approaches specifically designed for uncovering and summarizing insights in knowledge graphs have not been well studied yet. In this paper, we propose KGScope that supports interactive visual explorations and provides embedding-based guidance to derive insights from knowledge graphs. We demonstrate KGScope with a usage scenario and assess its efficacy in supporting knowledge graph exploration with a user study. The results show that KGScope supports knowledge graph exploration effectively by providing useful information and aiding comprehensive exploration.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585596
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585596
KW  - Interactive visual exploration
KW  - Knowledge graph
KW  - Knowledge graph embedding
ER  - 

TY  - CONF
TI  - Interactive Handwriting Device for Enhancing Active Recollection of Character Forms by Voice Assistance for Chinese Character Learning
AU  - Otsu, Kouyou
AU  - Izumi, Tomoko
T3  - CHI EA '23
AB  - Learning the Chinese characters used in Japan and China is a relatively difficult task, and even native speakers often have difficulty recalling them. Despite the existence of numerous platforms for learning Chinese characters, there is still a lack of interactive resources that can help with retrieving information during composition and improving retention simultaneously. In this study, we propose an interactive handwriting-support device that provides verbal hints about Chinese characters’ compositions and how to write the character. The device has the shape of a pen and can audibly indicate to the user how to write a character while writing. From the experiment, it is found that retention tended to be highest when the character composition was guided only by a voice assistance, compared to when the correct character form was presented visually. This result suggests that presenting human-like cues through speech may promote active recollection activities compared to presenting visual information.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585814
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585814
KW  - Character amnesia
KW  - Chinese character
KW  - Interaction device
KW  - Language learning
ER  - 

TY  - CONF
TI  - Interactive Generation of Image Variations for Copy-Paste Data Augmentation
AU  - Higuchi, Keita
AU  - Mizuhashi, Taiyo
AU  - Matulic, Fabrice
AU  - Igarashi, Takeo
T3  - CHI EA '23
AB  - In machine learning, data augmentation is an important technique to artificially increase the amount of training data by generating variations, e.g., geometric and colour transformations. Simple data augmentation such as scaling and rotation is already provided by existing tools, but advanced data augmentation such as copy-paste image composition requires coding. Such composition operations are difficult to intuitively define in coding environments as typically there is no visual confirmation of generated images. Therefore, composition-based augmentations are not frequently used by developers. To address this issue, we propose a dedicated graphical tool. Contrary to image operations of standard graphics editors designed to produce a single image, our tool creates multiple image variations to be used as training data. The editor allows the user to visually and interactively set parameter ranges for transformations, and quickly review synthesized images based on the parameters. We report performance evaluations and user studies with machine learning experts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585856
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585856
KW  - data augmentations
KW  - interactive machine learning
KW  - visualization
ER  - 

TY  - CONF
TI  - Interacting with Masculinities: A Scoping Review
AU  - Seaborn, Katie
T3  - CHI EA '23
AB  - Gender is a hot topic in the field of human-computer interaction (HCI). Work has run the gamut, from assessing how we embed gender in our computational creations to correcting systemic sexism, online and off. While gender is often framed around women and femininities, we must recognize the genderful nature of humanity, acknowledge the evasiveness of men and masculinities, and avoid burdening women and genderful folk as the central actors and targets of change. Indeed, critical voices have called for a shift in focus to masculinities, not only in terms of privilege, power, and patriarchal harms, but also participation, plurality, and transformation. To this end, I present a 30-year history of masculinities in HCI work through a scoping review of 126 papers published to the ACM Human Factors in Computing Systems (CHI) conference proceedings. I offer a primer and agenda grounded in the CHI and extant literatures to direct future work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585770
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585770
KW  - CHI
KW  - gender
KW  - human-computer interaction
KW  - Masculinities
KW  - masculinity
KW  - scoping review
ER  - 

TY  - CONF
TI  - Interaction Region Characteristics for Midair Barehand Targeting on a Television
AU  - Henderson, Jay
AU  - Neshati, Ali
AU  - Mizobuchi, Sachi
AU  - Zhou, Wei
AU  - Vogel, Daniel
AU  - Lank, Edward
T3  - CHI EA '23
AB  - Recent computer vision advances can enable television control using midair barehand input, for which selecting targets using hand positions is a primary task. Yet, the size and position of a preferred 2D interaction region has not been specifically investigated for this setting. We report on a field study with people in front of their own television in their own home. Controlled variations of target position stimuli were presented while a camera records the natural hand position used by the participant in response. Based on hand and face landmarks, density plots define a preferred input region location and size using a human-scaled unit of face-widths. Distribution of hand positions relative to target stimuli reveals consistency and precision, suggesting an ability for users to map their input space to display space. We elicit an ideal input region from participants and provide a range of dimensions for designers implementing barehand input techniques.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585877
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585877
KW  - Barehand input
KW  - Smart TV
KW  - Targeting
ER  - 

TY  - CONF
TI  - Inclusive Social Virtual Environments: Exploring the Acceptability of Different Navigation and Awareness Techniques
AU  - Gonçalves, Inês
AU  - Rodrigues, André
AU  - Guerreiro, Tiago
AU  - Guerreiro, João
T3  - CHI EA '23
AB  - Social virtual environments are becoming more prevalent, replicating and sometimes replacing real-world interactions. Nowadays, such environments are not accessible and end up excluding blind people, due to their strong visual components. In this study, we designed and explored multiple navigation and feedback techniques assessing social acceptability, ease of use, and efficiency. We developed a virtual environment composed of six scenarios to analyze different navigation methods (Free Exploration, Teleport, Auto-Walk, and Co-Pilot) and awareness cues in group conversations (Audio Cues While In-Group Footsteps and In-Group Teleport), and conducted a user study with 8 blind and 8 sighted participants. Our results indicate that participants tend to privilege autonomy and room awareness over efficiency and navigation ease and disapprove of intrusive actions that may jeopardize privacy.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585700
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585700
KW  - Accessibility
KW  - Blind
KW  - Nonvisual Interaction.
KW  - Social Acceptability
KW  - Social Virtual Environments
ER  - 

TY  - CONF
TI  - Improving Multiparty Interactions with a Robot Using Large Language Models
AU  - Murali, Prasanth
AU  - Steenstra, Ian
AU  - Yun, Hye Sun
AU  - Shamekhi, Ameneh
AU  - Bickmore, Timothy
T3  - CHI EA '23
AB  - Speaker diarization is a key component of systems that support multiparty interactions of co-located users, such as meeting facilitation robots. The goal is to identify who spoke what, often to provide feedback, moderate participation, and personalize responses by the robot. Current systems use a combination of acoustic (e.g. pitch differences) and visual features (e.g. gaze) to perform diarization, but involve the use of additional sensors or require overhead signal processing efforts. Alternatively, automatic speech recognition (ASR) is a necessary step in the diarization pipeline, and utilizing the transcribed text to directly identify speaker labels in the conversation can eliminate such challenges. With that motivation, we leverage large language models (LLMs) to identify speaker labels from transcribed text and observe an exact match of 77% and a word level accuracy of 90%. We discuss our findings and the potential use of LLMs as a diarization tool for future systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585602
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585602
KW  - ChatGPT
KW  - Diarization
KW  - Large Language Models (LLMs)
KW  - Meeting Facilitation
KW  - Social Robots
ER  - 

TY  - CONF
TI  - Improving Learning-based Camera Pose Estimation for Image-based Augmented Reality Applications
AU  - Cai, Enyu
AU  - Rossi, Ryan
AU  - Xiao, Chang
T3  - CHI EA '23
AB  - Camera tracking is essential for many augmented reality (AR) applications, such as rendering virtual content on top of a display. While marker-based camera tracking methods can accurately estimate the camera pose, they require pre-placed markers and occupy valuable screen space, potentially impacting the user experience. In contrast, markerless camera tracking methods do not have these limitations but tend to be less stable. In this work, we propose an improved approach for camera tracking that utilizes salient visual features commonly found on websites. We develop robust algorithms for detecting these features and design efficient methods for estimating the camera pose from them. Our approach outperforms state-of-the-art methods in terms of robustness, as demonstrated by our experiments. This work paves the way for a wide range of important AR applications, such as online shopping and interactive AR games.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585756
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585756
KW  - Camera tracking
KW  - robustness
ER  - 

TY  - CONF
TI  - Industrial Metaverse: Supporting remote maintenance with avatars and digital twins in collaborative XR environments
AU  - Oppermann, Leif
AU  - Buchholz, Florian
AU  - Uzun, Yücel
T3  - CHI EA '23
AB  - We present a 5G mixed reality toolbox that supports hands-free remote assistance in industrial settings. It provides mixed reality and virtual reality views for on-site and office workers linked via a shared digital space. Working on actual machines in a real production line, our system uses the actual CAD-data of those machines to provide for a realistic prototyping-environment. We focus on data-scarcity with cloud-services to protect intellectual property, while embracing the possibilities offered by new technology, such as remote rendering over wireless networks. The presented prototype exhibits several key characteristics of an industrial metaverse application.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585835
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585835
KW  - 5G
KW  - Industry
KW  - Metaverse
KW  - Mixed Reality
KW  - Remote Maintenance
KW  - User
KW  - VR/AR
ER  - 

TY  - CONF
TI  - “In Your Face!”: Visualizing Fitness Tracker Data in Augmented Reality
AU  - Rigling, Sebastian
AU  - Yu, Xingyao
AU  - Sedlmair, Michael
T3  - CHI EA '23
AB  - The benefits of augmented reality (AR) have been demonstrated in both medicine and fitness, while its application in areas where these two fields overlap has been barely explored. We argue that AR opens up new opportunities to interact with, understand and share personal health data. To this end, we developed an app prototype that uses a Snapchat-like face filter to visualize personal health data from a fitness tracker in AR. We tested this prototype in two pilot studies and found that AR does have potential in this type of application. We suggest that AR cannot replace the current interfaces of smartwatches and mobile apps, but it can pick up where current technology falls short in creating intrinsic motivation and personal health awareness. We also provide ideas for future work in this direction.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585912
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585912
KW  - augmented reality
KW  - fitness tracker
KW  - health
KW  - visualization
ER  - 

TY  - CONF
TI  - Improving Environmental Knowledge with a Serious Game: An experimental study
AU  - Bauer, Mathias
AU  - Weiß, Malte
T3  - CHI EA '23
AB  - Climate change mitigation is the century’s obligation to humanity. People all throughout the world have too little knowledge and comprehension of the planet’s ecosystem. Increasing people’s awareness and knowledge about the environment might help reduce environmental-hostile behavior. We propose a serious game that helps players to learn more about the environment in a fun and engaging manner. The game’s effectiveness in teaching players about the environment is evaluated, and its role as a mediation tool is estimated by measuring environmental knowledge and consciousness using literature-based questionnaires before and after the game is played. Our results show significant differences in participants’ environmental knowledge. Differences in environmental consciousness are not significant. Strengths and weaknesses of the developed serious game based on user feedback are identified to improve future iterations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585789
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585789
KW  - environmental knowledge
KW  - pre- and post-test
KW  - serious games
ER  - 

TY  - CONF
TI  - Improved Image Caption Rating – Datasets, Game, and Model
AU  - Scott, Andrew Taylor
AU  - Narins, Lothar D
AU  - Kulkarni, Anagha
AU  - Castanon, Mar
AU  - Kao, Benjamin
AU  - Ihorn, Shasta
AU  - Siu, Yue-Ting
AU  - Yoon, Ilmi
T3  - CHI EA '23
AB  - How well a caption fits an image can be difficult to assess due to the subjective nature of caption quality. What is a good caption? We investigate this problem by focusing on image-caption ratings and by generating high quality datasets from human feedback with gamification. We validate the datasets by showing a higher level of inter-rater agreement, and by using them to train custom machine learning models to predict new ratings. Our approach outperforms previous metrics – the resulting datasets are more easily learned and are of higher quality than other currently available datasets for image-caption rating.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585632
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585632
KW  - human-in-the-loop
KW  - image captioning
KW  - multimodal learning
KW  - visually-impaired
ER  - 

TY  - CONF
TI  - Impact of User Mobility on Attentional Tunneling in Handheld AR
AU  - Parmar, Mehul
AU  - Silpasuwanchai, Chaklam
T3  - CHI EA '23
AB  - Attentional tunneling in augmented reality (AR) refers to a phenomenon where users pay disproportionately high attention to virtual content while ignoring events in the real world. Although many handheld AR applications are deployed in public places where users are expected to be attentive to their surroundings while walking freely, the effect of user mobility on attentional tunneling is not yet ascertained. To investigate the effects of user mobility, we designed a 2x3 study comparing two postures (stationary and walking) with three AR tasks (a non-cognitive baseline task, a working memory task, and a perceptual monitoring task). The results suggest that walking significantly magnifies the tunneling effect, provided the user is engaged with a task that is associated with the virtual content being viewed. We demonstrate the significance of considering user mobility when evaluating AR application usage and provide guidelines for designers to evaluate the application in such scenarios.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585692
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585692
KW  - Attentional Tunneling
KW  - Augmented Reality
KW  - Mobile Devices
KW  - Walking
ER  - 

TY  - CONF
TI  - Immersive Reading: Comparison of Performance and User Experience for Reading Long Texts in Virtual Reality
AU  - Gabel, Jenny
AU  - Ludwig, Melanie
AU  - Steinicke, Frank
T3  - CHI EA '23
AB  - Specific use cases in virtual reality (VR) require users to read long texts on their headsets. We use VR to support researchers in the humanities, which includes the display of long text descriptions in VR. However, research on suitable user interface (UI) patterns for displaying and interacting with long texts in VR is scarce. To address this gap, we designed four text panel variants and conducted a within-participants study (N=24) to evaluate user experience (UX) and reading performance. Our findings suggest that there are no significant differences between conditions regarding reading performance. Yet, there are significant effects of conditions on some aspects of UX. Our work offers initial insights and future directions for research on the design of suitable UI patterns and the UX for reading long texts in VR.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585895
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585895
KW  - interface design patterns
KW  - reading
KW  - user-centred design
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Ignoring As a Moderation Strategy for Volunteer Moderators on Twitch
AU  - Li, Na
AU  - Cai, Jie
AU  - Wohn, Donghee Yvette
T3  - CHI EA '23
AB  - Content moderation is a crucial aspect of online platforms, and it requires human moderators (mods) to repeatedly review and remove harmful content. However, this moderation process can lead to cognitive overload and emotional labor for the mods. As new platforms and designs emerge, such as live streaming space, new challenges arise due to the real-time nature of the interactions. In this study, we examined the use of ignoring as a moderation strategy by interviewing 19 Twitch mods. Our findings indicated that ignoring involves complex cognitive processes and significant invisible labor in the decision-making process. Additionally, we found that ignoring is an essential component of real-time moderation. These preliminary findings suggest that ignoring has the potential to be a valuable moderation strategy in future interactive systems, which highlights the need to design better support for ignoring in interactive live-streaming systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585704
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585704
KW  - cognitive load
KW  - content moderation
KW  - context moderation
KW  - ignoring
KW  - live streaming
KW  - moderation strategy
KW  - real-time moderation
KW  - volunteer moderator
ER  - 

TY  - CONF
TI  - I (Don’t) Know What You Did Last Summer: A Framework for Ubiquitous Research Preservation
AU  - Elagroudy, Passant
AU  - Knierim, Pascal
AU  - Schmidt, Albrecht
AU  - Woźniak, Pawe\l W.
AU  - Feger, Sebastian S.
T3  - CHI EA '23
AB  - Research preservation is a pillar for knowledge transfer, science reproducibility and saving time by reusing existing resources. However, human compliance with efficient capturing strategies is a key barrier to creating complete scientific repositories. To circumvent this issue, we introduce the term: Ubiquitous Research Preservation (URP), describing automated knowledge capturing and retrieval in computational science. We also propose a framework composed of three models for designing URP systems (URPS) to 1) understand users’ interaction and data governance, 2) propose technical pipelines for data management, and 3) understand users’ sharing practices. Our work is a theoretical reflection on our past experiences in designing URPS. We plan future evaluation by using the framework to analyze existing URPS. We expect a positive impact from using URPS on researchers’ sense-making and ability to share findings and resources. Our framework is a checklist for design decisions needed to build successful URPS.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585754
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585754
KW  - Computational Science
KW  - Reproducibility
KW  - Sensemaking
KW  - Training
KW  - Ubiquitous Research Preservation
ER  - 

TY  - CONF
TI  - “I'm” Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets
AU  - Seaborn, Katie
AU  - Kim, Yeongdae
T3  - CHI EA '23
AB  - As virtual assistants continue to be taken up globally, there is an ever-greater need for these speech-based systems to communicate naturally in a variety of languages. Crowdsourcing initiatives have focused on multilingual translation of big, open data sets for use in natural language processing (NLP). Yet, language translation is often not one-to-one, and biases can trickle in. In this late-breaking work, we focus on the case of pronouns translated between English and Japanese in the crowdsourced Tatoeba database. We found that masculine pronoun biases were present overall, even though plurality in language was accounted for in other ways. Importantly, we detected biases in the translation process that reflect nuanced reactions to the presence of feminine, neutral, and/or non-binary pronouns. We raise the issue of translation bias for pronouns and offer a practical solution to embed plurality in NLP data sets.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585667
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585667
KW  - Data sets
KW  - Feminist HCI
KW  - Gender bias
KW  - Natural language processing
KW  - Translation
ER  - 

TY  - CONF
TI  - "I Want To Be Able To Change The Speed And Size Of The Avatar": Assessing User Requirements For Animated Sign Language Translation Interfaces
AU  - Nolte, Amelie
AU  - Gleißl, Barbara
AU  - Heckmann, Jule
AU  - Wallach, Dieter
AU  - Jochems, Nicole
T3  - CHI EA '23
AB  - Despite research having shown that signing users vary in their preferences and needs of distinct sign language (SL) parameters, current research on SL avatars lacks consideration of the UI context’s options for individualization or configuration of such parameters. Our paper addresses this gap as it presents our ability-oriented online survey, in which we asked native signers about parameters they would like to configure, as well content types that should be offered for translation within travel contexts. Our results indicate that parameters with a direct influence on the understandability of the avatar are most important for individual adjustments and situations with high time-pressure are valued highly for translation within travelling contexts. Also, our study design revealed that assessing the language background of participants in the form of an example-based self-assessment can help achieve more sensitive results, emphasizing the need for adequate research approaches.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585675
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585675
KW  - Deaf and Hard of Hearing user studies
KW  - requirements analysis
KW  - sign language avatar design
ER  - 

TY  - CONF
TI  - I Know Your Feelings Before You Do: Predicting Future Affective Reactions in Human-Computer Dialogue
AU  - Li, Yuanchao
AU  - Inoue, Koji
AU  - Tian, Leimin
AU  - Fu, Changzeng
AU  - Ishi, Carlos Toshinori
AU  - Ishiguro, Hiroshi
AU  - Kawahara, Tatsuya
AU  - Lai, Catherine
T3  - CHI EA '23
AB  - Current Spoken Dialogue Systems (SDSs) often serve as passive listeners that respond only after receiving user speech. To achieve human-like dialogue, we propose a novel future prediction architecture that allows an SDS to anticipate future affective reactions based on its current behaviors before the user speaks. In this work, we investigate two scenarios: speech and laughter. In speech, we propose to predict the user’s future emotion based on its temporal relationship with the system’s current emotion and its causal relationship with the system’s current Dialogue Act (DA). In laughter, we propose to predict the occurrence and type of the user’s laughter using the system’s laughter behaviors in the current turn. Preliminary analysis of human-robot dialogue demonstrated synchronicity in the emotions and laughter displayed by the human and robot, as well as DA-emotion causality in their dialogue. This verifies that our architecture can contribute to the development of an anticipatory SDS.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585869
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585869
KW  - dialogue act
KW  - emotion
KW  - interaction
KW  - laughter
KW  - spoken dialogue system
ER  - 

TY  - CONF
TI  - “I Could Wear It All of the Time, Just Like My Wedding Ring:” Insights into Older People’s Perceptions of Smart Rings
AU  - Bilius, Laura-Bianca
AU  - Vatavu, Radu-Daniel
T3  - CHI EA '23
AB  - We present findings from an examination of older adults’ perceptions of and preferences for smart rings, a unique class of interactive wearables gaining traction in the consumer market. To this end, we conducted semi-structured interviews with nine older adults, aged between 61 and 69 years old, to understand their perceptions regarding several smart ring models representative of rings, ring-like, and ring-ready finger-augmentation devices. We also elicited our participants’ preferences for using smart rings in their everyday life, such as for controlling various home appliances and electronic devices. Our results show an overall positive experience and openness toward adopting smart rings, which were perceived useful to assist with various activities. Based on our findings and following the aging research agenda in HCI, we propose future work opportunities for designing smart ring technology tailored to the needs and preferences of older adults.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585771
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585771
KW  - interviews
KW  - older adults
KW  - Smart rings
KW  - study
KW  - user experience
ER  - 

TY  - CONF
TI  - HybridMingler: Towards Mixed-Reality Support for Mingling at Hybrid Conferences
AU  - Le, Khanh-Duy
AU  - Ly, Duy-Nam
AU  - Nguyen, Hoang-Long
AU  - Le, Quang-Tri
AU  - Fjeld, Morten
AU  - Tran, Minh-Triet
T3  - CHI EA '23
AB  - Mingling, the activity of ad-hoc, private, opportunistic conversations ahead of, during, or after breaks, is an important socializing activity for attendees at scheduled events, such as in-person conferences. The Covid-19 pandemic had a dramatic impact on the way conferences are organized, so that most of them now take place in a hybrid mode where people can either attend on-site or remotely. While on-site attendees can resume in-person mingling, hybrid modes make it challenging for remote attendees to mingle with on-site peers. In addressing this problem, we propose a collaborative mixed-reality (MR) concept, including a prototype, called HybridMingler. This is a distributed MR system supporting ambient awareness and allowing both on-site and remote conference attendees to virtually mingle. HybridMingler aims to provide both on-site and remote attendees with a spatial sense of co-location in the very same venue location, thus ultimately improving perceived presence.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585806
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585806
KW  - AR
KW  - distributed systems
KW  - hybrid conferences
KW  - mingling
KW  - mobile devices
KW  - MR
KW  - VR
ER  - 

TY  - CONF
TI  - How Pairing by Code Similarity Influences Discussions in Peer Learning
AU  - Xu, Shiyu
AU  - Zhang, Ashley Ge
AU  - Oney, Steve
T3  - CHI EA '23
AB  - Peer learning, as a form of collaborative learning, has been widely used in programming courses as a means of promoting active learning and enhancing students’ programming skills. However, it is challenging for instructors to group students effectively so that they can have fruitful conversations. We conducted a study with 15 students from an introductory programming course to investigate whether and how grouping students with similar or different solutions affects the discussions that take place within groups. The findings indicate that pairing students by the similarity of their code might influence students’ learning and coding skills. Specifically, students who were paired with people that had different solutions had, on average, more engaging conversations and were more likely to write more diverse solutions in the future. The results also highlight the need for tools to facilitate the pairing process in programming courses in order to optimize the learning outcomes for students.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585837
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585837
KW  - peer learning
KW  - programming education
ER  - 

TY  - CONF
TI  - How Pricing and Ratings Affect Perceived Value of Digital Detox Apps
AU  - Purohit, Aditya Kumar
AU  - Raggi, Martina
AU  - Holzer, Adrian
T3  - CHI EA '23
AB  - As the number of mobile apps has exploded over the last decade, different pricing models have emerged (e.g., free, paid, freemium). However, it is not clear how these models affect users’ perceptions of the value of apps that promote behavior change, such as digital detox apps, and what role social ratings play in this relationship. This paper investigates this issue using an experimental approach. The results of a controlled between-subjects experiment (N = 894) suggest that pricing models significantly influence the perceived value of digital detox apps. Digital detox apps using the paid model are perceived to be significantly less valuable than free and freemium apps. No significant difference has been found between free and freemium pricing models. Theoretical and practical implications are discussed.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585681
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585681
KW  - Apple App Store
KW  - Digital Detox Apps
KW  - Digital nudging
KW  - Free
KW  - Freemium
KW  - In-app purchase
KW  - iOS
KW  - Paid
KW  - Pricing
KW  - Ratings
ER  - 

TY  - CONF
TI  - How do employees imagine AI they want to work with: A drawing study
AU  - Straka, Samantha
AU  - Koch, Martin Jakobus
AU  - Carolus, Astrid
AU  - Latoschik, Marc Erich
AU  - Wienrich, Carolin
T3  - CHI EA '23
AB  - Perceptions about AI influence the attribution of characteristics and the interaction with AI. To find out how workers imagine an AI they would like to work with and what characteristics they attribute to it, we asked 174 working individuals to draw an AI they would like to work with, to report five adjectives they associate with their drawing and to evaluate the drawn and three other, typical AI representations (e.g. robot, smartphone) either presented as male or female. Participants mainly drew humanoid or robotic AIs. The adjectives that describe AI mainly referred to the inner characteristics, capabilities, shape, or relationship types. Regarding the evaluation, we identified four dimensions (warmth, competence, animacy, size) that can be reproduced for male and female AIs and different AI representations. This work addresses diverse conceptions of AI in the workplace and shows that human-centered AI development is necessary to address the huge design space.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585631
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585631
KW  - artificial intelligence
KW  - drawings
KW  - representation
KW  - user-centered
KW  - warmth and competence
ER  - 

TY  - CONF
TI  - How Can We Design for Gender-Neutrality in Games? – A Case Study With Children Using Gameplay Rehearsals
AU  - Moreira Pinto, Valéria
AU  - Seiça, Mariana
AU  - Roque, Licinio
T3  - CHI EA '23
AB  - Gender-oriented games have been prevalent in cultural media, perpetuating stereotypes that promote gender inequality. As an alternative, what insights could be gathered from a game designed for gender-neutrality? We present a case study of a gender-neutral game design within a STEAM diversity initiative to engage younger populations. A qualitative methodological approach was followed to analyze gameplay rehearsal observations and interviews, focusing on playful behavior, cooperative gameplay, social interactions, competence development, and gender-related aspects. Players engaged in mutual collaboration, encouraging and suggesting actions and strategies, while also adopting gender-specific differentiation language regarding their role play. From coded evidence, we propose three design insights that might influence the perception of gender-neutrality: (i) multiple activity modes that offer tasks diversity, (ii) a collaborative environment, featuring egalitarian roles and (iii) audiovisual representations adopting neutral gender patterns.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585637
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585637
KW  - child-computer interaction
KW  - cooperative gameplay
KW  - game design
KW  - Gender-neutrality
KW  - playful probing
ER  - 

TY  - CONF
TI  - “How Can I Help You?”: User Perceptions of Privacy in Retail Chat Agents
AU  - Dev, Jayati
AU  - Dev, Sruti
T3  - CHI EA '23
AB  - Chatbots that request user data are proliferating in the retail industry. There are studies showing that increase in perceived privacy risks can decrease their adoption rate. In this study, we interview eight participants about their reasons behind these perceived privacy risks so that developers can make retail chatbots more privacy-preserving and respectful of user choices. This short thematic analysis highlights some of the privacy concerns in such bots and some of the recommendations that will be helpful for future work to build on.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585796
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585796
KW  - chatbots
KW  - conversational privacy
KW  - privacy
KW  - trust
ER  - 

TY  - CONF
TI  - How can HCI support end-of-life care? Critical perspectives on sociotechnical imaginaries for palliative care
AU  - Ahmadpour, Naseem
AU  - Gough, Phillip
AU  - Lovell, Melanie
AU  - Austin, Philip
AU  - Poronnik, Philip
AU  - Zhang, Wendy Qi
AU  - Kay, Judy
AU  - Kummerfeld, Bob
AU  - Luckett, Tim
AU  - Brown, Martin
AU  - Phillips, Jane L.
AU  - Agar, Meera
T3  - CHI EA '23
AB  - Designing technologies in the palliative care environment is difficult due to the sensitivity of the context and vulnerability of the patients and their families in a critical stage of life. We conducted two focus groups with 9 healthcare workers to capture sociotechnical imaginaries to support physical, psychological, social and spiritual aspects of the patient care in the palliative environment. The findings reveal recurring themes of care: expressing respect in safe spaces, transitioning into the unknown and experiencing home again, taking opportunities for uplifting care, communication for empowerment and risk mitigation, and connection to support networks. These are discussed through a lens of the materiality of care provided to patients, where tangible materials of care are entwined with patients’ values and culture. This in turn offers insight into opportunities for palliative care technology.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585768
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585768
KW  - end-of-life
KW  - ethic of care
KW  - materiality of care
KW  - palliative care
KW  - sociotechnical infrastructure
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Hearing the Way Forward: Exploring Ambient Navigational Awareness with Reduced Cognitive Load through Spatial Audio-AR
AU  - Gordon, Jeremy Raboff
AU  - Fiannaca, Alexander J.
AU  - Kneisel, Melanie
AU  - Cutrell, Edward
AU  - Miller, Amos
AU  - Gonzalez-Franco, Mar
T3  - CHI EA '23
AB  - Notifications and alerts can both convey critical data needed to make decisions as we go about our day, and at the same time be completely ignored as a result of the overuse of these channels. Auditory notifications can be especially intrusive given their demand for synchronous attention. However, during some activities, such as navigation guidance via GPS, immediate information cues are necessary. In this case audio alerts and instructions are typically implemented as voice commands, but processing language requires significant cognitive resources and attention. In this study we report findings about the feasibility of a novel ambient pedestrian guidance system inspired by neuroscience. Results suggest that it is possible to communicate precise spatial actions without the intrusion of verbal turn-by-turn cues. We also share learnings from our use of low-fidelity prototyping to evaluate the novel audio-AR interaction.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585800
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585800
KW  - augmented reality
KW  - pedestrian navigation
KW  - planning
KW  - spatial audio
KW  - wayfinding
ER  - 

TY  - CONF
TI  - HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies
AU  - Chulpongsatorn, Neil
AU  - Willett, Wesley
AU  - Suzuki, Ryo
T3  - CHI EA '23
AB  - We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585738
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585738
KW  - Cross-Device Interaction
KW  - Embedded Data Visualization
KW  - Mixed Reality
KW  - Tangible Interaction
ER  - 

TY  - CONF
TI  - HaptiX: Vibrotactile Haptic Feedback for Communication of 3D Directional Cues
AU  - Pascher, Max
AU  - Franzen, Til
AU  - Kronhardt, Kirill
AU  - Gruenefeld, Uwe
AU  - Schneegass, Stefan
AU  - Gerken, Jens
T3  - CHI EA '23
AB  - In Human-Computer-Interaction, vibrotactile haptic feedback offers the advantage of being independent of any visual perception of the environment. Most importantly, the user’s field of view is not obscured by user interface elements, and the visual sense is not unnecessarily strained. This is especially advantageous when the visual channel is already busy, or the visual sense is limited. We developed three design variants based on different vibrotactile illusions to communicate 3D directional cues. In particular, we explored two variants based on the vibrotactile illusion of the cutaneous rabbit and one based on apparent vibrotactile motion. To communicate gradient information, we combined these with pulse-based and intensity-based mapping. A subsequent study showed that the pulse-based variants based on the vibrotactile illusion of the cutaneous rabbit are suitable for communicating both directional and gradient characteristics. The results further show that a representation of 3D directions via vibrations can be effective and beneficial.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585601
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585601
KW  - directional cues
KW  - haptic feedback
KW  - vibrotactile feedback
ER  - 

TY  - CONF
TI  - HapticPalmrest: Haptic Feedback through the Palm for the Laptop Keyboard
AU  - Yim, Jisu
AU  - Lee, Sangyoon
AU  - Lee, Geehyuk
T3  - CHI EA '23
AB  - Programmable haptic feedback on touchscreen keyboards enriches user experiences but is hard to realize for physical keyboards because this requires individually augmenting each key with an actuator. As an alternative approach, we propose HapticPalmrest, where haptic feedback for a physical keyboard is provided to the palms. This is particularly feasible for a laptop environment, where users usually rest their palms while interacting with the keyboard. To verify the feasibility of the approach, we conducted two user studies. The first study showed that at least one palm was on palmrest for more than 90% of key interaction time. The second study showed a vibration power of 1.17 g (peak-to-peak) and a duration of 4 ms was sufficient for reliable perception of palmrest vibrations during keyboard interaction. We finally demonstrated the potential of such an approach by designing Dwell+ Key, an application that extends the function of each key by enabling timed dwelling operations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585663
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585663
KW  - haptic feedback
KW  - laptop keyboard
KW  - sensory substitution
ER  - 

TY  - CONF
TI  - H4VR: One-handed Gesture-based Text Entry in Virtual Reality Using a Four-key Keyboard
AU  - Fallah, Saba
AU  - Mackenzie, Scott
T3  - CHI EA '23
AB  - H4VR is a text entry method offering two layouts – flat and cross – of a four-key keyboard in VR. Hand gestures select the keys with a different selection method for each layout. The entry speed and error rate were measured and analyzed in a five-session longitudinal user study. Five participants entered ten phrases on each keyboard in each session. They reached an average entry speed of 4.57 and 3.63 words per minute on the flat and cross keyboards, respectively. The average error rate was less than 2% on both keyboards.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585876
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585876
KW  - Gesture-based text entry
KW  - H4-Writer
KW  - Huffman codes
KW  - Virtual reality
ER  - 

TY  - CONF
TI  - Happje: Stimulating Collaborative Cooking for People with Dementia
AU  - Ruitenburg, Yvon
AU  - Brankaert, Rens
AU  - Houben, Maarten
AU  - Lee, Minha
AU  - Pasman, Gert
T3  - CHI EA '23
AB  - People with dementia often experience difficulty performing daily activities, including cooking. Previous studies have focused on creating technological interventions for guiding people with dementia individually through cooking tasks and reducing errors. However, collaborative cooking can often promote social engagement and increase self-esteem. This paper presents the iterative development of an easy-to-use recipe tool Happje with step-by-step instructions designed for and with people with dementia. Throughout the project, 13 iterations of the prototype were built and evaluated in the homes and meeting centres of people with dementia. Happje is designed to meet the cognitive abilities of people with dementia and promote collaboration. Moreover, Happje supports informal caregivers in creating personalised recipes. The present study emphasises the significance of utilising intuitive technology and fostering collaboration in daily living activities to promote autonomy and social engagement for individuals with dementia.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585653
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585653
KW  - collaboration
KW  - cooking
KW  - dementia
KW  - step-by-step
ER  - 

TY  - CONF
TI  - GitUI: A Community-Based Platform to Democratize User Interfaces
AU  - Alves, Sérgio
AU  - Costa, Ricardo
AU  - Montague, Kyle
AU  - Guerreiro, Tiago
T3  - CHI EA '23
AB  - Customization empowers users to tailor user interfaces to their needs. Although beneficial, its adoption is limited by the required effort, skills, and creativity. Following the success of open software repositories, we present a novel community-based customization system where users can: 1) customize UIs for the self and others – using a customization toolkit; 2) use and further adapt public customization templates – found in an online repository; or 3) request customization assistance. We explored this concept in the context of Web technologies by developing GitUI. GitUI was iteratively developed and evaluated over two deployment phases. In a two-phase study (n=9), experts and non-experts 1) used, for two weeks, the customization toolkit; and 2) explored the repository. Results suggest that community-based customization is feasible. People are motivated to customize for others and enjoy the convenience of public templates. We present challenges and opportunities for future research seeking to democratize customization.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585668
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585668
KW  - Agency
KW  - Customization
KW  - Democratization
KW  - End-user
KW  - Personalization
ER  - 

TY  - CONF
TI  - GazeReader: Detecting Unknown Word Using Webcam for English as a Second Language (ESL) Learners
AU  - Ding, Jiexin
AU  - Zhao, Bowen
AU  - Huang, Yuqi
AU  - Wang, Yuntao
AU  - Shi, Yuanchun
T3  - CHI EA '23
AB  - Automatic unknown word detection techniques can enable new applications for assisting English as a Second Language (ESL) learners, thus improving their reading experiences. However, most modern unknown word detection methods require dedicated eye-tracking devices with high precision that are not easily accessible to end-users. In this work, we propose GazeReader, an unknown word detection method only using a webcam. GazeReader tracks the learner’s gaze and then applies a transformer-based machine learning model that encodes the text information to locate the unknown word. We applied knowledge enhancement including term frequency, part of speech, and named entity recognition to improve the performance. The user study indicates that the accuracy and F1-score of our method were 98.09% and 75.73%, respectively. Lastly, we explored the design scope for ESL reading and discussed the findings.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585790
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585790
KW  - eye tracking
KW  - natural language processing
KW  - unknown words detection
KW  - webcam
ER  - 

TY  - CONF
TI  - Gaze-based Metrics of Cognitive Load in a Conjunctive Visual Memory Task
AU  - Bacchin, Davide
AU  - Gehrer, Nina A.
AU  - Krejtz, Krzysztof
AU  - Duchowski, Andrew T.
AU  - Gamberini, Luciano
T3  - CHI EA '23
AB  - Measurement of Cognitive Load (CL) is of considerable importance to Human-Computer Interaction (HCI) as it relates to ease of learn- and usability. Numerous methods have been used for this purpose, both subjective and objective. The former relies on perception of expended effort subject to confounding factors. Among objective measures, eye tracking has demonstrated its effectiveness as a precise and non-invasive alternative. Since eye-tracking indices have mainly been tested in tasks involving single visual properties (e.g., shape), this work aims to compare their sensitivity to conjunctive features. Specifically, this study evaluates the Low/High Index of Pupillary Activity (LHIPA) and microsaccade magnitude in the Color Visual Short-Term Memory (CVSTM) task versus the previously validated n-back task. Results show LHIPA and microsaccade magnitude are as effective in discerning baseline and task in CVSTM as in n-back, replicating earlier results and extending their reliability for evaluation of CL in tasks involving multivalent conjunctive features.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585650
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585650
KW  - cognitive load
KW  - eye tracking
KW  - visual attention
ER  - 

TY  - CONF
TI  - Futuring from an indigenous community stance: projecting temporal duality from the past into the future
AU  - Muashekele, Chris
AU  - Rodil, Kasper
AU  - Winschiers-Theophilus, Heike
AU  - Magoath, Christof
T3  - CHI EA '23
AB  - This paper presents the first instance and experience of futuring with a rural San community from the Kalahari desert in Donkerbos, Namibia. Over a series of sessions we explore divergent speculative design and design fiction methods to stimulate and invoke alternative green energy use cases. These alternatives are premised on the imagination of unorthodox green energy use, superseding interventionist energy use which is constantly propagated and mainstream. We showcase the application of speculative design and design fiction in challenging the dominant interventionist approach and singular temporal view, resulting in a dissentient dual temporality. As well as demonstrate its utility and inadequacies in transitioning an African rural indigenous community into the speculative, arguing for the appropriation and widening of futuring methods in an African context.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585761
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585761
KW  - Futuring
KW  - Indigenous participants
KW  - Namibia
KW  - Temporality
ER  - 

TY  - CONF
TI  - From Thoughts to Interaction: Designing Controls for Video Playback Gestures with Embodied Schemata
AU  - Friedman, Adina
AU  - Cafaro, Francesco
T3  - CHI EA '23
AB  - Interactive public displays are now pervasive; however, designing gestures to interact with them is still a challenge for embodied interaction. We introduce a methodology, based on Conceptual Metaphor Theory (CMT) and Elicitation Studies, that can inform the work of interaction designers when they craft gestures that "make sense" to their users. Our approach is structured in three phases: elicitation, analysis, and design. Through the use case of an interactive video player, we describe how we collected data from participants in an elicitation study, how we extracted the embodied schemata that users associated with each video function, and how an interaction designer can use those schemata to design multiple gestures. We then present the results of a survey that show that the gestures generated with embodied schemata made more sense to people than those crafted without using embodied schemata.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585769
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585769
KW  - Design Methods
KW  - Embodied Interaction
KW  - Gestural Interaction
ER  - 

TY  - CONF
TI  - From Point A to Point B: Identity-Informed Safety in Navigation Technology
AU  - Williams, Ty Michael Masao
AU  - Cooper, Emily H. S.
AU  - Dew, Kristin
T3  - CHI EA '23
AB  - HCI scholars have explored how safety and mobility intersect in urban environments, particularly for women and people with disabilities. However, existing work has yet to explore how intersecting identities shape perceptions of safety and navigation strategies. To better understand these relationships, we conducted 12 semi-structured interviews with a diverse group of Seattle residents who regularly navigate the city. Age, gender, race, ability, and addiction recovery shaped how participants characterized a route's safety and their navigation practices. Technology served multiple roles in safe navigation — some in tension — by surfacing route information, distracting from surroundings, and empowering decision-making. Our findings highlight opportunities for future research and navigational technology design to meet the needs of differing safety experiences by incorporating personalization, relevant data, and guidance.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585776
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585776
KW  - gender identity
KW  - identity
KW  - intersectionality
KW  - mapping applications
KW  - Navigation technology
KW  - race
KW  - safety
KW  - urban navigation
ER  - 

TY  - CONF
TI  - From Bin to Playin’: Give Vintage Objects a New Purpose as Game Controllers
AU  - Pokorny, Jan
AU  - Kejstova, Magdalena
AU  - Rusnak, Vit
AU  - Kriglstein, Simone
T3  - CHI EA '23
AB  - Alternative game controllers offer opportunities to explore player interactions and enhance game enjoyment. This paper presents an approach to creating playful game controllers using everyday objects that have outlived their usefulness. By incorporating an Arduino microcontroller, we aimed to upcycle them and create unique controllers that can enhance the gaming experience while reducing waste and promoting sustainability. To demonstrate our approach, we created three alternative game controllers from an alarm clock, a transistor radio, and a rotary phone. We also conducted an initial user study to get feedback on the gameplay compared to traditional controllers (keyboards or mice). The results showed that our custom controllers were more enjoyable, even when participants scored lower, and that the utility, usability, and user experience were comparable to standard controllers. Further user studies are needed to ensure that the controllers are as intuitive and comfortable as possible.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585665
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585665
KW  - Arduino
KW  - Playful Game Controllers
KW  - Playful Interaction
KW  - Upcycling
ER  - 

TY  - CONF
TI  - Four Challenges for IML Designers: Lessons of an Interactive Customer Segmentation Prototype in a Global Manufacturing Company
AU  - Raees, Muhammad
AU  - Khan, Vassilis-Javed
AU  - Papangelis, Konstantinos
T3  - CHI EA '23
AB  - Interactive Machine Learning (IML) apps permeate all aspects of businesses, including sales. Customer segmentation is integral for sales, to identify customer groups to serve them appropriately. However, the novelty of such apps in a sales context raises the question: what challenges designers of such apps will face, in a sales context? To explore this question, we report our reflections on an IML study for customer clustering. We used data from a global manufacturing company to cluster customers using the Recency, Frequency, and Monetary (RFM) method. We applied a machine learning clustering model (K-Means) and discussed with seven seasoned sales managers the interaction with clusters. We report four challenges and foresee that designers of such systems will face, in the context of sales operations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585788
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585788
KW  - Analytics
KW  - Contextualization
KW  - Customer Segmentation
ER  - 

TY  - CONF
TI  - Following the Master’s Hands: Capturing Piano Performances for Mixed Reality Piano Learning Applications
AU  - Labrou, Katerina
AU  - Zaman, Cagri Hakan
AU  - Turkyasar, Arda
AU  - Davis, Randall
T3  - CHI EA '23
AB  - Piano learning applications in Mixed Reality (MR) are a promising substitute for physical instruction when a piano teacher is absent. Existing piano learning applications that use visual indicators to highlight the notes to be played on the keyboard or employ video projections of a pianist provide minimal guidance on how the learner should execute hand movements to develop their technique in performance and prevent injuries. To address this gap, we developed an immersive first-person piano learning experience that uses a library of targeted visualizations of the teacher’s hands and 3D traces of hand movements in MR. Seeing the piano teacher’s hands while hearing the music is central to developing the novice’s musical intuition. We introduced an end-to-end workflow to accurately capture the pianist’s technical gestures and align them with the musical score. We recorded pianists playing technical exercises and music pieces. We developed a multimodal performance dataset (MPD) comprising virtual hand models, keyboard (MIDI) recordings and the corresponding music scores, and different visualizations of hand traces capturing movement. Finally, we developed Pianoverse, an MR application to assist piano learning, and performed exploratory user testing with novice piano players to understand the impact of multimodal representations of movement on skill learning. Our initial observations suggest that apprehending the movement traces of a recorded performance over a physical keyboard increases the learner’s ability to position their body and hands correctly and to replicate hand gestures while playing from written music. Further research will focus on automating performance data collection and a comprehensive evaluation of the use of leading movement traces in piano learning.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585838
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585838
KW  - Embodied Computing
KW  - Mixed Reality
KW  - Motion Capture
KW  - Piano training
ER  - 

TY  - CONF
TI  - FoodFighters - Improving Memory Retention of Food Items through a Mobile Serious Game
AU  - Jespersen, Kristian Nyborg
AU  - Odgaard, Rasmus
AU  - Julsgaard, Kristian
AU  - Madsbøll, Jens Lakmann
AU  - Lundbak, Marcus Høyen
AU  - Niebuhr, Mathias
AU  - Skovfoged, Milo Marsfeldt
AU  - Löchtefeld, Markus
T3  - CHI EA '23
AB  - Food waste in private households of industrialised countries is becoming an increasing concern, as its impact on greenhouse gas emissions is comparable to that of the aviation industry. One particular unnecessary contribution to food waste is a person forgetting which food items they have in their household, which often leads to food items expiring before they are used. This paper introduces FoodFighters a mobile serious game aimed at encouraging young adult players to interact with their food items thereby making them more memorable. FoodFighters works by taking pictures of food items, that then can be customized into so called Food Fighters, which are then used to battle other players/friends fighters. In two preliminary lab studies, we validated that Food Fighters actually improved retention of food items and found that players found the game enjoyable based on a GEQ-questionnaire.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585633
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585633
KW  - Food Waste
KW  - Serious Games
KW  - Sustainability
ER  - 

TY  - CONF
TI  - Flying Names: Manipulating Name Tags in XR Social Environments for Target Selection Tasks
AU  - Wang, Fengyusheng
AU  - Chang, Chia-Ming
AU  - Igarashi, Takeo
T3  - CHI EA '23
AB  - Recent developments in Extended Reality (XR) have led to the creation of various Virtual Reality (VR) social applications that allow small groups of people to interact and participate in various activities. However, these applications are not suitable for larger-scale social scenarios. One major challenge is the lacking of effective solutions for target selection because existing methods for occluded-target selection do not apply well to humans. In this paper, we propose a method called “Flying Names” to improve decision-making accuracy during target selection for both VR and Augmented Reality (AR) social environments by manipulating the heights of name tags on the fly and connecting an auxiliary line from a name tag to its highlighted owner. Our user study results indicate that this proposal effectively improves the accuracy of identifying the actual target person and is better than using either one or none of manipulating heights and connecting lines.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585677
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585677
ER  - 

TY  - CONF
TI  - Focus Time for Wellbeing and Work Engagement of Information Workers
AU  - Saha, Koustuv
AU  - Iqbal, Shamsi T
T3  - CHI EA '23
AB  - Having little time for focused work is a major challenge in information work. While research has explored computing-assisted user-facing solutions for protecting time for focused work, there is limited empirical evidence about the effectiveness of these features on wellbeing and work engagement. Towards this problem, we study the effects of automatically scheduling time for focused work on people’s work calendars using the Focus Time feature on Outlook calendars. We conducted an experimental study over six weeks with 15 Treatment and 10 Control participants who responded to survey questions on wellbeing and work engagement throughout the study. We find that the Treatment participants showed higher wellbeing, including increased excitement, relaxation, and satisfaction, and decreased anger, frustration, tiredness, and stress. We study the needs, benefits, and challenges of scheduling focus time, and discuss the importance and design recommendations for enabling mechanisms and tools supporting focused work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585688
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585688
KW  - experimental study
KW  - focus work
KW  - time protection
KW  - wellbeing
KW  - work engagement workplace
ER  - 

TY  - CONF
TI  - FeelTheNews: Augmenting Affective Perceptions of News Videos with Thermal and Vibrotactile Stimulation
AU  - Ooms, Simone
AU  - Lee, Minha
AU  - Cesar, Pablo
AU  - El Ali, Abdallah
T3  - CHI EA '23
AB  - Emotion plays a key role in the emerging wave of immersive, multi-sensory audience news engagement experiences. Since emotions can be triggered by somatosensory feedback, in this work we explore how augmenting news video watching with haptics can influence affective perceptions of news. Using a mixed-methods approach, we design and evaluate FeelTheNews, a prototype that combines vibrotactile and thermal stimulation (Matching, 70Hz/20°&nbsp;C, 200Hz/40°&nbsp;C) during news video watching. In a within-subjects study (N=20), we investigate the effects of haptic stimulation and video valence on perceived valence, emotion intensity, comfort, and overall haptic experiences. Findings showed: (a) news valence and emotion intensity ratings were not affected by haptics, (b) no stimulation was more comfortable than including stimulation, (c) attention and engagement with the news can override haptic sensations, and (d) users’ perceived agency over their reactions is critical to avoid distrust. We contribute cautionary insights for haptic augmentation of the news watching experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585638
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585638
KW  - emotion
KW  - haptics
KW  - journalism
KW  - news
KW  - thermal
KW  - vibrotactile
ER  - 

TY  - CONF
TI  - First Bite/Chew: distinguish different types of food by first biting/chewing and the corresponding hand movement
AU  - Chen, Junyu
AU  - Wang, Xiongqi
AU  - Li, Juling
AU  - Chernyshov, George
AU  - Huang, Yifei
AU  - Kunze, Kai
AU  - Huang, Jing
AU  - Starner, Thad
AU  - Zhang, Qing
T3  - CHI EA '23
AB  - Imbalanced food intake contributes to various diseases, such as obesity, diabetes, high blood pressure, high cholesterol, heart disease, and type-2 diabetes. At the same time, food intake monitoring systems play a significant role in the treatment. Most current food intake tracking methods are camera-based, on-body sensor-based, microphone based, and self-reported. The challenges that remain are social acceptance, lightweight, easy to use, and inexpensive. Our method leverages two 6-axe Inertial Measurement Units (IMU) on the glasses’ leg and the wrist to detect the user’s food intake activities using a machine learning capable Micro Controller Unit (MCU). We introduced the concept of the first bite/chew, which is a stable and reliable indicator to distinguish food types. Our implementation results show that our method can distinguish seven kinds of food at an accuracy of 93.26% (average) over all four participants.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585845
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585845
KW  - diet monitoring
KW  - food intake
KW  - smart eyewear
ER  - 

TY  - CONF
TI  - Fashioning the Future: Unlocking the Creative Potential of Deep Generative Models for Design Space Exploration
AU  - Davis, Richard Lee
AU  - Wambsganss, Thiemo
AU  - Jiang, Wei
AU  - Kim, Kevin Gonyop
AU  - Käser, Tanja
AU  - Dillenbourg, Pierre
T3  - CHI EA '23
AB  - This paper investigates the potential impact of deep generative models on the work of creative professionals, specifically focusing on fashion design. We argue that current generative modeling tools lack critical features that would make them useful creativity support tools, and introduce our own tool, generative.fashion1, which was designed with theoretical principles of design space exploration in mind. Through qualitative studies with fashion design apprentices, we demonstrate how generative.fashion supported both divergent and convergent thinking, and compare it with a state-of-the-art diffusion model, Stable Diffusion. In general, the apprentices preferred generative.fashion over Stable Diffusion, citing the features explicitly designed to support ideation. We conclude that the exploration and development of novel interfaces and interaction modalities that are theoretically aligned with principles of design space exploration is crucial for unlocking the creative potential of generative AI and advancing a new era of creativity.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585644
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585644
KW  - Creativity
KW  - Creativity Support Tools (CSTs)
KW  - Deep Generative Models
KW  - Design Space Exploration
KW  - Fashion Design
KW  - Generative AI
KW  - Ideation Process
ER  - 

TY  - CONF
TI  - Fable Reborn: Investigating Gameplay Experience between a Human Player and a Virtual Dungeon Master
AU  - Ang, Charlene
AU  - Cortel, Lorraine Renee
AU  - Santos, Carlo Luis
AU  - Ong, Ethel
T3  - CHI EA '23
AB  - Dungeons &amp; Dragons (D&amp;D) is a role-playing game typically played face-to-face with participants seated around a tabletop. Online technologies have enabled the conduct of live sessions on virtual platforms, allowing players to continue enjoying the game despite geographic distances. Playing D&amp;D relies heavily on a dungeon master who is tasked with preparing the fictional world and facilitating the interaction between players who each control a single story character. In this paper, we investigate the impact of employing AI techniques in designing a virtual dungeon master (VDM) on the gameplay experience of D&amp;D players. The VDM utilizes Open AI’s GPT2 model to generate story prompts in combination with an input plausibility checker, a dice rolling feature, and a candidate story prompt scorer. Feedback from D&amp;D players revealed that the VDM is capable of producing believable fantasy stories but lacks consistency in the quality of its generated stories. Our findings point to the potential abilities of an artificially intelligent agent in engaging human D&amp;D players in role-playing games; however, the VDM is still not capable of truly replicating the experience of playing with a human DM.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585793
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585793
KW  - Dragons
KW  - Dungeons &
KW  - gameplay experience
KW  - interactive storytelling
KW  - role-playing game
KW  - virtual dungeon master
ER  - 

TY  - CONF
TI  - EyesOnMe: Investigating Haptic and Visual User Guidance for Near-Eye Positioning of Mobile Phones for Self-Eye-Examinations
AU  - Meinhardt, Luca-Maxim
AU  - Van Laerhoven, Kristof
AU  - Dobbelstein, David
T3  - CHI EA '23
AB  - The scarcity of professional ophthalmic equipment in rural areas and during exceptional situations such as the COVID-19 pandemic highlights the need for tele-ophthalmology. This late-breaking work presents a novel method for guiding users to a specific pose (3D position and 3D orientation) near the eye for mobile self-eye examinations using a smartphone. The user guidance is implemented utilizing haptic and visual modalities to guide the user and subsequently capture a close-up photo of the user’s eyes. In a within-subject user study (n=24), the required time, success rate, and perceived demand for the visual and haptic feedback conditions were examined. The results indicate that haptic feedback was the most efficient and least cognitively demanding in the positioning task near the eye, whereas relying on only visual feedback can be more difficult due to the near focus point or refractive errors.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585799
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585799
KW  - mobile self-ophthalmology
KW  - near-eye positioning
KW  - smartphone
KW  - user guidance
ER  - 

TY  - CONF
TI  - Eye Movement Analysis of Human Visual Recognition Processes with Camera Eye Tracker: Higher Mean and Variance of Fixation Duration for Familiar Images
AU  - Chan, Samantha
AU  - Zhang, Haimo
AU  - Nanayakkara, Suranga
T3  - CHI EA '23
AB  - Eye movements could provide information on a person’s cognitive context. Previous works showed that human visual recognition processes could be detected via electrooculography (EOG) data and revealed top-ranked eye movement features for detection. However, they lack analysis on how eye movements differ when viewing recognised (familiar) and unrecognised (unfamiliar) images. EOG methods are less prevalent and have limited scalability for detecting other cognitive processes. Our study with 34 participants showed that saccade count and fixation count decreased while the mean and variance of fixation duration increased with image familiarity. We discuss the differences in eye movements when seeing images of different categories and lessons learnt for our next steps to enable implicit interactions using wearable camera-based eye trackers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585782
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585782
KW  - Cognitive Context
KW  - Eye Movement Analysis
KW  - Eye Tracking
KW  - Image Familiarity
KW  - Physiological Sensing
KW  - Visual Memory Recall
KW  - Visual Recognition
ER  - 

TY  - CONF
TI  - Exploring Types of On-Demand Reading Assistance for Elementary School Students
AU  - Kutter, Jonathan
AU  - Lunte, Tobias
AU  - Boll, Susanne
T3  - CHI EA '23
AB  - The ability to read is an essential skill for participating in modern society, yet almost 20% of all third- and fourth grade students in Germany do not have a sufficient level of reading performance. Computer-based learning assistants provide a promising approach for wide-spread reading support, however, it is unclear which types of assistance visualization are effective in overcoming reading difficulties. We present a prototype of an interactive online reading assistant for self-directed learning. This prototype comprises tools for adjusting the text display as a whole, as well as assistance visualizations for individual words (syllabication, explanation and base form). In a formative user test with five primary school students, we gather feedback regarding the general acceptance of the application, differences between the assistance types and suggestions for further improvement. In addition, we provide guidelines on how to adjust the evaluation procedure to better match the intended user group in the future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585711
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585711
KW  - assistance systems
KW  - augmented reading
KW  - learning to read
KW  - Reading difficulties
KW  - support visualization
ER  - 

TY  - CONF
TI  - FabricFaces: Combining Textiles and 3D Printing for Maker-Friendly Folding-Based Assembly
AU  - Wagner, Adrian
AU  - Preuschoff, Paul Miles
AU  - Wacker, Philipp
AU  - Voelker, Simon
AU  - Borchers, Jan
T3  - CHI EA '23
AB  - We introduce a Personal Fabrication workflow to easily create feature-rich 3D objects with textile-covered surfaces. Our approach unfolds a 3D model into a series of flat frames with connectors, which are then 3D-printed onto a piece of fabric, and folded manually into the shape of the original model. This opens up an accessible way to incorporate established 2D textile workflows, such as embroidery, using color patterns, and combining different fabrics, when creating 3D objects. FabricFaces objects can also be flattened again easily for transport and storage. We provide an open-source plugin for the common 3D tool Blender. It enables a one-click workflow to turn a user-provided model into 3D printer instructions, textile cut patterns, and connector support. Generated frames can be refined quickly and iteratively through previews and extensive options for manual intervention. We present example objects illustrating a variety of use cases.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585854
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585854
KW  - 3D Printing
KW  - Fabrication
KW  - Textiles
ER  - 

TY  - CONF
TI  - Exploring the Use of the SoundVizVR Plugin with Game Developers in the Development of Sound-Accessible Virtual Reality Games
AU  - Li, Ziming
AU  - Shinohara, Kristen
AU  - Peiris, Roshan L
T3  - CHI EA '23
AB  - Based on a virtual reality (VR) sound visualization indicator system named “SoundVizVR” proposed and evaluated in a previous research, we developed a “SoundVizVR Plugin” for the Unity platform which enabled developers to adopt the SoundVizVR system in their VR applications and games. In this study, we worked with two VR game developers to explore the usability of the SoundVizVR Plugin and how it impacted the view on accessibility from the game developers’ perspectives. The developers used the SoundVizVR Plugin for one week to integrate it into their current projects or design new games with the plugin. According to the findings of the study process, we provide game design practices for making sounds in VR games accessible and suggestions on optimizing the developer experience of a sound accessibility plugin for the Unity platform.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585750
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585750
KW  - accessibility
KW  - audio visualization
KW  - deaf and hard-of-hearing
KW  - development tool
KW  - game development
KW  - sound accessibility
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Exploring the Use of Large Language Models for Improving the Awareness of Mindfulness
AU  - Kumar, Harsh
AU  - Wang, Yiyi
AU  - Shi, Jiakai
AU  - Musabirov, Ilya
AU  - Farb, Norman A. S.
AU  - Williams, Joseph Jay
T3  - CHI EA '23
AB  - Teachable self-help techniques, such as mindfulness, can reduce anxiety and improve mental well-being outcomes. However, people lack proper awareness of such techniques. In this work, we explore the design space of using online dissemination channels to help people learn about mindfulness. We investigate the potential benefits of using Large Language Models (LLMs) to improve awareness and willingness to practice these techniques, building on a video-based intervention to introduce mindfulness. We designed a pilot between subjects randomized factorial experiment of 2 (Informational Chatbot: present vs. absent) x 2 (Tutorial Video: present vs. absent) x 2 (Reflection Chatbot: present vs. absent). Our preliminary findings suggest that interaction with either of the chatbots improved the participants’ intent to practice Mindfulness again, and the tutorial video improved the participants’ reported overall experience of the exercise. This highlights the potential promise and outlines the directions for exploring the use of LLM-based chatbots for awareness-related interventions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585614
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585614
KW  - factorial experiment
KW  - GPT-3
KW  - large language models
KW  - mental well-being
ER  - 

TY  - CONF
TI  - Exploring the Use of Electromagnets to Influence Key Targeting on Physical Keyboards
AU  - Mecke, Lukas
AU  - Prieto Romero, Ismael
AU  - Delgado Rodriguez, Sarah
AU  - Alt, Florian
T3  - CHI EA '23
AB  - In this work, we explore the use of force induced through electromagnets to influence finger movement while using a keyboard. To achieve this we generate a magnetic field below a keyboard and place a permanent magnet on the user’s finger as a minimally invasive approach to dynamically induce variable force. Contrary to other approaches our setup can thus generate forces even at a distance from the keyboard. We explore this concept by building a prototype and analyzing different configurations of electromagnets (i.e., attraction and repulsion) and placements of a permanent magnet on the user’s fingers in a preliminary study (N=4). Our force measurements show that we can induce 3.56&nbsp;N at a distance of 10&nbsp;mm. Placing the magnet on the index finger allowed for influencing key press times and was perceived as comfortable. Finally, we discuss implications and potential application areas like mid-air feedback and guidance.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585703
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585703
KW  - electromagnets
KW  - keyboards
KW  - output
KW  - typing
ER  - 

TY  - CONF
TI  - Exploring the Use of Collaborative Robots in Cinematography
AU  - Praveena, Pragathi
AU  - Cagiltay, Bengisu
AU  - Gleicher, Michael
AU  - Mutlu, Bilge
T3  - CHI EA '23
AB  - Robotic technology can support the creation of new tools that improve the creative process of cinematography. It is crucial to consider the specific requirements and perspectives of industry professionals when designing and developing these tools. In this paper, we present the results from exploratory interviews with three cinematography practitioners, which included a demonstration of a prototype robotic system. We identified many factors that can impact the design, adoption, and use of robotic support for cinematography, including: (1) the ability to meet requirements for cost, quality, mobility, creativity, and reliability; (2) the compatibility and integration of tools with existing workflows, equipment, and software; and (3) the potential for new creative opportunities that robotic technology can open up. Our findings provide a starting point for future co-design projects that aim to support the work of cinematographers with collaborative robots.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585715
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585715
KW  - automated cinematography
KW  - cinema robot
KW  - cobot
KW  - collaborative robot
KW  - human-robot interaction
KW  - motion control
ER  - 

TY  - CONF
TI  - Exploring the Perception of Pain in Virtual Reality through Perceptual Manipulations
AU  - Clavelin, Gaëlle
AU  - Bouhier, Mickael
AU  - Tseng, Wen-Jie
AU  - Gugenheimer, Jan
T3  - CHI EA '23
AB  - Perceptual manipulations (PMs) in Virtual Reality (VR) can steer users’ actions (e.g., redirection techniques) and amplify haptic perceptions (e.g., weight). However, their ability to amplify or induce negative perceptions such as physical pain is not well understood. In this work, we explore if PMs can be leveraged to induce the perception of pain, without modifying the physical stimulus. We implemented a VR experience combined with a haptic prototype, simulating the dislocation of a finger. A user study (n=18) compared three conditions (visual-only, haptic-only and combined) on the perception of physical pain and physical discomfort. We observed that using PMs with a haptic device resulted in a significantly higher perception of physical discomfort and an increase in the perception of pain compared to the unmodified sensation (haptic-only). Finally, we discuss how perception of pain can be leveraged in future VR applications and reflect on ethical concerns.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585674
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585674
KW  - Haptic Devices
KW  - Perceptual Manipulations
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Exploring the Design Space of Automatically Generated Emotive Captions for Deaf or Hard of Hearing Users
AU  - Hassan, Saad
AU  - Ding, Yao
AU  - Kerure, Agneya Abhimanyu
AU  - Miller, Christi
AU  - Burnett, John
AU  - Biondo, Emily
AU  - Gilbert, Brenden
T3  - CHI EA '23
AB  - Caption text conveys salient auditory information to deaf or hard-of-hearing (DHH) viewers. However, the emotional information within the speech is not captured. We developed three emotive captioning schemas that map the output of audio-based emotion detection models to expressive caption text that can convey underlying emotions. The three schemas used typographic changes to the text, color changes, or both. Next, we designed a Unity framework to implement these schemas and used it to generate stimuli videos. In an experimental evaluation with 28 DHH viewers, we compared DHH viewers’ ability to understand emotions and their subjective judgments across the three captioning schemas. We found no significant difference in participants’ ability to understand the emotion based on the captions or their subjective preference ratings. Open-ended feedback revealed factors contributing to individual differences in preferences among the participants and challenges with automatically generated emotive captions that motivate future work.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585880
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585880
KW  - Applications of emotion recognition
KW  - captions
KW  - Deaf or hard of hearing users
KW  - emotive captions
ER  - 

TY  - CONF
TI  - Exploring the Challenges and Opportunities in Developing Systems to Improve Alcohol Use Disorder through Chatbot Technology
AU  - Qiu, Xiang-Zhi
AU  - Yuan, Chien Wen (Tina)
AU  - Bi, Nanyi
AU  - Huang, Ming-Chyi
AU  - You, Chuang-Wen
T3  - CHI EA '23
AB  - Alcohol use disorder is a debilitating psychiatric condition, which can have devastating effects on the individual, their friends, and family. Most of the communication between patients and their treatment team involves brief verbal exchanges within a clinical setting, which is not necessarily conducive to the needs of the patient in their daily life. In this research, we sought to identify methods by which chatbot technology could be used to enhance treatment for alcohol use disorder (AUD). We also sought to establish an alternative communication medium by which to engage in digestible daily interactions with AUD patients (to monitor the psychological state of the user) as well as their companions (to make them aware of important events and coach them in their interactions with the user).
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585635
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585635
KW  - Alcohol Use Disorder
KW  - Chatbot Technology
ER  - 

TY  - CONF
TI  - Exploring the Accessibility of Crypto Technologies
AU  - Lyke, Nash
AU  - Gorman, Benjamin M.
AU  - Tigwell, Garreth W.
T3  - CHI EA '23
AB  - Blockchain and crypto-based technologies are a rapidly-growing domain on the cutting edge of web technologies; however, little research has examined their accessibility for users with disabilities. We focused on a specific area of this domain by completing accessibility audits of four major cryptocurrency exchanges and administered a questionnaire to disabled people to understand potential accessibility challenges. Our accessibility audit revealed many severe accessibility violations among each of the major exchange sites. Participants (n = 72, 23 crypto adopters) reported a wide variety of accessibility concerns with cryptocurrency exchanges and using cryptocurrency itself, which presented barriers to access and adoption of these technologies. We discuss the implications for our findings and propose future areas of work in this domain.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585746
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585746
KW  - Accessibility
KW  - Blockchain
KW  - Cryptocurrency
ER  - 

TY  - CONF
TI  - Exploring the design space for Crowdsourcing Journey eXperience
AU  - Zileli, Selin
AU  - Gomer, Richard C
AU  - schraefel, m.c.
T3  - CHI EA '23
AB  - This paper aims to establish a design space for tools to crowdsource data about Journey eXperience (JX). Understanding JX could provide a range of benefits in various domains, including transport planning, urban design, and individual route planning, and support efforts to achieve more sustainable transport systems. A key challenge in studying JX is finding effective ways to collect data. We present initial results from a diary study that explores what JX means and how JX data might be collected. We show how the experience of journeying through space differs from experiences of being in space, provide an initial description of factors that influence JX, and offer high-level insights of relevance to the design space of JX data collection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585818
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585818
KW  - behaviour
KW  - diary
KW  - emotions
KW  - journey
KW  - senses
KW  - sustainability
KW  - transport
KW  - user experience
ER  - 

TY  - CONF
TI  - Exploring Tangible User Interface Design for Social Connection Among Older Adults: A Preliminary Review
AU  - Bhowmick, Pallabi
AU  - Stolterman Bergqvist, Erik
T3  - CHI EA '23
AB  - Older adults (aged 65 or above) are the fastest growing section of the population and increasing number of older adults are reporting of social isolation. WHO recognizes social engagement as an important factor for reducing isolation among older adults. Researchers have historically investigated digital technologies to build connections, but they involve disadvantages like accessibility issues and have not been a good match for the aged population. In this paper, we investigate existing work that focuses on improving social connections among older adults and then explore the potential of tangible user interaction as an alternate solution. We conclude the paper with design consideration for HCI researchers working in the space of tangible user interface design for older adults. This paper is a preliminary review towards opening a conversation about the suitability of tangible design for older adults in improving social connection.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585722
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585722
KW  - older adults
KW  - social isolation
KW  - tangible technologies
ER  - 

TY  - CONF
TI  - Exploring Shape Designs for Soft Robotics and Users’ Associations with Them
AU  - Brocker, Anke
AU  - Nedorubkova, Ekaterina
AU  - Voelker, Simon
AU  - Borchers, Jan
T3  - CHI EA '23
AB  - Soft robotics provides flexible structures and materials that move in natural and organic ways. They facilitate creating safe and tolerant mechanisms for human–machine interaction. This makes soft robotics attractive for tasks that rigid robots are unable to carry out. Users may also display a higher acceptance of soft robots compared to rigid robots because their natural way of movement helps users to relate to scenarios they know from everyday life, making the interaction with the soft robot feel more intuitive. However, the variety of soft robotics shape designs, and how to integrate them into applications, have not been explored fully yet. In a user study, we investigated users’ associations and ideas for application areas for 36 soft robotics shape designs, brainstormed with users beforehand. We derived first design recommendations for soft robotics designs such as clear signifiers indicating the possible motion.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585606
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585606
KW  - Human Associations
KW  - Movement Effects
KW  - Shape Design
KW  - Soft Robotics
KW  - Soft Robotics Application
ER  - 

TY  - CONF
TI  - Exploring Physiological Correlates of Visual Complexity Adaptation: Insights from EDA, ECG, and EEG Data for Adaptation Evaluation in VR Adaptive Systems
AU  - Chiossi, Francesco
AU  - Ou, Changkun
AU  - Mayer, Sven
T3  - CHI EA '23
AB  - Physiologically-adaptive Virtual Reality can drive interactions and adjust virtual content to better fit users’ needs and support specific goals. However, the complexity of psychophysiological inference hinders efficient adaptation as the relationship between cognitive and physiological features rarely show one-to-one correspondence. Therefore, it is necessary to employ multimodal approaches to evaluate the effect of adaptations. In this work, we analyzed a multimodal dataset (EEG, ECG, and EDA) acquired during interaction with a VR-adaptive system that employed EDA as input for adaptation of secondary task difficulty. We evaluated the effect of dynamic adjustments on different physiological features and their correlation. Our results show that when the adaptive system increased the secondary task difficulty, theta, beta, and phasic EDA features increased. Moreover, we found a high correlation between theta, alpha, and beta oscillations during difficulty adjustments. Our results show how specific EEG and EDA features can be employed for evaluating VR adaptive systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585624
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585624
KW  - Adaptive Systems
KW  - Physiological Computing
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Exploring Potential Contributions of Social Learning to Adaptive Learning Systems
AU  - Gautam, Sanjana
AU  - Rosson, Mary Beth
AU  - Akgun, Mahir
T3  - CHI EA '23
AB  - Adaptive learning systems aim to emulate how skilled educators seek to provide every student the best possible learning experience. We investigate how such systems might be enriched by activities and indicators of social learning - an aspect of learning that focuses on the influences of learners’ social context and interactions. In this paper we describe a pilot study aimed at exploring the potential for including social learning in an adaptive system. Our analysis of the social learning scale demonstrates its validity and usefulness for our ongoing work. Our qualitative analysis of students’ learning demonstrates how social learning vary among students. We discuss how the rating scale results and observations of social learning can be integrated within a student model needed to drive an adaptive system. More generally, our work illustrates how theories of learning can contribute to the design of adaptive learning systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585758
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585758
KW  - adaptive learning
KW  - education
KW  - peer learning
KW  - social constructivism
ER  - 

TY  - CONF
TI  - Exploring Mobility Behavior Around Ambient Displays Using Clusters of Multi-dimensional Walking Trajectories
AU  - Schwarzer, Jan
AU  - Fietkau, Julian
AU  - Fuchs, Laurenz
AU  - Draheim, Susanne
AU  - Von Luck, Kai
AU  - Koch, Michael
T3  - CHI EA '23
AB  - Spatial information has become crucial in ambient display research and helps to better understand how people behave in a display’s vicinity. Walking trajectories have long been used to uncover such information and tools have been developed to capture them anonymously and automatically. However, more research is needed on the level of automation during mobility behavior analyses. Particularly, working with depth-based skeletal data still requires significant manual effort to, for instance, determine walking trajectories similar in shape. To advance on this situation, we adopt both agglomerative hierarchical clustering and dynamic time warping in this research. To the best of our knowledge, both algorithms have so far not found application in our field. Using a multi-dimensional data set obtained from a longitudinal, real-world deployment, we demonstrate here the applicability and usefulness of this approach. In doing so, we contribute insightful ideas for future discussions on the methodological development in ambient display research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585661
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585661
KW  - agglomerative hierarchical clustering
KW  - Ambient displays
KW  - dynamic time warping
KW  - mobility behavior
KW  - walking trajectories
ER  - 

TY  - CONF
TI  - Exploring Mixed Reality in General Aviation to Support Pilot Workload
AU  - Katins, Christopher
AU  - Feger, Sebastian S.
AU  - Kosch, Thomas
T3  - CHI EA '23
AB  - Pilots in non-commercial aviation have minimal access to digital support tools. Equipping aircraft with modern technologies introduces high costs and is labor intensive. Hence, wearable or mobile support, such as common 2D maps displayed on standard tablets, is often the only digital information source used by pilots. Yet, they fail to adequately capture the 3D airspace and its surroundings, challenging the pilot’s workload. This work explores how mixed reality can support pilots by projecting supportive elements into their fields of view. Considering the design of a preliminary mixed reality prototype, we conducted a user study with twelve pilots in a full-sized flight simulator. Our measures show that the prototype positively influenced the participants’ situational awareness and overall landing routine efficiency, who also had generally favorable views regarding mixed reality in the cockpit. This work shows the utility of mixed reality technologies while emphasizing future research directions in general aviation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585742
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585742
KW  - Augmented Reality
KW  - General Aviation
KW  - Highlighting
KW  - Mixed Reality
KW  - Situational Awareness
KW  - Workload
ER  - 

TY  - CONF
TI  - Exploring key categories of social perception and moral responsibility of AI-based agents at work: Findings from a case study in an industrial setting
AU  - Mandl, Sarah
AU  - Kobert, Maria
AU  - Bretschneider, Maximilian
AU  - Asbrock, Frank
AU  - Meyer, Bertolt
AU  - Strobel, Anja
AU  - Süße, Thomas
T3  - CHI EA '23
AB  - The increasing adoption of smart and interactive technologies, based on Artificial Intelligence (AI), in business and society transforms humans’ perception of these technologies towards social actors. However, since there are also reservations of humans to interact with artificial agents, it is fundamental to explore the social perception of this new technology and the implications thereof. Social perception governs social behavior and subsequently affects interactions with AI-agents. Moral responsibility plays a pivotal role in functioning societies and should thus be taken into account when implementing AI. This qualitative study examines workers in an industrial setting, who perform a decision-making task together with an AI-agent possessing no visual human-like characteristics. Based on the model of Responsibility in Hybrid Societies we show that workers assign capacities of social perception and moral responsibility to their AI-based counterpart. We present first evidence that theoretically derived models of social perception and moral responsibility are applicable in industrial settings.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585906
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585906
KW  - Human-AI-Collaboration
KW  - modern work
KW  - qualitative analysis
KW  - responsibility
KW  - SPRS social perception of robots scale
ER  - 

TY  - CONF
TI  - Exploring Interaction, Movement and Video Game Experience in an Educational VR Experience
AU  - Sun, Yilu
AU  - Pandita, Swati
AU  - Madden, Jack
AU  - Kim, Byungdoo
AU  - Holmes, N. G.
AU  - Won, Andrea Stevenson
T3  - CHI EA '23
AB  - Findings of increased engagement and preference for XR learning are well-established. However, there are concerns that the high sense of presence that virtual reality can engender may increase cognitive load and actually decrement learning outcomes [16]. Recent research has highlighted the importance of understanding the contributions of embodiment to learning in virtual reality [13]. In this paper, we analyze previously unpublished secondary data of participant interactions, movements, and presence ratings to investigate how user behavior may predict learning in embodied, immersive virtual environments, and how this can guide the development of broadly useful XR interventions. We find that increased global movement predicts higher post-test scores, but more embodied interactions (i.e., dragging the Moon using hand gestures rather than button presses) do not improve learning. Rather, actions linked to greater familiarity with video game play predict greater learning of the subject matter.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585882
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585882
KW  - Embodiment
KW  - Learning
KW  - Movement
KW  - Presence
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Exploring Gesture and Gaze Proxies to Communicate Instructor’s Nonverbal Cues in Lecture Videos
AU  - Wagner, Tobias
AU  - Hirzle, Teresa
AU  - Huckauf, Anke
AU  - Rukzio, Enrico
T3  - CHI EA '23
AB  - Teaching via lecture video has become the defacto standard for remote education, but videos make it difficult to interpret instructors’ nonverbal referencing to the content. This is problematic, as nonverbal cues are essential for students to follow and understand a lecture. As remedy, we explored different proxies representing instructors’ pointing gestures and gaze to provide students a point of reference in a lecture video: no proxy, gesture proxy, gaze proxy, alternating proxy, and concurrent proxies. In an online study with 100 students, we evaluated the proxies’ effects on mental effort, cognitive load, learning performance, and user experience. Our results show that the proxies had no significant effect on learning-directed aspects and that the gesture and alternating proxy achieved the highest pragmatic quality. Furthermore, we found that alternating between proxies is a promising approach providing students with information about instructors’ pointing and gaze position in a lecture video.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585842
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585842
KW  - Education
KW  - Eye-tracking
KW  - Gaze
KW  - Gesture
KW  - Lecture video
ER  - 

TY  - CONF
TI  - Exploratory Thematic Analysis of Crowdsourced Photosensitivity Warnings
AU  - South, Laura
AU  - Yildirim, Caglar
AU  - Pavel, Amy
AU  - Borkin, Michelle A.
T3  - CHI EA '23
AB  - Films often include sequences of flashing lights for visual effect that may inadvertently trigger seizures when viewed by individuals with photosensitive epilepsy (PSE). Warnings about photosensitive risk in films can help people with PSE make informed decisions about their personal safety, but little is known about how to design such warnings and what information to include. To better understand the design space for photosensitive risk warnings, we conducted a qualitative analysis of 265 crowdsourced warnings about flashing lights in films. We find that the crowdsourced warnings were tightly coupled to the scenic and temporal contexts of the films being described, unlike current practices for labeling media with potentially seizure-inducing sequences using general warnings that are not specific to the media at hand. As technological capabilities for detecting seizure-inducing sequences continue to improve, understanding how to effectively communicate this information to individuals with photosensitive epilepsy is critical for ensuring accessibility.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585649
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585649
KW  - accessibility
KW  - film
KW  - photosensitive epilepsy
KW  - seizures
ER  - 

TY  - CONF
TI  - Exploring Creativity Support for Concept Art Ideation
AU  - Williford, Blake
AU  - Ray, Samantha
AU  - Koh, Jung In
AU  - Cherian, Josh
AU  - Taele, Paul
AU  - Hammond, Tracy
T3  - CHI EA '23
AB  - Creatives often struggle with fixation on a narrow set of ideas. There is potential for co-creative systems to stimulate creatives in new and powerful ways. We sought to lay a foundation for such systems with an exploratory study. We recruited 20 university students and asked them to rapidly draw a series of creature concepts with two technology probes, one of which generates ambiguous stimuli from user strokes. We analyzed the 240 sketches visually and discovered that while most participants were fixated on humanoid forms, those that began sketching with the ambiguous stimuli first were provoked to explore more unusual varieties (p &lt; 0.01). We also interviewed participants and used thematic analysis to analyze the data. While some participants resisted the partial loss of control and freedom, most believed the stimuli encouraged more divergent exploration and holistic thinking, and they acknowledged their potential benefit in the earliest stages of the ideation process.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585684
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585684
KW  - Co-creative System
KW  - Concept Art
KW  - Creativity Support
KW  - Drawing
KW  - Human-Computer Interaction
KW  - Sketching
KW  - User Experience Design
ER  - 

TY  - CONF
TI  - Exploration of verbal descriptions and dynamic indoors environments for people with sight loss
AU  - Alrashidi, Abdulaziz
AU  - Cudd, Peter
AU  - Abhayaratne, Charith
AU  - Gotoh, Yoshihiko
T3  - CHI EA '23
AB  - Our study explored the navigational challenges of an unfamiliar room (with moving furniture and people) and what verbal guidance would be useful for visually impaired people(VIPs). A mainly qualitative approach of observation and interviews with ten VIPs revealed a lot about the challenges, guidance content and delivery. Further research is indicated to explore effective implementation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585883
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585883
KW  - Dynamic Indoor environments
KW  - Navigation
KW  - Visually Impaired
ER  - 

TY  - CONF
TI  - Exploration of Bare-Hand Mid-Air Pointing Selection Techniques for Dense Virtual Reality Environments
AU  - Shi, Rongkai
AU  - Zhang, Jialin
AU  - Yue, Yong
AU  - Yu, Lingyun
AU  - Liang, Hai-Ning
T3  - CHI EA '23
AB  - Target selection in dense virtual reality (VR) environments is challenging. Prior work has explored different controller-based raycasting techniques to assist target selection in such environments. However, limited research has focused on selection via mid-air barehand, which represents another major input metaphor for immersive environments. In this paper, we first review the existing raycasting selection techniques for dense VR environments. Based on this, we propose and develop two freehand pointing selection techniques—HandDepthCursor and HandConeGrid, and implement MultiFingerBubble, a recently-proposed technique. We then conduct a user study to compare and evaluate their performance and experience in a target selection task in dense VR environments. Our results suggest that HandDepthCursor and HandConeGrid led to significantly faster and more accurate selection performance, and lower perceived workload and arm fatigue. In addition, HandConeGrid showed a distinct advantage in high-density environments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585615
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585615
KW  - bare-hand interaction
KW  - dense environment
KW  - head-mounted displays
KW  - object selection
KW  - pointing selection
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Experts prefer text but videos help novices: an analysis of the utility of multi-media content
AU  - Song, Hayeong
AU  - Healey, Jennifer
AU  - Siu, Alexa F
AU  - Wigington, Curtis
AU  - Stasko, John
T3  - CHI EA '23
AB  - Multi-media increases engagement and is increasingly prevalent in online content including news, web blogs, and social media, however, it may not always be beneficial to users. To determine what types of media users actually wanted, we conducted an exploratory study where users got to choose their own media augmentation. Our findings showed that users desired different amounts and types of media depending on their familiarity with the content. To further investigate this difference, we created two versions of a media augmented document, one designed for novices and one designed for experts. We evaluated these prototypes in a two-way between-subject study with 48 participants and found that while multi-media enhanced novice readers’ perception of usability (p = .0100) and helped them with reading time (p = .0427), time on task (p= .0156), comprehension (p = .0161), experts largely ignored multi-media and primarily utilized text.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585900
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585900
KW  - animated
KW  - augmentation
KW  - customization
KW  - document intelligence
KW  - expert
KW  - gif
KW  - image
KW  - multi-media
KW  - novice
KW  - reading conditions
KW  - text
KW  - video
ER  - 

TY  - CONF
TI  - Expectation vs Reality in Users’ Willingness to Delegate to Digital Assistants
AU  - Svikhnushina, Ekaterina
AU  - Schellenberg, Marcel
AU  - Niedbala, Anna K
AU  - Barisic, Iva
AU  - Miles, Jeremy N
T3  - CHI EA '23
AB  - We report results of a survey with 2500 US-based users of popular digital assistants (DAs) to understand and prioritize the factors that drive consumer adoption. Using structural equation modelling, we investigated the relationship between respondents’ behavioural intentions to delegate tasks to their DAs and two predictor layers: DA (users’ attitudes and familiarity with them) and task factors (need for control/transparency, subjectivity, risk, self-efficacy, and frequency), mediated by a values layer (trust, perceived ease of use and usefulness). Perceived usefulness and trust were strong direct predictors of willingness to delegate. Both DA-related factors had indirect effects, with a surprising negative influence of familiarity on both trust and usefulness. Our novel findings of task-related effects on the value factors may explain this disparity. These results imply a mismatch between users’ expectations for DAs and their actual experiences. We interpret these findings in light of related work and derive implications for practitioners.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585763
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585763
KW  - digital assistant
KW  - expectations
KW  - SEM
KW  - technology adoption
KW  - trust
KW  - willingness to delegate
ER  - 

TY  - CONF
TI  - Evaluating Mobile Apps Targeting Personal Goals
AU  - Lolla, Sruzan
AU  - Sas, Corina
T3  - CHI EA '23
AB  - Goals are fundamental to everyday life and are reflected in the growing HCI research in personal informatics and behaviour change. Besides academic work, a wealth of commercial mobile apps have also been developed to support users in setting their goals and achieving them. Despite their popularity, such apps, however, have been limitedly evaluated. We report a functionality review grounded in auto-ethnography and expert evaluation of the 21 most popular such apps selected from 1336 apps on the Google Play Store. We used a hybrid approach based on goal-setting theory for the evaluation. Findings indicate the more nuanced functionality of goal capturing, extending those explored in previous work for goal setting, monitoring and maintaining motivation. They also highlight the importance of distinguishing between high and low-level goals and their domains since most apps support multiple rather than individual goals. We conclude with design implications to support the setting of multiple personal goals at both high and low levels and across different domains, the use of consistent terms for distinguishing goals at different levels, and for visualizing the relationships among multiple goals.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585725
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585725
KW  - Goal capturing
KW  - Goal domains
KW  - Goal monitoring
KW  - Goal setting theory
KW  - Goal tracking
KW  - Goals
KW  - Maslow’s hierarchy
KW  - Motivation
ER  - 

TY  - CONF
TI  - Evaluating Accessible Navigation for Blind People in Virtual Environments
AU  - Piçarra, Manuel
AU  - Rodrigues, André
AU  - Guerreiro, João
T3  - CHI EA '23
AB  - Blind people that want, and play digital games will often find barriers and a lack of accessibility features available when exploring virtual environments. Prior work has found navigation to be the primary barrier players face, and the one players develop the most coping mechanisms to overcome. In this paper, we explore a set of techniques that augment or are even embedded in the game design to facilitate navigation and spatial awareness of virtual environments. We conducted a user study where seven blind participants faced a number of navigational tasks in a virtual environment with these techniques and shared their perspectives on the experience. We contribute with an exploration of a catalog of techniques used to facilitate the navigation of virtual spaces and a reflection of their impact on players’ experience, highlighting avenues for future work in the field.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585813
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585813
KW  - accessibility
KW  - accessible virtual environments
KW  - blind
KW  - design guidelines
KW  - people with visual impairments
ER  - 

TY  - CONF
TI  - Establishing Awareness through Pointing Gestures during Collaborative Decision-Making in a Wall-Display Environment
AU  - Maquil, Valérie
AU  - Anastasiou, Dimitra
AU  - Afkari, Hoorieh
AU  - Coppens, Adrien
AU  - Hermen, Johannes
AU  - Schwartz, Lou
T3  - CHI EA '23
AB  - Sharing a physical environment, such as that of a wall-display, facilitates gaining awareness of others’ actions and intentions, thereby bringing benefits for collaboration. Previous studies have provided first insights on awareness in the context of tabletops or smaller vertical displays. This paper seeks to advance the current understanding on how users share awareness information in wall-display environments and focusses on mid-air pointing gestures as a foundational part of communication. We present a scenario dealing with the organization of medical supply chains in crisis situations, and report on the results of a user study with 24 users, split into 6 groups of 4, performing several tasks. We investigate pointing gestures and identify three subtypes used as awareness cues during face-to-face collaboration: narrative pointing, loose pointing, and sharp pointing. Our observations show that reliance on gesture subtypes varies across participants and groups, and that sometimes vague pointing is sufficient to support verbal negotiations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585830
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585830
KW  - Awareness
KW  - Collaborative Decision-Making
KW  - Large Interactive Displays
KW  - Pointing Gestures
KW  - User Study
KW  - Wall Displays
ER  - 

TY  - CONF
TI  - Enhancing ESL Learners’ Experience and Performance through Gradual Adjustment of Video Speed during Extensive Viewing
AU  - Chung, Yu-Jung
AU  - Hsu, Chen-Wei
AU  - Chan, Meng-Hsun
AU  - Cherng, Fu-Yin
T3  - CHI EA '23
AB  - Learning different languages is a trend among global learners as it improves international communication. One way to learn a second language outside the classroom is through extensive viewing, which helps learners become more familiar with the target language. However, previous research has suggested that directly adjusting the video speed can disrupt learning. This study explores whether gradually adjusting the speed instead can alleviate these disruptions. We conducted an experiment (N=32) with English-as-a-second-language (ESL) participants to compare the cognitive load, flow state, and video comprehension when using the direct and gradual speed adjustment methods to accelerate or decelerate videos. Using both objective measurements, including pupil diameter, and subjective surveys, we found that the gradual method resulted in a higher flow state and improved video comprehension. These findings suggest potential directions for future research on the effects of speed adjustments on ESL learners during extensive viewing.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585804
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585804
KW  - Cognitive Load
KW  - ESL Learner
KW  - Extensive Viewing
KW  - Flow State
KW  - Playback Speed
KW  - Pupillometry
ER  - 

TY  - CONF
TI  - Enhancing Notification Awareness for Online Presenters via a Wrist-Worn Device
AU  - Schäfer, René
AU  - Wagner, Tobias
AU  - Lavnikevich, Ulyana
AU  - Borchers, Jan
T3  - CHI EA '23
AB  - The practice of giving presentations online has exploded during the Covid pandemic. However, in these settings, presenters often find themselves overlooking questions and feedback, e.g. via chat, from the audience, because the presenter’s screen is dominated by their slides, with other channels becoming less noticeable. This causes frustration among presenters and their audience alike. We investigate the impact of additional visual, auditory, and haptic cues for presenters in online scenarios, using a wrist-worn prototype. For this, we conducted a study where participants gave presentations via the videoconferencing tool Zoom on specific topics while trying to notice and correctly identify incoming notifications. Our findings indicate that supplementary notifications can be helpful in online presentations without inappropriately disturbing the presenter.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585855
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585855
KW  - Audience Feedback
KW  - Interaction Modalities
KW  - Notification Awareness
KW  - Online Presenters
KW  - Peripheral Recognition
KW  - Wrist-Worn
ER  - 

TY  - CONF
TI  - Enhanced Auditoriums for Attending Talks in Social Virtual Reality
AU  - Weissker, Tim
AU  - Pieters, Leander
AU  - Kuhlen, Torsten
T3  - CHI EA '23
AB  - Replicating traditional auditorium layouts for attending talks in social virtual reality often results in poor visibility of the presentation and a reduced feeling of being there together with others. Motivated by the use case of academic conferences, we therefore propose to display miniature representations of the stage close to the viewers for enhanced presentation visibility as well as group table arrangements for enhanced social co-watching. We conducted an initial user study with 12 participants in groups of three to evaluate the influence of these ideas on audience experience. Our results confirm the hypothesized positive effects of both enhancements and show that their combination was particularly appreciated by audience members. Our results therefore strongly encourage us to rethink conventional auditorium layouts in social virtual reality.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3585718
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3585718
KW  - Audience Experience
KW  - Head-Mounted Display
KW  - Multi-User
KW  - Social Interaction
KW  - Virtual Presentations
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Living Data Systems: Co-Designing Community-Based Methods And Local Technologies For Inclusive Socioeconomic Alternatives
AU  - Guerrero Millan, Carlos
T3  - CHI EA '23
AB  - This research project aims to collaborate with underserved communities leading social justice efforts through alternative economic practices, in the co-creation of a data model based on sets that members can collect to represent meaningful, contextual and social information. Data, understood from a cooperative-value and qualitative perspective, could be interesting for the common use of the group to interpret and exchange through non-monetary transactions, in contrast to the predominantly capital value mainstream networks. This system could facilitate group conversations on collective appropriation, ownership and adaptation processes through the co-design of local, situated technologies and alternative outputs of information. Furthermore, it could be significant for existing practices and goals around socioeconomic change, autonomy or activism.It is necessary to research the implementation of novel data collecting methods and data-driven systems focused on non-traditional, qualitative and plural representations of knowledge. This could be instrumental for understanding how to visualise and integrate omitted, hidden or underrepresented experiences, how to include marginalised individuals with different backgrounds into diverse decision-making processes and how to co-design new technologies that account for shared values. On a deeper level, it could help uncover new data epistemologies and definitions emerging from the construction of new collective knowledge platforms, understood as living systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577053
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577053
KW  - Community Economics
KW  - Data Commons
KW  - Design Justice
KW  - Design Research
KW  - Human Data Interactions
ER  - 

TY  - CONF
TI  - HEROES, Design of an Exergame for Balance Recovery of Stroke Patients for a Home Environment
AU  - Ruiz-Rodriguez, Aurora
AU  - Hermens, Hermie
AU  - van Asseldonk, Edwin
T3  - CHI EA '23
AB  - Stroke survivors suffer from balance impairment, causing an increased risk of falling. To recover balance, adequate stepping responses are key and these are practised by perturbing the patients during rehabilitation. Serious videogames, such as exergames, that train voluntary stepping can be found, but they don’t allow to practice fast recovery steps in people with stroke. In this paper, we propose the design of a serious exergame (HEROES) to train stepping responses of stroke patients in a home environment. For this, we employed recent findings of action observation and motor imagery. We followed an iterative user-centred methodology to design the HEROES exergame. Stroke patients, physiotherapists and game designers were involved in every stage. The design of the HEROES exergame complies with the stroke accessibility guidelines, providing clear instructions and feedback. Therapeutic goals are defined by the progression of the level, ensuring to train paretic and non-paretic legs in a safe but challenging set-up.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577037
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577037
KW  - exergames
KW  - rehabilitation
KW  - serious videogames
KW  - Stroke patients
ER  - 

TY  - CONF
TI  - Exploring the Potential Role of Digital Technologies to Support Family Networks with Misinformation Correction
AU  - Scott, Lauren
T3  - CHI EA '23
AB  - As we navigate into a more digital world, information gets easier to produce and share, and the credibility of information comes into question. Individuals are exposed to misinformation on a regular basis, from multiple sources, and this misinformation can cause changes to behaviour and identity, and can have detrimental effects on individuals’ health and well-being. As misinformation spreads online, current research has focused on platform-based interventions to address these beliefs and to have a positive change on misinformed individuals’ behaviours. My thesis explores how technology can support trusted individuals such as family members in their efforts challenging misinformed belief. Through this work my aim is to build a better understanding of how family members currently address misinformed beliefs, and where the limitations with current digital interventions lie, to create a tool to assist these conversations within families, and ultimately reduce the impact misinformation has on our society.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577054
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577054
KW  - Correction
KW  - Family
KW  - Misinformation
ER  - 

TY  - CONF
TI  - Enabling Haptic Experiences Anywhere, Anytime
AU  - Teng, Shan-Yuan
T3  - CHI EA '23
AB  - While seminal screen-based computing technologies (e.g., desktop or VR/AR headsets) have evolved to respond to users’ needs for extreme freedom and mobility, the same cannot be said about rich haptic experiences (e.g., those that allow users to feel touch and forces). In my research I trace back the possible root causes to the way that haptic devices are engineered—to deliver realistic &amp; immersive sensations, haptics devices use large actuators, which leads to two interface issues: (1) cumbersome form-factors that obstruct the user's body and prevent users from engaging in other dexterous tasks; and (2) extreme power consumption that causes these devices to have a short-lived life or even be tethered—all of which are incompatible with the users’ needs and desires for freedom and mobility. The consequence of these two issues is that, as of now, haptics is mostly a tool for VR, but is absent from other interactive contexts, especially those where users move freely and interact with everyday tools (e.g., AR). As such, in my research I posit we need to redesign haptic devices with users in mind rather than only guided by the metric of virtual haptic realism. As such, I propose that (1) haptic devices need to play well with everyday tasks (e.g., they cannot prevent users from interacting with their loved ones or with their everyday tools), and (2) haptic devices need to be always available (without the need for bulky batteries or cables). In the following, I demonstrate two examples of wearable haptic devices that I engineered to illustrate that these goals are not just possible but desirable.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577052
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577052
KW  - Augmented Reality
KW  - Haptics
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Disentangling Online Manipulation Strategies from the Perspective of Digital Inequalities
AU  - Sánchez Chamorro, Lorena
T3  - CHI EA '23
AB  - There is a growing concern about the use of manipulative mechanisms in online interfaces and the underlying harm to users’ autonomy under the label of ’dark patterns’. The effect of these mechanisms, especially in vulnerable populations, is still under-researched. The present doctoral dissertation aims to understand the conditions under which users are less likely to resist manipulation, following the idea of digital inequalities in manipulative designs. This dissertation expects to contribute in two ways. First, bringing empirical insights about the effectiveness of manipulative mechanisms, especially in low digital skilled populations, and providing enablers that allow them to resist manipulation. Second, providing with guidelines that support practitioners in designing user interfaces for these populations and policymakers in improving the current regulations on manipulative designs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577060
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577060
KW  - Dark patterns
KW  - deceptive design
KW  - digital inequalities
KW  - manipulative design
ER  - 

TY  - CONF
TI  - Digital Storytelling for the Support of Maternal and Child-wellbeing Through Community-based Co-design
AU  - Farao, Jaydon
T3  - CHI EA '23
AB  - In rural, under-resourced, and marginalised regions, digital health information has become a tool with which to reach new and expecting parents for the care of their and their children's wellbeing. However, the types of health information shared is often inaccessible since “top-down” approaches are utilised in creating and sharing content, with limited input by recipients of the information. Furthermore, access to health information has been prioritised over the learning thereof, indicating a need to refocus efforts on how health information is curated. I aim to explore how community-based co-design can be leveraged to design and develop digital storytelling content for the support of maternal and child-wellbeing (MCWB). With the consideration of intersectional feminist methods, participatory visual techniques, and Lambert's taxonomy of participatory media practices, I seek to understand existing storytelling and communication practices, as well as dissemination mechanisms in two rural South African communities for the support of MCWB. This will be achieved through four phases, namely understanding, making, connecting, and embracing, using in-depth interviews, photovoice, generative workshops, and focus groups. I am interested in how various community stakeholders participate in the MCWB and health information sharing ecosystem, thus I will be including mothers, fathers, other caregivers, healthcare workers and community leaders. With the creation of digital story artefacts, community-based methods and techniques, and an understanding of health information content creation and sharing via community-based co-design, the intended contributions are: describing how existing communal practices can influence novel approaches to promoting MCWB; developing an understanding of how different degrees of participation in the creation of digital stories impact how people create, share, and learn from digital stories; advances in community-based co-design for rural and under-resourced populations; and explaining how digital stories could impact MCWB within a community.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577050
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577050
KW  - community-based co-design
KW  - digital storytelling
KW  - maternal and child-wellbeing
ER  - 

TY  - CONF
TI  - Designing Interactive Experiences For Gut Health Engagement and Reflection
AU  - Pasumarthy, Nandini
T3  - CHI EA '23
AB  - Human gut health is the epicentre of human health and well-being. We engage in microscopic interactions in our day-to-day lives that influence our gut health, however, our understanding of this relationship is scarce. Current approaches to engage people on gut-related factors are heavily jargonised, lacking real-world application and focus on disease-causing aspects, thus limiting motivation to engage with gut health. Research suggests that games can act as powerful tools for engagement and reflection on this topic. This PhD research explores the design of two games to understand the key game design features that enable engagement with gut health. The results from testing these games will be generalised to inform the design of physical and digital games for engagement and reflection on health.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577058
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577058
KW  - gut health
KW  - gut microbiome
KW  - human-food interaction
KW  - persuasive games
KW  - serious games
ER  - 

TY  - CONF
TI  - Designing For Sustainable and Equitable Agricultural Labor and Technologies
AU  - Doggett, Olivia
T3  - CHI EA '23
AB  - This dissertation project begins from the literature-informed premise that dominant and historical conditions which have shaped the agricultural industry, namely scientific agriculture and racialized systems of migrant labor, may be perpetuated by today’s commercial agtech. Implications for commercial agtech carrying these dominant values are that emerging agtech may continue to exploit racialized labor and exclude sustainable farming priorities. My research investigates how these labor production systems, which have historically been used for commercial farming practices, may be redirected to support more sustainable and socially equitable farming. My project is situated between Ontario, Canada, where the largest concentration of migrant farmers work and Oaxaca, Mexico, the home state of many migrant farmers employed in Ontario. I rely upon qualitative and design research methods to explore how migrant farmers are affected by agtech, how migrant farmers’ agricultural knowledge and expertise are interpreted and used transnationally, and how Canadian growers and agtech designers envision how migrant labor fits into alternative food system futures.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577040
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577040
KW  - agriculture
KW  - climate change
KW  - digital agriculture
KW  - environmental justice
KW  - farming
KW  - food systems
KW  - migrant labor
KW  - migration
KW  - sustainability
ER  - 

TY  - CONF
TI  - Designing for Inclusivity and Accessibility of Mental Health Technologies
AU  - Sien, Sang-Wha
T3  - CHI EA '23
AB  - Mental health has been a serious concern among university students, and minority students are known to be particularly vulnerable due to underutilization of mental health services and unfamiliarity with Western health care approaches. My research explores the accessibility and inclusivity of mental health technologies, mainly focusing on how the perspectives and experiences of university students of diverse cultural backgrounds, visible minorities, and international students can inform more inclusive designs. In my first study, I uncovered cultural and communication barriers that suggest that more scaffolding is needed for these students to engage with technologies for their mental health, including supporting storytelling and skill learning from peers as well as providing cultural support and representation. In my second study, I co-designed with campus mental health experts and international students to understand what features and support they desired in these technologies, discovering that stories once again featured heavily in their ideas. For the next two studies, I plan to build and evaluate prototypes that feature a novel storytelling peer support platform.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577038
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577038
KW  - culture
KW  - design thinking
KW  - inclusive designs
KW  - international students
KW  - mental health
KW  - minority students
KW  - peer support
KW  - social support
KW  - university students
ER  - 

TY  - CONF
TI  - Designing for In-Home Long-Term Family-Robot Interactions: Family Preferences, Connection-Making, and Privacy
AU  - Cagiltay, Bengisu
T3  - CHI EA '23
AB  - Participatory approaches to designing technology with families, for families allow designers to have a first-hand understanding of needs, desires, and preferences of families toward new technology. For example, in my prior work, I conducted participatory design studies with children and their families in order to design social robots that could facilitate long term interactions, with multiple users, in their homes. Our design sessions identified that children and families preferred an in-home robot to have the role of a companion or an assistant, be able to hold group interactions and participate in shared recreation activities, and had concerns about the robot’s ability to follow conversational privacy norms (i.e., within a family, what information is shared with whom). In a long-term field deployment, I explored how children engaged in dyadic interactions with a reading companion robot in their homes and how interactions with multiple family members formed with and around the robot. However, family-centered insights are limited in the Human-Robot Interaction field. In my research I aim to further explore long-term family-robot interactions in group settings, with social companion robots that serve as a playmate or a confidant. I seek to design social robots that can facilitate connection-making between family members and mitigate communication privacy conflicts in these group interactions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577035
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577035
KW  - Child-robot interaction
KW  - family-centered design
KW  - interaction design
KW  - multi-party
KW  - social robots
ER  - 

TY  - CONF
TI  - Designing for Appreciation: How Digital Spaces Can Support Art and Culture
AU  - Von Davier, Thomas Serban
T3  - CHI EA '23
AB  - Throughout history, a complex network of human actors shaped how the general public perceived art. Today, social media platforms and their algorithms influence artful experiences for billions. How has this changed the appreciation and perception of art? The role of visual art as items we use to define ourselves and our societies motivates research to explore how recommendation algorithms impact our ability to appreciate and perceive art. There are three aspects to explore: the art metadata and algorithm functionality, conversations with artworld experts, and redesigning digital art experiences. These three methods will follow open science practices and methods by releasing open-access datasets and research prototypes. Ultimately, this proposed thesis aims to contribute to theories of content base algorithmic recommendation and its role in presenting art and culture to users.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577041
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577041
KW  - art
KW  - datasets
KW  - recommendation algorithms
KW  - thesis proposal
ER  - 

TY  - CONF
TI  - Designing Digital Content to Accommodate for Colour Vision Deficiency
AU  - Geddes, Connor
T3  - CHI EA '23
AB  - Digital content and designs feature coloured components in an effort to provide information, however, this information can be lost for those who have Colour Vision Deficiency (CVD). Over the past three decades research to provide digital aids has progressed by creating both tools that enable for simulations of types and severities of CVD and various corrections through recolouring. However, simulations have often been overvalued and in many cases fully replace CVD lived experiences in design, and recolouring tools tend to take a destructive approach modifying all colours in an attempt to ‘correct’ for CVD. This research first looks to understand the dangers in relying on simulations for both designs and assistive tools. Next, I look to understand the current perspectives and use cases of current assistive technologies like recolouring by those with CVD. Finally, I develop guidelines to show how design can be done to better accommodate those with CVD in the design of coloured interfaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577047
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577047
KW  - Colour Patterns
KW  - Colour Vision Deficiency
KW  - Colour Vision Deficiency Simulation
KW  - Inclusive Design
KW  - Recolouring
ER  - 

TY  - CONF
TI  - Designing Data Science Software for Social Care Organisations
AU  - Reinmund, Tyler John
T3  - CHI EA '23
AB  - Within the last few decades, data science has risen towards the top of agendas in public services such as adult social care. Concomitant with this ever-increasing appetite for data science is an expanding catalogue of challenges associated with developing, deploying, and maintaining data science software: choosing the appropriate, if any, analytical technique to use; balancing competing conceptions of success; and sustaining user adoption. In my thesis, I argue that these are sociotechnical challenges: issues that arise in the tension between what people do, and how data science software supports, limits, and, crucially, changes what they do. Through design science research, this thesis will develop, demonstrate, and evaluate a design approach for data science software that attempts to address such sociotechnical challenges. The empirical sites in which these research activities will take place are live data science projects with local government organisations responsible for adult social care services in England. The resultant approach will include a conceptual model for sociotechnical data science, process guidance and methods for applying the design approach, and results from applying the approach in a real-world data science project in collaboration with an industry partner.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577062
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577062
KW  - data science
KW  - design science research
KW  - social care
KW  - sociotechnical challenges
ER  - 

TY  - CONF
TI  - Designing Accessible Visualizations for People with Intellectual and Developmental Disabilities
AU  - Wu, Keke
T3  - CHI EA '23
AB  - Visualization amplifies cognition and helps a viewer see the trends, patterns, and outliers in data. However, conventional visualization tools and guidelines do not actively consider the unique needs and abilities of people with Intellectual and Developmental Disabilities (IDD), leaving them excluded from data-driven activities and vulnerable to ethical issues in everyday life. My dissertation work explores the challenges and opportunities of cognitively accessible visualization. Through mixed-method approaches and close collaboration with people with IDD, my team and I ran experiments and developed guidelines to improve current visualizations, we interviewed people with IDD and gained initial understandings of their daily data experiences, and we are currently in the process of revising a participatory design workshop to create accessible visualizations for and with this population. For the remaining dissertation work, I hope to further expand our knowledge of cognitively accessible visualization, translating what I have learned from these experiences into a graphical user interface that supports people with IDD with their self-advocacy and self-expression using personally relevant data. My ultimate career goal is to theorize cognitively accessible visualization and empower people with IDD to make informed decisions and generate meaningful discoveries through accessible visual analytics.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577048
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577048
KW  - Cognitive Accessibility
KW  - Personal Informatics
KW  - Physicalization
KW  - Storytelling
ER  - 

TY  - CONF
TI  - Collaboratively Mitigating Racial Disparities in Automated Speech Recognition and Language Technologies with African American English Speakers: Community-Collaborative and Equity-Centered Approaches Toward Designing Inclusive Natural Language Systems
AU  - Cunningham, Jay L.
T3  - CHI EA '23
AB  - Automated speech recognition (ASR) systems that rely on natural language processing (NLP) techniques are becoming increasingly prevalent within people's everyday lives. From virtual assistants integrated into mobile devices (e.g. Apple's Siri), smart home assistants (e.g. Google's Nest; Amazon's Alexa/Echo), and vehicles (e.g. Apple's CarPlay; Android Auto); to software tasks such as automatic translation, automatic captioning, automatic subtitling and even hands-free computing, ASR systems are core components of IoT (Internet of things) devices and applications. However, scholars have begun to show that with these increasing innovations and system capabilities, emerges fairness-related harms of user experiences and racial disparities that negatively impact African American speakers of African American Vernacular English (AAVE). As users of ASR, AAVE speakers’ language is less accurately recognized and processed, leading to inequitable interactions among this ethnolect community. My graduate research seeks to address this challenge by developing and validating community-collaborative methods to innovate responsible approaches toward designing more representative and equitable ASR language technologies that accommodate African American speakers of AAVE.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577057
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577057
KW  - Action Research
KW  - Co-Design
KW  - Community-Based Participatory Research
KW  - Equity Centered Design
KW  - Human Computer Interaction (HCI)
KW  - Inclusive Design
KW  - Natural Language Processing
KW  - Participatory Design
KW  - Responsible Artificial Intelligence (AI)
ER  - 

TY  - CONF
TI  - Crafting Human-AI Collaborative Analysis for User Experience Evaluation
AU  - Kuang, Emily
T3  - CHI EA '23
AB  - AI has been increasingly adopted in user experience (UX) analysis, in which UX evaluators review test recordings to identify usability problems. However, most AI-infused systems apply fully automatic approaches, leading to distrust from UX evaluators. In my dissertation work, we consider AI as assisting, not replacing human judgment. Through an international survey, we investigated the current practices and challenges of UX evaluators and identified an opportunity for AI assistance. We then studied nuanced cooperative work between UX evaluators and AI, by employing either non-interactive visualizations or interactive conversational assistants (CAs). The next steps include building upon our findings about the reactive Q&amp;A dynamic with CAs, by exploring how a proactive approach or a combination of visualizations and CAs may better support UX evaluators. This research will identify interactions and representations that give rise to productive and trusting collaborations with AI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577042
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577042
KW  - Conversational agents
KW  - Human-AI collaboration
KW  - Usability testing
KW  - User experience
ER  - 

TY  - CONF
TI  - Conceptualizing and Rethinking the Design of Cross-platform Creator Moderation
AU  - Ma, Renkai
T3  - CHI EA '23
AB  - My doctoral research explores how content creators experience creator moderation across different platforms through mixed methods. Through qualitative methods such as semi-structured interview, my prior work has gained understanding of the socioeconomic implications of creator moderation on creators, the fairness and bureaucracy challenges creators face, and what transparency design requires to address these challenges. My proposed future work will first quantitatively identify what algorithmic moderation design affects creators’ perceived transparency, fairness, and accountability of creator moderation across different platforms. Then, I will co-design with creators and commercial moderators from different platforms to rethink what and how creator moderation can take creators’ interests into account. My dissertation aims to contribute to HCI and CSCW fields by conceptualizing the notion of creator moderation and detailing design considerations for empowering creators.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577049
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577049
KW  - content creators
KW  - content moderation
KW  - Creator moderation
ER  - 

TY  - CONF
TI  - Bring-Your-Own Input: Context-Aware Multi-Modal Input for More Accessible Virtual Reality
AU  - Wentzel, Johann
T3  - CHI EA '23
AB  - Virtual reality applications make assumptions about user ability which may be difficult or even impossible to meet by people with limited mobility. However, we can increase the accessibility of these applications by taking advantage of the device combinations and usage contexts that people with mobility limitations already employ. By designing context aware multi-modal interfaces which gracefully adapt not only to the user’s input devices, but also to surrounding usage context like body or workspace position, we can meaningfully improve the overall accessibility of spatial computing. My research plan is threefold: first, qualitative research reveals how people with mobility limitations combine input devices to overcome accessibility barriers (published at CHI 2022). Next, we categorize these combinations based on their input dimensions, and develop a study of gracefully degrading input fidelity to understand how device combinations’ differing input space affects VR usage. Finally, we examine how the user’s surrounding context affects VR input and output, by exploring the design space of context-aware interfaces which adapt to changes in the user’s body position, output device (headset or desktop), or workspace proximity. My overall goal is to show how intelligent adaptation to input device combinations and surrounding input context can lead to more accessible spatial interfaces, and to provide actionable recommendations for designers and researchers creating accessible VR experiences.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577056
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577056
KW  - accessibility
KW  - controlled experiments
KW  - interaction techniques
KW  - spatial interfaces
ER  - 

TY  - CONF
TI  - Beyond Text-to-Image: Multimodal Prompts to Explore Generative AI
AU  - Liu, Vivian
T3  - CHI EA '23
AB  - Text-to-image AI systems have proven to have extraordinary generative capacities that have facilitated widespread adoption. However, these systems are primarily text-based, which is a fundamental inversion of what many artists are traditionally used to: having full control over the composition of their work. Prior work has shown that there is great utility in using text prompts and that AI augmented workflows can increase momentum on creative tasks for end users. However, multimodal interactions beyond text need to be further defined, so end users can have rich points of interaction that allow them to truly co-pilot AI-generated content creation. To this end, the goal of my research is to equip creators with workflows that 1) translate abstract design goals into prompts of visual language, 2) structure exploration of design outcomes, and 3) integrate creator contributions into generations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577043
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577043
KW  - co-creative AI
KW  - creativity support tools
KW  - large language models
KW  - multimodal
KW  - prompt engineering
KW  - prompting
KW  - text-to-image generation
ER  - 

TY  - CONF
TI  - A Methodology and a Tool to Support the Sustainable Design of Interactive Systems: Adapting systemic design tools to model complexity in interaction design
AU  - Bornes, Laetitia
T3  - CHI EA '23
AB  - Sustainable HCI was initially structured along two axes: sustainability in design, i.e. reducing the material impact of software and hardware, and sustainability through design, i.e. influencing user behavior to reduce energy consumption. These approaches have been criticized for being reductive and insufficient in the face of the systemic problem of ecological transition. Some voices in the HCI community call for a broader consideration of non-human aspects in HCI and argue that new methods and tools should be developed for this purpose. The thesis aims at proposing a methodology to understand the interactions between the system to be designed (e.g. agricultural robot) and the dynamics of the socio-technical and social system (e.g. the agriculture and food sectors), in order to avoid simplistic solutions that could be counter-productive (e.g. rebound effect). It draws on the methods, tools, and techniques of systemic design (a recent field of research that brings together design and systems thinking) in order to build, with the stakeholders and the help of experts, a model of the socio-technical system, its dynamics, and its possible interactions with the system to be designed. The aim is not to build a "digital twin" of the socio-technical system from which one could predict its evolution, but rather to co-build a handmade and approximate model to support debate, to inform decisions, and to compare scenarios. To this end, the thesis proposes a "quali-quantitative" modeling tool based on the formalism of causal loop diagrams.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577055
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577055
ER  - 

TY  - CONF
TI  - A Human-Centered Approach to Improving Adolescent Real-Time Online Risk Detection Algorithms
AU  - Alsoubai, Ashwaq
T3  - CHI EA '23
AB  - Computational approaches to detect the online risks that the youth encounter have presented promising potentials to protect them online. However, a major identified trend among these approaches is the lack of human-centered machine learning (HCML) aspect. It is necessary to move beyond the computational lens of the detection task to address the societal needs of such a vulnerable population. Therefore, I direct my attention in this dissertation to better understand youths’ risk experiences prior to enhancing the development of risk detection algorithms by 1) Examining youths’ (ages 13–17) public disclosures about sexual experiences and contextualizing these experiences based on the levels of consent (i.e., consensual, non-consensual, sexual abuse) and relationship types (i.e., stranger, dating/friend, family), 2) Moving beyond the sexual experiences to examine a broader array of risks within the private conversations of youth (N = 173) between 13 and 21 and contextualizing the dynamics of youth online and offline risks and the self-reports of risk experiences to the digital trace data, and 3) Building real-time machine learning models for risk detection by creating a contextualized framework. This dissertation provides a human-centered approach for improving automated real-time risk predictions that are derived from a contextualized understanding of the nuances relative to youths’ risk experiences.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577045
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577045
ER  - 

TY  - CONF
TI  - A Generative Framework for Designing Interactions to Overcome the Gaps between Humans and Imperfect AIs Instead of Improving the Accuracy of the AIs
AU  - Yakura, Hiromu
T3  - CHI EA '23
AB  - My research focuses on improving human-machine collaboration in the context of machine learning, particularly by recognizing the limitations and potential for errors in machine learning techniques and designing effective interactions for filling the gaps between humans and them. To this end, I have explored the application of machine learning in a variety of domains, such as malware analysis, music recommendation, conversation analysis, photo editing, and video-based learning. I also worked on clarifying the limitations of the current technologies by using adversarial approaches and qualitative methods. My thesis is planned to synthesize what I learned from these projects into design principles for constructing interactions that take full advantage of imperfect machine learning models. I particularly put emphasis on deriving principles that do not depend on the fine-tuning of the models, thereby providing a generative framework allowing researchers and practitioners to design a range of effective intelligent interactions without incurring significant computational and data collection costs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577036
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577036
ER  - 

TY  - CONF
TI  - Wheel time interaction: A demonstration of PedalMouse for healthy interaction: Wheel time interaction, a demonstration of PedalMouse: Towards less sedentary interaction with computers.
AU  - Dalton, Nick Sheep
AU  - Dow, Andy
T3  - CHI EA '23
AB  - We present PedalMouse a new kind of under desk input device. Sedentary behaviour has been identified as a contributing factor to the proliferation of various health conditions in developed countries. To mitigate the negative effects of prolonged sitting, researchers in the field of Human-Computer Interaction have examined the use of fitness devices that can be used concurrently with computers. Specifically, the focus has been on developing active interfaces, which aim to unobtrusively prompt and motivate users to remain physically active while engaged in computer-based tasks. Recent findings suggest that one reason individuals may cease movement while using computers is to devote their cognitive resources to high-demand tasks. This demonstration introduces PedalMouse, a device that utilises a set of under-desk pedals to manipulate the scrolling function of a desktop computer through a standard graphic user interface. The hypothesis underlying this innovation is that the integration of physical activity into the primary task will not divert the user's attention.The demonstration will show the operation of an ‘integrated active interface’.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583900
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583900
KW  - Active workstations
KW  - foot input
KW  - Health intervention
KW  - Workplace
ER  - 

TY  - CONF
TI  - Versatile Immersive Virtual and Augmented Tangible OR – Using VR, AR and Tangibles to Support Surgical Practice
AU  - Reinschluessel, Anke Verena
AU  - Muender, Thomas
AU  - Fischer, Roland
AU  - Kraft, Valentin
AU  - Uslar, Verena Nicole
AU  - Weyhe, Dirk
AU  - Schenk, Andrea
AU  - Zachmann, Gabriel
AU  - Döring, Tanja
AU  - Malaka, Rainer
T3  - CHI EA '23
AB  - Immersive technologies such as virtual reality (VR) and augmented reality (AR), in combination with advanced image segmentation and visualization, have considerable potential to improve and support a surgeon’s work. We demonstrate a solution to help surgeons plan and perform surgeries and educate future medical staff using VR, AR, and tangibles. A VR planning tool improves spatial understanding of an individual’s anatomy, a tangible organ model allows for intuitive interaction, and AR gives contactless access to medical images in the operating room. Additionally, we present improvements regarding point cloud representations to provide detailed visual information to a remote expert and about the remote expert. Therefore, we give an exemplary setup showing how recent interaction techniques and modalities benefit an area that can positively change the life of patients.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583895
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583895
KW  - AR
KW  - augmented reality
KW  - multiuser
KW  - point clouds
KW  - surgery
KW  - tangibles
KW  - virtual reality
KW  - VR
ER  - 

TY  - CONF
TI  - The Art of Privacy – A Theatrical Privacy Installation in Virtual Reality
AU  - Jung, Frederike
AU  - Kaiser, Jonah-Noël
AU  - Von Holdt, Kai
AU  - Heuten, Wilko
AU  - Meyer, Jochen
T3  - CHI EA '23
AB  - In a digitized world, matters of (online) privacy become increasingly immanent in people’s lives. Paradoxically, while consumers claim they care about what happens to their personal data, they undertake little to protect it. Awareness is a crucial step towards making informed privacy decisions. Therefore, we present the Art of Privacy, a Virtual Reality (VR) installation, generated in collaboration with theater artists. This Interactivity immerses viewers into the world of data and unfolds possible consequences of clicking ‘accept’, without reading the terms and conditions or privacy policies. With this work, we contribute an artistic VR installation, designed to shed new light on digital privacy, spark discussions and encourage self-reflection of personal privacy behaviors.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583893
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583893
KW  - media art
KW  - mixed reality
KW  - privacy
KW  - virtual reality
KW  - visualization
ER  - 

TY  - CONF
TI  - Towards More Inclusive and Accessible Virtual Reality: Conducting Large-scale Studies in the Wild
AU  - Schmelter, Thereza
AU  - Kruse, Lucie
AU  - Karaosmanoglu, Sukran
AU  - Rings, Sebastian
AU  - Steinicke, Frank
AU  - Hildebrand, Kristian
T3  - CHI EA '23
AB  - In this work, we demonstrate a mobile laboratory with virtual and augmented reality (VR/AR) technology housed in a truck that enables large-scale VR/AR studies and therapies in real-world environments. This project aims to improve accessibility and inclusiveness in human-computer interaction (HCI) methods, providing a platform for researchers, medical professionals, and patients to utilize laboratory hardware and space. The mobile laboratory is equipped with motion tracking technology and other hardware to allow for a range of user groups to participate in VR studies and therapies that could otherwise never partake or benefit from these services. Our findings, applications, and experiences will be presented at the CHI interactivity track, with the goal of fostering future research opportunities.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583888
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583888
KW  - evaluation
KW  - health
KW  - living lab
KW  - mobility
KW  - motion tracking
KW  - research
KW  - truck
KW  - virtual reality
ER  - 

TY  - CONF
TI  - TOUCHLESS: Demonstrations of Contactless Haptics for Affective Touch.
AU  - Chew, Sean
AU  - Dalsgaard, Tor-Salve
AU  - Maunsbach, Martin
AU  - Seifi, Hasti
AU  - Bergström, Joanna
AU  - Hornbæk, Kasper
AU  - Irisarri, Josu
AU  - Ezcurdia, Iñigo
AU  - Iriarte, Naroa
AU  - Marzo, Asier
AU  - Frier, William
AU  - Georgiou, Orestis
AU  - Sheremetieva, Anna
AU  - Kwarciak, Kamil
AU  - Stroinski, Maciej
AU  - Hemmerling, Daria Joanna
AU  - Maksymenko, Mykola
AU  - Cataldo, Antonio
AU  - Obrist, Marianna
AU  - Haggard, Patrick
AU  - Subramanian, Sriram
T3  - CHI EA '23
AB  - A set of demonstrators of contactless haptic principles is described in this work. The technologies are based on electrostatic piloerection, chemical compounds and ultrasound. Additionally, applications related to affective touch are presented, ranging from storytelling to biosignal transfer, accompanied with a simple application to edit dynamic tactile patterns in an easy way. The demonstrators are the result of the Touchless project, which is a H2020 european collaborative project that integrates 3 universities and 3 companies. These demostrators are contactless haptic experiences and thus facilitate the come-and-interact paradigm, where users can approach the demo booth and directly experience the applications without having to wear devices, making the experience fast and hygienic.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583913
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583913
KW  - affective touch
KW  - haptics
KW  - piloerection
KW  - ultrasound
ER  - 

TY  - CONF
TI  - ThermalPen: Adding Thermal Haptic Feedback to 3D Sketching
AU  - Hoffmann, Philipp Pascal
AU  - Elsayed, Hesham
AU  - Mühlhäuser, Max
AU  - Wehbe, Rina R.
AU  - Barrera Machuca, Mayra Donaji
T3  - CHI EA '23
AB  - Sketching in virtual 3D environments has enabled new forms of artistic expression and a variety of novel design use-cases. However, the lack of haptic feedback proves to be one of the main challenges in this field. While prior work has investigated vibrotactile and force-feedback devices, this paper proposes the addition of thermal feedback. We present ThermalPen, a novel pen for 3D sketching that associates the texture and colour of strokes with different thermal properties. For example, a fire texture elicits an increase in temperature, while an ice texture causes a temperature drop in the pen. Our goal with ThermalPen is to enhance the 3D sketching experience and allow users to use this tool to increase their creativity while sketching. We plan on evaluating the influence of thermal feedback on the 3D sketching experience, with a focus on user creativity in the future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583901
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583901
KW  - 3D Sketching
KW  - Creativity
KW  - Haptics
KW  - Pen-input
KW  - Thermal
KW  - User Experience
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - The Aachen Lab Demo: From Fundamental Perception to Design Tools
AU  - Borchers, Jan
AU  - Brocker, Anke
AU  - Hueber, Sebastian
AU  - Nowak, Oliver
AU  - Schäfer, René
AU  - Wagner, Adrian
AU  - Preuschoff, Paul Miles
AU  - Schirp, Lea Emilia
T3  - CHI EA '23
AB  - This year, the Media Computing Group at RWTH Aachen University turns 20. We celebrate this anniversary with a Lab Interactivity Demo at CHI that showcases not past achievements, but the range of currently ongoing research at the lab. It features hands-on interactive demos ranging from fundamental research in perception and cognition with traditional devices, such as experiencing input latency and Dark Patterns, to new input and output techniques beyond the desktop, such as user-perspective rendering in handheld AR and interaction with time-based media through conducting, to physical interfaces and the tools and processes for their design and fabrication, such as textile icons and sliders, soft robotics, and 3D printing fabric-covered objects.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583937
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583937
KW  - conducting
KW  - dark patterns
KW  - e-textiles
KW  - latency
KW  - soft robotics
KW  - user-perspective rendering
ER  - 

TY  - CONF
TI  - Textile Game Controller: Smart knee pads for Therapeutic Exercising
AU  - Zahn, Esther Friederike
AU  - Fischer, Hannah Friederike
AU  - Gleiß, Clara Elisabeth
AU  - Avramidis, Eleftherios
AU  - Joost, Gesche
T3  - CHI EA '23
AB  - In the field of physiotherapy and rehabilitation, location-independent training has gained importance. We present the further development of a wearable for this purpose including gamification to improve successful training. A wearable was developed to increase the motivation of patients to perform their prescribed physical therapy exercises at home. Extending a pair of smart trousers [12], smart knee pads connected to a gaming app were developed. A comparative qualitative study was conducted in order to explore how users react to playing a game as an extension of their physiotherapy session. The results of the user test show that the majority of respondents consider technology-enabled training to be helpful for their therapy success. Aspects of a "playful approach" and "competition" were named as the main motivating factors for the use of wearables in a therapy context. However, "competition" was only rated positively by male participants.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583899
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583899
KW  - Gait analysis
KW  - patient self-empowerment
KW  - Smart Trousers
KW  - Therapeutic Gaming
KW  - Wearable
ER  - 

TY  - CONF
TI  - REVEAL: REal and Virtual Environments Augmentation Lab @ Bath
AU  - Lutteroth, Christof
AU  - Jicol, Crescent
AU  - Clarke, Christopher
AU  - Proulx, Michael J
AU  - O'Neill, Eamonn
AU  - Petrini, Karin
AU  - Fitton, Isabel Sophie
AU  - Tor, Emilia
AU  - Yoon, Jinha
T3  - CHI EA '23
AB  - The REal and Virtual Environments Augmentation Lab (REVEAL) is a research centre for Human-Computer Interaction at the University of Bath with a focus on immersive technology. Virtual reality (VR) has the potential to change the way we experience the world and interact with each other. It can be used for a wide range of applications such as exercise, training, entertainment, and therapy. In this demo paper, we will showcase some of our VR research that has been published at CHI which can enhance VR experiences across three specific areas of study: learning with avatars, presence, and exergaming.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583934
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583934
KW  - Avatars
KW  - Exergaming
KW  - Learning
KW  - Presence
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Remapped Interfaces: Building Contextually Adaptive User Interfaces with Haptic Retargeting
AU  - Matthews, Brandon J
AU  - Reichherzer, Carolin
AU  - Smith, Ross T
T3  - CHI EA '23
AB  - User interfaces in virtual reality are dynamic and contextual, making it challenging to provide accurate haptic feedback. This paper presents a remapped interface system that leverages haptic retargeting to reuse a limited set of controls for a wide array of interfaces. The system enables the creation of virtual user interfaces that can adapt to the context in which they are being used and provide accurate haptic feedback. Using the system, we developed four exemplar applications: an immersive painting app, an extensible music production tool, a simulated aircraft cockpit and a user-configurable interface design tool.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583912
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583912
KW  - haptic retargeting
KW  - interaction
KW  - remapped interfaces
KW  - user interfaces
KW  - virtual reality
ER  - 

TY  - CONF
TI  - QRUco: Interactive QR Codes Through Thermoresponsive Embeddings
AU  - Jenss, Kay Erik
AU  - Mayer, Simon
T3  - CHI EA '23
AB  - Due to their low cost and ease of deployment, fiducial markers – primarily Quick Response (QR) codes – gained widespread popularity over the past decade. Given their original use cases in logistics, these markers were created with the goal of transmitting a single static payload. We introduce QRUco as an approach to create cheap yet interactive fiducial markers. QRUco uses thermochromic paint to embed three secondary markers into QR code finder patterns. Users may interact with these markers through rubbing or pressing/touching, thereby changing the appearance of the marker while leaving the primary QR code intact. In this paper, we present the QRUco concept and demonstrate that our proposed approach is effective. We emphasize that QRUco markers can be created cheaply and that they do not require any specialized scanning equipment. We furthermore discuss limitations of the proposed approach and propose application domains that would benefit from QRUco.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583923
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583923
KW  - ArUco
KW  - Interactive Fiducial Markers
KW  - Interactive QR
KW  - Passive Identification
KW  - Passive Interaction
ER  - 

TY  - CONF
TI  - Pushing Fabrication Research past the Makers
AU  - Baudisch, Patrick
AU  - Mueller, Stefanie
AU  - Roumen, Thijs
AU  - Lopes, Pedro
AU  - Kovacs, Robert
AU  - Shigeyama, Jotaro
AU  - Katakura, Shohei
AU  - Abdullah, Muhammad
AU  - Lempert, Conrad
AU  - Taraz, Martin
AU  - Rambold, Lukas
T3  - CHI EA '23
AB  - In this demonstration, we show a selection of twelve past CHI and UIST projects by our lab, which taken together aim at helping the field of digital fabrication using laser cutters transition past makers—and towards true non-experts, which we refer to as “consumers”. Our software systems provide such non-experts with domain knowledge (Kyub and fastForce), hardware and machine knowledge (Constructable, LaserOrigami, LaserStacker, springFit, kerf-canceling mechanisms, Assembler3 and autoAssembler), assembling laser-cut objects (FoolProofJoint, Roadkill, HingeCore) and demonstrate our contributions in solving these challenges over the course of twelve projects during the last few years.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583922
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583922
KW  - Laser cutting
KW  - Personal Fabrication
ER  - 

TY  - CONF
TI  - Phygital Samples: Enhancing Retail Experiences with Digital Augmentations of Physical Materials
AU  - Van Rheden, Vincent
AU  - Maurer, Bernhard
AU  - Murer, Martin
T3  - CHI EA '23
AB  - Retail industry is subject to radical developments. Due to mass-customization it is not possible for retailers to present all possible configurations in-store for customer to experience. Additionally, there is a shift towards online shopping. Even in the context of purchasing cars it is common to pre-order cars online, without having experienced the car upfront. Physical material samples are a way for customers to get an impression of what the whole product is like, without retailers actually having the whole in their store. This comes with the drawback that it is hard for customers to experience the whole based on a single sample for a specific configuration. Particularly in the case of samples that have been taken home, the connection with the whole product can be lost. In this paper we present Phygital Samples, combining physical and digital in the context of retail. Phygital Samples connect with a digital layer that fills the gap between the detailed sample and the whole product. The interaction mapping with the sample and digital ’whole’ or ’bigger picture’ is based on the interaction to perceive the material quality of the specific sample. In this demo, we present the Phygital Sample box containing four different samples illustrating our material interaction design approach.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583904
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583904
KW  - Interaction Design
KW  - Material Sample
KW  - Materiality
KW  - Phygital
KW  - Retail
ER  - 

TY  - CONF
TI  - OCOsense Glasses – Monitoring Facial Gestures and Expressions for Augmented Human-Computer Interaction: OCOsense Glasses for Monitoring Facial Gestures and Expressions
AU  - Gjoreski, Hristijan
AU  - Mavridou, Ifigeneia
AU  - Archer, James Archer William
AU  - Cleal, Andrew
AU  - Stankoski, Simon
AU  - Kiprijanovska, Ivana
AU  - Fatoorechi, Mohsen
AU  - Walas, Piotr
AU  - Broulidakis, John
AU  - Gjoreski, Martin
AU  - Nduka, Charles
T3  - CHI EA '23
AB  - The paper presents the OCOsenseTM smart glasses system, which recognizes and monitors facial gestures and expressions by using non-contact optomyographic OCOTM sensors and an IMU placed inside the frames of the glasses. The glasses stream the sensor data via Bluetooth to a mobile device, where data-fusion algorithms are applied, to recognize facial gestures and expressions in real time. The recognized gestures and expressions are then used as input to interact with the mobile device. We will demonstrate how the system is used in practice, i.e., a participant will wear the OCOsenseTM glasses and will interact with the mobile device by doing facial gestures and expressions. Three use cases will be presented: video control, call control, and game control. We believe that the OCOsenseTM glasses are the next generation in wearables, which will allow for a better understanding of the user's context and emotional state, and will allow numerous ways to interact with smart devices and computer systems, even within Augmented and Extended Reality environments. Future versions of the system can be used in a variety of domains, including, affective computing, remote mental-health monitoring, and hands-free human-computer interaction, thus improving accessibility and inclusivity of future technologies.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583918
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583918
KW  - Affective Computing
KW  - Emotion Recognition
KW  - Facial Expressions
KW  - Facial Gestures
KW  - Glasses
KW  - IMU
KW  - Machine Learning
KW  - OMG
ER  - 

TY  - CONF
TI  - Nose Gym: An Interactive Smell Training Solution
AU  - Beşevli, Ceylan
AU  - Dawes, Christopher
AU  - Brianza, Giada
AU  - Fatah Gen. Schieck, Ava
AU  - Boak, Duncan
AU  - Philpott, Carl
AU  - Maggioni, Emanuela
AU  - Obrist, Marianna
T3  - CHI EA '23
AB  - When was the last time you had your sense of smell checked? Smell is one of the most neglected senses in daily life and in HCI. In Europe and the USA, around 22% of the general adult population has some form of smell dysfunction. This number rises to 75% for people aged between 70–80 years and negatively impacts peoples’ quality of life and well-being. Regular smell training can make a difference. Today, smell training is done by sniffing essential oils in jars or scented pens. Based on advances in digital technology, we present a new interactive smell training solution to help people train their nose. At CHI, users will have a chance to try out the scent-delivery device and companion App at the ‘Nose Gym’ booth. We will combine the interactivity with additional information on the I-smell project that is using this digital smell training solution in a real-world deployment to establish a culture of care for our sense of smell.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583906
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583906
KW  - Digital smell health: Digital smell technology.
KW  - Odour interfaces
KW  - Olfactory experiences
KW  - Scent design
KW  - Smell
KW  - Smell care
KW  - Smell training
KW  - Smell-based interaction design
ER  - 

TY  - CONF
TI  - MOFA: Exploring Asymmetric Mixed Reality Design Strategy for Co-located Multiplayer Between Handheld and Head-mounted Augmented Reality
AU  - Hu, Botao
AU  - Zhang, Yuchen
AU  - Hao, Sizheng
AU  - Tao, Yilan
T3  - CHI EA '23
AB  - For co-located multiplayer asymmetric Mixed Reality (MR) scenarios involving both Handheld Augmented Reality (HAR) and head-mounted Stereoscopic Augmented Reality (StAR) devices, we propose a design strategy to distinguish the roles of different players based on the affordances, limitations, and capabilities of these two kinds of AR devices. Specifically, the roles include: a HAR player as a third-person passive participant (termed spectator), a third-person active participant (termed puppeteer), a first-person participant, and a first-person partial-information participant; and a StAR player as a first-person participant and a first-person partial-information participant. In order to explore this concept, we designed four multiplayer MR game prototypes: The Duck, The Ghost, The Dragon, and The Duel to demonstrate strategies for creating interesting, engaging, and strategic cooperative experiences between players.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583935
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583935
KW  - asymmetric game design
KW  - Augmented reality
KW  - collocated multiplayer
KW  - mixed reality
ER  - 

TY  - CONF
TI  - Interactive Paper Displays: Enabling Digital Functionalities on Physical Paper
AU  - Campos, Cuauhtli
AU  - Kljun, Matjaž
AU  - Sandak, Jakub
AU  - Čopič Pucihar, Klen
T3  - CHI EA '23
AB  - Despite numerous possibilities to combine digital functionalities with physical paper, these solutions require users to handle, wear (e.g. smart phones, head-mounted displays) or set up (e.g. projectors) additional hardware, or require special manufacturing (e.g. embedding electronics, using conductive ink). We overcame these limitations by designing and developing several new interactive paper-display technologies that allow one to interact with paper and digital content, when paper is placed on a horizontal interactive display such as a table computer (tabletop) or tablet. Since the content on the display is combined with the content on paper, the screen real-estate the paper is covering is not lost. We present twelve practical applications: various interactive learning exercises and drawing aids as well as instant digitisation of handwriting when filling a from on paper, annotating a blueprint or writing a sticky note. With these we demonstrate various new opportunities of adding digital functionalities to paper and aim to initiate a debate on the future role of paper in our society.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583932
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583932
KW  - apple pen
KW  - digitiser
KW  - interactive paper
KW  - paper display
KW  - paper interfaces
KW  - pinhole paper
KW  - rear projection
ER  - 

TY  - CONF
TI  - Navel - a social robot with verbal and nonverbal communication skills
AU  - Toussaint, Claude
AU  - Schwarz, Philipp T
AU  - Petermann, Markus
T3  - CHI EA '23
AB  - As robots are used not only in factories but increasingly in everyday life, interaction with them must be as intuitive as possible for everyone. We present Navel, a mobile social robot that supports nonverbal interaction in addition to verbal communication. Thus, the interaction with our novel hardware-software-system is similar to human-to-human communication and appears natural and intuitive for everyone. For social signal perception, multiple computer vision algorithms run in near real-time on an NVIDIA edge device in the robot, achieving low latency and maintaining privacy. For the representation of social signals, an innovative combination of displays and fiber-optic plates is used, allowing the creation of expressive three-dimensional eyes for building realistic eye contact. A lean high-performance software architecture is used to generate agile, lively and context-sensitive behavior. An abstracted humanoid design avoids the Uncanny Valley.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583898
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583898
KW  - human robot interaction
KW  - nonverbal communication
KW  - social cues
KW  - social robot
ER  - 

TY  - CONF
TI  - Interacting with Neural Radiance Fields in Immersive Virtual Reality
AU  - Li, Ke
AU  - Rolff, Tim
AU  - Schmidt, Susanne
AU  - Bacher, Reinhard
AU  - Leemans, Wim
AU  - Steinicke, Frank
T3  - CHI EA '23
AB  - Recent advancements in the neural radiance field (NeRF) technology, in particular its extension by instant neural graphics primitives, provide tremendous opportunities for the use of real-time immersive virtual reality (VR) applications. Moreover, the recent release of an immersive neural graphics primitives framework (immersive-ngp) brings real-time, stereoscopic NeRF rendering to the Unity game engine. However, the system and application research combining NeRF and human-computer interaction in VR is still at the very beginning. In this demo, we present multiple interactive system features for immersive-ngp with design principles focusing on improving the usability and interactivity of the framework for small to medium-scale NeRF scenes. We demonstrate that these new feature implementations such as exocentric manipulation, VR tunneling effects, and immersive scene appearance editing enable novel VR-NeRF experiences, for example, for customized experiences in inspecting a particle accelerator environment.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583920
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583920
KW  - Immersive Virtual Reality
KW  - Neural Radiance Field
ER  - 

TY  - CONF
TI  - Fencing Hallucination: An Interactive Installation for Fencing with AI and Synthesizing Chronophotographs
AU  - Qiu, Weihao
AU  - Legrady, George
T3  - CHI EA '23
AB  - Fencing Hallucination is a multi-screen interactive installation that enables real-time human-AI interaction in the form of a Fencing game and generates a chronophotograph based on the audience’s movement. It mitigates the conflicts between interactivity, modality variety, and computational limitation in creative AI tools. Fencing Hallucination captures the audience’s pose data as an input to the Multilayer Perceptron(MLP), which generates the virtual AI Fencer’s pose data. It also uses the audience’s pose to synthesize the chronophotograph. The system first represents pose data as stick figures. Then it uses a diffusion model to perform image-to-image translations, converting the stick figures into a series of realistic fencing images. Finally, it combines all images with an additive effect into one image as the result. This multi-step process overcomes the challenge of preserving both the overall motion patterns and fine details when synthesizing a chronophotograph.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583929
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583929
KW  - Chronophotography
KW  - Diffusion Model
KW  - Human-AI Interaction
KW  - Image-to-image Translation
KW  - Motion Synthesis
ER  - 

TY  - CONF
TI  - InExChange: Fostering Genuine Social Connection through Embodied Breath Sharing in Mixed Reality
AU  - Morris, Caitlin
AU  - Liu, Pinyao
AU  - Riecke, Bernhard E.
AU  - Maes, Pattie
T3  - CHI EA '23
AB  - InExChange is an interactive mixed reality experience centering around an inflatable vest which conveys a physical sense of shared breathing on the diaphragm between two or more participants. The experience is composed of three acts in which the participants’ breaths are transformed into metaphorical projected representations: expansive waves, flowing light trails, and growing tree branches. The inflatable wearable devices physically enact in near real-time the inhale/exhale pattern of the other person’s breath, varying in intensity level to create an attention interplay between the embodied sensation and the projection. Through this embodied sense of playful shared breathing, we aim to cultivate a genuine feeling of connection and contribute to the integration of somaesthetic design principles in mixed reality HCI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583917
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583917
KW  - breathing biofeedback
KW  - haptics
KW  - interactive installation
KW  - mixed reality
KW  - social connection
KW  - somaesthetics
ER  - 

TY  - CONF
TI  - HUGO, a High-Resolution Tactile Emulator for Complex Surfaces
AU  - Herbst, Yair
AU  - Wolf, Alon
AU  - Zelnik-Manor, Lihi
T3  - CHI EA '23
AB  - Many of our activities rely on tactile feedback perceived through mechanoreceptors in our skin. While visual and auditory devices provide immersive experiences, cutaneous feedback devices are typically limited in the range of sensations they provide and are hence usually used and tested on relatively simple synthetic surfaces. In this paper we demonstrate HUGO, a device designed in a human-centered process, triggering the mechanoreceptors sensitive to pressure, low-frequency vibrations, and high-frequency vibrations, enabling one to experience touch of surfaces “in-the-wild". The device is based on a parallel manipulator and a pin-array, that operate simultaneously at 200Hz and emulate coarse and fine geometrical features, respectively. The decomposition into coarse and fine features, alongside the high operation frequency, enable simulation of virtual surfaces. HUGO will be showcased in multiple applications such as social interactions, e-commerce and gaming to allow haptic interaction with real-world surfaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583892
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583892
KW  - Haptic Textures
KW  - Haptics
KW  - High-Resolution Haptics
KW  - Human Computer Interface
KW  - User Study
ER  - 

TY  - CONF
TI  - HMDspeller: Fast and Hands-free Text Entry System for Head Mount Displays using Silent Spelling Recognition
AU  - Asano, Kei
AU  - Kimura, Naoki
AU  - Rekimoto, Jun
T3  - CHI EA '23
AB  - As virtual reality and augmented reality technology become more popular in office and communication contexts, the need for simple and efficient text input methods for these devices becomes more evident. We propose the use of an HMDspeller, which allows for text input at a speed of more than 30 words per minute without the need of using hands. Our method utilizes a technique called "silent spelling," which serves as a compromise between text entry and silent speech. The HMDspeller uses an infrared camera to capture the user’s silent spelling and decode the words, achieving a character error rate of 13.9% for seen words and 26.6% for unseen words without using language models or dictionaries.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583910
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583910
KW  - augmented reality
KW  - head mount display
KW  - lip reading
KW  - silent speech
KW  - text entry
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Gaze & Tongue: A Subtle, Hands-Free Interaction for Head-Worn Devices
AU  - Gemicioglu, Tan
AU  - Winters, R. Michael
AU  - Wang, Yu-Te
AU  - Gable, Thomas M.
AU  - Paradiso, Ann
AU  - Tashev, Ivan J.
T3  - CHI EA '23
AB  - Gaze tracking allows hands-free and voice-free interaction with computers, and has gained more use recently in virtual and augmented reality headsets. However, it traditionally uses dwell time for selection tasks, which suffers from the Midas Touch problem. Tongue gestures are subtle, accessible and can be sensed non-intrusively using an IMU at the back of the ear, PPG and EEG. We demonstrate a novel interaction method combining gaze tracking with tongue gestures for gaze-based selection faster than dwell time and multiple selection options. We showcase its usage as a point-and-click interface in three hands-free games and a musical instrument.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583930
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583930
KW  - BCI
KW  - eye tracking
KW  - hands-free
KW  - non-intrusive
KW  - tongue gestures
KW  - tongue interface
ER  - 

TY  - CONF
TI  - Exploring the impact of VR and embodiment on environmental literacy
AU  - Bordegoni, Monica
AU  - Carulli, Marina
AU  - Spadoni, Elena
AU  - Gallace, Alberto
AU  - Clerici, Monica
AU  - Liu, Ruiyi
AU  - Paoli, Matteo
AU  - Restifo Pilato, Simone
T3  - CHI EA '23
AB  - Reduction of global bee populations is one of the relevant topics in the list of environmental issues defined in the United Nations Sustainable Development Goals Agenda. Virtual Reality technologies can play a strategic role in raising awareness and education for sustainability by allowing users to visualize, demonstrate and emphasize information, making it more accessible. Virtual Reality can also elicit emotional involvement, which is important for influencing user behavior. The authors have designed and developed an educational Virtual Reality application called Colonies, which allows users to understand the issues related to the bee problem and empathize with bee colonies. The experience also offers suggestions for more sustainable behaviors.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583903
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583903
ER  - 

TY  - CONF
TI  - External noise reduction using WhisperMask, a mask-type wearable microphone
AU  - Hiraki, Hirotaka
AU  - Kanazawa, Shusuke
AU  - Miura, Takahiro
AU  - Yoshida, Manabu
AU  - Mochimaru, Masaaki
AU  - Rekimoto, Jun
T3  - CHI EA '23
AB  - Conversation through voice is one of the basic means of human communication. Online communication systems and voice user interfaces for operating smartphones or smart devices are increasingly important as an interface that anyone can use daily. However, voice input is difficult to use in noisy environments or in environments where multiple people speak at the same time because unintended voices are included. Conventional microphones such as pin microphones or contact-type microphones such as throat microphones, and NAM microphones have been proposed for reducing external noise, however, pin microphones are not tolerant of high volume, and contact-type microphones generate contact noise when the user nods or walks. We propose WhisperMask, a wearable electret condenser microphone that can acquire speech even in noisy environments. In addition, the proposed mask-shaped microphone allows hands-free input and is wearable, unobtrusive, and lightweight interface.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583936
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583936
KW  - mask-type interface
KW  - microphone
KW  - noise cancelling
KW  - speech
KW  - speech enhancement
KW  - wearable device
ER  - 

TY  - CONF
TI  - Exploring Augmented Reality Waste Data Representations for Eco Feedback.
AU  - Assor, Ambre
AU  - Prouzeau, Arnaud
AU  - Dragicevic, Pierre
AU  - Hachet, Martin
T3  - CHI EA '23
AB  - In this demo, we show how Augmented Reality can be used to visualize waste accumulation data in an engaging and visceral way. The negative impact humans have on the environment is partly caused by thoughtless consumption leading to unnecessary waste. A likely contributing factor is the relative invisibility of waste: waste produced by individuals is either out of their sight or quickly taken away. Nevertheless, waste disposal systems sometimes break down, creating natural information displays of waste production that can have educational value. We take inspiration from such natural displays and introduce a class of situated visualizations we call augmented-reality waste accumulation visualizations or ARwavs, which are literal representations of waste data embedded in users’ familiar environment. We implemented examples of ARwavs and will present them at the venue.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583905
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583905
KW  - Augmented Reality
KW  - Concrete Scales
KW  - Embodied Interactions.
KW  - Visualization
ER  - 

TY  - CONF
TI  - Exploring a Digital Art Collection through Drawing Interactions with a Deep Generative Model
AU  - Sivertsen, Christian
AU  - Haas, René
AU  - Jensen, Halfdan Hauch
AU  - Løvlie, Anders Sundnes
T3  - CHI EA '23
AB  - New Snow is an interactive drawing table that investigates human interaction with a deep generative model based on Edvard Munch’s sketching practice. Through drawings with pen and paper, the user can interact with the model which will return synthetic sketches based on the input drawings in real time. The model is a reflection of the training data, and it is thus constrained to representing images within the latent space of Edvard Munch’s sketching practice. As the user familiarizes themselves with the model it allows them to become sensitized to the visual aesthetic belonging to this practice. This potential for familiarization with the aesthetic of a dataset via the model has implications for human-AI interaction and non-verbal art mediation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583902
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583902
KW  - embodied interaction
KW  - fine art
KW  - interaction
KW  - sketching
KW  - stylegan
ER  - 

TY  - CONF
TI  - Explore the Future Earth with Wander 2.0: AI Chatbot Driven By Knowledge-base Story Generation and Text-to-image Model
AU  - Sun, Yuqian
AU  - Xu, Ying
AU  - Cheng, Chenhang
AU  - Li, Yihua
AU  - Lee, Chang Hee
AU  - Asadipour, Ali
T3  - CHI EA '23
AB  - People always envision the future of earth through science fiction (Sci-fi), so can we create a unique experience of "visiting the future earth" through the lens of artificial intelligence (AI)? We introduce Wander 2.0, an AI chatbot that co-creates sci-fi stories through knowledge-based story generation on daily communication platforms like WeChat and Discord. Using location information from Google Maps, Wander generates narrative travelogues about specific locations (e.g. Paris) through a large-scale language model (LLM). Additionally, using the large-scale text-to-image model (LTGM) Stable Diffusion, Wander transfers future scenes that match both the text description and location photo, facilitating future imagination. The project also includes a real-time visualization of the human-AI collaborations on a future map. Through journeys with visitors from all over the world, Wander demonstrates how AI can serve as a subjective interface linking fiction and reality. Our research shows that multi-modal AI systems have the potential to extend the artistic experience and creative world-building through adaptive and unique content generation for different people. Wander 2.0 is available at http://wander001.com/
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583931
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583931
KW  - Artificial intelligence
KW  - chatbot
KW  - design fiction
KW  - gaming
KW  - human-AI interaction
KW  - interactive fiction
ER  - 

TY  - CONF
TI  - Explainable Human-Robot Training and Cooperation with Augmented Reality
AU  - Wang, Chao
AU  - Belardinelli, Anna
AU  - Hasler, Stephan
AU  - Stouraitis, Theodoros
AU  - Tanneberg, Daniel
AU  - Gienger, Michael
T3  - CHI EA '23
AB  - The current spread of social and assistive robotics applications is increasingly highlighting the need for robots that can be easily taught and interacted with, even by users with no technical background. Still, it is often difficult to grasp what such robots know or to assess if a correct representation of the task is being formed. Augmented Reality (AR) has the potential to bridge this gap. We demonstrate three use cases where AR design elements enhance the explainability and efficiency of human-robot interaction: 1) a human teaching a robot some simple kitchen tasks by demonstration, 2) the robot showing its plan for solving novel tasks in AR to a human for validation, and 3) a robot communicating its intentions via AR while assisting people with limited mobility during daily activities.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583889
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583889
KW  - augmented reality
KW  - explainability
KW  - human-robot interaction
ER  - 

TY  - CONF
TI  - Experiencing Rapid Prototyping of Machine Learning Based Multimedia Applications in Rapsai
AU  - Du, Ruofei
AU  - Li, Na
AU  - Jin, Jing
AU  - Carney, Michelle
AU  - Yuan, Xiuxiu
AU  - Iyengar, Ram
AU  - Yu, Ping
AU  - Kowdle, Adarsh
AU  - Olwal, Alex
T3  - CHI EA '23
AB  - We demonstrate Rapsai, a visual programming platform that aims to streamline the rapid and iterative development of end-to-end machine learning (ML)-based multimedia applications. Rapsai features a node-graph editor that enables interactive characterization and visualization of ML model performance, which facilitates the understanding of how the model behaves in different scenarios. Moreover, the platform streamlines end-to-end prototyping by providing interactive data augmentation and model comparison capabilities within a no-coding environment. Our demonstration showcases the versatility of Rapsai through several use cases, including virtual background, visual effects with depth estimation, and audio denoising. The implementation of Rapsai is intended to support ML practitioners in streamlining their workflow, making data-driven decisions, and comprehensively evaluating model behavior with real-world input.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583925
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583925
KW  - data augmentation
KW  - deep learning
KW  - deep neural networks
KW  - model comparison
KW  - node-graph editor
KW  - visual analytics
KW  - visual programming
ER  - 

TY  - CONF
TI  - Enable Blind Users’ Experience in 3D Virtual Environments: The Scene Weaver Prototype
AU  - Balasubramanian, Harshadha
AU  - Morrison, Cecily
AU  - Grayson, Martin
AU  - Makhataeva, Zhanat
AU  - Marques, Rita Faia
AU  - Gable, Thomas
AU  - Perez, Dalya
AU  - Cutrell, Edward
T3  - CHI EA '23
AB  - Three-dimensional virtual environments are currently inaccessible to people who are blind, as current screen-reading solutions for 2D content are not fully extensible to achieve the needed embodied spatial presence. Forefronting perceptual agency as key to any access approach for users who are blind, we offer Scene Weaving as an interactional metaphor that allows users to choose how and when they perceive the environment and the people in it. We illustrate how this metaphor can be implemented in an example prototype system. In this interactivity, users can control how and when they perceive a virtual museum environment and people within it through a range of interaction mechanisms.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583909
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583909
KW  - Accessibility
KW  - Interaction Metaphor
KW  - Perceptual Agency
KW  - Virtual Environments
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Design and Fabrication of Body-Based Interfaces (Demo of Saarland HCI Lab)
AU  - Steimle, Jürgen
AU  - Muehlhaus, Marie
AU  - Nicolae, Madalina Luciana
AU  - Nittala, Aditya Shekhar
AU  - Pourjafarian, Narjes
AU  - Sharma, Adwait
AU  - Teyssier, Marc
AU  - Koelle, Marion
AU  - Fruchard, Bruno
AU  - Strohmeier, Paul
T3  - CHI EA '23
AB  - This Interactivity shows live demonstrations of our lab’s most recent work on body-based interfaces. The soft, curved and deformable surface of the human body presents unique opportunities and challenges for interfaces. New form factors, materials and interaction techniques are required that move past the conventional rigid, planar and rectangular devices and the corresponding interaction styles. We highlight three themes of challenges for soft body-based interfaces: 1) How to design interfaces that are optimized for the body? We demonstrate how interactive computational design tools can help novices and experts to create better device designs. 2) Once they are designed, how to physically prototype and fabricate soft interfaces? We show accessible DIY fabrication methods for soft devices made of functional materials that make use of biomaterials. 3) How to leverage the richness of interacting on the body? We demonstrate on-body and off-body interactions that leverage the soft properties of the interface.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583916
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583916
KW  - computational design
KW  - critical design.
KW  - fabrication
KW  - new materials
KW  - On-body interaction
ER  - 

TY  - CONF
TI  - Demonstration of CoilCAM: an Action-Oriented Toolpath Programming System for Clay 3D Printing
AU  - Bourgault, Samuelle
AU  - Frost, Devon
AU  - Wiley, Pilar
AU  - Farber, Avi
AU  - Jacobs, Jennifer
T3  - CHI EA '23
AB  - Clay 3D printing provides the benefits of digital fabrication automation and reconfigurability through a method that evokes manual clay coiling. Existing design technologies for clay 3D printing reflect the general 3D printing workflow in which solid forms are designed in CAD and then converted to a toolpath. In contrast, in hand-coiling, form is determined by the actions taken by the artist’s hands through space in response to the material. We theorized that an action-oriented approach for clay 3D printing could allow creators to design digital fabrication toolpaths that reflect clay material properties. We present CoilCAM, a domain-specific CAM programming system that supports the integrated generation of parametric forms and surface textures through mathematically defined toolpath operations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583921
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583921
KW  - Artist Residency
KW  - Clay 3D Printing
KW  - Computer-Aided Machining
KW  - Digital Fabrication
ER  - 

TY  - CONF
TI  - Demonstrating Waxpaper Plus: Sequentially and Conditionally Programmable Morphing Wax Fabrics
AU  - Wu, Di
AU  - Lu, Qiuyu
AU  - Lai, Hsuanju
AU  - Zhang, Yunjia
AU  - Yao, Lining
T3  - CHI EA '23
AB  - We print wax on paper and turn the composite into a sequentially-controllable, rapidly-fabricated, low-cost, and biodegradable shape-changing material. This is a novel, versatile yet highly accessible enabling technology that expands the library of morphing materials in HCI. By integrating three physical phenomena (including the bilayer bending actuation, the hygroscopic nature of the paper, and the hydrophobicity property of the wax) and rapidly printing various wax patterns on paper with an off-the-shelf solid ink printer, we develop wax paper actuators that have highly controllable sequential deformation with a wide range of intervals (from seconds to hours). This paper describes the design factor, fabrication process, sequential control, and transformation primitives, and envisions example applications.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583924
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583924
KW  - morphing materials
KW  - programmable interface
KW  - rapid fabrication
ER  - 

TY  - CONF
TI  - Demonstrating Virtual Teamwork with Synchrobots: A Robot-Mediated Approach to Improving Connectedness
AU  - Watanabe, Yuna
AU  - Cang, Xi Laura
AU  - Guerra, Rúbia Reis
AU  - Mclaren, Devyani
AU  - Vyas, Preeti
AU  - Rekimoto, Jun
AU  - Maclean, Karon E
T3  - CHI EA '23
AB  - The increased prevalence of online collaborative work, through necessity or preference, is accompanied by measurable drops in satisfaction, creativity and energy, often termed “zoom fatigue.” As loss of physical co-presence and associated nonverbal communication are identified as contributors, we introduce Synchrobots – robots designed to channel human biophysiology for group connectedness. We propose an Interactivity demo wherein two participants perform an online problem-solving task while wearing physiological sensors and holding a Synchrobot as it physically renders a translation of their partner’s heartrate. The setup involves two stations, each with a laptop running Zoom, a set of wearable sensors recording heart rate, respiratory rate, and electrodermal activity, and a Synchrobot. After the problem-solving task, we will invite participants to reflect on how connected they felt with each other as well as their satisfaction with the collaboration quality. Participants may consent to release this data for later inclusion as part of a study.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583896
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583896
KW  - biosignal display
KW  - physical co-presence during online collaboration
KW  - robot haptic display
KW  - team connectedness
ER  - 

TY  - CONF
TI  - Demonstration of transPAF: Rendering Omnidirectional Impact Feedback with Dynamic Point of Application of Force All Round a Controller
AU  - Chen, Hong-Xian
AU  - Chiu, Shih-Kang
AU  - Wen, Chi-Ching
AU  - Tsai, Hsin-Ruey
T3  - CHI EA '23
AB  - Impact force is common haptic feedback on virtual reality (VR) controllers, such as hitting objects with weapons or rackets. It applies to different points of application of force (PAFs) and directions in varied scenarios. Therefore, we propose a controller, transPAF, to render omnidirectional impact feedback with dynamic PAF all round the controller for versatile VR scenarios. transPAF consists of a controller, a semicircular track, a linear track, and an impactor, which are all rotatable. The impactor can move to any position in a sphere, which means the whole 3D space all round the controller, and rotate in any direction. In the demonstration, users can use four weapons, including a sword, a pickaxe, a hook, a dagger, and a tennis racket in the VR scene to attack monsters and hit balls, so that they can feel the sensation of the impact force applied to different PAFs and directions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583894
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583894
KW  - Haptic feedback
KW  - impact force feedback
KW  - point of application of force
KW  - virtual reality.
ER  - 

TY  - CONF
TI  - Demonstration of FlexBoard: A Flexible Breadboard Platform for Interaction Prototyping on Curved and Deformable Objects
AU  - Ko, Donghyeon
AU  - Kim, Yoonji
AU  - Zhu, Junyi
AU  - Wessely, Michael
AU  - Mueller, Stefanie
T3  - CHI EA '23
AB  - We demonstrate FlexBoard, a flexible breadboard that enables interaction prototyping with electronic components such as sensors, actuators, and displays on curved and deformable objects. We show how FlexBoard offers flexible and bidirectional bending capabilities to conform to different shapes and materials, including the rapid prototyping capabilities of the traditional breadboard. FlexBoard’s bendability is enabled by providing a flexible living hinge instead of the rigid body of a traditional breadboard. FlexBoard holds the metal strips as the traditional breadboard, which can maintain the standard pin spacing for compatibility. In addition, FlexBoards are shape-customizable. Users can cut Flexboard to a specific length and join them together to cover various ranges of prototyping areas. We present the way of fabricating FlexBoard and three application scenarios with interactive textiles, curved tangible user interfaces, and VR devices.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583915
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583915
KW  - breadboards
KW  - deformable user interfaces.
KW  - electronic prototyping
ER  - 

TY  - CONF
TI  - Demonstrating Trusscillator: a System for Fabricating Human-Scale Human-Powered Oscillating Devices
AU  - Kovacs, Robert
AU  - Rambold, Lukas
AU  - Fritzsche, Lukas
AU  - Meier, Dominik
AU  - Shigeyama, Jotaro
AU  - Katakura, Shohei
AU  - Zhang, Ran
AU  - Baudisch, Patrick
T3  - CHI EA '23
AB  - Trusscillator is an end-to-end system that allows non-engineers to create human-scale human-powered devices that perform oscillatory movements, such as playground equipment, workout devices, and interactive kinetic installations. While recent research has been focusing on generating mechanisms that produce specific movement-path, without considering the required energy for the motion (kinematic approach), Trusscillator supports users in designing mechanisms that recycle energy in the system in the form of oscillating mechanisms (dynamic approach), specifically with the help of coil-springs. The presented system features a novel set of tools tailored for designing the dynamic experience of the motion. These tools allow designers to focus on user experience-specific aspects, such as motion range, tempo, and effort while abstracting away the underlying technicalities of eigenfrequencies, spring constants, and energy. Since the forces involved in the resulting devices can be high, Trusscillator helps users to fabricate from steel by picking out appropriate steal springs, generating part lists, and producing stencils and welding jigs that help weld with precision. To validate our system, we designed, built, and tested a series of unique playground equipment featuring 2-4 degrees of movement.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583887
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583887
KW  - dynamics
KW  - mechanical oscillation
KW  - personal fabrication
KW  - welding
ER  - 

TY  - CONF
TI  - Demonstrating Thermotion: Design and Fabrication of Thermofluidic Composites for Animation Effects on Object Surfaces
AU  - Yu, Tianyu
AU  - Xu, Weiye
AU  - Xu, Haiqing
AU  - Liu, Guanhong
AU  - Liu, Chang
AU  - Wang, Guanyun
AU  - Mi, Haipeng
T3  - CHI EA '23
AB  - We demonstrate Thermotion, a novel method using thermofluidic composites to design and display thermochromic animation effects on object surfaces. With fluidic channels embedded under the object surfaces, the composites utilize thermofluidic flows to dynamically control the surface temperature as an actuator for thermochromic paints, which enables researchers and designers for the first time to create animations not only on two and three-dimensional surfaces but also on the surface made of a few flexible everyday materials. We demonstrate the fabrication workflow of the composites and the design space of the animation effects. A range of applications is shown leveraging the objects’ dynamic displays both visually and thermally, including dynamic artifacts, teaching aids, and ambient displays. We envision an opportunity to extend thermofluidic composites to other heat-related practices for further dynamic and programmable interactions with temperature.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583907
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583907
KW  - Color-changing Interface
KW  - Computational Fabrication
KW  - Human-Material Interaction
KW  - Programmable Materials
KW  - Thermal Design
KW  - Thermofluidic Composites
ER  - 

TY  - CONF
TI  - Demonstrating JumpMod: Haptic Backpack that Modifies Users' Perceived Jump
AU  - Nith, Romain
AU  - Serfaty, Jacob
AU  - Shatzkin, Samuel G
AU  - Shen, Alan
AU  - Lopes, Pedro
T3  - CHI EA '23
AB  - Abstract. Vertical force-feedback is extremely rare in mainstream interactive experiences. This happens because existing haptic devices capable of sufficiently strong forces that would modify a user's jump require grounding (e.g., motion platforms or pulleys) or cumbersome actuators (e.g., large propellers attached or held by the user). To enable interactive experiences to feature jump-based haptics without sacrificing wearability, we propose JumpMod, an untethered backpack that modifies one's sense of jumping. JumpMod achieves this by moving a weight up/down along the user's back, which modifies perceived jump momentum—creating accelerated &amp; decelerated jump sensations. Our device can render five distinct effects: jump higher, land harder/softer, pulled higher/lower, which we demonstrate in a jump-based VR experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583890
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583890
KW  - backpack
KW  - full-body
KW  - haptics
KW  - jumping
KW  - virtual reality
KW  - wearable
ER  - 

TY  - CONF
TI  - Demonstrating InflatableMod: Untethered and Reconfigurable Inflatable Modules for Tabletop-sized Pneumatic Physical Interfaces
AU  - Morita, Takafumi
AU  - Jiang, Ziyuan
AU  - Aoyama, Kanon
AU  - Minaminosono, Ayato
AU  - Kuwajima, Yu
AU  - Hosoya, Naoki
AU  - Maeda, Shingo
AU  - Kakehi, Yasuaki
T3  - CHI EA '23
AB  - Inflatable systems have been attracting attention in the field of interaction design. Conventional tabletop-sized pneumatic systems tend to be complex because they require bulky and noisy equipment. Therefore, several liquid-to-gas phase change actuators that use vaporization have been proposed. But these actuators have problems with controllability, reusability, and reconfigurability. In this study, we propose InflatableMod, novel inflatable modules based on the efficient control of liquid-to-gas phase change actuators. These are designed with a compact circuit that has a liquid transfer function to feed the required amount of low-boiling-point liquid into the pouch and a heating function to inflate the pouch by the volume change. This approach allows for a compact, silent, and untethered inflatable system. It is also possible to create an untethered and reconfigurable multi-inflatable system because each module is synchronized. In this paper, we demonstrate the basic operation and some applications with InflatableMod.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583928
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583928
KW  - Electrohydrodynamics.
KW  - Inflatables
KW  - Liquid-to-gas Phase Change Actuators
KW  - Multi-inflatables
KW  - Pneumatic
KW  - Programmable Materials
ER  - 

TY  - CONF
TI  - Demonstrating TactorBots: A Haptic Design Toolkit for Exploration of Emotional Robotic Touch
AU  - Zhou, Ran
AU  - Schwemler, Zachary
AU  - Baweja, Akshay
AU  - Sareen, Harpreet
AU  - Hunt, Casey Lee
AU  - Leithinger, Daniel
T3  - CHI EA '23
AB  - Emerging research has demonstrated the viability of emotional communication through haptic technology inspired by interpersonal touch. However, the meaning-making of artificial touch remains ambiguous and contextual. We see this ambiguity caused by robotic touch’s "otherness" as an opportunity for exploring alternatives. To empower designers to explore emotional robotic touch, we devise TactorBots. It contains eight plug-and-play wearable tactor modules that render a series of social gestures driven by servo motors. Our specialized web GUI allows easy control, modification, and storage of tactile patterns to support fast prototyping. Taking emotional haptics as a "design canvas" with broad opportunities, TactorBots is the first "playground" for designers to try out various tactile sensations, feel around the nuanced connection between touches and emotions, and come up with creative imaginations.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583897
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583897
KW  - Creativity Support
KW  - Design Research
KW  - Emotional Robotic Touch
KW  - Haptic Design Toolkit
KW  - Wearable
ER  - 

TY  - CONF
TI  - Demonstrating FoodSkin: A Method for Creating Electronic Circuits on Food Surfaces by Using Edible Gold Leaf for Enhancement of Eating Experience
AU  - Kato, Kunihiro
AU  - Motomura, Ami
AU  - Ikematsu, Kaori
AU  - Nakamura, Hiromi
AU  - Igarashi, Yuki
T3  - CHI EA '23
AB  - In this demonstration, we introduce FoodSkin, a method for fabricating an electronic circuit on food surfaces by using edible gold leaf. The circuit is easily fabricated using three readily available materials: gold leaf, water, edible paper, and potato starch. Previous methods for enhancing the eating experience, including the presentation of an electrical taste, by making food part of an electronic circuit are difficult to apply to foods with low water content because of their low conductivity. Our method enables the incorporation of dry foods into an electronic circuit by using edible gold leaf to form a circuit on the surface of the food. FoodSkin thus contributes to expanding the design space of the computer-augmented dining experience. We demonstrate the use of FoodSkin for three applications: controlling food taste through electrical stimulation, controlling food temperature, and providing auditory feedback when eating sweets.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583933
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583933
KW  - eating experience
KW  - electrical taste
KW  - fabrication.
KW  - Gold leaf
ER  - 

TY  - CONF
TI  - Conversation Starters: How Can We Misunderstand AI Better?
AU  - Nicenboim, Iohanna
AU  - Venkat, Shruthi
AU  - Rustad, Neva Linn
AU  - Vardanyan, Diana
AU  - Giaccardi, Elisa
AU  - Redström, Johan
T3  - CHI EA '23
AB  - Conversation Starters is a series of interactive prototypes that probe how to design explainable interactions with AI in everyday life. Taking a more-than-human approach, we explore how ‘failures’ could be transformed into opportunities for situated understandings of AI. We describe the process of designing fictional artifacts and scenarios about conversational agents that can grow at home. While overall the project suggests that misunderstandings could help people develop sensitivities for knowing when to trust AI systems, the metaphor of ‘growing an AI’ (which positions training as a matter of care), highlights that practices of sharing and experimenting could be valuable starting points for designing explainable and trustworthy interactions with of AI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583914
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583914
ER  - 

TY  - CONF
TI  - Demonstrating Full-hand Electro-Tactile Feedback without Obstructing Palmar Side of Hand
AU  - Tanaka, Yudai
AU  - Shen, Alan
AU  - Kong, Andy
AU  - Lopes, Pedro
T3  - CHI EA '23
AB  - We present a technique to render tactile feedback to the palmar side of the hand while keeping it unobstructed and, thus, preserving manual dexterity during interactions with physical objects. We implement this by applying electro-tactile stimulation only to the back of the hand and to the wrist. In our approach, there are no electrodes on the palmar side, yet that is where tactile sensations are felt. While we place electrodes outside the user's palm, we do so in strategic locations that conduct the electrical currents to the median/ulnar nerves, causing tactile sensations on the palmar side of the hand.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583919
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583919
KW  - Electro-tactile
KW  - Haptics
KW  - Mixed Reality
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Demonstrating Fluito: A playful floatation tank experience
AU  - Montoya, Maria F.
AU  - Ji, Yuyang
AU  - Pell, Sarah Jane
AU  - Mueller, Florian ‘Floyd’
T3  - CHI EA '23
AB  - The use of technologies for interactions in bodies of water has fostered the WaterHCI field. However, the interactive systems proposed for water activities have, so far, primarily focused on supporting instrumental and performance aspects. In contrast, the use of interactive technology for experiential purposes, such as water play, appears to be underexplored. We designed Fluito, a playful floatation tank experience, to expand discovery potentials. Fluito has a unique combination of technology (a floatation tank, a virtual reality headset, a heart rate sensor, and a pneumatic system) that leverages water affordances to create and amplify different experiences, such as play, relaxation, and bodily illusions. The CHI community will benefit from our prototype through the novel experiences it affords, difficult to describe in words, and the first-hand accounts it can facilitate, which is useful for inspiring the design community towards future playful water experiences.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583908
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583908
KW  - extended reality
KW  - floatation tank
KW  - flotation pod
KW  - playful experience
KW  - Water
KW  - water activities
KW  - WaterHCI
ER  - 

TY  - CONF
TI  - Demonstrating CleAR Sight: Transparent Interaction Panels for Augmented Reality
AU  - Büschel, Wolfgang
AU  - Krug, Katja
AU  - Klamka, Konstantin
AU  - Dachselt, Raimund
T3  - CHI EA '23
AB  - In this work, we demonstrate our concepts for transparent interaction panels in augmented-reality environments. Mobile devices can support interaction with head-mounted displays by providing additional input channels, such as touch &amp; pen input and spatial device input, and also an additional, personal display. However, occlusion of the physical context, other people, or the virtual content can be problematic. To address this, we previously introduced CleAR Sight, a concept and research platform for transparent interaction panels to support interaction in HMD-based mixed reality. Here, we will demonstrate the different interaction and visualization techniques supported in CleAR Sight that facilitate basic manipulation, data exploration, and sketching &amp; annotation for various use cases such as 3D volume visualization, collaborative data analysis, and smart home control.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583891
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583891
KW  - augmented reality
KW  - human-computer interaction
KW  - transparent displays
KW  - visualization
ER  - 

TY  - CONF
TI  - Computational Assistance for User Interface Design: Smarter Generation and Evaluation of Design Ideas
AU  - Hegemann, Lena
AU  - Jiang, Yue
AU  - Shin, Joon Gi
AU  - Liao, Yi-Chi
AU  - Laine, Markku
AU  - Oulasvirta, Antti
T3  - CHI EA '23
AB  - This paper describes a lab demo by the User Interfaces group at Aalto University. The demo allows attendees to interactively experience recent research prototypes aiming to facilitate designers’ creative and problem-solving capabilities in user interface (UI) design. Empirical work on designers suggests that UI design is challenging, partially because of the presence of very large design spaces, multiple and ill-defined objectives, design fixation and biases, as well as multiple requirements that need to to kept in mind. At the exhibition, members of the lab provide live demonstrations of six computational features, with a special focus on plug-ins created for Figma, a popular UI design tool. The demos draw from the group’s latest research published at HCI conferences. They demonstrate how to interactively exploit machine learning methods ranging from deep nets to Bayesian inference and NLP. We also present our design approach and provide a summary of findings from empirical evaluations with designers.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583960
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583960
KW  - AI-assisted design
KW  - Computational design
KW  - design tools
KW  - design-support systems
KW  - interaction design
KW  - UI design
ER  - 

TY  - CONF
TI  - Blow Molding Artifacts with PneuFab Method
AU  - Wang, Guanyun
AU  - Zhu, Kuangqi
AU  - Zhou, Lingchuan
AU  - Guo, Mengyan
AU  - Chen, Haotian
AU  - Yan, Zihan
AU  - Pan, Deying
AU  - Yang, Yue
AU  - Li, Jiaji
AU  - Wu, Jiang
AU  - Tao, Ye
AU  - Sun, Lingyun
T3  - CHI EA '23
AB  - We demonstrate a novel and democratized blow molding technique, PneuFab, enabled by FDM 3D-printed custom structures and temporal triggering methods. Access to computer-aided fabrication tools, such as 3D printing, empowers various craft techniques to democratize the creation of artifacts. To afford new blow molding techniques in the field of Human-Computer Interaction, we make efforts to simplify this challenging handy fabrication and enrich the design space of blow molding by taking advantage of the thermoformability and heat deformability of 3D printed thermoplastics. Showcasing design spaces, including artifacts with complex geometries and tunable stiffness, we hope to expand access and dive into what more the digital blow molding fabrication can be.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583938
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583938
KW  - 3D Printing
KW  - Blow Molding
KW  - Hybrid Fabrication
KW  - Shape Changing
ER  - 

TY  - CONF
TI  - 3D Printable Play-Dough
AU  - Buechley, Leah
AU  - Ta, Ruby
AU  - Johnson, Alyssa
T3  - CHI EA '23
AB  - Play-dough is a brightly-colored, easy-to-make, and familiar material. We have developed and tested custom play-dough materials that can be employed in 3D printers designed for clay. We demonstrate how custom-color prints can be designed and constructed. We also explore the design potential of play-dough as a sustainable fabrication material, highlighting its recyclability, compostability, and repairability. Finally, we present a set of example artifacts made from play-dough. We believe play-dough 3D printing can enable new kinds of aesthetic and functional applications in digital fabrication and could make 3D printing more feasible in a range of educational settings.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583927
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583927
KW  - keywords
ER  - 

TY  - CONF
TI  - Unsocial Robots: How Western Culture Dooms Consumer Social Robots to a Society of One
AU  - Aylett, Matthew Peter
AU  - Gomez, Randy
AU  - Sandry, Eleanor
AU  - Sabanovic, Selma
T3  - CHI EA '23
AB  - Markus and Kitayama suggests Western centric culture has a bias to the independent rather than the interdependence self. We argue that this has resulted in a bias for social robots to be assistants, companions, wing-men and one-to-one carers. Thus, the social in most commercial social robots is a simulated social interaction with a single user, an echo chamber of unnecessary interaction that inevitability creates systems that obstruct social interaction rather than encourage it. The resulting robot flunkies, yes-men and pretend friends have little long term utility. In contrast, we argue that rather it is as mediators, facilitators and working within human communities and groups that offers the real opportunity for social robots.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582751
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582751
KW  - Social Robots
ER  - 

TY  - CONF
TI  - TTRPG UX: Requirements & Beyond
AU  - Sturdee, Miriam
AU  - Gamboa, Mafalda
AU  - Heron, Michael
T3  - CHI EA '23
AB  - Tabletop Role Playing Games (TTRPG) allow the player to immerse themselves in a world where anything can happen – within the rules. You can become someone new, fight demons, play out exciting and speculative storylines, all with the help of your party. This ability to place yourself in the life of another person (or ethereal being) resonates with principles of User Experience Design (UX) where usability experts strive to understand the impact their application or interface might have on a hypothetical audience. This paper explores the parallels and potentials of TTRPG within the context of UX and Requirements, its characters, contexts and interactions. We propose creating playable UX worlds with the potential to provide deeper, more insightful output, and make recommendations for the addition of a TTRPG approach to User Experience processes.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582737
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582737
KW  - Blades in the Dark
KW  - Dungeons and Dragons
KW  - personas
KW  - roleplaying games
KW  - TTRPG
KW  - UCD
KW  - user experience
KW  - UX
ER  - 

TY  - CONF
TI  - Towards Developing a Virtual Guitar Instructor through Biometrics Informed Human-Computer Interaction
AU  - Rhodes, Chris
AU  - Allmendinger, Richard
AU  - Jay, Caroline
AU  - Climent, Ricardo
T3  - CHI EA '23
AB  - Within the last few years, wearable sensor technologies have allowed us to access novel biometrics that give us the ability to connect musical gesture to computing systems. Doing this affords us to study how we perform musically and understand the process at data level. However, biometric information is complex and cannot be directly mapped to digital systems. In this work, we study how guitar performance techniques can be captured/analysed towards developing an AI which can provide real-time feedback to guitar students. We do this by performing musical exercises on the guitar whilst acquiring and processing biometric (plus audiovisual) information during their performance. Our results show: there are notable differences within biometrics when playing a guitar scale in two different ways (legato and staccato) and this outcome can be used to motivate our intention to build an AI guitar tutor.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582738
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582738
KW  - Biometrics
KW  - Deep learning
KW  - EMG
KW  - Game engines
KW  - Guitar
KW  - HCI
KW  - Multimodal data
KW  - Musical performance
ER  - 

TY  - CONF
TI  - The problem with gender-blind design and how we might begin to address it: A model for intersectional feminist ethical deliberation
AU  - Henriques, Ana O.
AU  - Rafael, Sónia
AU  - Almeida, Victor M
AU  - Pinto, José Gomes
T3  - CHI EA '23
AB  - Gender-blind design hinges upon an assumption that designing equally is the same as designing for equality. That, however, is inaccurate, as gender-blindness is merely a synonym for neutrality. Neutrality, because it lacks a concerted effort to subvert, favors hegemonic values and epistemologies, which counters the purported aim of equality. Supposedly objective methods of analysis, such as data gathering and interpreting, are not deprived of this hegemonic bias either. As such, through an acknowledgment of ethics, the designer must recognize that they are, indeed, imbuing their values into their designs, which bears influence on the ways in which the user interacts and interprets those designs, a notion which is especially relevant to a field concerned with user experience. This may be done deliberately or by accident, but it is always inevitable. Ethics is, in this way, inextricable from the design process, and, thus, the present article aims to propose that designing for equality requires the designer to act as an ethical agent — responsibly, consciously, and knowingly — especially if one hopes to avoid a design which embodies and communicates oppressive notions. In particular, within the purview of ethics, and by making use of some case-studies and examples, it argues that designing toward gender equality requires not the more typical gender-blind approach, but rather one which is specifically gender-conscious. Further, this article also offers some suggestions as to how we might begin to act as ethical design agents and implement marginalized epistemologies into the design process.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582750
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582750
KW  - Conceptual Model
KW  - Ethics
KW  - Feminist Design
KW  - Gender-Blind Design
ER  - 

TY  - CONF
TI  - The Systematic Review-lution: A Manifesto to Promote Rigour and Inclusivity in Research Synthesis
AU  - Rogers, Katja
AU  - Seaborn, Katie
T3  - CHI EA '23
AB  - The field of human-computer interaction (HCI) is maturing. Systematic reviews, a staple of many disciplines, play an important and often essential role in how each field contributes to human knowledge. On this prospect, we argue that our meta-level approach to research within HCI needs a revolution. First, we echo previous calls for greater rigour in primary research reporting with a view towards supporting knowledge synthesis in secondary research. Second, we must decide as a community how to carry out systematic review work in light of the many ways that knowledge is produced within HCI (rigour in secondary research methods and epistemological inclusivity). In short, our manifesto is this: we need to develop and make space for an inclusive but rigorous set of standards that supports systematic review work in HCI, through careful consideration of both primary and secondary research methods, expectations, and infrastructure. We call for any and all fellow systematic review-lutionaries to join us.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582733
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582733
KW  - epistemology
KW  - literature
KW  - research synthesis
KW  - rigour
KW  - systematic review
ER  - 

TY  - CONF
TI  - The Internet of Bananas: Critical Design and Playfulness for Citizen Sensing and Electronic Literacy
AU  - Thibault, Mattia
AU  - Cordeiro, Artur Vasconcelos
AU  - Chisik, Yoram
AU  - Altarriba Bertran, Ferran
AU  - Smith, Annique
AU  - Medeiros, Marina L.
AU  - Legaki, Eleni
AU  - Gebhardt Fearns, Vera Karina
AU  - Kolettis, Vasileios
T3  - CHI EA '23
AB  - In this paper we recount the “Internet of Bananas” (IoB), a design-led exploration of citizen sensing as well as an exercise in “useful futility”. The project mixed critical design and satire to explore social justice attitudes towards data collection and electronic literacy. In the IoB a number of participants from around the world collaboratively created and set up a small IoT network by programming and interconnecting a set of sensor kits with which they monitored the colour, surface temperature and humidity of a network of bananas for the duration of one week. The main goal of the creation of such network was to be a platform for reflection, discussion and exchange on themes related to data production and collection. The IoB was active for a week, the “Banana Jam”, after which a debriefing provided an occasion to gather precious feedback from the participants and to assess, with their help, the entire process. The feedback, articulated around five main themes, has let to the creation of six final design considerations related to the combination of natural elements and digital technologies, the values of weirdness and play for critical design and its dissemination, and the importance of inclusivity and openness in regard of data collection and visualization.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582746
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582746
KW  - Critical Design
KW  - Going bananas
KW  - Internet of Things
ER  - 

TY  - CONF
TI  - The Fitts’ Law Filter Bubble
AU  - Drewes, Heiko
T3  - CHI EA '23
AB  - Fitts derived a formula that allows one to calculate the time it takes to hit a target of a given size. MacKenzie called this formula imperfect and suggested an alternative formula. This paper asks some simple questions about MacKenzie’s theory. If the human-computer interaction (HCI) community does not have satisfying answers, it means that MacKenzie’s formula is unfounded. In consequence, the HCI community should stop using and citing MacKenzie’s formula and use Fitts’ original formula instead and only when necessary. Additionally, the HCI community should review the Fitts’ Law research of the last 35 years concerning criteria that indicate an echo chamber and a filter bubble and debate whether they want to publish papers based on information theory in the future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582739
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582739
KW  - Fitts’ Law
KW  - information theory
KW  - MacKenzie’s formula
KW  - Shannon’s Theorem 17
ER  - 

TY  - CONF
TI  - Objectify: Better Living Through Anticipatory, Just-for-you 3D Printing!
AU  - Savage, Valkyrie
AU  - Homewood, Sarah
AU  - Shklovski, Irina
T3  - CHI EA '23
AB  - The ubiquity of 3D printers reveals a problem: people do not know what to use them for. If they do have an idea, they struggle to realize it, despite decades of research into design tools. However, consumption patterns suggest people still desire new objects, and advanced AI and digital fabrication point together toward an easy, post-scarcity future. This satirical advertorial presents Objectify, a program that harvests users’ data to create bespoke objects they could want, just in time. Pushing ’cutting edge’ AI’s promises to their logical conclusion, our implemented pipeline uses AI-based content generation (GPT-3 [4] and Dreamfusion [14]) to ideate, generate 3D models, and print just-in-time objects. Objectify is ‘pataphysical software [16]; created objects were non-functional monolothic pieces of blob-like single-color plastic. We discuss implications of the post-scarcity just-for-you vision of technological progress in AI and digital fabrication.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582748
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582748
KW  - ’pataphysical software
KW  - 3D printing
KW  - design tools
KW  - machine learning
KW  - technological charisma
ER  - 

TY  - CONF
TI  - Enough With “Human-AI Collaboration”
AU  - Sarkar, Advait
T3  - CHI EA '23
AB  - Describing our interaction with Artificial Intelligence (AI) systems as ‘collaboration’ is well-intentioned, but flawed. Not only is it misleading, but it also takes away the credit of AI ‘labour’ from the humans behind it, and erases and obscures an often exploitative arrangement between AI producers and consumers. The AI ‘collaboration’ metaphor is merely the latest episode in a long history of labour appropriation and credit reassignment that disenfranchises labourers in the Global South. I propose that viewing AI as a tool or an instrument, rather than a collaborator, is more accurate, and ultimately fairer.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582735
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582735
KW  - annotation
KW  - datasets
KW  - equity
KW  - fairness
KW  - labelling
KW  - labour
KW  - metaphors
ER  - 

TY  - CONF
TI  - Talking ‘bout my Generation … or not? The Digital Technology Life Experiences of Older People
AU  - Petrie, Helen
T3  - CHI EA '23
AB  - I argue that research on digital technologies for older people is largely failing to address two key issues: first, the lack of understanding and stereotypical views about older people by young researchers and developers; second, the tendency of researchers to treat all older people as a homogeneous group. I set out the case for the importance of digital technologies for older people, and the evidence for each of these issues, partly using a review of 102 papers on the topic from the ACM Digital Library. As one part of the way forward, I present a series of pastiche personas of older people, which young researchers and developers may find engaging and informative. Finally, I discuss strategies we might use to improve our understanding of the samples of participants we work with in developing digital technologies for older people.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582742
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582742
KW  - digital technologies
KW  - life experiences
KW  - older people
KW  - stereotypes
ER  - 

TY  - CONF
TI  - Should Computers Be Easy To Use? Questioning the Doctrine of Simplicity in User Interface Design
AU  - Sarkar, Advait
T3  - CHI EA '23
AB  - That computers should be easy to learn and use is a rarely-questioned tenet of user interface design. But what do we gain from prioritising usability and learnability, and what do we lose? I explore how simplicity is not an inevitable truth of user interface design, but rather contingent on a series of events in the evolution of software. Not only does a rigid adherence to this doctrine place an artificial ceiling on the power and flexibility of software, but it is also culturally relative, privileging certain information cultures over others. I propose that for feature-rich software, negotiated complexity is a better target than simplicity, and we must revisit the ill-regarded relationship between learning, documentation, and software.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582741
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582741
KW  - critical theory
KW  - culture
KW  - learnability
KW  - usability
ER  - 

TY  - CONF
TI  - It's about Time: Let's Do More to Support the Process of Aging (vs. the State of Being “Old”)
AU  - Jones, William Paul
AU  - Donner, Sascha
AU  - Narayan, Bhuva
AU  - Reyes, Vanessa
T3  - CHI EA '23
AB  - Focus on aging as a process vs. (old) age as a state of life. How do needs for supporting information and information tools change through the years of a person's adult life? Of special interest in the context of successful aging are innovations that are better for all adults but work even better for people as they age. To identify innovations that “age well”, begin by routinely sampling across a spectrum of adult ages, both in studies of current tool use (e.g., observations, interviews, surveys) and design alternatives. As a further step, cross age with other factors. Less formal methods involving forms of group deliberation can also elucidate age-related changes in the landscape of information need. A focus on the process of aging (vs. “old age”) is inclusive of people across the decades of their adult lives.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582740
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582740
KW  - Personal information management (PIM)
KW  - successful aging
ER  - 

TY  - CONF
TI  - Intra-Acting Body and Textile Expressions Becoming with Digital Movement Translation: Exploring relational expressions of the body and textiles using a human-robot-textile installation
AU  - Tepe, Jan
AU  - Gollob, Emanuel
AU  - Escudero, Julio Andres
AU  - Bastani, Amir
T3  - CHI EA '23
AB  - Body-centric design disciplines that utilize digitization processes such as fashion are tasked to engage with theoretical concepts commonly applied in digital-native design disciplines in order to use digital technologies as more than simple tools. Guided by intra-action theory, alternative ontological and hierarchical relations between the body and textiles were explored by digitally translating their movement. An installation was developed to find hybrid body-textile expressions using motion-capture sensors and robotic arms. The findings suggest that technological augmentations of the body and textiles can increasingly be diffracted in terms of their apparent physical-material boundaries through movement translation. Movement data functioned as a performative mediator, expanding movement-based expressions from one agent to another. Body-textile hybrids emerged from this process, and shaped each other in a mutual act of becoming, challenging ontological structures of the body and textiles commonly applied in fashion design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582736
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582736
KW  - Hybrid bodies
KW  - Movement as material
KW  - Responsive textile systems
KW  - Textile-robot interaction
ER  - 

TY  - CONF
TI  - Doodle Away: An Autoethnographic Exploration of Doodling as a Strategy for Self-Control Strength in Online Spaces
AU  - Lewis, Makayla
AU  - Sturdee, Miriam
AU  - Gamboa, Mafalda
AU  - Lengyel, Denise
T3  - CHI EA '23
AB  - We think we are not alone when we say: navigating the new online spaces surrounding us is more difficult than we could have predicted. In this paper, we explore doodling as a tool for self-control while attending passive online spaces. We, four researchers in the field of Human-Computer Interaction, engaged in doodling during our online meetings, seminars, and conferences. We also kept an autoethnographic diary along with a collection of our doodles. We reflected and then discussed through affinity diagramming, whereby five themes were developed: More than human, Designerly ways of sketching, Traces of time and space, Emotional aesthetics &amp; thoughts, Sketching materials, techniques, and tangible characteristics. We conclude by inviting the HCI community to contribute with their doodles during the CHI2023 conference in Hamburg or remotely.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582747
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582747
KW  - autoethnography
KW  - doodles
KW  - remote meetings
KW  - sketching
KW  - visual thinking
ER  - 

TY  - CONF
TI  - Dispensing with Humans in Human-Computer Interaction Research
AU  - Byun, Courtni
AU  - Vasicek, Piper
AU  - Seppi, Kevin
T3  - CHI EA '23
AB  - Machine Learning models have become more advanced than could have been supposed even a few years ago, often surpassing human performance on many tasks. Large language models (LLM) can produce text indistinguishable from human-produced text. This begs the question, how necessary are humans - even for tasks where humans appear indispensable? Qualitative Analysis (QA) is integral to human-computer interaction research, requiring both human-produced data and human analysis of that data to illuminate human opinions about and experiences with technology. We use GPT-3 and ChatGPT to replace human analysis and then to dispense with human-produced text altogether. We find GPT-3 is capable of automatically identifying themes and generating nuanced analyses of qualitative data arguably similar to those written by human researchers. We also briefly ponder philosophical implications of this research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582749
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582749
KW  - gpt-3
KW  - prompt engineering
KW  - qualitative analysis
ER  - 

TY  - CONF
TI  - Criptopias: Speculative Stories Exploring Worlds Worth Wanting
AU  - Angelini, Robin
AU  - Burtscher, Sabrina
AU  - Fussenegger, Felix
AU  - Kender, Kay
AU  - Spiel, Katta
AU  - Steinbrecher, Franz
AU  - Suchanek, Oliver
T3  - CHI EA '23
AB  - In a manner of cripping access in technology, we use the concept of criptopias and what it might bring to technology research and Human-Computer Interaction along a range of speculative stories that explore desirable worlds from a crip perspective. We stretch our bodyminds into the past, present and futures to identify how we might thrive in worlds that welcome us, instead of giving us the persistent notion of being considered as an afterthought. Such a collection is necessarily eclectic and not oriented on providing solutions; rather, we carefully tread forward on trying to find different stories we tell to and about ourselves through speculative explorations of how disability-centred interactions could be shaped. However, as we discuss briefly at the end, allowing ourselves to desire difference has the tendency to throw us back into the lack of a given status quo, making such an endeavour surprisingly painful to endure – while simultaneously providing wholesome alternatives worth fighting for in solidarity.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582743
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582743
KW  - Access
KW  - Crip HCI
KW  - Criptopia
KW  - Speculative Fictions
ER  - 

TY  - CONF
TI  - Collision Design
AU  - Marshall, Joe
AU  - Tennent, Paul
AU  - Li, Christine
AU  - Pacheco, Claudia Núñez
AU  - Garrett, Rachael
AU  - Tsaknaki, Vasiliki
AU  - Höök, Kristina
AU  - Caleb-Solly, Praminda
AU  - Benford, Steven David
T3  - CHI EA '23
AB  - Collision, "the violent encounter of a moving body with another", is poorly understood in HCI. When we discuss people colliding with the physical artifacts we create, or colliding with each other while using our systems, this is primarily treated as a hazard, something which we should design to avoid. However many other human activities involve situations where deliberate exposure to risk of collision may in fact have positive aspects. In this paper we discuss how the ’risk matrix’, a widely used risk-management tool, which categorizes risks in terms of likelihood and severity, may limit interaction in unintended ways. We discuss reframings of this matrix in relation to design concepts of ’adventure’, ’disempowerment/agency’ and ’consent’. and show that a range of design spaces for collisions exist which may be fruitful to explore.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582734
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582734
KW  - collision
KW  - human-robot interaction
KW  - risk
ER  - 

TY  - CONF
TI  - Wizard of Oz Prototyping for Interactive Spatial Augmented Reality in HCI Education: Experiences with Rapid Prototyping for Interactive Spatial Augmented Reality
AU  - Mast, Danica
AU  - Roidl, Alex
AU  - Jylha, Antti
T3  - CHI EA '23
AB  - In this paper we present our findings that emerged from Wizard of Oz (WOz) prototyping workshops of an undergrad course on UX design between 2017 – 2022. The purpose of these workshops is both to familiarize the students with WOz as a rapid low-complexity prototyping method and to facilitate them in designing for interactive systems beyond typical graphical user interfaces. In these workshops, students develop and test Wizard of Oz prototypes for interactive spatial augmented reality (SAR). Over the past six years, in total 93 prototypes have been created on the course. We analyzed the prototypes that emerged from the workshops based on input, purpose, play characteristics and projection surfaces. Based on the analysis and our experiences during the workshops, we conclude that the workshops stimulate creativity, enable students to rapidly create interactive SAR interfaces without being limited by their technical skills and time limitations and provide them with a tool that they apply beyond the scope of the prototyping course. We discuss advantages and limitations of the use of WOz prototyping for interactive Spatial Augmented Reality.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573861
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573861
ER  - 

TY  - CONF
TI  - Weisst Du wieviel Sternlein stehen? – Building older adults’ confidence in technology use through co-designing digital storytelling
AU  - An, Lan
AU  - Huwald, Christel
AU  - Muñoz, Diego
AU  - Pedell, Sonja
AU  - Sterling, Leon
T3  - CHI EA '23
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573868
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573868
KW  - co-design
KW  - confidence
KW  - digital storytelling
KW  - older adults
KW  - technology
ER  - 

TY  - CONF
TI  - A Playful Twist on the Peer Review Process and Methodological Gaslighting
AU  - Eagle, Tessa
AU  - Baltaxe-Admony, Leya Breanna
AU  - Taber, Lee
AU  - Ringland, Kathryn E.
T3  - CHI EA '23
AB  - Peer review in research is like jury duty – no one wants to do it but everyone needs to in order for the community to continue to produce quality peer-reviewed work. However, there is no explicit incentive and little-to-no training for writing reviews. This is especially difficult in interdisciplinary communities such as CHI, where quantitative and qualitative research are both common and reviews could be coming from someone with any area of expertise. In this piece, we give parody reviews for a quantitative paper as qualitative researcher reviewers. Many of the requests and commentary found within this piece are paraphrased from reviews we have received of our own qualitative research. Using this playful reversal, we promote discussion around responsible review practices, the inclusion of more transparent research where bias, ethics, potential harm, and positionality are explicitly discussed across methodologies and epistemologies.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582745
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582745
KW  - peer review
KW  - qualitative research
ER  - 

TY  - CONF
TI  - Bits are Cheap, Atoms are Expensive: Critiquing the Turn Towards Tangibility in HCI
AU  - Holmquist, Lars Erik
T3  - CHI EA '23
AB  - Ever since the introduction of the desktop interface, HCI has strived to develop alternatives that make interacting with computers more physical, embodied and ubiquitous. In particular, the vision of tangible user interfaces (TUI) has had a large impact and inspired an extensive body of research over the last 25 years. However, despite strong interest from the research community, commercial success has been limited. We argue that the reason is that whereas graphical user interfaces are inherently cheap, physical interfaces are expensive: to create; to control; to modify; to maintain; and to mass-produce and distribute. This also leads to TUIs being highly problematic from a sustainability viewpoint. Finally, as a way to combine the best of both worlds, we introduce a vision of liberated pixels, which are visual output elements that are perceivable, addressable, and persistent in the physical world.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3582744
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3582744
KW  - embodied interaction
KW  - future of HCI
KW  - liberated pixels
KW  - sustainability
KW  - Tangible user interfaces
KW  - ubiquitous computing
ER  - 

TY  - CONF
TI  - Your mileage may vary: Case study of a robotic telepresence pilot roll-out for a hybrid knowledge work organisation
AU  - Boudouraki, Andriana
AU  - Fischer, Joel E
AU  - Reeves, Stuart
AU  - Rintel, Sean
T3  - CHI EA '23
AB  - Organisations wishing to maintain employee satisfaction for hybrid collaboration need to explore flexible solutions that provide value for both remote and on-site employees. In this case study, we report on the roll-out of a telepresence robot pilot at Microsoft Research Cambridge UK to test whether robots would provide enjoyable planned and unplanned encounters between remote and on-site employees. We describe the work that was undertaken to prepare for the roll-out, including the Occupational Health and Safety assessment, systems for safety and security, and the information for employees on safe and effective use practices. The pilot ended after three months, and robot use has been discontinued after weighing the opportunities against low adoption and other challenges. We discuss the pros and cons within this organisational setting, and make suggestions for future work and roll-outs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573871
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573871
KW  - hybrid office
KW  - hybrid work
KW  - mobile robotic telepresence
KW  - videoconferencing
ER  - 

TY  - CONF
TI  - Visualizing Client Interactions in B2B Context: Design Explorations
AU  - Yeshi, Tenzin
AU  - Lee, Alice Yoonjeong
AU  - Moore, Robert
AU  - Ren, Guang-Jie
T3  - CHI EA '23
AB  - In business-to-business (B2B) commerce, the provider organization’s collective understanding of the client organization is distributed across the communications among a multitude of individuals. However, the substance of many of these communications typically goes unrecorded even when using standard Customer Relationship Management (CRM) tools and therefore their value remains largely untapped. In an attempt to capture these valuable client interaction data, we built an intuitive data capture tool that fits in with sellers’ client-facing workflows. But despite giving positive feedback on our prototype, our study participants informed us that the company was transitioning to a new CRM system, an industry standard. Therefore, we pivoted to creating visualizations for client insights. Based on extensive feedback from our participants, we designed four novel B2B interaction visualizations: 1) Interactions, 2) Timeline, 3) Topics and 4) Network. In this paper, we report on our design exploration for using CRM data to visualize client relationships in B2B context and discuss the challenges we encountered.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573860
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573860
KW  - client interactions
KW  - interaction visualization
KW  - network visualization
KW  - timeline visualization
KW  - topic visualization
ER  - 

TY  - CONF
TI  - Using Smart Glasses to Support Situated Decision Making in Aquaculture
AU  - Xi, Mingze
AU  - Adcock, Matt
AU  - Thomas, Bruce H
AU  - McCulloch, John
AU  - Arnold, Stuart
AU  - George, Andrew
T3  - CHI EA '23
AB  - The rapidly expanding prawn farming industry is vital in providing high-quality protein for the increasing global population. The key to consistently high yield is the efficient and effective management of pond water, maintaining the optimal growth environment. Our consultations with seven Australian commercial prawn farms found that the lack of access to essential real-time water information and trends has hindered farmers from making confident and timely decisions while in the field, which contributes considerably to either prolonged suboptimal pond conditions or increases in operational costs. This paper describes two aquaculture pond water management tasks that can benefit from wearable technology and discusses general concerns about using smart eyewear in harsh outdoor farming environments. A Pondside Visualisation System was created to allow farmers to access visualised historical and real-time water data during field operations using Google Glass Enterprise Edition 2. The application uses a new data visualisation style that is optimised for small near-eye displays. A validation study was conducted with seven industrial practitioners (including a supervisor and six farm technicians) on a commercial farm with real data from the recent growing season, where each technician made 100 pond management decisions using our system. Objective measurements of task completion time and task accuracy indicated the farmers achieved an accuracy of 86.4% and 89.2% for two management tasks with at least 41.0% less time compared to existing desktop-based practice. A structured expert review confirmed the usability of our system and discussed methods to mitigate issues discovered during the study. We also discussed lessons learned from the project.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573856
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573856
KW  - aquaculture
KW  - decision-support
KW  - empirical study
KW  - in-situ analysis
KW  - smart farming
KW  - smart glasses
ER  - 

TY  - CONF
TI  - Unraveling The Complexity: A User-Centered Design Process For Narrative Visualization
AU  - Tuzcu, Nil
AU  - White, Annie
AU  - Leonard, Brendan
AU  - Geofrey, Steven
T3  - CHI EA '23
AB  - In this case study, we introduce a user-centered design process for developing Metroverse, a narrative visualization platform that communicates urban economic composition and growth opportunities for cities. The primary challenge in making Metroverse stems from the complexity of the underlying research and data, both of which need to be effectively communicated to a wide range of end-users with different backgrounds. To unravel the complexity of the research, and to design the platform, we followed a user-centered design process. Our design process brought together researchers, designers, and various end-users, who collectively guided the design of the narrative visualization. Engaging end-users in the early phases of the project allowed us to identify the valuable insights in the data and subsequently design effective visualizations that convey those insights. We believe findings from our process can provide a template for similar projects that require translating complex research data and methodologies into user-friendly story structures.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573866
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573866
KW  - data visualization
KW  - narrative visualization
KW  - storytelling
ER  - 

TY  - CONF
TI  - Understanding the Needs of Enterprise Users in Collaborative Python Notebooks: This paper examines enterprise user needs in collaborative Python notebooks through a dyadic interview study
AU  - Li, Catherine
AU  - Massachi, Talie
AU  - Eschler, Jordan
AU  - Huang, Jeff
T3  - CHI EA '23
AB  - Python notebooks are an important productivity tool for technical employees in software companies. The Python notebook format originates from open-source coding projects and scientific research; notebooks were intended to spread knowledge about solving problems and modeling analytic approaches through code. In this case study writeup, we describe a qualitative study of Python notebooks as sites of user collaboration among varied roles (engineers, data scientists, and technical investigators) in a Fortune 500 software enterprise. Findings of the case study build on previous research on collaboration via notebooks, and articulate specific collaborative tasks undertaken by participants, the benefits of these collaborative tasks to the user and the broader enterprise, and design implications of findings around user needs for collaborative workflows. Finally, we reflect on the findings of this study in terms of applying a method specific to the use context of interest, as well as the study's impact on enterprise software strategy.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573843
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573843
ER  - 

TY  - CONF
TI  - TOFI: Designing Intraoral Computer Interfaces for Gamified Myofunctional Therapy
AU  - Franzke, Luke
AU  - Gartmann, Jonas
AU  - Bachmann, Dominik
AU  - Töpper, Tino
AU  - Franinović, Karmen
T3  - CHI EA '23
AB  - In the last two decades, there have been several proposals for Intraoral Computer Interfaces (ICI), with demonstrations of novel technologies mostly aimed at assistive devices or in hand-free scenarios. This paper demonstrates a case study for wearable ICIs that allows users to train their tongue muscles with gamified myofunctional therapy: a method that can reduce snoring and mild sleep apnea. This demonstrates a novel application of ICIs together with new design and technological solutions for fabricating such devices. We also discuss the various challenges associated with the design of ICIs and ICI based interactions to lay the groundwork for future research, prototypes and a broader exploration of ICI application areas.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3573848
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3573848
KW  - Gamification
KW  - Intraoral Interface
KW  - Prototyping
KW  - Therapy
ER  - 

TY  - CONF
TI  - Comprehensive evaluation of multi-criteria ship stowage schemes based on AHP-fuzzy-Topsis
AU  - Wang, Guo
AU  - Han, Can
AU  - Li, Qiangkun
AU  - Liu, Jingqiao
AU  - Mu, Nan
AU  - Li, Jiang
T3  - EITCE '22
AB  - A scientific and effective ship stowage scheme is of great practical significance for the realization of efficient maritime force projection. Ship stowage scheme is a multi - criteria decision making problem, by analyzing the basic requirements and difficulties of ship stowage, the evaluation indicators of ship stowage plan are clarified, and the index system for the evaluation of the ship stowage scheme is established. Use fuzzy analytic hierarchy process (FAHP) to calculate the weight of each evaluation index of ship stowage scheme, on the basis of simplifying the analysis of multiple sub-objectives of the stowage scheme, a mathematical model of ship stowage is established. The AHP-fuzzy-Topsis evaluation model is established by combining with the technique for order preference by similarity to an ideal solution. And ten stowage schemes are taken as examples to conduct case analysis. The results show that the effectiveness and feasibility of the evaluation system of ship stowage schemes, and lays a theoretical foundation for the evaluation system of ship stowage schemes.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573499
SP  - 411
EP  - 416
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573499
ER  - 

TY  - CONF
TI  - Dynamic RCS Statistical Modeling of Stealth Aircraft
AU  - Ma, Qiankuo
AU  - Zhang, Xiaokuan
AU  - Wang, Yang
AU  - Zong, Binfeng
AU  - Xv, Jiahua
AU  - Zheng, Shuyu
AU  - Su, Yongquan
T3  - EITCE '22
AB  - With the development of stealth technology, the threat of stealth aircraft with high speed and high maneuverability is increasing. Statistical distribution model can reveal dynamic RCS characteristics, which is an important part of anti-stealth technology. In this paper, the static RCS database is established initially. Combining with the level flight and the circling track models, two dynamic RCS sequences are obtained based on the static RCS database. Then, these dynamic RCS sequences are described by chi-square distribution model, log-normal distribution model and Weibull distribution model. The K-S test results reveal that the log-normal distribution has high accuracy. So, the log-normal distribution has good potential in anti-stealth.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573496
SP  - 395
EP  - 399
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573496
KW  - Dynamic RCS statistical characteristics
KW  - Fitting degree test
KW  - Log-normal distribution model
KW  - Radar Cross Section (RCS)
KW  - Stealth aircraft
ER  - 

TY  - CONF
TI  - Design of wind sensor measurement and control system for extreme cold environment ∗
AU  - Shang, Zhiwei
AU  - Qi, Suiping
AU  - Ma, Ran
AU  - Li, Yunzhou
T3  - EITCE '22
AB  - With the development of meteorological observation refinement, the polar regions and other extremely cold regions also need to carry out real-time wind observation, but the existing various types of wind measurement sensors are difficult to adapt to such extremely cold environment. In this paper, we developed a wind measurement and control system based on the principle of ultrasonic wind measurement with time difference method for extremely cold environment, and designed the basic circuit consisting of STM32 microcontroller minimum system, transducer driving circuit, echo signal receiving and conditioning circuit, etc. Based on this, we designed a fuzzy PID temperature control circuit to protect the sensitive element transducer at constant temperature, and also carried out the thermal insulation and protection design for the measurement and control part of the shell. And through the software simulation of the designed PID temperature control mode to select the verification. The wind sensor measurement and control circuit designed in this paper is applicable to the extremely cold environment, which has a guaranteed role in the development of wind measurement sensors applicable to the extremely cold environment and is of great significance for the acquisition of wind element information in the polar region.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573498
SP  - 406
EP  - 410
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573498
KW  - measurement and control circuit
KW  - sonic wind measurement
KW  - wind measurement sensor
ER  - 

TY  - CONF
TI  - Two-stage Pipelined SRAM Design Based on 14nm FinFET Process
AU  - Lou, Yuan
AU  - Zhang, Lijun
AU  - Yan, Yuling
AU  - Ma, Lijun
AU  - Zhang, Zhongda
T3  - EITCE '22
AB  - In this paper, we propose a two-stage pipeline architecture for Static Random Memories (SRAM), which can reduce the decoder delay and thus effectively improve the memory operation speed. The proposed two-stage pipeline architecture divides the SRAM in the conventional architecture into two parts, the decoder and the read/write path, by a hierarchical approach and uses registers to connect these two parts. Simulation results using SMIC 14nm FinFET devices show that for a high-speed SRAM of 512words*16bits, the access speed of the array is improved by 21% compared to the SRAM under the conventional architecture. This design not only implements the read/write function of the two-stage pipelined SRAM, but also provides some optimization of its performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573497
SP  - 400
EP  - 405
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573497
KW  - 14nm FinFET
KW  - High Speed
KW  - Pipeline
KW  - SRAM
ER  - 

TY  - CONF
TI  - Research on Mask Wearing Recognition Based on Deep Learning
AU  - Fu, Jingyu
T3  - EITCE '22
AB  - Since the outbreak of COVID-19 epidemic, research results have shown that the COVID-19 transmitted by droplets, and the most effective means of epidemic prevention is to wear masks. In public places where crowds gather, it is particularly important to use technical means to detect the situation of wearing masks, and remind people to wear masks in time to prevent cross-infection. This paper mainly starts with the target detection and tracking technology in the field of computer vision, and takes the recognition of whether to wear a mask as the entry point. Using python as the development tool, based on the convolutional neural network, the YOLOv2 algorithm is used as the core algorithm, and the ResNet50 network structure is built. Compared with other existing system test experiments, we can see that the system we built has better detection performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573495
SP  - 390
EP  - 394
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573495
KW  - COVID-19
KW  - Mask Recognition
KW  - ResNet50
KW  - YOLOv2
ER  - 

TY  - CONF
TI  - Cowpea disease leaf Contour Extraction Based on Improved Kmeans Algorithm ∗
AU  - Li, Jingcong
AU  - Xian, Zeng
T3  - EITCE '22
AB  - In order to extract complete leaf image contours of cowpea diseases under natural environment, cowpea disease leaf image segmentation method combining squirrel search algorithm and Kmeans clustering algorithm was proposed. Firstly, the images were converted from RGB color space to HSV color space; then the squirrel search algorithm was used to obtain the initial cluster centers to improve the Kmeans algorithm for image segmentation; morphological operations were used to smooth the images; finally, after removing small area noise, the Canny algorithm was used to extract the complete cowpea diseased leaf outline. The experimental results show that the cowpea diseased leaf images segmented by the algorithm used in this paper have smooth edges and can effectively segment cowpea leaves, which provides a basis for the application of computer vision in cowpea disease identification.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573492
SP  - 373
EP  - 377
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573492
KW  - canny algorithm
KW  - contour Extraction
KW  - image segmentation
KW  - kmeans algorithm
KW  - squirrel search algorithm
ER  - 

TY  - CONF
TI  - Automatic proportioning system for indium electrolyte based on single neuron PID
AU  - Hu, Qirui
AU  - Jiao, Peng
AU  - Yu, Ruichen
AU  - An, Jiming
AU  - Zhang, Hesheng
AU  - Gao, Zhiyuan
T3  - EITCE '22
AB  - To address the problem that indium electrolyte needs to be manually proportioned and diluted several times during indium ion concentration measurement, this paper uses a single-neuron adaptive PID control algorithm, with STM32 as the core controller to study and design an automatic proportioning system for indium metal electrolyte. The control result of single-neuron PID is quantified by using pulse width modulation technique, and the PWM control signal is generated by the output of STM32. This signal is amplified by the speed regulation circuit and used to control the gear pump for pumping and proportioning. Experimental results show that the average error of the proportioning is only 0.35 ml, and the accuracy can reach 99.96%, which realizes the high-precision automatic proportioning and improves the efficiency of indium ion concentration measurement.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573491
SP  - 367
EP  - 372
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573491
KW  - Indium ion
KW  - Proportioning system
KW  - Single neuron PID
KW  - STM32
ER  - 

TY  - CONF
TI  - Sonar Pulse Detection and Recognition Based on Deep Denoising
AU  - Yin, Yaping
AU  - Qiu, Jiaxing
AU  - Sun, Shilin
AU  - Zhou, Leilei
AU  - Li, Haitao
T3  - EITCE '22
AB  - In view of the slow convergence of the typical denoising network, which is prone to excessive smoothing of images and insufficient recovery of detailed features, this paper proposed a deep denoising network architecture based on the auto-encoder network and the generative adversarial network. That took advantage of the adversarial learning of generators and discriminators, making denoising results sharper and clearer, improving the over-smoothing issue of images, and enhancing the restoration of specific information. Meanwhile, the residual structure was introduced into encoders of the auto-encoder network, which further augmented their denoising capacity and accelerated the convergence of the loss function of the generative adversarial network. In the end, the YOLOv3 network was respectively employed to detect the sonar pulse power spectrum images before and after denoising and analyze the performance of the proposed deep denoising network in the sonar pulse detection. The experimental results manifest that both the power signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) of the denoised image are improved, compared with those of the low signal-noise sonar pulse power spectrum image and that the target detection accuracy is remarkably lifted, which proves the proposed the effectiveness of the deep denoising network in improving the quality of the power spectrum image about the sonar pulse signal, and the significance of denoising process in the sonar pulse detection.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573494
SP  - 384
EP  - 389
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573494
ER  - 

TY  - CONF
TI  - Equipment leakage risk assessment based on Fault Tree-Bayesian Network and consequence simulation
AU  - Chen, Qiyun
AU  - Li, Qifang
AU  - Han, Xuefeng
AU  - Bo, Cuimei
T3  - EITCE '22
AB  - In this paper, a risk assessment method based on the fusion of Fault Tree and Bayesian Network is proposed for the leakage risk assessment of hazardous chemical production equipment. The influencing factors of typical chemical equipment leakage are first analyzed, and an equipment leakage Fault Tree is constructed according to the causal factor analysis method to quantitatively describe the possibility of leakage accidents. Then, the Bayesian Network of equipment leakage is constructed based on the Fault Tree, and it is concluded that valve failure and flange failure are the main risk factors leading to leakage. Finally, Aspen dynamics is used to establish a simulation system of acrylic acid production process. Aiming at the risk factors of reactor feed valve failure, the leakage failure caused by the valve in different degrees is simulated, and the diffusion consequence caused by leakage are calculated, which prove the effectiveness of the above methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573493
SP  - 378
EP  - 383
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573493
KW  - Bayesian Network
KW  - Fault Tree
KW  - leakage
KW  - risk assessment
ER  - 

TY  - CONF
TI  - A denoising method based on CNN through multi-layer separation
AU  - Huang, Jianyu
AU  - Cai, Nanting
AU  - Mao, Jian
AU  - Zhang, Jialin
AU  - Zhao, Xiaochun
T3  - EITCE '22
AB  - In the process of electromagnetic information leakage detection, the traditional denoising methods have the problem of insufficient ability to identify useful information under low SNR. This problem results in the useful information being easily removed as a noise signal in the denoising process. Aiming at this problem, this paper proposes a denoising method based on convolutional neural network (CNN), which is achieved by decomposing red and black signals layer by layer. This method can not only show a better denoising effect under a low SNR condition, but also locate, identify and enhance the useful information effectively.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573490
SP  - 361
EP  - 366
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573490
KW  - CNN
KW  - EM leakage
KW  - Grad-CAM
KW  - separation of signal
KW  - Signal denoising
ER  - 

TY  - CONF
TI  - Prediction of flocculant dosage in water plant based on LSTM network
AU  - Hu, Yingtao
AU  - Li, Jin
T3  - EITCE '22
AB  - Flocculation and sedimentation is a crucial step in the water treatment process. Currently, most water plants still use a fixed-value proportional dosing method for flocculant dosing, which has low accuracy. Flocculant dosing prediction is a time series problem, and the complexity of the problem that can be expressed using traditional time-series modeling is limited, and machine learning requires a more complex manual feature engineering component. In this paper, we propose an LSTM neural network prediction model incorporating the Attention mechanism to correlate current sensor acquisition data with historical moment data, extract multidimensional features, and focus on key information and ignore redundant information. It can be a better solution for this problem with nonlinearity, multiple input factors, uncertainty, and time-varying characteristics. Through experiments, comparing the common models such as BP, RNN, LSTM, etc. to predict the flocculant dosing of half-yearly in water plants, the model has a high accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573489
SP  - 356
EP  - 360
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573489
ER  - 

TY  - CONF
TI  - Admission Probability Prediction of College Entrance Examination Based on Siamese Network
AU  - Gao, Sida
AU  - Liu, Tianming
AU  - Fu, Lijun
AU  - Chen, Xueliang
T3  - EITCE '22
AB  - For students taking the College Entrance Examination, the choice of major is as important as their scores. The choice is often related to whether the candidate can be admitted with a higher probability. Therefore, how to accurately predict the admission probability has become the important problem. In this paper, by using the candidate's provincial rank in the current year and the provincial enrollment rank of each major in the past three years, Siamese network structure combined with gated recurrent unit is used to predict the admission probability of the candidate in each major. It was found that the model can accurately calculate the admission probability, and can capture the time series information of the rank change in previous years. Compared with the traditional average method, it has a great improvement.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573488
SP  - 352
EP  - 355
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573488
ER  - 

TY  - CONF
TI  - MATLAB-Based App for Handwritten Numeral Recognition
AU  - Wang, Yongzhe
T3  - EITCE '22
AB  - Handwritten numeral recognition (HNR) is widely used in various industries and is essential to the research and development of optical character recognition (OCR) technology. Given that most of the current HNR algorithms require high-quality input images rather than naturally taken photographs, a MATLAB-based application with a graphical user interface (GUI) is designed for pre-processing and segmenting photographs of handwritten numerals and then recognizing the numerals. For the various conditions that a naturally taken a photograph may have in practice, the application can perform denoising, perspective correction, and binarization of the original image, as well as removing horizontal lines, grids, or boxes from the background. The application can then segment and recognize every numeral from the processed image. It has been experimentally verified that the application can satisfactorily pre-process the original image while providing high accuracy in recognizing numerals.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573485
SP  - 331
EP  - 337
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573485
KW  - handwritten numeral recognition
KW  - image processing
KW  - MATLAB
ER  - 

TY  - CONF
TI  - Transformer-based Iterative Update Stereo Matching Network
AU  - Kong, Qun
AU  - Zhang, Liye
AU  - Wang, Zhuang
AU  - Li, Yegang
AU  - Wei, Bingcai
T3  - EITCE '22
AB  - Feature extraction is a crucial part of the stereo matching algorithm based on deep learning. The existing stereo matching algorithms have poor matching effects on smaller objects in the background and low-texture areas, which leads to the decrease of disparity estimation accuracy. To improve the accuracy of disparity estimates, we propose TUNet, a Transformer-based iterative update stereo matching network in this paper. After the feature extraction module, the attention mechanism and positional encoding of the Transformer algorithm are added to the network, which enables the transformed features to better combine global context information. In the disparity calculation stage, the improved Gate Recurrent Unit (GRU) module in Recurrent All-Pairs Field Transforms for Optical Flow (RAFT) algorithm is added. In addition, the correlation of each feature is calculated at various resolutions. With correlation lookup and disparity update at the highest resolution and the final disparity map is obtained by GRU cross-up update. Our results show higher accuracy and dense disparity. The matching effect of smaller objects in the background or low-texture areas is improved, as is overall disparity accuracy. The proposed method is trained in ETH3D, Middlebury, and KITTI 2015 datasets. The proposed method minimizes the rate of mismatching and has some robustness when compared to earlier stereo matching algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573487
SP  - 345
EP  - 351
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573487
KW  - 4D Correlation Volumes
KW  - Attention Mechanism
KW  - GRU
KW  - Stereo Matching
ER  - 

TY  - CONF
TI  - A robust ground segmentation method for vehicle lidar
AU  - Ren, Yanyong
AU  - Meng, Shaojie
AU  - Huang, Miaohua
AU  - Hou, Yang
T3  - EITCE '22
AB  - Ground points of lidar is the redundant information in the perception process of autonomous driving. Removal of ground points is beneficial to the improvement of accuracy and real-time performance in the perception process. Aiming at the problems of under-segmentation and over-segmentation in current methods, proposes a segmentation method based on point cloud normal clustering. First, the original point cloud is preprocessed to reduce the time cost of the whole process; then, the preprocessed point cloud is quickly pre-segmented by the ray threshold method, and the ground point cloud containing some non-ground points is obtained; finally, according to the normal vector features of ground point and non-ground points, we filter out the non-ground points in the ground point cloud to obtain the final ground point cloud. The experimental results show that the average precision and recall rate of this method in various road conditions can reach 90%, and the average time consumption is 50 ms, which has good real-time performance and adaptability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573486
SP  - 338
EP  - 344
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573486
KW  - Normal vector
KW  - Point cloud
KW  - Post-segmentation
KW  - Pre-segmentation
KW  - Precision
KW  - Recall
ER  - 

TY  - CONF
TI  - Use Edge Detection Method and Matlab for Time Measurement in Athletics Field
AU  - Weng, Yiting
T3  - EITCE '22
AB  - Even though the technology of real-time recording in the Athletics field is highly developed, it is still not easy for people to calculate the time from a recorded video. People can only estimate the time with their eyes if a randomly chosen video is given. So in this paper, the method will be introduced to provide a fundamental choice to solve such a problem. The process will be based on the Matlab program as it is a convenient tool providing an essential technique for image processing. For the detail of this method, the Edge Detection method and Hough Transform are used to locate the edge of athletes and tracks to find out the time score from a running race video. Even though the result may have an error in about 0.03 seconds, it is much more precise than calculating from the human eyes and, as a result, can have practical use with further development.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573484
SP  - 326
EP  - 330
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573484
KW  - Edge Detection
KW  - Matlab
KW  - Running
KW  - Time recording
ER  - 

TY  - CONF
TI  - Recurrence, Analysis and Prototype Regression Verification of Occasional Problems in Chip Design
AU  - Ning, Zhenhai
AU  - Li, Dejian
AU  - Feng, Xi
AU  - Zhang, Yanxin
AU  - He, Longlong
AU  - Li, Jinwang
AU  - Tan, Lang
AU  - Yang, Lixin
T3  - EITCE '22
AB  - In the early stage of chip development, prototype verification has become a main way to save time, reduce cost and improve the success rate of chip flow. Its purpose is to restore the real application scenario of the chip as much as possible before streaming, so as fully verify the function of the chip, ensure the reliability and stability of functional modules as much as possible, improve the overall efficiency of chip development, reduce development errors, and reduce the risk of streaming failure. However, in the face of the complexity of the situation, it is obvious that prototype verification cannot reach 100% coverage, which makes some hidden design flaws become fish that escape from the net. This article describes the problems in specific scenarios during chip verification and trial. Aiming at this problem, this paper expounds the analysis methods and solutions of the problem in detail, that is, scene reproduction - defect analysis - simulation modification - regression prototype verification.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573483
SP  - 318
EP  - 325
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573483
ER  - 

TY  - CONF
TI  - Ultra-Broadband RCS Reduction Using "Bow-Shaped" Polarization Conversion Metasurface
AU  - Du, Jianglong
AU  - Zhao, Yongjiu
T3  - EITCE '22
AB  - A novel ultra-wideband (UWB) metasurface has been proposed to realize radar cross-section (RCS) reduction based on double layer chessboard structured polarization conversion metasurface (PCM). The “bow-shaped” unit cell consists of three split rings and one strap, which can produce five resonance points to improve the bandwidth of convert linear polarized waves into their orthogonal polarized ones. The structure has an ultra-wideband linear polarization conversion efficiency with at least a 90% polarization conversion ratio (PCR) from 7.3 to 26.1 GHz. Using the proposed cell and its mirror cell to form a chessboard structured metasurface, and comparing it with a metal surface of the same size, the obtained simulation results show that the proposed metasurface realizes a 10dB monostatic RCS reduction from 7.3-25.8 GHz.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573481
SP  - 307
EP  - 311
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573481
KW  - Metasurface
KW  - Polarization conversion metasurface
KW  - RCS reduction
KW  - Ultra-wideband
ER  - 

TY  - CONF
TI  - RDGFuzz: A directed greybox fuzzing optimization method based on Rich-Branch nodes
AU  - Wu, Zejun
AU  - Lu, Li
AU  - Jia, Qiong
AU  - Chen, Zhihao
T3  - EITCE '22
AB  - Directed fuzzing technology is one of the key technologies to quickly reach a specific location of software, and to conduct targeted testing or bug recurrence. However, directed fuzzing technology has some problems, such as unreasonable seed energy allocation, low code coverage and incomplete testing. To solve the above problems, this paper proposes an optimization method of directed fuzzing based on Rich-Branch nodes. In this method, the concept of Rich-Branch nodes is defined and the algorithm of extracting Rich-Branch nodes is given. The optimization method collects the coverage information of the target program in the running process, calculates the weights of covered functions and nodes in real time by combining CG and CFG of the target program, and generates a list of Rich-Branch nodes. According to the weights of Rich-Branch nodes, the seed energy allocation algorithm of AFLGo is optimized and improved. Compared with AFLGo, this optimization method improves the average code coverage of each targeted point by 56.79%, and has the same target reaching ability as AFLGo.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573482
SP  - 312
EP  - 317
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573482
KW  - Code coverage rate
KW  - Directed fuzzing
KW  - Rich-Branch nodes
KW  - Vulnerability discovery
ER  - 

TY  - CONF
TI  - Research on Implementation and Simulation Verification of Low-Zero-Power Distributed Communication Interference Based on Cmax Algorithm
AU  - Zou, Jianjin
AU  - Ding, Yongtao
AU  - Zhu, Yang
AU  - Ma, Li
T3  - EITCE '22
AB  - Based on the background of "low-to-zero power operation" in the concept of electromagnetic spectrum operation, this paper explores the realization method of low-zero-power distributed communication interference, discusses the calculation and change law of distributed interference suppression zone, puts forward the power deployment strategy to realize low-zero-power distributed communication interference, optimizes and improves the strategy with the aim of improving the stability and effectiveness of the interference, and then proposes Cmax algorithm around the realization of the strategy. Finally, the strategy is simulated by loading practical data with MATLAB simulation tool, which verifies that the low-zero-power distributed communication interference method based on Cmax algorithm is feasible. And the low-zero-power distributed communication interference is realized theoretically, which lays a theoretical foundation for the research and development of the actual system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573479
SP  - 294
EP  - 300
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573479
KW  - Distributed Communications Interference
KW  - Electromagnetic Spectrum Operations
KW  - Low to Zero Power
ER  - 

TY  - CONF
TI  - An Anti-reverberation Approach for wideband Sonar: Based on Sparse Processing
AU  - Wang, Hao
AU  - Wang, Feng
AU  - Dong, Yangze
T3  - EITCE '22
AB  - Reverberation is the main factor that limits the detection of close-range targets by an active sonar system. In this paper, a sparse processing method of dynamic measurement vector is proposed to realize the parameter reconstruction of reverberation and target for broadband sonar scenario. In this method, the high-resolution parameters are reconstructed one by one along the coarse resolution range bin in the reverberation region, and a tolerance term is added in the iterative process of reconstruction to distinguish reverberation and target. The measurement vector is updated synchronously during the phase atom search of the dictionary matrix, which effectively overcomes the range migration of the target and reverberation. Simulation results show that the proposed method can achieve accurate reconstruction and detection of target parameters in a reverberation background.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573480
SP  - 301
EP  - 306
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573480
KW  - anti-reverberation
KW  - frequency agility
KW  - sparse signal processing
KW  - wideband sonar
ER  - 

TY  - CONF
TI  - Device Management Model based on Internet of Things
AU  - Yang, Yizhuo
AU  - Zeng, Hongjin
AU  - Chen, Tingping
T3  - EITCE '22
AB  - Under the rapid development of Internet of Things (IoT), it is possible to connect more intelligent devices by network. Recent research shows that IoT has great application potential in information-intensive industries. However, the transmission protocols of devices produced by different manufacturers are diverse, which makes it difficult for terminal devices to access the network. In the application layer, different devices adopt different parsing protocols, which also makes it difficult to parse data. Firstly, this paper proposes a set of IoT access model, which describes the attributes and behaviors of access network devices by ternary form Internet of Things Data (IoTD) represented by Device Object (DO), Link Object (LO) and State Object (SO). Secondly, based on the IoT access model, a set of device access system is realized combined with cloud computing and edge computing technology, so that devices with different protocols can quickly access the network. Finally, the device access system is verified by experiments from three aspects: heterogeneous connectivity, delay characteristics and throughput characteristics. The results show that in the distributed heterogeneous protocol device environment, the device access system based on the IoT access model supports the fast access of multiple protocol devices, and has the transmission performance that meets the field requirements.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573478
SP  - 287
EP  - 293
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573478
ER  - 

TY  - CONF
TI  - Forecast of photovoltaic Power Generation Based on GRU
AU  - Gong, Guanhua
AU  - Lou, Ke
AU  - Yin, Jie
AU  - Li, Dongyv
T3  - EITCE '22
AB  - Solar energy is widely used in the field of new energy. However, the instability of the fluctuating output of photovoltaic power generation limits its application and development. Predicting its working power in the next stage can effectively improve energy utilization and reduce the difficulty of system maintenance. Based on the historical time series data and irradiation data of the photovoltaic power plant, a model GRU for short-term power prediction of the photovoltaic power plant is proposed, which uses a gated recurrent unity neural network. GRU can quickly and efficiently extract the effective features of the data, input the data of numerical weather forecast, and output the final forecast results through the model. The final prediction results are evaluated by mean absolute error (MAE), root mean square error (RMSE), mean absolute percentage error (MAPE) and symmetric mean absolute percentage error (SMAPE), Finally, the prediction results of GRU model used in this paper are compared with those of CNN and LSTM models by evaluating these four indicators. The comparison of the results shows that the model selected in this paper has high accuracy and stability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573477
SP  - 283
EP  - 286
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573477
KW  - gated recurrent unity
KW  - numerical weather prediction
KW  - short-term power prediction
ER  - 

TY  - CONF
TI  - Depth-aware Trimodal Network for RGB-T Salient Object Dection
AU  - Zhang, Zisen
AU  - Li, Wei
T3  - EITCE '22
AB  - RGB-T salient object detection (SOD) aims to locate and segment the most attractive object in color-thermal image pairs. Depth information has been proved beneficial in RGB-D salient object detection during recent years. To take advantage of the structural information contained in the depth map, we build a depth-aware trimodal network (DATNet) to introduce depth modal into RGB-T SOD. First, we generate depth maps from RGB frames through existing monocular depth estimation methods, depth stream constitutes the third input to our DATNet. We use three independent transformer backbone net to extract hierarchical features. Our multimodal interaction module (MIM) is designed to achieve three modal feature enhancement and complementation. Notably, we treat the three modals unequally. Multimodal enhanced fusion module (MEFM) aims to refine the features after MIM and fuse them in stages. Finally, we use multiple supervisions in progressive decoding to obtain high-quality saliency maps. Comprehensive experiments on three public RGB-T SOD datasets show that the proposed network surpasses 8 state-of-the-art RGB-T SOD methods in terms of five metrics.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573476
SP  - 277
EP  - 282
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573476
KW  - multi-modal
KW  - salient object detection
KW  - transformer
ER  - 

TY  - CONF
TI  - Fish freshness evaluation based on MobileNetV1 and attention mechanism
AU  - Guo, Xin
AU  - Gu, Shenming
AU  - Wei, Dan
T3  - EITCE '22
AB  - Rapid acquisition of fish freshness is an important task. The traditional freshness detection of aquatic fish has the problems of damaging samples, complicated operation and long detection time. A convenient, rapid, nondestructive and accurate freshness detection method is urgently needed in production. In this study, the freshness of aquatic fish was evaluated nondestructively and rapidly by machine vision. Firstly, we select the appropriate data set, and add the attention mechanism module to the end of the MobileNetV1 with the default alpha value. Secondly, the alpha value of all models is reduced to compare the performance for subsequent deployment to the cloud and small embedded devices with limited resources. Finally, the network is trained by real data. The results show that the MobilenetV1 network with attention mechanism module can better evaluate the freshness of fish through the fisheye image. The convergence speed and accuracy of the network are improved compared with the original network, and it is more suitable for the task of determining the freshness of fish through fisheye.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573475
SP  - 270
EP  - 276
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573475
KW  - attention mechanism
KW  - deep learning
KW  - fisheye
KW  - freshness evaluation
KW  - image recognition
ER  - 

TY  - CONF
TI  - Modulation strategy based on midpoint potential control∗
AU  - Hu, Zhao
T3  - EITCE '22
AB  - The T-type three-level inverter has the advantage of lower conduction loss and higher output waveform quality than other types of inverters, but it also has the problem of midpoint voltage imbalance. In order to improve the midpoint equilibrium problem, this paper studies an optimized modulation strategy with T-type three-level as the research object. The adjustment factor is introduced during the virtual vector synthesis, and the adjustment factor is used to charge and discharge the upper and lower capacitors in the main circuit of the inverter according to the situation, and the simulation verifies the method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573474
SP  - 266
EP  - 269
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573474
KW  - Inverter
KW  - Midpoint potential balance
KW  - Modulation strategy
KW  - Regulatory factors
ER  - 

TY  - CONF
TI  - A GB-InSAR Atmospheri Phase Compensation Method in Complex Atmospheric Environment
AU  - Chen, Jiao
AU  - Liu, Yu
AU  - Jin, Chongyang
AU  - Tang, Jin
AU  - Yang, Zhihang
T3  - EITCE '22
AB  - In the deformation measurement of ground-based interferometric synthetic aperture radar (GB-InSAR), the phase delay caused by atmospheric changes is one of the main error sources. Conventional methods cannot effectively compensate for the severe spatial and temporal variability of the atmosphere in complex environments. Therefore, this paper proposes an improved method based on parametric models. Firstly the method compensates PS (Permanent Scatterer) with a conventional linear model, analyzes the standard deviation of the interferometric phase sequence of PS after compensation, and combines amplitude dispersion and amplitude threshold to achieve stable PS selection with three thresholds. Then, a two-dimensional high-order atmospheric phase model based on the polar coordinate system is constructed, and the model parameters are solved by least squares using stable PS, so as to realize the atmospheric phase compensation of all PSs. The method in this paper is used to analyze the measured data of a geological disaster monitoring site in Wanzhou District, Chongqing. The results show that the method can effectively compensate the atmospheric phase and greatly improve the deformation measurement accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573473
SP  - 261
EP  - 265
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573473
KW  - atmospheric phase compensation
KW  - ground-based interferometric synthetic aperture radar
KW  - stable permanent scatterer
KW  - two-dimensional high-order atmospheric phase model
ER  - 

TY  - CONF
TI  - Light Field Saliency Detection Based on Multi-modal Fusion
AU  - Jiang, Ben
AU  - Xu, Dan
AU  - Shi, Jinlong
T3  - EITCE '22
AB  - Compared with RGB images, light field images contain more abundant visual information, which is helpful to accurately detect salient objects in complex scenes. However, most of the existing light field saliency detection methods use single light field data or do not fully consider the differences and complementarities between different light field data, resulting in insufficient multi-modal fusion. To address these issues, a multi-modal feature fusion network is proposed, which makes full use of the rich visual information in the light field images to realize the accurate saliency object detection. The proposed network consists of two parallel subnets, which are used to process the micro-lens image array and all-foucs image respectively. Then the light field refinement module is used to refine the feature map extracted from the micro-lens array stream, and finally the multi-modal feature fusion is realized by the light field attention module to predict saliency objects more accurately. In order to verify the effectiveness of proposed method, extensive comparison with several existing light field saliency detection algorithms is carried on both Lytro-Illum and LFSD datasets. Experimental results show that the proposed method is superior to others in all evaluation metrics on Lytro-Illum dataset, and has desired generalization abilities on LFSD dataset.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573472
SP  - 253
EP  - 260
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573472
KW  - convolutional neural network
KW  - light field
KW  - micro-lens image array
KW  - multi-modal fusion
KW  - saliency detection
ER  - 

TY  - CONF
TI  - RSSI 3D Location Algorithm Based on Multiple Communication Radius and Distance Correction
AU  - Wang, Jun
AU  - Lu, He
AU  - Sheng, Haixian
T3  - EITCE '22
AB  - Three-dimensional ranging and positioning algorithms in wireless sensor networks mostly rely on the principle of two-dimensional positioning algorithm. At present, RSSI-based positioning algorithm is widely used because of its simplicity, but RSSI algorithm has high energy consumption and large ranging error when positioning nodes, which affects the service life of the network and the positioning accuracy of nodes. To solve this problem, On the basis of the existing RSSI localization algorithms, this paper proposes a RSSI three-dimensional localization algorithm based on multiple communication radius and distance corrections (MD-RSSI), which selects anchor nodes by five-step communication mechanism and distance correction factor corrects the estimated distance. Firstly, the multi-communication radius is used to communicate with the anchor node step by step, and the distance between the anchor node and the node to be measured is calculated by RSSI's own ranging model. Then, a correction factor is introduced to correct the distance and the free space loss model of energy is used to calculate the remaining energy of the anchor node after communication. Finally, three anchor nodes with a small number of partners and relatively high energy are selected through constraints to locate unknown nodes. Theoretical analysis and experimental results show that the improved MD-RSSI localization algorithm can reduce the energy consumption of node localization and improve the localization accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573471
SP  - 249
EP  - 252
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573471
ER  - 

TY  - CONF
TI  - Automatic generation of SysML requirement models based on Chinese natural language requirements
AU  - Chen, Jialu
AU  - Hu, Baokun
AU  - Diao, Wanwan
AU  - Huang, Yuqian
T3  - EITCE '22
AB  - In the face of increasingly complex systems engineering R&amp;D, Model-Based Systems Engineering (MBSE) is gradually replacing Traditional Systems Engineering, producing a significant shift in modelling language, modelling thinking and modelling tools. And SysML, as a common modelling language for MBSE practitioners, has many irreplaceable advantages. Requirements diagrams are the primary medium of SysML for conveying traceability between requirements and from requirements to structure and behaviour in a system model. Today, how to automate the construction of SysML requirements models is a significant challenge. This paper proposes an automatic SysML model generation method based on Chinese free-text requirements using natural language processing. Firstly, perform word segmentation and POS Tagging on the requirement text to construct a domain lexicon, extract effective requirements by combining the domain lexicon and regular expressions, and then mark the effective requirements with semantic roles, and determine the requirements elements through established rules, which are ultimately converted into SysML requirements diagrams.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573470
SP  - 242
EP  - 248
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573470
KW  - Model transformation
KW  - Natural language requirement text
KW  - SysML requirement diagram
KW  - System modelling language
ER  - 

TY  - CONF
TI  - A fast RCS simulation method for dynamic target based on Kriging interpolation
AU  - Wang, Tao
AU  - Su, Min
AU  - Liu, Jia
AU  - Hang, Runqin
AU  - Wei, Xiaoni
T3  - EITCE '22
AB  - This paper investigates the problem of radar cross sections (RCS) modeling and simulation for dynamic aircraft. The trade-off between RCS computation accuracy and efficiency are discussed for spatial fluctuation interference. In order to obtain dynamic RCS data with expected accuracy and efficiency, this paper proposes a RCS simulation method for dynamic targets based on Kriging interpolation. The method uses the attitude angle with perturbation modelling and RCS information in matrix from static simulation. The Kriging method integrates two types of information in a specific strategy to achieve the fast RCS simulation. Compared with the traditional interpolation algorithm, experimental results indicate that the dynamic RCS from Kriging interpolation algorithm can provide an expected computational accuracy with higher efficiency.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573469
SP  - 236
EP  - 241
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573469
KW  - dynamic target
KW  - Kriging
KW  - modeling and simulation
KW  - radar cross section
ER  - 

TY  - CONF
TI  - Recent Deep Learning Techniques on Short Text Classification
AU  - Yang, Zile
T3  - EITCE '22
AB  - A key work in language processing is text classification, which is used in information retrieval, recommendation, and sentiment analysis. Thanks to the advent of platforms like social media, short text has become one of the most predominant forms of communication. Recently, because of the unprecedented development of deep learning, deep neural network has been used to handle text classification by researchers. Although quantities of methods have been proposed in literature and the research work about this classification task has come a long way, there is a little summary about it, raising the need of a comprehensive review about the development of this task for the latest decade. This paper makes an overview of the classification task about introducing the techniques people used to improve the performance on the model. What's more, I make an analysis about the potential problems of this task which may be the key points that we should pay attention to in the future.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573468
SP  - 231
EP  - 235
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573468
KW  - deep learning
KW  - text classification
KW  - text mining
ER  - 

TY  - CONF
TI  - Research on information security risk assessment based on integrated influence of neighborhood
AU  - Wang, Tianyu
AU  - Zhao, Jianming
AU  - Zhang, Bowen
T3  - EITCE '22
AB  - At present, the information technology of industrial automation control system is developing rapidly, and the system information security is facing severe challenges. Accurate and efficient risk assessment of industrial control systems is conducive to their protection and efficient production. Although there have been quite a few studies on the risk assessment of industrial control systems, there is less consideration of the interaction between the equipment in the system at present. In view of this, this paper proposes an information security risk assessment method based on the impact of neighborhood integration, which can fully consider the changes of equipment functions within the damaged range of industrial control systems. The experimental results in some model systems reveal that the algorithm in this paper can evaluate the information security risks of industrial control systems more accurately, and provides a theoretical method for the stable operation of industrial systems.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573466
SP  - 220
EP  - 225
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573466
KW  - Industrial control system
KW  - Integrated influence
KW  - Risk assessment
ER  - 

TY  - CONF
TI  - Application research of photovoltaic power station operation and maintenance system based on Internet of Things technology
AU  - Zheng, Yun
AU  - Sun, Rongrong
AU  - Li, Zhicheng
AU  - Zhuang, Qiunai
T3  - EITCE '22
AB  - In order to adapt to the current high-quality development situation of the photovoltaic industry and improve the operation and maintenance efficiency of the photovoltaic power generation system while reducing the operating cost of the power station, it is inevitable to apply the Internet of Things technology to the operation and maintenance process of the photovoltaic power station. This paper first analyzes the defects of the operation and maintenance of the traditional photovoltaic power station, emphasizes the importance of applying the Internet of Things technology when changing the traditional operation and maintenance mode, then sorts out the existing operation and maintenance work methods based on the Internet of Things technology, and expounds its work content, system configuration and core technical issues, and finally prospects the application prospect of the Internet of Things technology in the operation and maintenance system of the photovoltaic power station.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573467
SP  - 226
EP  - 230
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573467
KW  - Distribution network planning
KW  - Internet of Things
KW  - Photovoltaic power generation
ER  - 

TY  - CONF
TI  - News classifications based on CBA-PreambleCNN Model
AU  - Wan, Zheng
AU  - Wang, Fang
AU  - Huang, Shucheng
T3  - EITCE '22
AB  - In order to solve the problems of insufficient information extraction and poor classification effect of a single deep learning model, this paper proposes a hybrid multi-neural network CBOW-BiLSTM-Attention-PreambleCNN model(The CBA-PreambleCNN for short, PreambleCNN is the name of the improved TextCNN). The model uses Word2Vec as the word embedding layer to obtain the vector representation of the word, and then feeds the Bidirectional Long Short-Term Memory (BI-LSTM) network to capture the global information of the text, and then uses the Attention mechanism to make the word get different weights. Finally, it is fed into the improved Text Convolutional Neural Network (TextCNN fused with previous information, named PreambleCNN) to obtain the topic features of the Text, and the obtained feature vectors are fed into the softmax function for classification. After comparison with other models, this model has achieved good classification effect, and achieved 93.47% and 84.65% accuracy on Sina news dataset and Sohu news dataset, respectively. To some extent, this model solves the problem of insufficient information captured by a single model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573465
SP  - 214
EP  - 219
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573465
KW  - Attention
KW  - Convolutional Neural Network
KW  - Recurrent Neural Network
KW  - Text classification
KW  - Word embedding
ER  - 

TY  - CONF
TI  - Sequence Recognition of Scene Text Based on CRNN and CTPN Models
AU  - Liu, Yiyi
T3  - EITCE '22
AB  - Image-based sequence recognition has lately emerged as a prominent study subject in the science of computer vision, while text detection and identification in natural situations has emerged as an active research field. Based on scene text data, this paper addresses the theory of deep learning-based CRNN and CTPN models and the process of processing text. Using CRNN, text recognition can be turned into a time-dependent sequence learning issue, which is commonly employed for indeterminate-length text sequences. Contextual relationships between text images are learned using BLSTM and CTC, thus effectively improving text recognition accuracy and making the model more robust. It also excels in text recognition tests for wordless and lexical-based scenes, as it is not constrained by any predefined language. It produces a more efficient, but smaller, model that is more suited to real-world settings. CRNN recognition accuracy is lower for short texts with large morphological changes, such as artistic words, or texts with large changes in natural scenes. Because of the Anchor setting, CTPN can only detect horizontally distributed text, but a small improvement can detect vertical text by adding horizontal Anchor. As a result of the limitations of the framework, the irregularly inclined text can be detected very broadly.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573462
SP  - 196
EP  - 200
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573462
KW  - CTPN
KW  - LSTM
KW  - OCR
KW  - Sequence recognition
ER  - 

TY  - CONF
TI  - Unsupervised Sentiment and Style Transfer from Massive Texts
AU  - Shen, Xianjie
AU  - Chen, Wei
AU  - Xu, Shu
T3  - EITCE '22
AB  - Unsupervised style transfer aims to transfer the intrinsic style of text while preserving its content without parallel datasets. Many sophisticated methods using reinforcement learning and neural networks have been developed to address this problem, however, their performance is not very ideal yet. We observe that given massive unpaired texts, there would exist high-quality sentence pairs that have similar style-independent content but different style words. Inspiring by this observation, in this paper, we propose a simple yet effective method without any neural network. Specifically, we consider both embedding similarity and BLEU score to locate similar sentences of different styles for a pseudo-parallel dataset construction. From this pseudo-parallel dataset, we distill the style words and align them into pairs based on statistical signals. We further refine our pseudo-parallel dataset by ignoring the identified style words during similarity calculation. After the style word pairs converged, we put them together as a lookup table to recognize and replace style words for style transfer. Extensive experiments demonstrate that our method is effective in different style transferring settings, such as sentiment and formality, outperforming state-of-the-art methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573464
SP  - 206
EP  - 213
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573464
KW  - embedding similarity
KW  - pseudo parallel dataset
KW  - unsupervised learning
KW  - Unsupervised style transfer
ER  - 

TY  - CONF
TI  - Point cloud semantic segmentation method based on self-attention and pyramid fusion network model
AU  - Song, Zhenjie
AU  - Qi, Yunsong
T3  - EITCE '22
AB  - Semantic segmentation of point clouds has received extensive attention as the basis for 3D scene understanding, recognition, and various applications. However, the research on semantic segmentation of 3D point cloud scenes is extremely challenging due to the interference of sensor noise, the non-uniformity of point cloud density, and the complexity and diversity of the scene. This paper proposes a point cloud semantic segmentation network model named SAPFNet. Center and neighborhood self-attention mechanisms are introduced to enhance the ability to extract local features from point cloud data. At the same time, Pyramid Attention Network (PAN) is used to combine features of different resolutions and different semantic strengths to preserve good geometric features as much as possible. Furthermore, scene semantic segmentation experiments on the public dataset S3DIS show that the proposed network achieves certain improvements in segmentation results compared with other network models.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573463
SP  - 201
EP  - 205
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573463
KW  - Deep Learning
KW  - Point cloud
KW  - PointNet
KW  - Pyramid network
KW  - Self-attention mechanism
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - Dual Guidance Of Optical Flow And Decoupled Attention For Infrared Video Object Detection Network
AU  - Zhou, Zhiran
AU  - Wu, Ting
AU  - Ye, Yixi
AU  - Zhang, Yu
AU  - He, Yuting
AU  - Shi, Yangguang
T3  - EITCE '22
AB  - Infrared video object detection is a task to detect moving objects in infrared video. The traditional object detection algorithm often ignores the motion information of the target, and often miss detection and false detection of small objects and objects in complex backgrounds.This paper proposes a Flow Attention Dual-Guided Yolo (FADG-YOLO) algorithm. It is used to solve the problems such as difficult detection of moving targets, small and weak targets, and complex backgrounds. Specifically, our algorithm includes two modules, FlowFocus (FF) and Decoupled Attention (DA).FlowFocus is a module that calculates optical flow, aligns motion features with original image features and fuses them. It is used to introduce motion information into the model. Decoupled Attention is a module that enhances the feature responses of small objects and difficult-to-recognize objects in complex backgrounds. Based on the two modules of FlowFocus and Decoupled Attention, this paper constructed the FADG-YOLO algorithm for infrared video object detection. The result from extensive experiments on the ICCV2021 Anti-UAV Challenge Dataset show that our proposed algorithm has better performance than many popular object detection models.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573461
SP  - 191
EP  - 195
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573461
KW  - Decoupled attention
KW  - Infrared Video
KW  - Object Detection
KW  - Optical Flow
ER  - 

TY  - CONF
TI  - Color Search: An efficient region proposal generation method
AU  - Zheng, Kaiyuan
AU  - Zhang, Zhiyong
AU  - Qiu, Changzhen
T3  - EITCE '22
AB  - Inspired by the process of searching for targets by the human eyes, our proposed target candidate region generation method focuses on the color information of the target. Current mainstream target detection algorithms often incorporate an Region Proposal Network (RPN) component for finding out the possible locations and sizes of targets, which facilitates the training and optimization of the backbone network. The RPN network uses more convolutional layers, which makes it impossible to be applied in embedded platforms that require high real-time performance and does not take full advantage of the target's a priori information. In this paper, We convert the image from RGB color model to HSV model and reduce dimensionality to form a color set. After quantizing the color set, we can obtain the Q-HSV of the image by which to find out the possible locations of the target efficiently. With this method, we can find out the possible areas of the target using only one RGB template of the target, and it is not affected by target viewpoint changes, shape changes, etc. Our approach can significantly reduce the image data to be processed by recognition and detection algorithms by more than 80%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573460
SP  - 185
EP  - 190
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573460
KW  - Color model
KW  - Image segmentation
KW  - Object recognition
KW  - Region proposal
ER  - 

TY  - CONF
TI  - Design of a Radar and Laser Compound Altimeter for Ground Detection
AU  - Yang, Hui
AU  - Zhang, Yifei
AU  - Bi, Kaibo
T3  - EITCE '22
AB  - Radar altimeters and laser altimeters are two kinds of altitude detection devices with different performances. The laser altimeter has the advantages of high detection accuracy and strong anti-electromagnetic interference ability, while the radar altimeter is not affected by weather and environment, so it can be used in all weather. Therefore, the compound detection combined the radar altimeter and the laser altimeter is beneficial to improve the detection accuracy and enhance the anti-jamming capability of the system. According to the advantages and disadvantages of the two kinds of altimeters, a radar and laser compound altimeter is designed, the overall composition of the compound altimeter is studied, and the filtering and fusion algorithm of the two kinds of altimeters is proposed. The digital simulation result shows that the accuracy of the altitude detection based on multi-sensors fusion is higher than that of a single sensor, and the stability and reliability of the compound system are stronger. It shows that the compound altitude detection system combined radar and laser altimeter is feasible.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573459
SP  - 179
EP  - 184
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573459
KW  - Compound altimeter
KW  - Laser altimeter
KW  - Radar altimeter
KW  - Signal fusion
ER  - 

TY  - CONF
TI  - Comparative Analysis of Crop Disease Detection Based on Few-shot Learning
AU  - WANG, RUOYU
AU  - WU, JUNHUI
AU  - Zhou, Zihao
T3  - EITCE '22
AB  - Disease is an important factor influencing crop yield and quality. In recent years, deep learning has made great progress in the field of crop disease detection, much superior to traditional methods. However, the excellent performance of deep learning needs a large number of training samples. In the field of plant science and biology, it is not easy to obtain a large amount of labeled data. So how to use a small number of samples for crop disease detection has become a topic that researchers are very concerned about. According to different learning methods, this study analyzes the researches on crop disease detection based on few-shot learning in recent years from four aspects: data augmentation, semi-supervised learning, metric learning, and meta-learning, we summarize the advantages and disadvantages of each method, and compare the performance of existing methods. On this basis, we discuss possible challenges in practical applications and proposes possible solutions. Finally, we analyzes and forecasts the future trends of crop disease detection based on few-shot learning.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573458
SP  - 171
EP  - 178
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573458
ER  - 

TY  - CONF
TI  - Research on the Rural Community Elderly Care Service Management Systems based on The Internet of Things
AU  - Zhu, Tingting
AU  - Wu, Huarui
AU  - Chen, Cheng
AU  - Zhu, Huaji
T3  - EITCE '22
AB  - Under the background of the in-depth implementation of the Rural Revitalization Strategy, the conditions of public service facilities for the elderly have improved significantly in rural areas. However, the problem is that the asymmetry between the intelligent management and construction of the corresponding elderly care services is more prominent. It leads to the lagging management of elderly care services, poor service information, and other problems. In order to solve the above series of problems, we propose an IoT-based rural community elderly care service management system, which can effectively assist community elderly care. The designs of structure, function, and key technologies are discussed in this article. To provide more timely and accurate services for the elderly, the system can realize real-time data collection of behavior, vital signs, and the surrounding environment of the elderly, monitor and warn of abnormal situations.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573456
SP  - 157
EP  - 164
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573456
KW  - Internet of Things
KW  - service for the aged
KW  - system design
ER  - 

TY  - CONF
TI  - Task Offloading Based on GRU Model in IoT
AU  - Zhang, Xiao
AU  - He, Yuxiong
AU  - Wang, Youhuai
AU  - Chen, Xiaoming
AU  - Jin, Shi
AU  - Liang, Ye
T3  - EITCE '22
AB  - With the rapid growth of the Internet of Things (IoTs), edge computing draws greater attention. Task offloading becomes the main part of edge computing which can affect performance. To reduce the tasks time delay and improve the utilization of the edge server, the task offloading problem can be modeled as a decision-making problem for minimizing the time latency and develop a GRU-based model to predict the computational task offloading. We choose a dataset from Google Cluster and offload the top 1000 tasks for comparison. Compering with existing offloading techniques such as total offloading (TOT), random offloading technique (ROT), and deep learning-based offloading technique (DOT), the GRU-based model can save 15.09% time than TOT, 13.46% time than ROT and 4.25% time than DOT while offloading 1000 tasks on an edge computing system in IoT. Experimental result showed that, compared with other techniques, our proposed GRU-based model is able to reduce the delay of tasks effectively, while increasing the number of tasks and enhancing the offloading performance on edge computing system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573455
SP  - 151
EP  - 156
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573455
KW  - Deep Learning
KW  - Edge Computing
KW  - Gate Recurrent Unit
KW  - Task Offloading
ER  - 

TY  - CONF
TI  - VDDT: Improving Vessel Detection with Deformable Transfomer
AU  - Chen, Siyu
AU  - Liu, Yiling
AU  - Su, Jinhe
AU  - Zheng, Ruixin
AU  - Chen, Zhihui
AU  - Wang, Lefan
T3  - EITCE '22
AB  - Vessel detection has received wide attention in object detection, and the recently proposed DETR has successfully achieved true end-to-end object detection and has shown good performance. However, DETR is not sensitive to detect small objects, resulting in its unsatisfactory performance in vessel detection. In this paper, we use Deformable DETR as the baseline model and modify it on top of that. Firstly, we add reference point information to object queries to make the features learned by object queries richer to improve the performance of the detector. Secondly, we use multi-layer perceptron instead of multi-head self-attention to reduce the computational effort of the decoder. In addition, we collected 85 videos annotated with 4563 images and used these images to make a vessel dataset. The experimental data on our vessel dataset shows that VDDT performs better compared to the baseline.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573457
SP  - 165
EP  - 170
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573457
KW  - multilayer perceptron
KW  - Object detection
KW  - Transformer
KW  - Vessel detection
ER  - 

TY  - CONF
TI  - Multi-loss joint cross-modal pedestrian re-identification method fused with grayscale and RGA
AU  - Yuan, Ruichao
AU  - Hu, Xiaoguang
AU  - Dong, Anyang
AU  - Cai, Nengbin
T3  - EITCE '22
AB  - Cross-modal pedestrian re-identification is to match the color image and infrared image of the pedestrian to determine whether there is the same pedestrian. The images have large inter-modal differences and large intra-modal variations, resulting in low recognition accuracy. This paper proposes a multi-loss joint cross-modal pedestrian re-identification method that fuses grayscale images and relation-aware global attention (RGA). First, grayscale the color images in the cross-modal dataset to reduce the network's dependence on color information; second, use the trained generative adversarial network to convert the color images and infrared images in the dataset to each other to reduce pedestrian poses and modality changes; then, the RGA is embedded into a shared-weight dual-stream ResNet50 to capture more robust features; finally, the hard sample triplet loss is improved and converted into a cross-modal hard sample triplet loss. The cross-entropy loss of the smooth label is combined with the hard sample triplet loss and the cross-modal hard sample triplet loss, respectively, to form joint functions L1 and L2, and then supervised training of the network. Experiments are carried out on the RegDB and SYSU-MM01 datasets, and the mAP reaches 75.85% and 69.56%, respectively, which are better than many current methods, indicating that the proposed method has better recognition accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573775
SP  - 143
EP  - 150
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573775
KW  - Cross-modal person re-identification
KW  - generative adversarial networks
KW  - grayscale
KW  - Multi-loss joint function
KW  - RGA
ER  - 

TY  - CONF
TI  - Design and Implementation of Course Review System
AU  - Yi, Yan
AU  - Liu, Yu
T3  - EITCE '22
AB  - Based on the guiding of “Internet Plus Education”, this paper researches the main stream technical framework of website development, designs and implements a course review system. Its implementation is divided into two parts: the main website and the admin management. The main website includes searching information, registering, and reviewing courses, modifying user information, viewing personal favorites, comments and notices; the admin management includes user information, course information, comment information, collection information, review information, and notice information management. The system adopts four-layer (View- Controller-Service-Infrastructure) architecture, mainlyuses Spring Boot and Mybatis-Plus, integrates Elastic Search and Redis. The application of these technologies can reduce construction and maintenance costs, improve the user access experience inconcurrent scenarios and enhance the search accuracy and performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573453
SP  - 137
EP  - 142
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573453
KW  - Course review
KW  - Elastic Search
KW  - Four-layer architecture
KW  - Mybatis-Plus
KW  - Redis
KW  - Spring Boot
ER  - 

TY  - CONF
TI  - Design and Development of Campus Micro Weather Station Based on Internet of Things Cloud Platform
AU  - Wang, Jue
AU  - Wang, Ruilin
T3  - EITCE '22
AB  - Campus weather station is the key carrier of meteorological science education. However, current on-campus weather stations suffer from uneven construction distribution, insufficient detection content, and relatively limited data display. To address the above issues, in this paper, we study a tiny campus weather station, based on Arduino open-source hardware module to collect data, combined with the Internet of things open platform to achieve data storage, and complete data transmission through the Internet of things module to the APP side. Finally, the campus micro weather station can realize the functions of temperature and humidity detection, rainfall judgment, ultraviolet intensity detection and air quality judgment. Combined with the example testing, the campus micro weather station can obtain accurate weather data with great portability and practicality.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573452
SP  - 131
EP  - 136
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573452
KW  - Arduino
KW  - Campus weather station
KW  - Internet of Things
KW  - Meteorological science
ER  - 

TY  - CONF
TI  - Face recognition using feature dimension decrease arithmetic∗
AU  - Wang, Tong
AU  - Tan, Wenan
AU  - Xue, Jianxin
AU  - Niu, Sen
AU  - Du, Yi
AU  - Cao, Xiaoxia
T3  - EITCE '22
AB  - DR (Dimensional Decrease) arithmetic is a tool. Initially, DR arithmetic was used to solve problems in computer vision. Here, DR arithmetic is used to decrease the number of features. Contrast among various DR arithmetics is executed to face discrimination. Contrast among various DR arithmetics is executed to face discrimination. Tall order of dimension face pictures is low order of dimension manifolds in nature. The manifold learning arithmetic can decrease the order of dimension by digging the essential structure of the data, draw the inherent features of tall order of dimension face image data, and find the low order of dimension embedded manifold equivalent to the tall order of dimension original data. Contrast among LLE, Isomap arithmetic and modified Isomap arithmetic are performed to face discrimination. The outcomes of the test are gratifying, which it makes clear that DR arithmetic can settle face discrimination problems well.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573451
SP  - 126
EP  - 130
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573451
ER  - 

TY  - CONF
TI  - Multi-scale Fusion based Multi-stage Small Object Detection in Aerial Images ∗
AU  - Yang, Mingrui
AU  - Wang, Yu
AU  - Zhang, Xindong
T3  - EITCE '22
AB  - In aerial images, the objects are mostly small. The number of objects is large and the scale is diverse, so it is difficult to extract the features of multiple scale objects at the same time. The location distribution of object in aerial images is usually dense, making it difficult to locate. These factors bring great challenges to aerial image object feature extraction, and then reduce the performance of detection. Therefore, a multi-scale fusion based multi-stage small object detection method (MSMSD) for aerial images is proposed in this paper. MSMSD adopts EfficientNet as feature extraction backbone and add deformable convolution blocks to achieve better detection performance on objects with irregular shapes. NAS-FPN is leveraged to fuse multi-scale features effectively. A cascade detection mechanism is also designed to reduce noisy detection and mis-detection in this task. In experiment section, the proposed MSMSD outperforms five benchmark object detection algorithms on two aerial image datasets. Experimental results demonstrate that MSMSD can handle the small object detection task in aerial images efficiently.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573449
SP  - 114
EP  - 119
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573449
KW  - Computer vision
KW  - Deep learning
KW  - Image processing
KW  - Multi-scale
KW  - Small object detection
ER  - 

TY  - CONF
TI  - An Improved Faster RCNN based on Swin Transformer for Surface Defect Detection of Metal Workpieces
AU  - Xu, Shiwei
AU  - Shao, Zhangyi
T3  - EITCE '22
AB  - Surface defects are an inevitable problem in the production process of metal workpieces. Computer vision based surface defect detection methods outperform manual inspection methods and are gradually being applied in industrial production. In this paper, we proposed an improved Faster RCNN model for metal workpiece surface defects to tackle the problems of large size variation and many morphological changes in surface defects. Swin Transformer is used as the backbone to enhance the feature extraction ability, and FPN is introduced to carry out multi-scale feature fusion on the feature maps from its four stages. Focal loss is adopted as the classification loss to further improve the detection performance. Experimental results on the NEU-DET dataset show that the proposed model improves the mAP by 4.24% over the Faster RCNN with ResNet50 as its backbone, and the training process converges faster.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573774
SP  - 120
EP  - 125
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573774
KW  - Deep learning
KW  - Faster RCNN
KW  - Surface defect detection
KW  - Swin Transformer
ER  - 

TY  - CONF
TI  - The Pre-ordering Model for Statistical Machine Translation of Enhancing the N-best Syntactic Knowledge
AU  - Liu, Junyan
T3  - EITCE '22
AB  - Syntactic heterogeneity between source and target languages has an important impact on the performance of Statistical Machine Translation (SMT). On the basis of phrase-based Chinese-English SMT, a method of source language pre-ordering based on N-best syntactic knowledge enhancement is proposed. First, the source language input sentences are analyzed by N-best Syntax, and the high reliability sub-tree structure is obtained by calculating statistical probability. Two optimization strategies are used to optimize the initial rule set: rule deduction and rule probability threshold control mechanism. Second, the source language phrase translation table is used as a constraint to control the sequence between phrases. Finally, the syntax analysis tree of the source-side sentences is pre-ordered. The experimental results of Chinese-English SMT based on the NIST 2005 and 2008 test data sets show that comparing to the baseline system, the BLEU score of automatic evaluation criterion of the N-best syntactic knowledge-enhanced SMT pre-ordering method increased by 0.68 and 0.83 respectively.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573448
SP  - 109
EP  - 113
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573448
ER  - 

TY  - CONF
TI  - A Faster Time Series Data Prediction Method Based on LSTM
AU  - Song, Xuanpeng
T3  - EITCE '22
AB  - The complex structure of LSTM increases the number of parameters and leads to an increase in training time. We propose an improved prediction method for time series data based on LSTM, which can significantly reduce the training time while ensuring a certain prediction accuracy. Our method first uses wavelet decomposition to decompose the data into low-frequency data and high-frequency data and then uses LSTM to learn the characteristics of low-frequency data, use Random Forest to learn the characteristics of high-frequency data, and finally uses wavelet reconstruction to reconstruct the predictions of LSTM and Random Forest for different frequency data into prediction data. Test results on datasets in three different domains show that our method can predict the overall trend of time series data well, but the prediction results for local details are slightly worse. Compared with using LSTM directly, our method increases the average mae by 15.52% and the average mse by 31.10% on the three datasets but reduces the average training time by 69.66%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573447
SP  - 105
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573447
KW  - LSTM
KW  - time series data prediction
KW  - Wavelet
ER  - 

TY  - CONF
TI  - Design and Implementation of A Cache Adapted to the LoongArch Architecturert
AU  - Chen, Lin
AU  - Ma, Xiao
AU  - Ji, Xiang
AU  - Wang, Ziyan
T3  - EITCE '22
AB  - A cache adapted to the LoongArch architecture is designed and implemented using the FPAG platform. A simple and performance balanced Cache module is designed and implemented. The design of the read and write data paths of the Cache module is given, and a state machine is designed and implemented for the logical control of the Cache module. The interaction interface between the Cache and the CPU is designed. The CPU pipeline adaptation method for Cache in hit and unhit cases is given. The processing flow of UnCache access is given. Cache-related instructions in the LoongArch instruction set are implemented. The test results show that the scheme meets the design requirements. Cache is simple and effective, and is suitable as a case study for initial understanding of Cache functionality and structure.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573446
SP  - 99
EP  - 104
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573446
KW  - Cache
KW  - CPU
KW  - FPGA
KW  - LoongArch
ER  - 

TY  - CONF
TI  - Building Semantic Segmentation Through an Ensemble Architecture of UNet and Graph Convolution Networks
AU  - Shang, Yuxin
AU  - Cuib, Hao
AU  - Guo, Haitao
T3  - EITCE '22
AB  - Extracting building from remote sensing images remains a challenge because some obstacles, such as trees, cars, farmland, and shadows, disturb the identification accuracy. In recnet years, deep convolution neural networks have shown significant improvements in computer vision, however it is still difficult to extract irregular and small buildings. To develop the extraction accuracy of building, we propose a deep learning model, which combined UNet and graph convolution network, to capture the long-range information. Seven deep convolution neural networks were used on the Massachusetts Buildings Dataset for comparison. And the proposed model, which performed best among these compared models, achieved a building Intersection over Union (IOU) of 71.10%, mean IOU of 81.88%, recall of 81.90%, precision 84.36% and F1 score of 83.11%. This result indicated that the proposed model can accurately extract building objects. The visualization results showed that the proposed model performs better in extracting irregular and small buildings and caneffectively extracts buildings from high-resolution remote-sensing images.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573445
SP  - 93
EP  - 98
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573445
ER  - 

TY  - CONF
TI  - Research on survivability analysis method of spatial information network based on dynamic cumulative model
AU  - Zhao, Zhongwen
AU  - Li, Guodong
AU  - Lu, Di
T3  - EITCE '22
AB  - In view of the problem that multifunctional hierarchy and dynamic characteristics are not considered simultaneously in the research methods of survivability of spatial information networks. This paper first summarizes the main methods of survivability research and three main attack strategies. Secondly, the idea of data flow and the method of time accumulation graph were integrated into the spatial information network model, and the multi-layer dynamic spatial network accumulation model was established. Finally, the navigation satellite network, communication satellite network and remote sensing satellite network are taken as examples to construct the spatial information network simulation plan, and the attack is carried out according to the three attack strategies, and the survivability of the spatial information network is analyzed. The experimental results verify the rationality of the proposed method and the effectiveness of the index, and explore the rules.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573444
SP  - 86
EP  - 92
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573444
KW  - Anti-destroying ability
KW  - Attack strategy
KW  - Data flow idea
KW  - Multi-layer dynamic spatial information network
ER  - 

TY  - CONF
TI  - Rapid detecting of n-3 PUFAs content of enriched eggs during household storage based on near-infrared reflectance spectroscopy
AU  - Shen, Changying
AU  - Guan, Xinhui
AU  - Lü, Xueze
AU  - Zhang, Yuanzhi
AU  - Liu, Xue
T3  - EITCE '22
AB  - Eggs have been proved to be an ideal delivery for the human being to enhance the intake of Omega-3 polyunsaturated fatty acids (n-3 PUFAs). The variation of n-3 PUFAs concentration of the enriched eggs in household storage is a common concern, so, how to measure the n-3 PUFAs concentration in enriched eggs avoiding complicated and time-consuming procedures is a meaningful study. Near infrared spectroscopy (NIRS) technique was applied to achieve this aim in this research. 200 n-3 PUFAs enriched eggs were selected and stored under different household storage conditions (refrigeration and room temperature). Whole egg and liquid yolk for spectral scanning and measuring, Gas chromatography and NIRS were used to detect the content of n-3 PUFAs. The n-3 PUFAs content prediction models were developed based on NIRS. In comparison, the liquid yolk spectrum provided the best prediction using PLS combined with second derivative (2nd D) and Wavelet transform (WT), that Rc2=0.95, RMSECV=5.71, Rp2=0.83, RMSEP=16.9. This research demonstrated that NIRS technique coupled with opportune chemometric algorithms could be applied as a rapid detection technique for the content of n-3 PUFAs in eggs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573773
SP  - 77
EP  - 85
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573773
KW  - eggs
KW  - Haugh unit
KW  - n-3 PUFAs
KW  - near-infrared spectroscopy
KW  - partial least squares regression
ER  - 

TY  - CONF
TI  - Abnormal data detection method based on ant colony clustering
AU  - Chen, Lianyong
AU  - Song, Jinyu
T3  - EITCE '22
AB  - With the rapid growth of data, low quality data emerges, and data quality problems are increasingly serious. Abnormal data detection becomes an important aspect of data quality validity measurement. We propose an improved ant colony clustering algorithm based on LF algorithm [8] by optimizing ant position, attribute weight and moving step speed and then apply it to the abnormal data detection. The improved algorithm is programmed by Python, and the experiment is carried out on UCI data set. The results show that the improved algorithm can obtain better clustering effect, and make the accuracy of abnormal data detection results higher.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573441
SP  - 66
EP  - 72
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573441
ER  - 

TY  - CONF
TI  - Deep Cross-modal Hashing Retrieval Based on Semantics Preserving and Vision Transformer
AU  - Hong, Jinlin
AU  - Liu, Huayong
T3  - EITCE '22
AB  - In response to the problem of similarity measure differences in different similarity coefficients that occur in cross-modal multi-label retrieval, this article uses an interval parameter to correct this bias. A new supervised hash method is proposed by introducing the transformer structure which performs well in CV and NLP tasks into cross-modal hash retrieval, called the Deep Semantics Preserving Vision Transformer Hashing (DSPVTH). This method uses network structures such as vision transformer to map different modal data into binary hash codes. It also uses the similarity relationship of multiple tags to maintain the semantic association between different modal data. Validation on four commonly used multimodal text datasets, Mirflickr25k, NUS-WIDE, COCO2014 and IAPR TC-12, shows a 2% to 8% improvement in average accuracy compared with the current optimal method, which means our method is robust and effective.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573439
SP  - 52
EP  - 57
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573439
KW  - Cross-modal hash retrieval
KW  - Hashing learning
KW  - Multi-label semantic learning
ER  - 

TY  - CONF
TI  - The Method and Implementation of Temperature Drift Self-compensation for 4T CIS Based on FPGA
AU  - Cai, Jiajing
AU  - Kan, Jicheng
AU  - Ji, Xiang
T3  - EITCE '22
AB  - In this paper, a temperature drift self-compensation method for 4T CMOS image sensor based on FPGA is designed to solve the problems of pixel drift rise and image noise caused by temperature change. This method can automatically extract the compensation coefficient of temperature drift, compensate the difference and adjust the dynamic range, so as to suppress the noise effect of temperature on image data. The experimental results show that the temperature drift self-compensation method has a good compensation effect. The checkerboard simulation reduces the mean value of the image by 14.63%, the peak signal-to-noise ratio is relatively stable, and the average gradient is increased by about 21%, which effectively weakens the influence of temperature on image brightness and detail clarity. It can be proved that the proposed method provides a reliable guarantee for the application of 4T CMOS image sensor in the space field under high temperature environment.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573442
SP  - 73
EP  - 76
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573442
KW  - CMOS image sensor
KW  - difference compensation
KW  - dynamic range adjustment
KW  - FPGA implementation
ER  - 

TY  - CONF
TI  - Research on financial social public opinion communication model based on variation mechanism
AU  - Huang, Maojun
AU  - Hong, Mei
AU  - Dong, Lin
AU  - Yuan, Da
T3  - EITCE '22
AB  - In the context of rapid development of the Internet, the place of spreading financial public opinion is converted from traditional offline places to major online social platforms. Mastering the development mechanism of financial social opinion dissemination on online social media can effectively estimate the length of influence of public opinion and the scope of affected people, and provide effective guidance to relevant staff. Based on the Susceptible Infected Recovered Model, this paper divides the people involved in opinion diffusion into commenters and discussers, and introduces the variation mechanism to design the Susceptible-comment-discussion-removal model, then simulates the model to study the effects of different initial states and parameters on the model, and finally verifies the validity of the model by combining the real data of stock bars. The simulation experiments and validation show that the model can effectively describe the spread of public opinion among the user groups of financial social platforms when it occurs, and provide a valid reference for related workers. However, the content of public opinion, the personal influence of communicators, and the lag effect of communication all have an impact on communication, and these issues need to be addressed in future research.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573440
SP  - 58
EP  - 65
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573440
KW  - financial social opinion
KW  - public opinion dissemination
KW  - SCDR model
KW  - SIR model
KW  - variation mechanism
ER  - 

TY  - CONF
TI  - A residual gated convolution summary generation model based on contrast learning
AU  - Guan, Xiaohan
AU  - Liang, Shuo
T3  - EITCE '22
AB  - Contrastive learning achieves better results in several tasks in natural language processing. However, there are fewer studies on Chinese text summary generation tasks. In this paper, a new summary generation model is proposed. This model uses the reference summary of random word order as a negative sample. Let the model learn to predict the distribution of representations more reasonably. Using RoBERTa pre-trained language model to encode the text, the summary text is generated using the gated convolutional unit with the residual mechanism. The experimental results of the LCSTS dataset show that the model performs in this paper better than the baseline model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573438
SP  - 47
EP  - 51
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573438
KW  - contrast learning
KW  - gated convolution
KW  - pre-trained language model
KW  - RoBERTa
KW  - Summary generation
ER  - 

TY  - CONF
TI  - Parts quality inspection system and method based on line laser scanning
AU  - Ning, Yeyan
AU  - Li, Yunji
AU  - Zhang, Zhenyu
AU  - Huang, Hao
AU  - Xu, Donglai
T3  - EITCE '22
AB  - With the continuous development of science and technology, the processing of 3D point cloud data is a popular research direction in recent years. The quality inspection of mechanical parts has become the key to ensuring the quality of parts. According to the defects of traditional parts inspection methods, this paper proposes a part quality inspection method based on line laser scanning, and builds a parts quality inspection system. According to the collected 3D point cloud data, using the Hausdorff distance to simplify the collected 3D point cloud data, and using the principal component analysis method to register the simplified 3D point cloud data to reconstruct the 3D model of the part to be inspected. The square root error RMS is within 0.02mm, which improves the forming efficiency and scanning accuracy of the parts to be inspected. It is verified that the built part quality inspection system is conducive to the judgment and analysis of the quality inspection of the parts to be inspected.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573437
SP  - 41
EP  - 46
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573437
ER  - 

TY  - CONF
TI  - Based on NB-IoT Platform for air quality detection system
AU  - Xiong, Xianhong
AU  - Yan, Chuansheng
AU  - Luo, Xiaoliang
AU  - Guo, Jun
AU  - Pan, Ye
AU  - Luo, Qiang
T3  - EITCE '22
AB  - With the development of social economy, Internet of things (IoT) technology has been deeply applied to the management of smart cities. The NB-IoT technology, which undertakes the functions of remote data collection, storage and transmission, has been paid more and more attention by researchers. In this paper, the embedded platform and NB-IoT remote communication technology are used to detect air quality and communication. By using timed wake-up strategy, the terminal system can work in low power consumption mode, which is especially suitable for data collection in the field and mountainous areas. This technology will make NB-IoT communication have wider application space.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573435
SP  - 31
EP  - 35
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573435
KW  - air quality
KW  - embedded platform
KW  - low power consumption
KW  - NB-IoT
KW  - remote data collection
ER  - 

TY  - CONF
TI  - A blockchain-based Access Control Mechanism for IOT
AU  - Yu, Houhui
AU  - Chen, Taowei
AU  - Wang, Jingyi
T3  - EITCE '22
AB  - Because of lightweight, large-scale and dynamic access characteristics in IoT devices, the current centralized access control mechanism leads to many security problems such as failure of single point, privacy leakage and user authentication. With the advent of blockchain technology, it could be a better way to address these problems by decentralized, transparent and immutability properties of blockchain. Thus, a blockchain-based access control mechanism for IOT is proposed based on the ABAC access control model. Firstly, the model architecture and access control workflow are developed in detail, and the data format of transactions in the blockchain is defined so as to facilitate the release, update, and revocation of attributes and policies. And then, the smart contracts on chain are programed to ensure that the conditions they set on access and sharing will be enforced. Finally, experimental simulation demonstrates that the proposed scheme is efficient in policy-making and policy-querying. At the same time, the use of decentralized ABAC makes it much secure for decision-makers to control variables that ensure a fine-grained approach to access control.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573434
SP  - 25
EP  - 30
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573434
KW  - ABAC model
KW  - Access control
KW  - Blockchain
KW  - IOT
KW  - Smart contract
ER  - 

TY  - CONF
TI  - Study on Fractal Dimension modified MFCC
AU  - Mi, Pan
AU  - Wang, Li
T3  - EITCE '22
AB  - MFCC is widely used in the field of voiceprint recognition, and has achieved remarkable effects. However, MFCC focuses on the short-term spectrum characteristics of speech, while ignoring the self-similarity of speech itself. Fractal has the self-similarity characteristic of non-integer dimension. It is often used to describe the evolution of nature, such as Brownian motion, coastline, rock strata and minerals. Based on MFCC, we try to introduce fractal dimension, which makes up for the lack of self-similarity of MFCC. The experimental results show that compared with MFCC, the fractal dimension modified MFCC (FDMFCC) has improved accuracy and stability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573436
SP  - 36
EP  - 40
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573436
ER  - 

TY  - CONF
TI  - Infrared and Visible Image Fusion Method Based on Residual Block and Compression Decomposition Network
AU  - Ji, Keqin
AU  - Hou, Jiansheng
AU  - Zheng, Lin
AU  - Hou, Xianglin
AU  - Ju, Xiaoming
T3  - EITCE '22
AB  - The fusion of infrared images and visible images can enrich image information and obtain high-quality target images in complex environments. It has a wide range of applications in target detection, image enhancement and other fields. To solve the problems existing in the current deep learning-based infrared and visible image fusion methods that the network cannot fully extract the features of the source image and the information of the source image is not fully retained, this paper proposes a fusion network structure of infrared and visible image based on residual network and compression decomposition network. Firstly, a self-encoder based on the residual structure is used to extract features, fuse features and reconstruct features from two source images to extract and fuse more effective feature information. Secondly, we apply the idea of compression decomposition in image fusion. We not only consider the fusion process of the source image to the target, but also the decomposition process of the fusion image to the source image. Since the fusion result directly determines the decomposition quality of the image, the fusion result can be forced to contain more scene information. The experimental results show that this method can retain more detailed information, and can obtain more smooth and more delicate fusion images. The average value and information entropy of fusion results have obvious effects.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573432
SP  - 15
EP  - 20
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573432
KW  - decomposition network
KW  - Image fusion
KW  - infrared image
KW  - residual network
KW  - visible light image
ER  - 

TY  - CONF
TI  - Design and Optimization of RF Impedance Matching Network Based on ADS and SIwave
AU  - Li, Jianhua
AU  - Zhuo, Kang
AU  - Hu, Yi
AU  - You, Bin
AU  - Liu, Changjian
AU  - Cao, Shan
AU  - Xi, Lehou
T3  - EITCE '22
AB  - Impedance matching networks using discrete components are generally connected on the PCB through microstrip transmission lines. Affected by the impedance discontinuity and distribution parameters of the transmission line, the impedance matching network simply designed according to the input and output impedance of the device cannot accurately match the port impedance to the target impedance. Therefore, this paper introduces a method for designing and optimizing impedance matching circuits using ADS and SIwave. The microstrip line at the input and output of RF device is modeled by SIwave, and the S parameter is extracted. Then the ADS software is used to connect the S-parameter model of the device, the S-parameter model of the microstrip line, and the actual parameter model of the inductor and capacitor to carry out impedance matching design. The simulation results show that the method can optimize the return loss of the port to meet the design requirements.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573431
SP  - 10
EP  - 14
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573431
KW  - ADS
KW  - Impedance matching networks
KW  - Microstrip transmission lines
KW  - S-parameters
KW  - SIwave
ER  - 

TY  - CONF
TI  - Design of WEB Communication Security System: Based on Digital Signature
AU  - Liu, Yanjun
T3  - EITCE '22
AB  - With the development of modern network technology, the application of information sharing is extensive, but at the same time, the security problem of information and communication has become prominent and complex. As most nodes used in network communication exist in the form of clusters, it is easy to cause network traffic data transmitted at the same time, and the network congestion and network service are not able to process the information, which leads to network communication can not timely send out. If the security of network communication cannot be guaranteed, the number of users using network communication will decrease, which is not conducive to the development of network communication. In protecting network security, digital signature technology is a better security protection technology. In the era of rapid development of network communication, digital signature technology not only guarantees the security of network communication but also ensures the privacy and integrity of data in network communication. This paper presents the concept and principle of digital signature and the application of digital signature in WEB communication.&nbsp;
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573433
SP  - 21
EP  - 24
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573433
KW  - Cryptography
KW  - Digital Signatures
KW  - Network Security
KW  - Security Framework
KW  - WEB Design
ER  - 

TY  - CONF
TI  - Research on IGBT reliability method based on SSA-BP
AU  - Hu, Hailin
AU  - Chen, Jun
AU  - Chen, Weijin
T3  - EITCE '22
AB  - The health status of insulated gate bipolar transistor (IGBT) is of great significance to the safety and reliability of power electronic systems. Aiming at the problem of IGBT aging status prediction, a new method based on Sparrow Search Algorithm (SSA) and Back Propagation (BP) is proposed. Firstly, based on the analysis of IGBT structure and aging mechanism, the peak-to-peak voltage value of collector-emitter turn-off instantaneous is selected as the characteristic index of IGBT aging, and the aging data is preprocessed. Secondly, the weights and thresholds of the BP neural network model are optimized by SSA, so as to solve the problems of falling into local optimum and slow convergence, and realize the improvement of the BP neural network prediction model. Finally, the mean square error is used as the evaluation index, and the IGBT aging data provided by NASA is used to evaluate the established prediction model. The results show that the proposed SSA-BP method has higher prediction accuracy, and the stability is improved by 65.4%, which can better predict the aging state of IGBT.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573430
SP  - 5
EP  - 9
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573430
KW  - aging state prediction
KW  - BP neural network
KW  - IGBT
KW  - prediction model
KW  - sparrow search algorithm
ER  - 

TY  - CONF
TI  - A Novel Hyperspectral Unmixing Method with K-Means and VAE Based Network Structure
AU  - Xia, Zhipeng
AU  - Chen, Meng
T3  - EITCE '22
AB  - Since the existing blind hyperspectral unmixing methods based on deep learning (DL) are sensitive to spectral variability and noise, a network architecture based on the Variational AutoEncoder is proposed. The proposed algorithm first clusters the input HSI data and transports the clustered data into the VAE network to overcome the impact of spectral variability. At the same time, the hidden variable layer of VAE is used for pixel recovery, so that the network has a good ability to resist noise. Simulation data and real data experiments show that compared with the state-of-the-art DL algorithms, the proposed algorithm has a better unmixing performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573429
SP  - 1
EP  - 4
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573429
ER  - 

TY  - CONF
TI  - Towards Realistic Underwater Dataset Generation and Color Restoration✱
AU  - Jain, Neham
AU  - Matta, Gopi Raju
AU  - Mitra, Kaushik
T3  - ICVGIP '22
AB  - Recovery of true color from underwater images is an ill-posed problem. This is because the wide-band attenuation coefficients for the RGB color channels depend on object range, reflectance, etc. which are difficult to model. Also, there is backscattering due to suspended particles in water. Thus, most existing deep-learning based color restoration methods, which are trained on synthetic underwater datasets, do not perform well on real underwater data. This can be attributed to the fact that synthetic data cannot accurately represent real conditions. To address this issue, we use an image to image translation network to bridge the gap between the synthetic and real domains by translating images from synthetic underwater domain to real underwater domain. Using this multimodal domain adaptation technique, we create a dataset that can capture a diverse array of underwater conditions. We then train a simple but effective CNN based network on our domain adapted dataset to perform color restoration. Code and pre-trained models can be accessed at https://github.com/nehamjain10/TRUDGCR
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571630
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571630
KW  - domain adaptation
KW  - underwater image restoration
ER  - 

TY  - CONF
TI  - A Dataset and Model for Crossing Indian Roads
AU  - Brahmbhatt, Siddhi
T3  - ICVGIP '22
AB  - Roads in medium-sized Indian towns often have lots of traffic but no (or disregarded) traffic stops. This makes it hard for the blind to cross roads safely, because vision is crucial to determine when crossing is safe. Automatic and reliable image-based safety classifiers thus have the potential to help the blind to cross Indian roads. Yet, we currently lack datasets collected on Indian roads from the pedestrian point-of-view, labelled with road crossing safety information. Existing classifiers from other countries are often intended for crossroads, and hence rely on the detection and presence of traffic lights, which is not applicable in Indian conditions. We introduce INDRA (INdian Dataset for RoAd crossing), the first dataset capturing videos of Indian roads from the pedestrian point-of-view. INDRA contains 104 videos comprising of 26k 1080p frames, each annotated with a binary road crossing safety label and vehicle bounding boxes. We train various classifiers to predict road crossing safety on this data, ranging from SVMs to convolutional neural networks (CNNs). The best performing model DilatedRoadCrossNet is a novel single-image architecture tailored for deployment on the Nvidia Jetson Nano. It achieves 79% recall at 90% precision on unseen images. Lastly, we present a wearable road crossing assistant running DilatedRoadCrossNet, which can help the blind cross Indian roads in real-time. The project webpage is https://roadcross-assistant.github.io/Website/index.html
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571629
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571629
KW  - assistive technology
KW  - convolutional neural networks
KW  - road-crossing safety
ER  - 

TY  - CONF
TI  - Multi-view Learning with Two-stage Training of 2D CNNs for Tumor Sub-regions Segmentation from 3D Brain MRI Volumes
AU  - Lahoti, Ritu
AU  - Sinha, Neelam
AU  - Reddy, Vinod
T3  - ICVGIP '22
AB  - In this study, we have performed brain tumor segmentation on a publicly available BraTS 2019 dataset. The training data contains multi-modal 3D volumetric brain MRI data for 259 High Grade Glioma (HGG) cases and 76 Low Grade Glioma (LGG) cases. The focus is on being able to classify each of the brain voxels as belonging to either of the tumor-classes (whole tumor, tumor core, enhancing tumor) or non-tumor class. For this, two-stage training is performed on three 2D CNN models, one for each of sagittal, coronal and axial views. The models are first trained for binary segmentation of the whole brain tumor and then fine-tuned for tumor sub-regions segmentation tasks. Moreover, the models are trained on only tumor-bearing 2D slices of the brain MR volumes and as HGG data are more than LGG data, to make the segmentation models better generalized to both tumor grades, LGG data are augmented more than HGG data. The multi-view segmentation outputs of test data are integrated to obtain the final segmentation results. The entire approach has been evaluated on the BraTS training (335 cases) and validation (125 cases) datasets and compared with results of existing methods on the same dataset.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571628
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571628
KW  - 2D CNNs.
KW  - 2D segmentation
KW  - 3D tumor sub-regions
KW  - multi-view
KW  - Multimodal brain MRI
ER  - 

TY  - CONF
TI  - A Novel Statistical High Density Salt-and-Pepper Noise Removal Algorithm for Brain Magnetic Resonance Images
AU  - Halder, Amiya
AU  - Choudhuri, Rudrajit
AU  - Bhattacharya, Pritam
AU  - Sarkar, Apurba
T3  - ICVGIP '22
AB  - Brain Magnetic Resonance Imaging (MRI) is a non-invasive technique that produces high quality images of the brain and is most suitable for analysis and diagnosis. However, these images can be soiled with noise during image acquisition or transmission. The paper is targeted at removing high density salt and pepper noise from such medical images using a denoising technique based on centroidal mean formulation. The presented method is tested on various noisy brain MRI images and the obtained results are promising even for images with high density corruptions, which is suggestive of the resiliency of the algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571631
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571631
KW  - Brain MRI images.
KW  - Centroidal Mean
KW  - Medical Image Enhancement
KW  - Statistical Denoising Technique
ER  - 

TY  - CONF
TI  - Design of a System and Method for Optimal selection of Tumor Slice using Linear Ultrasound Imaging for Histopathology
AU  - Kumar, Abhishek
AU  - Sheet, Debdoot
T3  - ICVGIP '22
AB  - In excision biopsy, a tumor mass is surgically removed from the body. Subsequently, it is sliced at an appropriate location and investigated microscopically through a process called histopathology. Any bias in tumor slicing severely influences histopathology outcomes, such as if malignant foci do not appear in the sliced location, then, the tumor would be accidentally reported non-malignant. The standard approach adopted to solve this challenge by a histopathologist is to overcome this bias by slicing at multiple locations for their investigation. Till now, this process has been manual, time-consuming, and error-prone. We aim to design a system and develop a data-driven deep learning approach to assist histopathologists by providing them with a representative slice location for reporting to increase their efficiency and accuracy. We have developed a low cost linear gantry scanner that can acquire images and integrated with a deep learning model to predict the optimal slice representative of pathology in a tumor mass. We achieve an F1 score of 0.97 and an accuracy of 97.5% in predicting an optimal slice using this approach.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571627
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571627
KW  - Deep learning
KW  - Excision biopsy
KW  - Histopathology
KW  - Imaging gantry assembly
KW  - Ultrasound imaging
ER  - 

TY  - CONF
TI  - A Fine-Grained Vehicle Detection (FGVD) Dataset for Unconstrained Roads✱
AU  - Khoba, Prafful Kumar
AU  - Parikh, Chirag
AU  - Jawahar, C.V.
AU  - Sarvadevabhatla, Ravi Kiran
AU  - Saluja, Rohit
T3  - ICVGIP '22
AB  - The previous fine-grained datasets mainly focus on classification and are often captured in a controlled setup, with the camera focusing on the objects. We introduce the first Fine-Grained Vehicle Detection (FGVD) dataset in the wild, captured from a moving camera mounted on a car. It contains 5502 scene images with 210 unique fine-grained labels of multiple vehicle types organized in a three-level hierarchy. While previous classification datasets also include makes for different kinds of cars, the FGVD dataset introduces new class labels for categorizing two-wheelers, autorickshaws, and trucks. The FGVD dataset is challenging as it has vehicles in complex traffic scenarios with intra-class and inter-class variations in types, scale, pose, occlusion, and lighting conditions. The current object detectors like yolov5 and faster RCNN perform poorly on our dataset due to a lack of hierarchical modeling. Along with providing baseline results for existing object detectors on FGVD Dataset, we also present the results of a combination of an existing detector and the recent Hierarchical Residual Network (HRN) classifier for the FGVD task. Finally, we show that FGVD vehicle images are the most challenging to classify among the fine-grained datasets.&nbsp;[GitHub]
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571626
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571626
KW  - dataset
KW  - detection
KW  - Fine-grained
KW  - gradcam.
KW  - unconstrained roads
ER  - 

TY  - CONF
TI  - End-to-End GPU-Accelerated Low-Poly Remeshing using Curvature Map and Voronoi Tessellation✱
AU  - Chatterjee, Preetam Chayan
AU  - Soni, Ashutosh
AU  - Bhowmick, Iit Kharagpur, Partha Bhowmick
T3  - ICVGIP '22
AB  - We propose a novel algorithm for low-poly remeshing of 3D surfaces that runs fully in GPU. Since the input mesh is generally not well-organized, performing mesh simplification directly on the input mesh is liable to produce a low-poly mesh with a compromised face quality. Hence, instead of doing that, we voxelize the input mesh first. On the voxelized surface, we perform curvature estimation and discretization, Centroidal Voronoi Tessellation (CVT), and Delaunay triangulation to generate the output mesh. To control the vertex count, we exploit the curvature map, such that sufficiently large triangles constitute the low-curvature regions, whereas appropriately small triangles build up the high-curvature portions. We produce low-poly meshes at various levels of detail and measure their quality using Hausdorff error. We test our algorithm on different 3D scenes, and they are particularly chosen because they contain multiple objects with varied topologies. Upon testing on these datasets, our algorithm successfully achieves very low-poly approximation with a reasonable mesh quality, and at a reasonably faster pace, thus establishing its efficacy for mesh simplification.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571623
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571623
KW  - Centroidal Voronoi Tessellation
KW  - Digital Curvature Estimation
KW  - GPU-based Algorithms
KW  - Low-poly Approximation
KW  - Mesh Simplification
KW  - Parallel Computing
KW  - Remeshing
KW  - Surface Voxelization
ER  - 

TY  - CONF
TI  - Contrastive Multi-View Textual-Visual Encoding: Towards One Hundred Thousand-Scale One-Shot Logo Identification✱
AU  - Sharma, Nakul
AU  - Penamakuri, Abhirama Subramanyam V B
AU  - Mishra, Anand
T3  - ICVGIP '22
AB  - In this paper, we study the problem of identifying logos of business brands in natural scenes in an open-set one-shot setting. This problem setup is significantly more challenging than traditionally-studied ‘closed-set’ and ‘large-scale training samples per category’ logo recognition settings. We propose a novel multi-view textual-visual encoding framework that encodes text appearing in the logos as well as the graphical design of the logos to learn robust contrastive representations. These representations are jointly learned for multiple views of logos over a batch and thereby they generalize well to unseen logos. We evaluate our proposed framework for cropped logo verification, cropped logo identification, and end-to-end logo identification in natural scene tasks; and compare it against state-of-the-art methods. Further, the literature lacks a ‘very-large-scale’ collection of reference logo images that can facilitate the study of one-hundred thousand-scale logo identification. To fill this gap in the literature, we introduce Wikidata Reference Logo Dataset (WiRLD), containing logos for 100K business brands harvested from Wikidata. Our proposed framework that achieves an area under the ROC curve of 91.3% on the QMUL-OpenLogo dataset for the verification task, outperforms state-of-the-art methods by 9.1% and 2.6% on the one-shot logo identification task on the Toplogos-10 and the FlickrLogos32 datasets, respectively. Further, we show that our method is more stable compared to other baselines even when the number of candidate logos is on a 100K scale.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571625
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571625
KW  - logo identification.
KW  - one-shot learning
KW  - open-set recognition
KW  - supervised contrastive learning
ER  - 

TY  - CONF
TI  - Depth estimation using Stereo Light Field Camera✱
AU  - Nehra, Suresh
AU  - Laha, Jayanta
AU  - Mukhopadhyay, J.
AU  - Biswas, P. K.
T3  - ICVGIP '22
AB  - Light field imaging has emerged as a new modality, enabling to capture the angular and spatial information of a scene. This additional angular information is used to estimate the depth of a 3-D scene. The continuum of virtual view-points in light field data efficiently handles occlusion and provides a robust depth estimate for smaller distances. However, a narrow baseline in a light field camera limits the depth estimation for larger distances. To have an efficient occlusion handling and increase the operating distances, we proposed a novel disparity based stereo light field depth estimation method. First, segments are obtained in central sub-aperture of left view and then estimate the disparity vector of these segments using left camera sub-aperture images. This handles occlusion efficiently. Then stereo disparity at boundaries of these segments exploiting the epipolar geometry inherent in a light field data. Finally this stereo disparity at boundaries is propagated to other pixels and normalized. We provided a synthetic stereo light field data-set having inherent characteristic of a light field. We have tested our approach on a variety of real-world scenes captured with Lytro Illum camera and also on synthetic images. The proposed method outperforms several state-of-the-art algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571624
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571624
KW  - Light Field Imaging
KW  - Lytro Illum
KW  - stereo depth estimation.
KW  - stereo light field
ER  - 

TY  - CONF
TI  - REF-SHARP: REFined face and geometry reconstruction of people in loose clothing✱
AU  - Routhu, Snehith Goud
AU  - Sagar, Sai
AU  - Sharma, Avinash
T3  - ICVGIP '22
AB  - In this paper, we address the problem of monocular 3D human reconstruction with an acute focus on the challenge of recovering person-specific facial geometry as well as suppressing surface noise, specifically addressing the issue of false geometrical variations caused by textural edges. Most of the existing state-of-the-art methods in this domain fail to address these challenges. More specifically, we propose to integrate facial and wrinkle map priors in a learning-based framework to improve the quality of full-body 3D reconstruction from monocular images. By incorporating facial prior, we recover person-specific identity unlike many of the existing methods which rely on parametric shape models. Similarly, the wrinkle map prior enables our network to alleviate the challenge of false geometrical variations caused by high-frequency textural details present in the input image. We evaluate our method on publicly available datasets &amp; in-the-wild internet images with loose clothing and report superior performance both qualitatively and quantitatively when compared with SOTA methods.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571622
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571622
KW  - 3D Human Reconstruction
KW  - Face Reconstruction
ER  - 

TY  - CONF
TI  - Overcoming Label Noise for Source-free Unsupervised Video Domain Adaptation
AU  - Dasgupta, Avijit
AU  - Jawahar, C.V.
AU  - Alahari, Karteek
T3  - ICVGIP '22
AB  - Despite the progress seen in classification methods, current approaches for handling videos with distribution shifts in source and target domains remain source-dependent as they require access to the source data during the adaptation stage. In this paper, we present a self-training based source-free video domain adaptation approach (without bells and whistles) to address this challenge by bridging the gap between the source and the target domains. We use the source pre-trained model to generate pseudo-labels for the target domain samples, which are inevitably noisy. We treat the problem of source-free video domain adaptation as learning from noisy labels and argue that the samples with correct pseudo-labels can help in the adaptation stage. To this end, we leverage the cross-entropy loss as an indicator of the correctness of pseudo-labels, and use the resulting small-loss samples from the target domain for fine-tuning the model. Extensive experimental evaluations show that our method termed as CleanAdapt achieves gain over the source-only model and outperforms the state-of-the-art approaches on various open datasets.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571621
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571621
KW  - action recognition
KW  - domain adaptation
KW  - transfer learning
ER  - 

TY  - CONF
TI  - I’m GROOT: a multi head multi GRaph netwOrk recognizing surgical actiOn Triplets✱
AU  - Sista, Raviteja
AU  - Sathish, Rachana
AU  - Agrawal, Riya
AU  - De, Utpal
AU  - Chakrabarti, Partha
AU  - Sheet, Debdoot
T3  - ICVGIP '22
AB  - Laparoscopic cholecystectomy is a widely performed minimally invasive surgical procedure that imposes many challenges to the operating surgeon. While we strive to understand and automate such surgeries, the key is to identify the actions involved in it. An action involves a set of tools and a target anatomy, together forming the action triplets. However, the relations between the triplets and their constituents are sparse, making it challenging to learn their relations. In this paper, we propose a graph neural network based approach to exploit these underlying sparse relations in the data. We portray the proposed method’s ability to uniformly learn multiple tasks and classify triplets with an mAP of 0.261. In addition, we experimentally show the inability of fully connected and convolution layers to learn these sparse relations when trained on 40 laparoscopic videos and validated using five videos. Codes will be available at : https://github.com/iitkliv/groot.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571619
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571619
KW  - Graph neural networks
KW  - Laparoscopic cholecystectomy
KW  - Multi task learning
KW  - Sparse relations
KW  - Surgical action triplets
ER  - 

TY  - CONF
TI  - Supervised Contrastive Multi-tasking Learning Based Hierarchical Yoga Pose Classification Using CNNs
AU  - Chakka, Sai Pradeep
AU  - Sinha, Neelam
T3  - ICVGIP '22
AB  - In this paper, we propose a technique for hierarchical yoga pose classification in a multi-tasking framework. Novelty lies in the proposed supervised contrastive combined loss function. We propose the usage of linear combination of three loss functions: cross entropy, self-supervised contrastive loss and supervised contrastive loss in a multi-tasking manner. We introduce radial and cosine margin into the formulation of self-supervised and supervised contrastive loss to pull feature embeddings of same classes closer together compared to feature embeddings of different classes. We use a two stage transfer learning based end to end training methodology trained over novel supervised contrastive multi-tasking combined loss function in the first stage and later fine tune over cross entropy multi-tasking loss in the second stage. We apply our methodology on the publicly available Yoga-82 large-scale dataset. We report peak Top-1 yoga pose classification accuracy of 94.86% over 6 pose classes (Yoga-6), 91.9% over 20 pose classes (Yoga-20) and 87.17% over 82 pose classes (Yoga-82). Our proposed method achieves 5% improvement over Top-1 classification accuracy in Yoga-6, 7.3% improvement in Yoga-20 and 8.1% improvement in Yoga-82 in comparison with state of the art (SOTA) methodology. We achieve SOTA accuracies in all three hierarchies.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571620
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571620
KW  - CNN
KW  - Contrastive Learning
KW  - Multi-tasking
KW  - Transfer learning
KW  - Yoga Pose Classification
ER  - 

TY  - CONF
TI  - Split and Knit: 3D Fingerprint Capture with a Single Camera
AU  - Srivastava, Apoorva
AU  - Namboodiri, Anoop
T3  - ICVGIP '22
AB  - 3D fingerprint capture is less sensitive to skin moisture levels and avoids skin deformation, which is common in contact-based sensors, in addition to capturing depth information. Unfortunately, its adoption is limited due to high cost and system complexity. Photometric stereo provides an opportunity to build low-cost, simple sensors capable of high-quality 3D capture. However, it assumes that the surface being imaged is lambertian (unlike our fingers). We introduce the Split and Knit algorithm (SnK), a 3D reconstruction pipeline based on the photometric stereo for finger surfaces. It introduces an efficient way of estimating the direct illumination component, thus allowing us to do a higher-quality reconstruction of the entire finger surface. The algorithm also introduces a novel method to obtain the overall finger shape under NIR illumination, all using a single camera. Finally, we combine the overall finger shape and the ridge-valley point cloud to obtain a 3D finger phalange. The high-quality 3D reconstruction also results in better matching accuracy of the captured fingerprints. 1
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571618
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571618
KW  - 3D Fingerprint Reconstruction
KW  - Photometric Stereo
ER  - 

TY  - CONF
TI  - One shot learning in StyleALAE: Preserving facial identity during semantic modification
AU  - Kotlo Budde, Ravi Kiran Reddy
AU  - Shubham, Kumar
AU  - Venkatesh, Gopalakrishnan
AU  - Gandikota, Sriram
AU  - Khoche, Sarthak
AU  - Jayagopi, Dinesh Babu
AU  - Srinivasaraghavan, Gopalakrishnan
T3  - ICVGIP '22
AB  - Semantic face editing of real-world facial images is an important application of generative models. Recently, several works have explored possible techniques to generate such modifications by utilizing the latent structure of pre-trained GAN models. However, such approaches frequently necessitate the training of an encoder network, which is a time-consuming and resource-intensive procedure. StyleALAE&nbsp;[17], a latent-space based autoencoder that can generate photorealistic images of high quality, could be a viable alternative to a GAN-based architecture. Unfortunately, the reconstructed image in StyleALAE does not preserve the identity of the input facial image. This limits the application of StyleALAE for semantic face editing of images. In our work, we propose a one-shot learning approach to address this problem in StyleALAE. Our work ensures that the identity of the reconstructed image in StyleALAE is the same as the given input image. We also present ways to efficiently use the latent space of the pre-trained model to create semantic modification over the reconstructed image within the proposed one-shot learning approach. Results shows that our approach can generate semantic modifications on any real-world facial image while preserving identity.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571617
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571617
KW  - GAN
KW  - One shot learning
KW  - StyleALAE
ER  - 

TY  - CONF
TI  - FERA-net: An emotion classifier from facial expressions using FER-net with attention mechanism✱
AU  - R S, SREEDIVYA
AU  - P R, VIJITHA
AU  - GANAPATHY, SREELATHA
T3  - ICVGIP '22
AB  - Emotions play a significant and important role in daily life. It can be recognized by facial expressions, speech, and physiological signals such as electroencephalogram (EEG), electrocardiogram (ECG), body temperature, etc. Facial expression is one of the most natural ways of communication among humans. This paper focuses on designing and implementing an efficient emotion classification system using facial expressions. In order to improve the accuracy of the emotion classifier, we proposed a system in which the FER-net architecture is modified by incorporating an attention module and the proposed system is coined as FERA-net. In the FER-net model, each and every features of the facial regions are blindly extracted. It can lead to the misclassification of emotions. But the addition of attention module makes the network to extract only those features which are most vital for emotion recognition, diminishing other features. The FERA-net outperforms the existing state-of-the art methods in terms of accuracy, precision, recall and F1-score. FERA-net has been tested with three datasets: FER2013, CK+, and KDEF and compared with three state-of-the-art methods: VGG16, ResNet50 and FER-net. The proposed method has achieved an accuracy of 87.18 % for FER2013 dataset. A 2 % increment in the accuracy is obtained for FERA-net compared with that of the FER-net.1
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571616
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571616
KW  - Attention Mechanism
KW  - Convolutional Neural Network (CNN)
KW  - Emotion classification
KW  - Facial Expression Recognition (FER)
ER  - 

TY  - CONF
TI  - A Globally-Connected and Trainable Hierarchical Fine-Attention Generative Adversarial Network based Adversarial Defense
AU  - Kumar, Wahengbam Kanan
AU  - Paidimarri, Manoj
AU  - Sur, Arijit
T3  - ICVGIP '22
AB  - Deep Neural Network (DNN) inferences have been proven highly susceptible to carefully engineered adversarial perturbations, presenting a pivotal hindrance to real-world Computer Vision tasks. Most of the existing defenses have poor generalization ability due to their dependence on relatively limited Adversarial Examples (AE). Furthermore, the existing adversarial training necessitates continually retraining a target network with the sort of attack required to be repelled. The defense strategies that are primarily based on processing the perturbed image eventually fall short when pitted against constantly developing threats. Protection of DNN against adversarial attacks remains a difficult challenge on challenging datasets such as Fashion MNIST and CIFAR10. This paper proposes a GAN-based two-stage adversarial training model named Globally Connected and Trainable Hierarchical Fine Attention (GCTHFA). The first stage of the proposed GCTHFA GAN is to create a reconstructed image that is a purified version of an adversarial example. The proposed approach has used a trainable and globally linked attention map to teach the Generator about the different types of representations an image might have in different convolutional layers located at different levels in a network. The discriminator’s reliance on feature vectors produced by transfer learning eliminates the traditional dependency on standard image pixels. The second step involves adversarial training of a target classifier to provide resistance to such attacks. Extensive testing on the MNIST, Fashion MNIST, and CIFAR10 datasets with different classifiers and attacks show that the proposed model can handle adversarial attack settings for various target models. The proposed model uses only one type of adversarial training, with no requirement for retraining based on the type of attack.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571615
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571615
KW  - Adversarial Perturbation
KW  - Deep Learning
KW  - Generative Adversarial Network
KW  - Object Classification
ER  - 

TY  - CONF
TI  - Towards Robust Handwritten Text Recognition with On-the-fly User Participation
AU  - Mondal, Ajoy
AU  - Saluja, Rohit
AU  - Jawahar, C.V.
T3  - ICVGIP '22
AB  - Long-term OCR services aim to provide high-quality output to their users at competitive costs. It is essential to upgrade the models because of the complex data loaded by the users. The service providers encourage the users who provide data where the OCR model fails by rewarding them based on data complexity, readability, and available budget. Hitherto, the OCR works include preparing the models on standard datasets without considering the end-users. We propose a strategy of consistently upgrading an existing Handwritten Hindi OCR model three times on the dataset of 15 users. We fix the budget of 4 users for each iteration. For the first iteration, the model directly trains on the dataset from the first four users. For the rest iteration, all remaining users write a page each, which service providers later analyze to select the 4 (new) best users based on the quality of predictions on the human-readable words. Selected users write 23 more pages for upgrading the model. We upgrade the model with Curriculum Learning (CL) on the data available in the current iteration and compare the subset from previous iterations. The upgraded model is tested on a held-out set of one page each from all 23 users. We provide insights into our investigations on the effect of CL, user selection, and especially the data from unseen writing styles. Our work can be used for long-term OCR services in crowd-sourcing scenarios for the service providers and end users.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571613
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571613
KW  - curriculum learning.
KW  - handwritten
KW  - Hindi
KW  - OCR
KW  - robust
KW  - service
ER  - 

TY  - CONF
TI  - Low Resource Degraded Quality Document Image Binarization – Domain Adaptation is the Way
AU  - Kundu, Ahana
AU  - Bhattacharya, Ujjwal
T3  - ICVGIP '22
AB  - Usually, image binarization plays a crucial role in automatic analysis of degraded documents from their captured images. However, this binarization task is often difficult due to a number of reasons including the high similarity between noisy background and faded foreground pixels. The study presented here is particularly focused on binarization of images of low-resource degraded quality documents based on a set of recently collected image samples of several rare, ancient and severely degraded quality printed documents of Bangla, the 2nd and 5th most popular script of India and the world respectively. This new collection of degraded document image samples will henceforth be referred as ’ISIDDI2’ and it consists of 139 images of Bangla old document pages. Samples of ’ISIDDI’, another existing database of degraded Bangla document image samples, have also been used in the present study. A novel deep architecture based on attention UNET++ with dilated convolution operation is proposed for this binarization task. The model is optimized using human vision perceptible distance reciprocal distortion (DRD) loss. Since the binarization ground truth of samples of both ’ISIDDI2’ and ’ISIDDI’ are not available, the proposed network has been trained using samples of DIBCO and H-DIBCO datasets and an unsupervised domain adaptation (DA) module is employed for adaptation of the proposed architecture to the degradation patterns of ’ISIDDI2’ or ’ISIDDI’ samples. The proposed binarization strategy includes certain post-processing operation based on a modified k-neighbourhood based approach for recovery of broken characters. Results of our extensive experimentation show that the proposed binarization strategy has improved the binarization output of state-of-the-art methods on both ISIDDI2 and ISIDDI datasets. Also, its performance on well-known DIBCO samples is satisfactory.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571614
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571614
KW  - attention
KW  - degraded document image
KW  - domain adaptation
KW  - Image binarization
KW  - UNET++
ER  - 

TY  - CONF
TI  - Posture Guided Human Action Recognition for Fitness Applications
AU  - S R, Vishakha
AU  - Akula, Jayaprakash
AU  - Prasad, B H Pawan
AU  - Rosh, Green
T3  - ICVGIP '22
AB  - Human action recognition has attracted a lot of attention in the recent past due to newer applications in computer vision such as fitness tracking, augmented reality and virtual reality. Most of the existing deep learning based methods first deploy a deep neural network to estimate the human pose from a sequence of images followed by a second network to classify the human actions using all the estimated human poses. However, the pose estimation used in these methods typically fail to generalize for non-upright actions such as push-ups, plank, etc since the keypoints are closer to each other than observed in upright postures such as jump, dead-lift, etc. Hence, the accuracy of these methods gets impacted for non-upright actions, typically seen in fitness applications. In this paper, we propose a novel multi-stage deep learning based method for action recognition to predict upright as well as non-upright actions with high accuracy. We use a Light Weight Boundary Refinement Module (LWBRM) during pose estimation to distinguish closer keypoints more effectively. Further, we also introduce an intermediate frame-by-frame posture classification stage after pose estimation. We observed that this intermediate stage enables us to improve the human action recognition accuracy by while improving computational efficiency by ∼ 2 × compared to state-of-the-art methods. Our method can process at 104 frames per second on an android smartphone, and hence can readily be deployed for consumer oriented fitness applications.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571612
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571612
KW  - action recognition
KW  - deep learning
KW  - Pose estimation
ER  - 

TY  - CONF
TI  - Detecting Coronavirus (COVID -19) Disease Cues from Chest Radiography Images
AU  - Vinod, Athira
AU  - Shilna
AU  - K G, Sreeni
AU  - Purushothaman, Anurenjan
AU  - R S, Jeena
T3  - ICVGIP '22
AB  - This paper proposes a deep learning-based approach to detect COVID-19 infections in lung tissues from chest Computed Tomography (CT) images. A two-stage classification model is designed to identify the infection from CT scans of COVID-19 and Community Acquired Pneumonia (CAP) patients. The proposed neural model named, Residual C-NiN uses a modified convolutional neural network (CNN) with residual connections and a Network-in-Network (NiN) architecture for COVID-19 and CAP detection. The model is trained with the Signal Processing Grand Challenge (SPGC) 2021 COVID dataset. The proposed neural model achieves a slice-level classification accuracy of 93.54% on chest CT images and patient-level classification accuracy of 86.59% with class-wise sensitivity of 92.72%, 55.55%, and 95.83% for COVID-19, CAP, and Normal classes, respectively. Experimental results show the benefit of adding NiN and residual connections in the proposed neural architecture. Experiments conducted on the dataset show significant improvement over the existing state-of-the-art methods reported in the literature.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571611
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571611
KW  - Computed Tomography
KW  - COVID-19
KW  - Network in Network
KW  - Residual connections
ER  - 

TY  - CONF
TI  - Masked Student Dataset of Expressions
AU  - Sola, Sridhar
AU  - Gera, Darshan
T3  - ICVGIP '22
AB  - Facial expression recognition (FER) algorithms work well in constrained environments with little or no occlusion of the face. However, real-world face occlusion is prevalent, most notably with the need to use a face mask in the current Covid-19 scenario. While there are works on the problem of occlusion in FER, little has been done before on the particular face mask scenario. Moreover, the few works in this area largely use synthetically created masked FER datasets. Motivated by these challenges posed by the pandemic to FER, we present a novel dataset, the Masked Student Dataset of Expressions or MSD-E, consisting of 1,960 real-world non-masked and masked facial expression images collected from 142 individuals. Along with the issue of obfuscated facial features, we illustrate how other subtler issues in masked FER are represented in our dataset. We then provide baseline results using ResNet-18, finding that its performance dips in the non-masked case when trained for FER in the presence of masks. To tackle this, we test two training paradigms: contrastive learning and knowledge distillation, and find that they increase the model’s performance in the masked scenario while maintaining its non-masked performance. We further visualise our results using t-SNE plots and Grad-CAM, demonstrating that these paradigms capitalise on the limited features available in the masked scenario. Finally, we benchmark SOTA methods on MSD-E. The dataset is available at https://github.com/SridharSola/MSD-E.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571608
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571608
KW  - Computer vision
KW  - Covid-19
KW  - Facial expression recognition
KW  - Human-computer interaction
ER  - 

TY  - CONF
TI  - Topological Shape Matching using Multi-Dimensional Reeb Graphs
AU  - Ramamurthi, Yashwanth
AU  - Chattopadhyay, Amit
T3  - ICVGIP '22
AB  - Shape matching or retrieval is an important problem in computer graphics and data analysis. Topological techniques based on Reeb graphs and persistence diagrams have been employed to obtain an effective solution in this problem. In the current paper, we propose an improved technique based on the multi-dimensional Reeb graph (MDRG) that captures the topology of a multi-field through a hierarchy of Reeb graphs in different dimensions. To capture the persistent features in a multi-field, a hierarchy of persistence diagrams is then constructed by computing a persistence diagram corresponding to each Reeb graph of the MDRG. Based on this representation, we propose a novel distance measure between two MDRGs by extending the bottleneck distance between two Reeb graphs. We show that the proposed measure satisfies the pseudo-metric and stability properties. The effectiveness of the proposed multi-field topology based measure is tested on the shape data as compared to scalar topology based measures. We use normalized eigenfunctions of the Laplace-Beltrami operator, in pairs, as the bivariate descriptors of the shapes. The performance of the proposed measure is compared with the well-known topology based measures in shape matching using Heat Kernel Signature, Wave Kernel Signature and Scale-Invariant Heat Kernel Signature.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571606
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571606
KW  - Distance Measure
KW  - Multi-Dimensional Reeb graph
KW  - Multi-Field
KW  - Shape Matching
ER  - 

TY  - CONF
TI  - Learning from Multiple Datasets for Recognizing Human Actions
AU  - Kumbhare, Sevakram Tanaji
AU  - Chowdhury, Ananda
T3  - ICVGIP '22
AB  - Action recognition has evolved as an important research problem in the computer vision community. Majority of the human action recognition methods focus mainly on training from a single dataset. Scarcity of labelled data in a single dataset often leads to over-fitting for recognizing each and every action. So, use of multiple datasets is expected to alleviate this situation. However, in the real world, labelled data is frequently obtained from a variety of origins which can exhibit substantial variations. In this paper, we demonstrate how human actions can be accurately recognized by using multiple datasets based on the concept of unsupervised domain adaptation. We propose a novel approach termed as Multi-Dataset Human Action Recognition (MDHAR) for recognizing human actions using two or more publicly available benchmark datasets. Common and heterogeneous features for a dataset pair are aligned. Distributions across a dataset pair are also balanced to reduce class imbalance. We further show that our unsupervised domain adaptation approach can be extended to more than two datasets. Extensive experimentation on three publicly available benchmark datasets clearly reveal the efficacy of the proposed solution for cross dataset human action recognition from multiple datasets.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571605
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571605
KW  - Human action recognition
KW  - marginal and conditional distributions.
KW  - multi-dataset learning
KW  - unsupervised domain adaptation
ER  - 

TY  - CONF
TI  - Alzheimer’s severity classification using Transfer Learning and Residual Separable Convolution Network
AU  - Isunuri, Bala Venkateswarlu
AU  - Kakarla, Dr Jagadeesh
T3  - ICVGIP '22
AB  - Severity classification is the most pivotal task in Alzheimer’s disease diagnosis. Detection of brain structural changes from brain MR images is crucial for Alzheimer’s classification. In this paper, we have proposed a transfer learning and residual separable convolution network for the classification of Alzheimer’s. The proposed network includes three separable convolution layers with two average pooling layers. An upsampling has been performed to regain its spatial resolution for the residual connection. The main intuition of separable convolution is to optimize parameters with depth-wise convolution. Similarly, the residual connection has been used to reduce the vanishing gradient problem. Finally, a three-layer fully connected dense network has been used for the four-class Alzheimer’s classification. Kaggle dataset has been utilized for the experiments to report results. We have achieved an accuracy of 97.32% on the dataset with five-fold cross-validation. Our model has reported an improvement of 1% in jaccard similarity and outperforms the competing models in all vital metrics.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571610
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571610
KW  - Alxheimer’s disease
KW  - Residual Separable Convolution Network
KW  - Severity classification
KW  - Transfer Learning
ER  - 

TY  - CONF
TI  - Performance, Trust, or both? COVID-19 Diagnosis and Prognosis using Deep Ensemble Transfer Learning on X-ray Images✱
AU  - Tiwari, Abhishek
AU  - Singh, Rajeev Kumar
T3  - ICVGIP '22
AB  - The COVID-19 pandemic still affects most parts of the world today. Despite a lot of research on diagnosis, prognosis, and treatment, a big challenge today is the limited number of expert radiologists who provide diagnosis and prognosis on X-Ray images. Thus, to make the diagnosis of COVID-19 accessible and quicker, several researchers have proposed deep-learning-based Artificial Intelligence (AI) models. While most of these proposed machine and deep learning models work in theory, they may not find acceptance among the medical community for clinical use due to weak statistical validation. For this article, radiologists’ views were considered to understand the correlation between the theoretical findings and real-life observations. The article explores Convolutional Neural Network (CNN) classification models to build a four-class viz. "COVID-19", "Lung Opacity", "Pneumonia", and "Normal" classifiers, which also provide the uncertainty measure associated with each class. The authors also employ various pre-processing techniques to enhance the X-Ray images for specific features. To address the issues of over-fitting while training, as well as to address the class imbalance problem in our dataset, we use Monte Carlo dropout and Focal Loss respectively. Finally, we provide a comparative analysis of the following classification models - ResNet-18, VGG-19, ResNet-152, MobileNet-V2, Inception-V3, and EfficientNet-V2, where we match the state-of-the-art results on the Open Benchmark Chest X-ray datasets, with a sensitivity of 0.9954, specificity of 0.9886, the precision of 0.9880, F1-score of 0.9851, accuracy of 0.9816, and receiver operating characteristic (ROC) of the area under the curve (AUC) of 0.9781 (ROC-AUC score).
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571609
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571609
KW  - Chest X-ray
KW  - Classification
KW  - COVID-19
KW  - Deep Ensemble Transfer Learning
KW  - Pneumonia
KW  - SARS-CoV-2.
ER  - 

TY  - CONF
TI  - Convolutional Ensembling based Few-Shot Defect Detection Technique
AU  - Karmakar, Soumyajit
AU  - Banerjee, Abeer
AU  - Gidde, Prashant
AU  - Saurav, Sumeet
AU  - Singh, Sanjay
T3  - ICVGIP '22
AB  - Over the past few years, there has been a significant improvement in the domain of few-shot learning. This learning paradigm has shown promising results for the challenging problem of anomaly detection, where the general task is to deal with heavy class imbalance. Our paper presents a new approach to few-shot classification, where we employ the knowledge base of multiple pre-trained convolutional models that act as the backbone for our proposed few-shot framework. Our framework uses a novel ensembling technique for boosting the accuracy while drastically decreasing the total parameter count, thus paving the way for real-time implementation. We perform an extensive hyperparameter search using a power-line defect detection dataset and obtain an accuracy of 92.30% for the 5-way 5-shot task. Without further tuning, we evaluate our model on competing standards with the existing state-of-the-art methods and outperform them.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571607
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571607
KW  - Anomaly Detection
KW  - Ensemling Strategy
KW  - Few-Shot Classification
ER  - 

TY  - CONF
TI  - Quaternion Factorized Simulated Exposure Fusion
AU  - Saini, Saurabh
AU  - Narayanan, P. J.
T3  - ICVGIP '22
AB  - Image Fusion maximizes the visual information at each pixel location by merging content from multiple images in order to produce an enhanced image. Exposure Fusion, specifically, fuses a bracketed exposure stack of poorly lit images to generate a properly illuminated image. Given a single input image, exposure fusion can still be employed on a ‘simulated’ exposure stack, leading to direct single image contrast and low-light enhancement. In this work, we present a novel ‘Quaternion Factorized Simulated Exposure Fusion’ (QFSEF) method by factorizing an input image into multiple illumination consistent layers. To this end, we use an iterative sparse matrix factorization scheme by representing the image as a two-dimensional pure quaternion matrix. Theoretically, our representation is based on the dichromatic reflection model and accounts for the two scene illumination characteristics by factorizing each progressively generated image into separate specular and diffuse components. We empirically prove the advantages of our factorization scheme over other exposure simulation methods by using it for the low-light image enhancement task. Furthermore, we provide three exposure fusion strategies which can be used with our simulated stack and provide a comprehensive performance analysis. Finally, in order to validate our claims, we show extensive qualitative and quantitative comparisons against relevant state-of-the-art solutions on multiple standard datasets along with relevant ablation analysis to support our proposition. Our code and data are publicly available for easy reproducibility and reference. 1
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571604
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571604
KW  - Exposure Fusion
KW  - Low Light Image Enhancement
KW  - Quaternion Image Representation
KW  - Robust Principal Component Analysis
ER  - 

TY  - CONF
TI  - A Novel Multi-Scale Residual Dense Dehazing Network (MSRDNet) for Single Image Dehazing✱
AU  - M Manu, Chippy
AU  - K G, Sreeni
T3  - ICVGIP '22
AB  - Dehazing is a difficult process because of the damage caused by the non-uniform fog and haze distribution in images. To address these issues, a Multi-Scale Residual dense Dehazing Network (MSRDNet) is proposed in this paper. A Contextual feature extraction module (CFM) for extracting multi-scale features and an Adaptive Residual Dense Module (ARDN) are used as sub-modules of MSRDNet. Moreover, all the hierarchical features extracted by each ARDN are fused, which helps to detect hazy maps of varying lengths with multi-scale features. This framework outperforms the state-of-the-art dehazing methods in removing haze while maintaining and restoring image detail in real-world and synthetic images captured under various scenarios.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571601
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571601
KW  - Dehazing
KW  - Dilated Convolution
KW  - Image restoration
ER  - 

TY  - CONF
TI  - Interpreting Intrinsic Image Decomposition using Concept Activations
AU  - Gupta, Avani
AU  - Saini, Saurabh
AU  - Narayanan, P. J.
T3  - ICVGIP '22
AB  - Evaluation of ill-posed problems like Intrinsic Image Decomposition (IID) is challenging. IID involves decomposing an image into its constituent illumination-invariant Reflectance (R) and albedo-invariant Shading (S) components. Contemporary IID methods use Deep Learning models and require large datasets for training. The evaluation of IID is carried out on either synthetic Ground Truth images or sparsely annotated natural images. A scene can be split into reflectance and shading in multiple, valid ways. Comparison with one specific decomposition in the ground-truth images used by current IID evaluation metrics like LMSE, MSE, DSSIM, WHDR, SAW AP%, etc., is inadequate. Measuring R-S disentanglement is a better way to evaluate the quality of IID. Inspired by ML interpretability methods, we propose Concept Sensitivity Metrics (CSM) that directly measure disentanglement using sensitivity to relevant concepts. Activation vectors for albedo invariance and illumination invariance concepts are used for the IID problem. We evaluate and interpret three recent IID methods on our synthetic benchmark of controlled albedo and illumination invariance sets. We also compare our disentanglement score with existing IID evaluation metrics on both natural and synthetic scenes and report our observations. Our code and data are publicly available for reproducibility 1.
C1  - New York, NY, USA
C3  - Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571600.3571603
PB  - Association for Computing Machinery
SN  - 978-1-4503-9822-0
UR  - https://doi.org/10.1145/3571600.3571603
KW  - Disentanglement
KW  - evaluation techniques
KW  - ill-posed problems
KW  - Intrinsic Image Decomposition
KW  - ML interpretability
KW  - TCAV
ER  - 

TY  - CONF
TI  - The Spatial Performance Assessment for Cognitive Evaluation (SPACE): A Novel Game for the Early Detection of Cognitive Impairment
AU  - Colombo, Giorgio
AU  - Grübel, Jascha
T3  - CHI EA '23
AB  - Dementia is a leading cause of dependency and death among older adults and an economic burden to healthcare. In the fast-paced non-gaming environment of healthcare, the detection of dementia is limited to invasive and expensive procedures (e.g., PET) or less sensitive paper and pencil tests. Typically, dementia is preceded by Mild Cognitive Impairment (MCI) which is characterised by the loss of cognitive function including deficits in spatial ability. Spatial ability may be a sensitive marker for discriminating between healthy individuals and MCI patients. Virtual Reality now allows for spatial tests to be easily and safely deployed in clinics or at home. We introduce the Spatial Performance Assessment for Cognitive Evaluation (SPACE) as a transgressive, transformative gamified battery of spatial tests for tablets. SPACE is designed to identify differences in spatial ability to support clinicians in the early detection of dementia and offers a flexible ecosystem for immediate and longitudinal assessments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583828
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583828
KW  - Cognition
KW  - Dementia
KW  - Health Game
KW  - Mild Cognitive Impairment
KW  - Spatial Ability
ER  - 

TY  - CONF
TI  - Spelland: Situated Language Learning with a Mixed-Reality Spelling Game through Everyday Objects
AU  - Hsu, Chia
AU  - Chen, Yu
AU  - Liu, Yu-Jung
AU  - Chang, Yu-Cheng
AU  - Lee, Min-Jui
T3  - CHI EA '23
AB  - This work explores the use of mixed-reality (MR) technology to enable situated language learning using everyday objects in the environment around the learners. The learning method is based on Presentation, Practice, and Production (PPP), which cultivates the habit of independent learning through repetition, practice, and demonstration. In our game design, the learners first interact with real-world objects via MR, and the objects’ spelling and their pronunciation will appear (Presentation), the learners repeat the pronunciation (Practice) to collect the letters of this objects, and finally the learner use the collected letters to spell out the target words (Production), which then transform into interactive 3D objects. We designed the learning experience and content tools using gestural UI, voice input, and object-to-word engine. Children in the preliminary user study found the game to be immersive, helpful in learning the spelling of the everyday objects and the target words, and additionally showed increased interests in learning about other nearby objects after playing the game.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583830
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583830
KW  - Language Learning
KW  - Learning Experience
KW  - Mixed Reality
KW  - Situated Learning
KW  - Tangible Interaction
ER  - 

TY  - CONF
TI  - TitleIX: Step Up & Step In! A Mobile Augmented Reality Game Featuring Interactive Embodied Conversational Agents for Sexual Assault Bystander Intervention Training on US College Campuses
AU  - Schlesener, Elizabeth A
AU  - Lancaster, Caitlin Marie
AU  - Barwulor, Catherine
AU  - Murmu, Chandni
AU  - Schulenberg, Kelsea
T3  - CHI EA '23
AB  - Despite the efforts of existing Title IX training programs in the US, current intervention and prevention programs fail to address the problems caused by sexual violence on US college campuses. To address this issue, we designed a mobile augmented reality (AR) game – TitleIX: Step Up &amp; Step In! – that encourages students to become more active and supportive of bystanders through innovative game play, while aiming to improve current sexual assault bystander intervention training. Utilizing AR technology and embodied conversational agents (ECAs), this game provides highly immersive scenario based training for sexual assault bystander intervention while connecting the users to realistic campus experiences. This inventive game design leverages innovative technology to increase awareness of real-world problems; specifically, sexual harassment targeting women and LGBTQ+ students on college campuses. The design implemented in this paper can inform the future construction of AR serious games for social justice.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583832
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583832
KW  - Augmented Reality
KW  - Bystander Intervention
KW  - Embodied Conversation Agents
KW  - Serious Games
KW  - Sexual Assault Awareness
KW  - Transformative Gaming
ER  - 

TY  - CONF
TI  - Glow the Buzz: a VR Puzzle Adventure Game Mainly Played Through Haptic Feedback
AU  - Jeong, Sihyun
AU  - Yun, Hyun Ho
AU  - Lee, Yoonji
AU  - Han, Yeeun
T3  - CHI EA '23
AB  - Virtual Reality (VR) has become a popular tool, leading to increased demands for various immersive VR games for players. In addition, haptic technology is gaining attention as it adds a sense of touch to the visual and auditory dominant Human-Computer Interface (HCI) in terms of providing more extended VR experiences. However, most games, including VR, use haptics as a supplement while mostly depending on the visual elements as their main mode of transferring information. It is because the complexity of haptic in accurately capturing and replicating touch is still in its infancy. To further investigate the potential of haptics, we propose to Glow the Buzz, a VR game in which haptic feedback serves as a core element using wearable haptic devices. Our research explores whether haptic stimuli can be a primary form of interaction by conceiving iterative playtests for three puzzle designs - rhythm, texture, and direction. By proposing a VR haptic puzzle game that cannot be played without haptics, the study concludes that haptic technology in VR has the potential extendability. The study also suggests elements that enhance discriminability of haptic stimuli in each puzzle.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583827
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583827
KW  - Haptic Direction
KW  - Haptic Rhythm
KW  - Haptic Texturing
KW  - Haptic-central Gameplay
KW  - Virtual Reality
KW  - VR games
ER  - 

TY  - CONF
TI  - Spatial Chef: A Spatial Transforming VR Game with Full Body Interaction
AU  - Shin, Yeeun
AU  - Lee, Yewon
AU  - Kim, Sungbaek
AU  - Park, Soomin
T3  - CHI EA '23
AB  - How can we play with space? We present Spatial Chef, a spatial cooking game that focuses on interacting with space itself, shifting away from the conventional object interaction of virtual reality (VR) games. This allows players to generate and transform the virtual environment (VE) around them directly. To capture the ambiguity of space, we created a game interface with full-body movement based on the player’s perception of spatial interaction. This was evaluated as easy and intuitive, providing clues for the spatial interaction design. Our user study reveals that manipulating virtual space can lead to unique experiences: Being both a player and an absolute and Experiencing realized fantasy. This suggests the potential of interacting with space as an engaging gameplay mechanic. Spatial Chef proposes turning the VE, typically treated as a passive backdrop, into an active medium that responds to the player’s intentions, creating a fun and novel experience.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583826
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583826
KW  - Game Design
KW  - Spatial Interaction
KW  - Virtual Environment
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - MindTerior: A Mental Healthcare Game with Metaphoric Gamespace and Effective Activities for Mitigating Mild Emotional Difficulties
AU  - Lee, Ain
AU  - Lee, Juhyun
AU  - Ahn, Sooyeon
AU  - Lee, Youngik
T3  - CHI EA '23
AB  - Contemporaries suffer from more stress and emotional difficulties, but developing practices that allow them to manage and become aware of emotional states has been a challenge. MindTerior is a mental health care game developed for people who occasionally experience mild emotional difficulties. The game contains four mechanisms: measuring players’ emotional state, providing game activities that help mitigate certain negative emotions, visualizing players’ emotional state and letting players cultivate the game space with customizable items, and completing game events that educate players on how to cope with certain negative emotions. This set of gameplays can allow players to experience effective positive emotional relaxation and to perform gamified mental health care activities. Playtest showed that projecting players’ emotional state to a virtual game space is helpful for players to be conscious of their emotional state, and playing gamified activities is helpful for mental health care. Additionally, the game motivated players to practice the equivalent activities in real life.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583831
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583831
KW  - Inducing Behavior
KW  - Mental Health Care
KW  - Relaxing Emotion
KW  - Serious Game Design
ER  - 

TY  - CONF
TI  - MEDUSA - A View-Tracking Pong Game
AU  - Reinke, Nikolai Lukas
AU  - Wursthorn, Tobias
AU  - Jessen, Jan
T3  - CHI EA '23
AB  - Abstract: The purpose of this study was to develop a prototype game mechanic that limits the player’s sense of sight and to investigate how quickly players adapt to this mechanic as well as the effects of the mechanic on player competitiveness. We seek to incentivise players to track the current game-state as a mental image rather than getting visual input consistently. This could lead to them experiencing the game more intensely. In this study, a group of participants played a modified version of the classic game ’Pong’ on a touchscreen device while the game visually tracked the openness of their eyes. While this paper only represents a preliminary proof-of-concept and no full-scale study, initial results show meaningful differences in player action - acclimatisation and strategic adaption are clearly visible, even in very small datasets.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583825
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583825
KW  - Attention-Tracking
KW  - Attractiveness in connection with playing time
KW  - Change in screen time usage
KW  - Learnability
KW  - Pong
ER  - 

TY  - CONF
TI  - Breathero: Not Another Slow Breathing Game — Exploring Faster-Paced VR Breathing Exercise Games
AU  - Wang, Shun-Yu
AU  - Cheng, Chia-Yu
AU  - Huang, Shu-Meng
AU  - Chan, Weng Io
AU  - Huang, Yu-Hsuan
AU  - Lin, Jhih-Wei
T3  - CHI EA '23
AB  - BreatHero is a faster-paced Virtual Reality (VR) action game that explores the potential of combining breathing techniques learning with the combat elements of action games. BreatHero uses breathing techniques as various skills for attacking and defending against the enemies, so players can do breathing exercises while enjoying defeating the in-game enemies. We choose three breathing techniques: Kapalabhati, Box Breathing, and Full Yogic Breathing, which are all beneficial for physical and mental health. To enhance breathing techniques learning and memorization in action games, we present two design concepts: Imitative Breathing Feedback and Associate Learning on Breathing Techniques. Results from our study indicated that players found the game to be more engaging and were willing to play it repeatedly, suggesting that breathing exercises can be effectively integrated into faster-paced action games.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583829
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583829
KW  - Breath detection
KW  - Breathing exercises
KW  - Breathing game
KW  - Virtual Reality
ER  - 

TY  - CONF
TI  - Bean Academy: A Music Composition Game for Beginners with Vocal Query Transcription
AU  - Lee, Jaejun
AU  - Cho, Hyeyoon
AU  - Kim, Yonghyun
T3  - CHI EA '23
AB  - Bean Academy is a music composition game designed for musically-unskilled learners to lower entry barriers to music composition learning such as music theory comprehension, literacy and proficiency in utilizing music composition software. As a solution, Bean Academy’s Studio Mode was designed with the adaptation of an auditory-based ‘Vocal Query Transcription(VQT)’ model to enhance learners’ satisfaction and enjoyment towards music composition learning. Through the VQT model, players can experience a simple and efficient music composition process by experiencing their recorded voice input being transcripted into an actual musical piece. Based on our playtest, thematic analysis was conducted in two separate experiment groups. Here, we noticed that although Bean Academy does not outperform the current-level Digital Audio Workstation(DAW) in terms of performance or functionality, it can be highly considered as suitable learning material for musically-unskilled learners.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583824
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583824
KW  - Education game
KW  - Music composition
KW  - Serious game
KW  - Vocal Query Transcription
ER  - 

TY  - CONF
TI  - UniCompass: Helping High School Students Find the Right College Major
AU  - Lin, Liang-Cheng
AU  - Lai, Yi-Chun
AU  - Chang, Wei-Chien
AU  - Chiu, Hsin-Lun
AU  - Chen, Tzu-Yu
T3  - CHI EA '23
AB  - With the objective of furthering the United Nations’ mission to provide Quality Education, this project aims to aid high school students in Taiwan’s high-pressure, exam-oriented educational environment, by offering support and resources to help them uncover their interests and potential career paths. Through in-depth interviews with high school students, we identified common concerns in knowing and exploring college majors and career paths due to a lack of information and resources, unvarying suggestions, and barriers during the process of preparing for Academic Portfolio. To address these issues, we designed UniCompass using a user-centered design process. UniCompass is featured by: 1) finding the appropriate major for the student and comparing the differences between various universities and departments; 2) obtaining valuable information from the personal experiences shared by university students; and 3) receiving advice and guidance on building Academic Portfolios.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583848
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583848
KW  - Academic Portfolio
KW  - exam-oriented education
KW  - information-providing
KW  - major and career exploration website
KW  - university departments
ER  - 

TY  - CONF
TI  - Synthium: Mushrooms to facilitate the transition to the Post-Anthropocene
AU  - Puse, Aidan Mark
AU  - Knothe, Lillian Elizabeth
AU  - Tanovic, Brooklyn
AU  - Center, Shiraz
T3  - CHI EA '23
AB  - The United Nations has developed a set of Sustainable Development Goals (SDGs) as a call to action to promote prosperity while protecting the planet&nbsp;[16]. SDG 11 aims to make cities inclusive, safe, resilient, and sustainable, but there is a challenge to encourage adoption of a post-anthropocentric mindset that considers all stakeholders equally. We present Synthium, an interactive, tangible installation design that allows users to interact with other living organisms in a ludic way. We used an iterative design process to develop a multisensory system utilizing mushroom frequencies to enhance communal green spaces (see Figure 1). This prototype encourages restoration of humans’ relationship with nature within urban environments: the first step in achieving a post-anthropocentric mindset leading to sustainable city development.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583842
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583842
KW  - Bio-Design
KW  - Smart Cities
KW  - Sustainability
KW  - Sustainable Development Goals
ER  - 

TY  - CONF
TI  - SAM: Interface Design of a Mobile Application for Women in Risk Situations
AU  - De la Cruz Villarreal, Aketzali
AU  - Alavéz Santiago, Gerardo Neftalí
AU  - Martínez, Ángel
AU  - Baltazar Hernández, Eunice Lucero
AU  - López Pérez, Juan Carlos
AU  - Peralta Calvo, María del Rosario
T3  - CHI EA '23
AB  - The following paper presents a design proposal of a mobile application aimed to support women in risk situations in the City of Huajuapan de León, Oaxaca, Mexico. Our proposal, Assistance System for Women (or SAM), is a design for women in a situation of risk. Based on an user-centered design approach, our proposal features functionalities like Help buttons, Simulate Telephone Calls and Follow-up, as well as Location in real time. Gender violence and violence against women is a factor of enormous concern in Mexican society nowadays. By creating this interface prototype, we intend to offer our users security to be able to carry out their daily activities without fear. We are trying to be part of positive social development, an essential element to achieve the maintenance of peace and security.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583844
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583844
KW  - Justice and Strong Institutions.
KW  - Mexico
KW  - mobile application
KW  - Peace
KW  - Risk situation
KW  - UN Goals
KW  - Women’s risk
ER  - 

TY  - CONF
TI  - Lighting up well-being with Bulb
AU  - Ooms, Simone
AU  - Kolvenbag, Jay
AU  - Bording, Charlotte
T3  - CHI EA '23
AB  - Due to the Covid-19 pandemic, two problems arose. Students lacked 1) social opportunities and 2) motivation to maintain their schedules, e.g., studying or relaxing, as their work-life balance disappeared. Thus, we designed a social companion robot, Bulb, that helped students cycle through daily activities with subtle cues, i.e., light, gaze, and movements. Bulb’s "head" would light up with different colors or it gazes at different parts of the room, e.g., at the laptop to hint at studying or wiggling to suggest a small break. Five students evaluated Bulb through at-home use, which demonstrated that Bulb was seen as a "living being" and students were responsive to its social cues, like following Bulb’s gaze, resulting in a higher awareness and follow-through of students’ schedules. Our contribution is in designing a social companion robot that subtly persuaded students through light and anthropomorphic social cues, helping them maintain their daily schedule during the pandemic.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583838
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583838
KW  - design
KW  - interaction
KW  - social robot
ER  - 

TY  - CONF
TI  - ROBOTE: Interactive Educational Tool to Teach Basic Education Children to Classify and Collect Waste in their School Environment
AU  - Jiménez Barriga, Nadia
AU  - Hernández Villalba, Belen
T3  - CHI EA '23
AB  - The presented project, denominated ROBOTE, aims to develop a robot which teaches children to classify waste. The objective of ROBOTE is to educate children of basic school age about the importance of correctly classifying waste and promoting sustainable habits in their daily life with a feedback-and-reward system to encourage participation and motivation. This project is rooted in the current problem of the increasing consumption of plastics and the lack of adequate waste management, and seeks to contribute to the achievement of Goals 12, 14 and 15 of the UN 2030 Agenda.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583847
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583847
KW  - children
KW  - Design Thinking
KW  - Interface
KW  - plastics
KW  - recycling
KW  - UN Goals
KW  - usability testing
KW  - waste
ER  - 

TY  - CONF
TI  - HeritageSite AR: An Exploration Game for Quality Education and Sustainable Cultural Heritage✱
AU  - Xu, Ningning
AU  - Liang, Jiachen
AU  - Shuai, Kexiang
AU  - Li, Yuwen
AU  - Yan, Jiaqi
T3  - CHI EA '23
AB  - Cultural heritage (CH) plays an important role in realizing the Sustainable Development Goals (SDGs). In this paper, we focus on emerging technologies such as Augmented Reality (AR) and gamified learning to foster public understanding of cultural values in historical contexts. We design HeritageSite AR, an exploration game for onsite CH learning and visits with publics in Relics of Arhat Monastery and Twin Pagoda (also known as Shuangta). Based on research investigation of technical means, expert semi-structured interviews and online survey, we distill and incorporate four design goals using user journey map. The implemented game design is evaluated with respect to three design components (i.e., reality, meaning, play) and four stages (i.e., trigger, engage, consolidate, relate) in CH visits. We conclude our work with a discussion of contributions to SDGs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583837
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583837
KW  - augmented reality
KW  - cultural heritage
KW  - exploration game
KW  - quality education
KW  - sustainable development
ER  - 

TY  - CONF
TI  - Green Home: A Reflection on the Relationship between Human and Furniture
AU  - Huang, Tianhui
AU  - Ke, Tianming
AU  - Lin, Yuyang
AU  - Shi, Fangya
AU  - Zhang, Xinyu
T3  - CHI EA '23
AB  - People nowadays tend to discard furniture and replace it frequently, paying less attention to daily maintenance or keeping it in good condition for a second-hand transaction. This is inconsistent with the UN’s goal of responsible consumption and puts entire ecosystems and economies at risk. To solve this, we proposed Green Home, which encourages people to rethink their relationships and build an emotional connection with furniture through the analogy of plants. Our products consist of a plant-shaped tag with embedded sensors that can directly indicate the status of the furniture by colours, a wristband that provides a variety of interaction feedback to users, and an app that provides social and second-hand transaction functions. The difference between Green Home and existing solutions is that we focus on the entire furniture life cycle rather than just one part, achieving the UN’s goal of responsible consumption through long-term emotional interaction.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583833
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583833
KW  - emotional connection
KW  - internet of things
KW  - social media
KW  - wearable
ER  - 

TY  - CONF
TI  - FOODwell
AU  - Hsieh, An-Ting
AU  - Hsiao, Chih-Ching
AU  - Tsai, Hsin-Hua
AU  - Chen, Hung-Hsuan
AU  - Liu, Jui-Chun
T3  - CHI EA '23
AB  - Hunger is an often neglected issue, with millions of people worldwide affected by it in 2021 according to the United Nations. This issue also affects minority populations in Taiwan. One solution to this problem is the implementation of suspended meals, which are free meals provided to those in need. Our proposed solution, FOODwell, aims to allow recipients to dwell on better food provision and obtain wellness for their food needs. It is a system that simplifies the process of reserving and collecting suspended meals for recipients by enabling them to interact with the kiosk at the convenience store and cashier at the restaurant, without compromising confidentiality or requiring electronic devices. Overall, FOODwell eliminates obstacles for recipients when reserving and collecting suspended meals.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583840
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583840
KW  - interaction design
KW  - kiosks
KW  - suspended meals
KW  - user research
KW  - zero hunger
ER  - 

TY  - CONF
TI  - Financial Decision Buddy: A Decision-support Tool to Bridge the Gaps in Financial Education
AU  - Hu, Chujin
AU  - Chong, Clarissa
AU  - Kang, Yihan
AU  - Li, Yiran
AU  - Chen, Yujie
T3  - CHI EA '23
AB  - SDG 4 education and SDG 1 poverty are issues of global concern. Young people may fall into poverty due to various reasons: student debt, unemployment, and unpredictable events such as the pandemic. Therefore, education to improve their financial competence is necessary to increase their resilience to those risks and pressures. We analysed 62 participants’ questionnaire data and found that most participants struggle with making optimal financial decisions when spending. With this in mind, we designed a system that uses machine learning to analyse users’ previous spending habits and models it against a decision tree framework to calculate the most optimal decision within users’ budgets. The system used affective interaction and anthropomorphic communication to educate users in real-time shopping environments, for example when they’re shopping in a grocery store. Our user testing demonstrated that the design was helpful with cognitive offload and encouraged critical thinking when making purchasing decisions. Furthermore, our design idea sheds light on possible approaches to applying virtual AI assistants to improve skills when lacking resources such as time, place, or human experts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583835
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583835
KW  - affective interaction
KW  - decision support
KW  - financial education
KW  - financial literacy
KW  - MEU framework
KW  - reducing poverty
ER  - 

TY  - CONF
TI  - Crowdsourcing Data for Safer Travel Experiences for Women in India
AU  - Huang, Xiao Yuan
AU  - West, Emma
AU  - Pinnelli, Sai Samba Karthikeya
T3  - CHI EA '23
AB  - In 2018, the Thomas Reuters perception survey ranked India as the most dangerous country for women due to the high risk of sexual, and non-sexual violence, and harassment [2]. In a study conducted by Jagori and UN Women in Delhi, it was observed that the highest number of incidents reported by women occurred on buses, other public transportation, and on the streets [3]. With the rise of women traveling and entering the workforce, it's critical to observe how Information and Communications for Technology and Development (ICTD) may be designed to increase female safety while traveling. Through a diary study, competitor analysis, and user interview methodology, our team uncovered unique challenges in public transportation, social and gender role expectations, and familial interventions that shape the safety of women in Southern India. Informed by our research, we created Navi.io, a mobile safety application that enables users to feel safer and make informed decisions when traveling by utilizing crowdsourced data and connecting with contacts in transit.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583836
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583836
KW  - India
KW  - Location Sharing
KW  - Mobile Application
KW  - Navigation
KW  - Public Transportation
KW  - Women Safety
ER  - 

TY  - CONF
TI  - CO2LLAB: Creating an Eco-Conscious Community through Habit Tracking and Augmented Reality Visualisation
AU  - Chun, Hoi Yau Rosalyn
AU  - Gao, Yunhan
AU  - Nursalamah, Rahma Khairunisa
AU  - O Keeffe, Conor Michael
AU  - Shin, Haeji
T3  - CHI EA '23
AB  - CO2e emissions remain a substantial problem for the environment despite efforts from numerous initiatives over the years to curb their output. The role of younger generations is critical in this problem space. From user research, we found that young adults rarely volunteer but do engage frequently in individual actions geared towards the environment. They are also motivated when they see others' contributions. We decided to leverage this willingness for individual environmental actions and turn it into a collective effort by creating CO2LLAB, a platform that reimagines how young adults can reduce CO2e emissions with their community. It incorporates a habit-tracking app for eco-friendly actions and augmented reality technology to visualise their impact. Our prototype evaluation demonstrated that CO2LLAB not only educated them on the topic, but also motivated them to consider their impact on their community more.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583834
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583834
KW  - Augmented Reality
KW  - Climate Action
KW  - CO2e Emissions
KW  - Habit Tracker
KW  - Sustainable Community
ER  - 

TY  - CONF
TI  - Co-designing an Integrated Digital Education Portal for the Eastern Cape Rural Learners
AU  - Makalima, Chuma
AU  - Gwala, Yolanda
AU  - Makasi, Lutho
AU  - Baza, Anam
AU  - Lwanga, Andile Michael
T3  - CHI EA '23
AB  - The digital divide gap remains widening as poor and rural communities continue to struggle to access and benefit from emerging technologies. However, access to digital technology has bridged physical and economic barriers in some communities by allowing access to information, which, in turn, has pushed the digital economy or Industry 4.0 (4IR) forward. Unfortunately, in African rural communities, access to digital technology is still distant. Research on rural schools indicates that the greatest portion of those living in rural areas access their internet through their mobile phones unlike in urban areas where the internet is accessed through wireless and digital subscriber lines (DSL) in addition to mobile phones. As a result, these differences have created a digital divide between urban and rural areas as well as among provinces in South Africa. Additionally, rural schools produce poor results and have poor ICT infrastructure and physical resources, and the economic status of the learners is equally a huge worry. Rural schools have challenges in accessing books and the latest learning material, affecting the quality of education. Most critically, most digital education solutions are designed and developed without the involvement of rural learners and teachers. In this study, the Eastern Cape schools in South Africa are considered. Through participatory design, including learners, teachers and key education stakeholders, a digital education portal is co-designed. Results have shown that education stakeholders are willing to participate and contribute to digital education platforms. Stakeholders would like a simple design that considers their views and input in order to easily use and benefit from the designed platform.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583839
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583839
KW  - Co-Design
KW  - Digital Education
KW  - Quality Education
KW  - User Interface Design
ER  - 

TY  - CONF
TI  - Buddy: Helping School-age Children to Combat Bullying
AU  - McCaleb, Ali
AU  - Palmiere, Ellen
AU  - Bessellieu, Laura
AU  - Meyers, Alexandra
T3  - CHI EA '23
AB  - Bullying has been an ongoing and prevalent problem at school for years. School-age children need a way to feel safe and protected in their own school and be able to ask for help when being bullied. With the goal of improving quality education, we created the Buddy key chain and app aiming at combating bullying in regard to school-age children, parents, and teachers involved in the issue of bullying in elementary schools and middle schools. The Buddy key chain is an automatic, discreet device with a secret button that alerts parents and teachers of instances of bullying directly from the student who is bullied or witnesses bullying. When the button is pressed, the parents and teachers attached to that student’s account will be alerted. This provides the student with a way to report the bullying without encouraging the bullying to continue. The issue this device solves is the lack of quality education. Students cannot learn effectively if they do not feel safe in their learning environment.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583843
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583843
KW  - bully
KW  - interaction design
KW  - Quality education
ER  - 

TY  - CONF
TI  - Build a Smart Sustainable Windhoek: An AR game
AU  - Makosa, Isaac
AU  - Nuunyango, Clemens
AU  - Uchezuba, Kingsley Chidozie
T3  - CHI EA '23
AB  - The City of Windhoek is dedicated to become a Smart, Sustainable City, in alignment with sustainable development goal 11. Local officials strive to include residents to guide smart and sustainable initiatives and strategies, but lack tools and techniques to engage those unfamiliar with smart city concepts. We proposed a Build a Smart Sustainable Windhoek game, which educates and raises awareness while sharing citizen needs and desires to inform smart and sustainable city strategies. It is an interactive hybrid game combining physical interactions with boxes and augmented reality. The game was co-designed with unemployed youth from an informal settlement in the capital. It was played by 8 teams, each consisting of three Windhoek residents from different backgrounds, during a half-day smart city event. The survey results show that participants enjoyed the role of a town planner and building their own city having been teamed up with fellow residents from different suburbs. Moreover, they considered the game to be most informative in creating awareness on Smart City topics.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583841
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583841
KW  - augmented reality
KW  - city of Windhoek
KW  - interaction design
KW  - mobile application
KW  - resident engagement
KW  - smart city
KW  - smart technologies
KW  - sustainable city
ER  - 

TY  - CONF
TI  - Blooming: Changing Laundry Habits and Opening Windows to Brighter Cities
AU  - Ma, Yun
AU  - Chang, Ya-Chi
AU  - Cui, Zhuoyi
AU  - Rothwell, Dylan
AU  - Bykoriz, Anna
T3  - CHI EA '23
AB  - Laundry is a routine part of most individuals’ lives and an important factor in decisions around infrastructure and property development. It’s a routine that many take for granted, but in a world with increasing energy costs and environmental impact, the need to rethink the process is greater than ever. In this, tumble-dryers are associated with the greatest cost and carbon emissions in the laundry cycle while also being the most redundant. Blooming, a tumble-dryer alternative designed with cost-effectiveness, space adaptability, and sustainability at its core, is thus proposed. It is a smart-rack window installation that hangs the user’s wet clothes in the draft of their home. Using sensors of the environment, the window assesses when the weather is most suitable for clothes drying and opens with the clothes rack automatically or according to the user’s discretion. An accompanying app tracks the drying condition of the clothes and takes commands to close the window once finished. The app also gives feedback on the user’s environmental impact, cost savings, and community progress. As such, Blooming will fit naturally in any apartment home as a utility that discourages and substitutes the costly use of drying machines while having a user journey that remains familiar and convenient.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583846
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583846
KW  - behavioural change
KW  - domestic energy
KW  - laundry
KW  - sustainability
ER  - 

TY  - CONF
TI  - Agapet: Supporting A Responsible Adoption Process for Stray and Abandoned Pets in Urban Areas
AU  - Chang, Meiyin
AU  - Cañarte, Gabriel
T3  - CHI EA '23
AB  - The growing number of stray domestic animals negatively impacts cities’ possibilities to be safe and resilient spaces for their citizens, thus hindering possibilities of attaining the SDG 11 of fostering sustainable cities and communities. Organizations and governments strive to ensure stray pets are adopted. However, doing so is challenging: citizens often do not want to adopt, and many of those who do end up returning their pets to shelters. This situation worsens in countries from the Global South where in-place infrastructures struggle to reinforce existing policies. During four months, we worked closely with a civic-led rescue organization in Ecuador to explore how technology can support organizations in motivating responsible and sustained adoption. As a result, we propose Agapet, a mobile app that, using a timeline, visual representation of milestones, short pet-ownership courses, and a rewards system, sheds light on all the stages of the adoption journey. In this article, we summarize our design process and how the positive results we have obtained so far suggest the app is a step towards responsible pet ownership in urban spaces.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583845
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583845
KW  - design journey
KW  - designing with pet rescue organizations
KW  - stray animals
KW  - user-centered design
ER  - 

TY  - CONF
TI  - Towards Personalized User Interface Design For News Chatbots: A Pilot Study
AU  - Zhao, Xianglin
T3  - CHI EA '23
AB  - Numerous mainstream news organizations have adopted chatbots as an emerging channel for delivering personalized news services. However, the news presentation style of chatbots may not satisfy users’ personalization needs due to the “one-size-fits-all” design. In this context, we conducted two within-subject studies to investigate the impacts of news reader types, namely “dipper”, “tracker”, and “reviewer” on users’ preference for different interfaces for news selection and reading. Our preliminary findings reveal that all these types of news readers perceived a higher level of ease of selection when using the carousel design. For “trackers” and “reviewers”, the question-driven design resulted in a higher level of perceived ease of reading than the in-conversation design. Finally, I discuss my findings and provide insights into personalized user interface design for news chatbots.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583951
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583951
KW  - conversational agent
KW  - empirical study
KW  - news chatbot
KW  - personalized interface
ER  - 

TY  - CONF
TI  - Towards a Markerless 3D Pose Estimation Tool
AU  - Rahman, Amaan
T3  - CHI EA '23
AB  - Evaluation of exoskeleton performance benefits from standards to verify proper functionality and safety. Currently, there are limited evaluation methods for exoskeletons. Measurement methods to evaluate human-exoskeleton kinematics include optical tracking systems (OTS) and inertial measurement units (IMUs). However, OTS and IMUs can be intrusive, requiring the attachment of markers or sensors. This research focuses on investigating markerless 3D pose estimation algorithms with low-cost red, green, blue (RGB) cameras to determine their viability as methods for tracking human joint positions and deriving skeletal frame orientations. We present a tool that utilizes state-of-the-art 3D pose estimation algorithms to generate 3D pose estimation data. Future experiments will be performed to evaluate the viability of 3D pose estimation algorithms as markerless methods for joint position and orientation estimation.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583950
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583950
KW  - 3D human pose estimation
KW  - deep neural networks
KW  - exoskeleton/human kinematics
KW  - monocular computer vision
ER  - 

TY  - CONF
TI  - Not To Be Deceived? Timing Matters: Trustworthy Online Review Design
AU  - Jung, Yongnam
T3  - CHI EA '23
AB  - Studies have shown that the effects of fake reviews can be decided by how platforms operate such as how they display online reviews. A meta-analytic study of communication research suggests that the timing of communication source identification affects message credibility. The current study suggests implementing reviewer information, used as criteria in a fake review detection algorithm, in online reviews and adjusting the identification timing of this information. The study findings show that 1) the number of accumulated helpful votes for the reviewer positively influences reviewer credibility, 2) perceived review authenticity mediates the relationship between reviewer credibility and users’ intention to adopt the review, 3) reviewer identification timing affects the user's attitude about the product, such that viewing the reviewer's information alongside the review helps users consolidate their review evaluation. Implementing the recommended online review interface design based on the findings of this study can diminish the possible impact of fake reviews.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583952
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583952
ER  - 

TY  - CONF
TI  - Which Factors Predict the Chat Experience of a Natural Language Generation Dialogue Service?
AU  - Chen, Eason
T3  - CHI EA '23
AB  - In this paper, we proposed a conceptual model to predict the chat experience in a natural language generation dialog system. We evaluated the model with 120 participants with Partial Least Squares Structural Equation Modeling (PLS-SEM) and obtained an R-square (R2) with 0.541. The model considers various factors, including the prompts used for generation; coherence, sentiment, and similarity in the conversation; and users’ perceived dialog agents’ favorability. We then further explore the effectiveness of the subset of our proposed model. The results showed that users’ favorability and coherence, sentiment, and similarity in the dialogue are positive predictors of users’ chat experience. Moreover, we found users may prefer dialog agents with characteristics of Extroversion, Openness, Conscientiousness, Agreeableness, and Non-Neuroticism. Through our research, an adaptive dialog system might use collected data to infer factors in our model, predict the chat experience for users through these factors, and optimize it by adjusting prompts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583940
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583940
KW  - Big Five Personality
KW  - Chatbot
KW  - Coherence
KW  - Dialogue System
KW  - Partial Least Squares Structural Equation Modeling
KW  - User Experience
ER  - 

TY  - CONF
TI  - LongSAL: A Longitudinal Search as Learning Study with University Students
AU  - Bhattacharya, Nilavra
T3  - CHI EA '23
AB  - Learning, or addressing a gap in one’s knowledge, is an important motivator behind information-seeking activities. The Search as Learning research community advocates for transforming information search systems into educational platforms to support learning and sensemaking. Current search systems have yet to adapt to this function. One crucial step is identifying behavioural patterns that distinguish individuals who gain more knowledge from those who gain less. Previous research has mainly focused on short-term, laboratory-based studies of human-information interaction, which researchers believe is insufficient for understanding the prolonged process of learning. In response, we conducted LongSAL, an exploratory longitudinal study examining the long-term information searching behaviour of university students over a semester. Our preliminary results indicate that participants with higher levels of metacognition and self-regulation exhibit greater efficiency in their searching as learning process. Specifically, they visit fewer webpages, and spend less time dwelling on them, yet receive similar grades compared to participants who spend more time dwelling, and visiting more webpages. These findings will help develop improved search systems that foster learning and sensemaking.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583948
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583948
KW  - hii
KW  - human information behaviour
KW  - iir
KW  - interactive IR experiments
KW  - longitudinal study
KW  - longsal
KW  - remote IR studies
KW  - search as learning
ER  - 

TY  - CONF
TI  - HapticDiveBuddy: Assessing utility of haptic feedback in navigating high turbidity diving environments
AU  - Szyszka, Ewa Anna
T3  - CHI EA '23
AB  - Rescue, cave and police divers find themselves often working in murky, high turbidity environments. Those challenging environments often times are the scenes of rescue missions, key evidence recovery and in case of cave divers scientific discoveries. Work in those environments requires specialized training and despite rigorous safety protocols those environments become risky. Some of the main risks are disorientation, entanglement, injury as a result of collision with an unseen object and running out of gas as a result of prolonged stay underwater in attempt to orientate oneself. Therefore, the main focus of the proposed undergoing research is to prototype an assistive device for underwater navigation and test the suitability of haptic technology to underwater applications. The main contributions of the following project are (1) Proposal of a haptic diving costume technology navigation system for diving application (2) Conducting experiments aiming at assessing the potential strengths and drawbacks of haptic feedback in marine environments.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583939
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583939
KW  - Aquatic navigation
KW  - haptic feedback
KW  - marine signal processing
ER  - 

TY  - CONF
TI  - Exploring Computational Thinking Practices and Gestures in the Context of Matrix Math
AU  - Zaman, Ulia
T3  - CHI EA '23
AB  - Computational thinking (CT) is a unique skill set that can provide advantages not only in the field of computer science (CS) but also in other disciplines. There is potential benefit in incorporating CT practices in other subjects so students from interdisciplinary backgrounds can also gain CT skills and apply them in their respective disciplines. This study takes a look at how students from interdisciplinary backgrounds interact using gestures and use CT to understand matrix math concepts in a group setting. A mixed-methods analysis is used to gain insight into how students’ practice CT. Data collected from pre- and post- assessments measures students’ mastery level in matrix math concepts. Video data collected during the group activity shows students’ learning process. The results of this study provide a better perspective on how other disciplines are able to utilize CT and how CT learning can be implicitly taught in subjects other than CS.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583944
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583944
KW  - computational thinking
KW  - gestures
KW  - interaction
KW  - mathematics
ER  - 

TY  - CONF
TI  - Healthy Talks: Facilitating Collective Speculations and Co-design for Local Content Services
AU  - Sankar, Abirami
T3  - CHI EA '23
AB  - Despite 800 million additional individuals joining the Internet between 2019-2021, a significant digital divide persists. Moreover, monopoly over Internet Infrastructure has led to people having little control over their data. Community Networks (CNs) are an emerging solution providing autonomy and safe spaces in the digital context. While CNs can improve accessibility to the Internet, another critical component is local content, which makes the Internet more relevant for users. This paper explores methods and practices that can be adopted to promote local content production and dissemination. The research/study was conducted with the local front-line health workers (Health Navigators/HNs), the primary content creators of the COWHKI initiative. The Co-design and Speculative design activities reveal insights about the challenges and experiences of the HNs in engaging with content and technology. These insights have been translated into recommendations for Papad, the digital interface used for creating and curating content in the COWHKI initiative.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583949
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583949
KW  - Co-design
KW  - Community Networks
KW  - Democratisation of the Internet
KW  - Digital Divide
KW  - Local Content
KW  - Speculative design
ER  - 

TY  - CONF
TI  - Contrasting Technologists’ and Activists’ Positions on Signing Avatars
AU  - Angelini, Robin
T3  - CHI EA '23
AB  - The research and development of signing avatars has become widely publicised with the promise to provide novel, efficient and accessible solutions to existing access issues deaf people face in their everyday lives. However, the deaf community is often lukewarm in their enthusiasm for signing avatars. There are deep structural issues present in this technology due to the systematic underestimation of the complexity entailed in sign languages, but also the quality of solutions and lack of direct participation of deaf communities. In my research, I explore the particular interrelationship between the deaf community and technical stakeholders regarding signing avatar technologies to analyse the gaps between community positions and technical realisation – particularly from a Human-Computer Interaction (HCI) perspective. My results indicate that signing avatar require more nuanced conceptualisations to properly identify adequate contexts for implementation and use that are acceptable to and accepted by the deaf community.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583946
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583946
KW  - Accessibility Technology
KW  - Signing Avatars
KW  - User-Centered Design
ER  - 

TY  - CONF
TI  - Building a Participatory Data Design Approach to Examine Gender Bias in English-Twi Machine Translation
AU  - Oppong, Abigail
T3  - CHI EA '23
AB  - This project attempts to build a data-design approach to examine the detection and mitigation of gender bias in an English– Twi machine translation. This project makes use of an open-source data English-Akuapem Twi parallel corpus. Training the dataset on a sequence-to sequence model reveals a stereotypical bias in the machine translation system associated with a high-status profession like 'engineering.' The quality of translation for sentences associated with 'he' is higher than 'she.' Hence, a proposed data design approach is made to help examine bias in the dataset. The quality of the translation of sentences associated with either 'he’ or 'she’ improved and got either identical bleu scores or just a little difference in the bleu scores.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583942
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583942
ER  - 

TY  - CONF
TI  - CoCo: Compost Companion: Design and Evaluation of a Wearable Pet That Supports Composting Habits Towards an Interaction Design for Empathy
AU  - Jung, Debbie
T3  - CHI EA '23
AB  - Food waste is a major source of greenhouse gases and contributes significantly to climate change. Compost Companion, or CoCo, is a wearable anthropomorphic device that uses a GPS system to track composting locations on a college campus to make reducing food waste easy for students. CoCo provides informational feedback on the amount of food that a user has composted or wasted, as well as emotional feedback through the wagging of its tail based on how well the user has been composting. Information including composting locations and amount of food discarded are displayed through an OLED screen, and tail wagging is operated by a Servo motor. CoCo was designed over several iterations based on feedback received from users through surveys, interviews and observations, as well as from subject matter experts through the Delphi method. Overall, findings suggest that CoCo is usable and creates enjoyable composting experiences for users through empathy.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583945
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583945
KW  - Anthropomorphic wearable device
KW  - climate change awareness wearable
KW  - compost pet
KW  - composting habit wearable
ER  - 

TY  - CONF
TI  - Anonymous Online Support: Investigations of Identity and Heterogeneous Groups in Online Recovery Support
AU  - Zent, Matthew
T3  - CHI EA '23
AB  - How does anonymity impact perceptions of the effectiveness of support in online recovery communities? Prior work has shown how the multifaceted concept of identity plays an important role in support seeking, but its effects with respect to support providers are still unclear. I ground my investigation of interpretations of 12-Step anonymity in online recovery to demonstrate the effects of different facets of anonymity and 12-Step values on perceptions of supportive interactions using a controlled online experiment. I present a novel transposition of person-centered support and demonstrate its utility outside of dyadic interactions. Finally, I discuss implications for the design of mixed online health communities and implications for future emotional support and anonymity research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583947
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583947
KW  - Anonymity
KW  - online health community
KW  - peer support
KW  - recovery
KW  - verbal person-centeredness
ER  - 

TY  - CONF
TI  - Animated Patterns: Applying Dynamic Patterns to Vector Illustrations
AU  - Yang, Joshua Kong
T3  - CHI EA '23
AB  - Vector illustrations are object-based, comprised of strokes and shapes typically filled with flat and gradient colors. For the artist, this lends a lack of control over pixel-scale details, like shading and texture. These shortcomings have contributed to the rise of flat, geometric art styles which have become synonymous with vector graphics. We propose the use of animated patterns to give artists greater expression and streamline the creation of new visual results in vector illustration. By examining the interactions that occur when artists draw and customize these dynamic patterns, we discover design considerations for future vector illustration systems that may facilitate the creative authoring of such visuals.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583941
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583941
KW  - animation
KW  - kinetic textures
KW  - patterns
KW  - SVG
KW  - vector illustration
ER  - 

TY  - CONF
TI  - A Case Study on Scaffolding Exploratory Data Analysis for AI Pair Programmers
AU  - Zhou, Haoquan
AU  - Li, Jingbo
T3  - CHI EA '23
AB  - Recent advances in automatic code generation have made tools like GitHub Copilot attractive for programmers, as they allow for the creation of code blocks by simply providing descriptive prompts to the AI. While researchers have studied the performance of these AI-based tools in general-purpose programming, their effectiveness in data analysis is understudied. Unlike general-purpose programming which focuses more on algorithm-driven tasks like building novel software, data analysis requires a data-driven approach to actually gain insights. It remains unclear how these tools could be utilized to help data scientists analyze real-world problems. In this paper, we conducted a qualitative user study with 5 participants to understand the use of GitHub Copilot in solving problems by scaffolding prompts at different levels of specificity among data scientists. We discovered that effective prompts require carefully selected terminology, properly arranged word order, and sufficiently established interaction between humans and GitHub Copilot. We also spot some potential flaws in GitHub Copilot that hinder data scientists from efficiently scaffolding prompts. Our work points out some improvement directions for both data scientists and GitHub Copilot in the future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583943
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583943
KW  - AI pair programmer
KW  - exploratory data analysis
KW  - GitHub Copilot
KW  - large language model
ER  - 

TY  - CONF
TI  - Transparent Practices for Quantitative Empirical Research
AU  - Wacharamanotham, Chat
AU  - Yang, Fumeng
AU  - Pu, Xiaoying
AU  - Sarma, Abhraneel
T3  - CHI EA '23
AB  - Transparent research practices enable the research design, materials, analytic methods, and data to be thoroughly evaluated and potentially reproduced. The HCI community has recognized research transparency as one quality aspect of paper submission and review since CHI 2021. This course presents current best practices and tools that increase research transparency for HCI researchers and students. The course will be three online lectures and one in-person lab session. The lectures will cover the most relevant concepts, guidelines, and practices in Open Science, frequentist statistics, Bayesian statistics, and uncertainty visualization. In the lab session, the course participants will interactively explore implications of analytical choices using RStudio in pairs or small group and receive tailored feedback from instructors. For any participants cannot come to Hamburg, we will provide a parallel online session.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574168
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574168
KW  - Bayesian statistics
KW  - open science
KW  - transparent statistics
KW  - uncertainty visualization
ER  - 

TY  - CONF
TI  - The unwritten manual of becoming a professor of HCI
AU  - Michahelles, Florian
AU  - Boll, Susanne
AU  - Siek, Katie A.
AU  - Salim, Flora D.
AU  - Quigley, Aaron J
T3  - CHI EA '23
AB  - This course is about preparing researchers for a permanent career in academia. Based on personal practice the course organizers will describe the settings, roles, procedures, and motivations of search and appointment committees. Furthermore, the course will cover strategies for preparing a successful lecture talk, scientific talk, and plans and vision talk. Finally, this course will discuss the do’s and don’t for the interview on leadership and social competencies. A dedicated module on training pitches will enable participants to practice concepts on-site and provide peer review among each other. The organizers will provide a safe space for sharing following the Chatham house rules.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574192
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574192
KW  - career
KW  - hci
KW  - professpr
ER  - 

TY  - CONF
TI  - User Experience Design and Research in Games
AU  - Nacke, Lennart E.
AU  - Mirza-Babaei, Pejman
AU  - Drachen, Anders
T3  - CHI EA '23
AB  - This online course trains how user experience (UX) methods are used in a game context. The course consists of three units: UX design for games, games user research, and game analytics. The course material comes from the "Games User Research" book published by Oxford University Press, and the book’s editors will teach it. This course focuses on UX design and research for game development. Students will learn the skills they need to recognize, analyze, and understand player feedback so they can make valid decisions about how to design games. Through exercises and assignments, participants will learn how to identify factors that affect how a player plays a game and how to incorporate feedback into their design process. Participants will learn ways to get information from players, such as through direct observation, interviews, and surveys. Participants will be equipped with skills, knowledge, and tools to understand players to create engaging games.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574181
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574181
KW  - Game Analytics
KW  - Game Design
KW  - Games User Research
KW  - UX Design
KW  - UX for Games
ER  - 

TY  - CONF
TI  - The UCD Sprint: A Process for User-Centered Innovation
AU  - Larusdottir, Marta Kristin
AU  - Roto, Virpi
AU  - Lanzilotti, Rosa
AU  - Visescu, Ioana
T3  - CHI EA '23
AB  - Exploring innovative ideas for interactive software has its challenges. A new process called the User-Centred Design (UCD) Sprint process has been suggested to support teams in exploring users’ needs and the future usage of the software with the active involvement of users. Research study results show great benefits for the sprint participants. The course introduces the UCD Sprint process, and participants practices two steps from the UCD Sprint: the user group analysis and stating user experience goals. This in-person course appeals to researchers and developers interested in exploring their innovative ideas through a user-centered step-by-step process.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574176
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574176
ER  - 

TY  - CONF
TI  - The Joy of Sketch: A Hands-on Introductory Course on Sketching in HCI and UX within Research, Practice, and Education
AU  - Lewis, Makayla
AU  - Sturdee, Miriam
T3  - CHI EA '23
AB  - Sketching is a powerful tool for communication, expression, and interrogation – and yet it is also a joyful method that connects people and makes research and education more engaging. Whether hands-on with pen and paper or on a tablet, the manual action of creating an image to tell the story of research is a valuable addition to any student or professional’s skill set in Human-Computer Interaction and User Experience Design. We will take you on a complete journey in sketching, from the basics of mark-making right through to objects, interfaces, and interactions with people.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574187
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574187
KW  - comics
KW  - drawing
KW  - sketching
KW  - storyboards
KW  - UX
ER  - 

TY  - CONF
TI  - DOIT: The Design of Interactive Things. Selected methods for quickly and effectively designing interactive systems from the user’s perspective
AU  - Mackay, Wendy E.
T3  - CHI EA '23
AB  - The Design of Interactive Things teaches participants how to quickly and effectively design innovative interactive systems from the user’s perspective. Intended for both UX designers and HCI researchers, the course provides a coherent overview of the interaction design process, with detailed descriptions of four key design methods: story interviews, video brainstorming, video prototyping, and generative walkthroughs. Participants will apply these methods to design a novel interactive system, using materials and tools provided in the course. Each method has been tested in both industry and research settings, and is especially appropriate for participatory co-design with users.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574172
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574172
KW  - Co-Design
KW  - Participatory Design
KW  - User Experience Design
KW  - User-Centered Design
ER  - 

TY  - CONF
TI  - The Algorithmic Transparency Playbook: A Stakeholder-first Approach to Creating Transparency for Your Organization’s Algorithms
AU  - Bell, Andrew
AU  - Nov, Oded
AU  - Stoyanovich, Julia
T3  - CHI EA '23
AB  - Welcome to 2033, the year when AI, while not yet sentient, can finally be considered responsible. Only systems that work well, improve efficiency, are fair, law abiding, and transparent are in use today. It’s AI nirvana. You ask yourself: “How did we get here?” You may have played a major role! As more organizations use algorithmic systems, there is a need for practitioners, industry leaders, managers, and executives to take part in making AI responsible. In this course, we provide for influencing positive change and implementing algorithmic transparency into your organization’s algorithmic systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574169
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574169
KW  - algorithmic transparency
KW  - course
KW  - fundamentals of HCI
KW  - responsible AI
ER  - 

TY  - CONF
TI  - Structural Equation Modeling in HCI Research using SEMinR
AU  - Calero Valdez, André
AU  - Kojan, Lilian
AU  - Danks, Nicholas Patrick
AU  - Ray, Soumya
T3  - CHI EA '23
AB  - Structural equation models (SEMs) are statistical techniques that help to identify models of latent variables in survey data. This allows researchers to test both the quality of the measurement instrument—the survey—as well as the hypothesized relationships using a single model. Partial least squares structural equation modeling (PLS-SEM) is a subset of SEM that works well with small sample sizes and non-parametric data, which frequently occur in HCI research. In this course, we will provide a short introduction into SEMinR, an open-source library for the R language. SEMinR is an easy-to-use domain-specific language for defining, estimating, visualizing, and validating SEMs using the PLS method. SEMinR provides means for scientific reporting and can be used by academics and practitioners alike.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574171
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574171
KW  - causal analysis
KW  - data analysis
KW  - psychometric methods
KW  - SEMinR
KW  - SmartPLS
KW  - statistical methods
KW  - structural equation modeling
KW  - survey methods
ER  - 

TY  - CONF
TI  - Respecting, Facilitating and Recognising Children's Contributions in HCI: Course Submission
AU  - Read, Janet
AU  - Horton, Matthew
T3  - CHI EA '23
AB  - Child Computer Interaction is concerned with the research, design, and evaluation of interactive technologies for children. Working with children in HCI is rewarding and fun but managing that work so that children are kept comfortable and can participate in meaningful ways is not always easy. This course is based on over 20 years’ experience of working with children in research, design, and evaluation. It will provide attendees with practical tips to organise sessions with children, with signposts to methods for research, design, and evaluation, and will specifically consider the ethics of children's participation with checklists to support us in doing our most ethical work possible.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574167
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574167
KW  - Child Computer Interaction
KW  - Children
KW  - Design
KW  - Ethics
KW  - Evaluation
KW  - Research
KW  - UX research
ER  - 

TY  - CONF
TI  - Statistics for HCI
AU  - Dix, Alan
T3  - CHI EA '23
AB  - Many researchers and practitioners find statistics confusing. This course aims to give attendees an understanding of the meaning of the various statistics they see in papers or need to use in their own work. The course builds on the instructor’s previous tutorials and master classes including at CHI 2022, and on his recently book “Statistics for HCI: Making Sense of Quantitative Data”. The course will focus especially on material you will not find in a conventional textbook or statistics course including aspects of statistical ‘craft’ skill, and offer attendees an introduction to some of the instructor’s extensive online material.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574185
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574185
KW  - Bayesian statistics
KW  - evaluation
KW  - human–computer interaction
KW  - hypothesis testing
KW  - statistical crisis
KW  - Statistics
ER  - 

TY  - CONF
TI  - Making the Web Accessible to the Aging Population
AU  - Vaidya, Manasi Atul
AU  - Lee, Sheng-Hung
T3  - CHI EA '23
AB  - There is evidence that nearly half of the children born in industrialized economies will live beyond 100 years old. While aging populations are not occurring at the same pace in every nation, nearly all nations are experiencing longer lifespans. There will be one in five people in Africa, Asia, and South America over the age of 60 by 2050. Globally, there may be more adults over 60 than children under 15 by 2047. [1] Among the most marginalized groups, older adults are the fastest growing. Each of us will be a member of this group someday. Participants will be provided with objects that simulate visual impairments and arthritis. These aim to generate empathy to understand how older adults may experience the same websites and interactions differently due to their physical limitations, and will also explore ways in which the current interactions can be made better keeping this population in mind. Do we believe that when we are over the age of 70, we will be able to book a cab and buy groceries online with the same ease as we do today? Do we think older adults are comfortable using technology they are expected to use to perform tasks necessary to function in today’s world? Have you ever wondered why older adults need to click on a touchscreen multiple times in order to successfully complete a task? This course will equip you with the tools you need to empathize with the pain points older adults have while navigating the web as well as brainstorm and apply techniques that can make their experience better.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574194
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574194
KW  - Accessibility
KW  - Aging
KW  - Computer Science
KW  - Gerontology
KW  - Interaction Design
ER  - 

TY  - CONF
TI  - Introduction to Statistics for HCI Using Jamovi: A course for HCI practitioners and researchers on inferential statistics and Jamovi, an open-source statistics software, comparable to IBM SPSS
AU  - Breuninger, Jurek
T3  - CHI EA '23
AB  - When developing and improving products in a human-centered way or testing a hypothesis in your HCI research, you will very likely want to collect some quantitative data like user satisfaction or user performance and make sense of it. Is your design faster than the competitor? Does this new technology really lead to fewer errors?But alas, testing hypotheses... don't you need to understand statistics for that? And isn't statistics just boring mathematics, but harder?Do you want to learn how to do basic statistical tests on HCI-related data with a free open-source tool and have little to no affection for math? Then this course is for you!
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574164
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574164
KW  - Inferential Statistics
KW  - Statistics Software
KW  - Usability Testing
KW  - User Testing
ER  - 

TY  - CONF
TI  - CHI Course: Introduction to HCI
AU  - Hornbæk, Kasper
AU  - Kristensson, Per Ola
AU  - Oulasvirta, Antti
T3  - CHI EA '23
AB  - This course introduces the field of human-computer interaction (HCI). In the first unit, we present the characteristics of the field, discussing concepts and goals that distinguish it from other fields. In the second unit, we illustrate how to understand people, conduct user research, describe interaction, distinguish types of user interface, and design, engineer, and evaluate interactive systems. The course is based on an upcoming book (Introduction to Human-Computer Interaction) by the authors.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574189
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574189
KW  - Human-computer interaction
ER  - 

TY  - CONF
TI  - Introduction to Authentication using Behavioral Biometrics
AU  - Liebers, Jonathan
AU  - Gruenefeld, Uwe
AU  - Buschek, Daniel
AU  - Alt, Florian
AU  - Schneegass, Stefan
T3  - CHI EA '23
AB  - The trend of ubiquitous computing goes in parallel with ubiquitous authentication, as users must confirm their identity several times a day on their devices. Passwords are increasingly superseded by biometrics for their inherent drawbacks, and Behavioral Biometrics are particularly promising for increased usability and user experience. This course provides participants with an introduction to the overall topic, covering all phases of creating novel authentication schemes. We introduce important aspects of evaluating Behavioral Biometrics and provide an overview of technical machine-learning techniques in a hands-on session, inviting practitioners and researchers to extend their knowledge of Behavioral Biometrics.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574190
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574190
KW  - authentication
KW  - human-computer interaction
KW  - identification
KW  - machine learning
KW  - usable security
ER  - 

TY  - CONF
TI  - Interaction Design in Digital Games
AU  - Mirza-Babaei, Pejman
AU  - Stahlke, Samantha Nicole
T3  - CHI EA '23
AB  - This course covers user experience-focused approach to game interaction design. Created with the needs of aspiring game designers in mind, it’s course suitable for HCI and games students, educators and researchers looking for a deeper understanding of how players interact with video games and how these interactions impact player experience. With hundreds of universities worldwide offering digital media and game development programs, interactive technology is a fast-growing field of study. This course fills a much-needed gap in the CHI’s games and play community by connecting interaction design to fundamentals of user experience (UX) and general game design, addressing the needs of students and educators.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574178
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574178
KW  - Digital Games
KW  - Interaction Design
KW  - IxD
KW  - UI
KW  - UX
ER  - 

TY  - CONF
TI  - Human-Computer Interaction and AI: What practitioners need to know to design and build effective AI system from a human perspective
AU  - Russell, Daniel
AU  - Liao, Q. Vera
AU  - Kulkarni, Chinmay
AU  - Glassman, Elena L.
AU  - Martelaro, Nikolas
T3  - CHI EA '23
AB  - AI and ML are now essential parts of many systems that are currently being built. What should CHI practitioners know about the possibilities and potential drawbacks of building AI systems? Understanding the human side of AI/ML based systems requires understanding both how the system-side AI works, but also how people think about, understand, and use AI tools and systems. This course will cover what AI components and systems currently exist, how to design and build usable systems with AI components, along with how the mental models of AI/ML tools operate. These models lead to user expectations of how AI systems function, and ultimately, to design guidelines that avoid disappointing end-users by accidentally creating unintelligible AI tools. We'll also cover the ethics of AI, including data collection, algorithmic and data fairness considerations, along with other risks of AI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574170
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574170
KW  - AI fairness
KW  - AI trust
KW  - HAI
KW  - HCI
KW  - human-in-the-loop
KW  - UI design for AI systems
ER  - 

TY  - CONF
TI  - How to Write Better CHI Papers (with LaTeX in Overleaf)
AU  - Nacke, Lennart E.
T3  - CHI EA '23
AB  - Writing and organizing research papers is a valuable skill that can make or break your academic career. This course will help you improve your skills in writing research papers for publication at CHI. In the past five years, my writing course at CHI has introduced you to everything you wanted to know about writing papers. Now, it is time to take your skills even further. This course is now also about how to use LaTeX and Overleaf to format your papers so that they are easy to read and have the most practical impact. It is broken up into four 75-minute online units that will help you structure your paper’s research content and typographic design. The goal of the course is to help you write something that makes a contribution to the field of human-computer interaction and can be understood by other HCI researchers through engaging formatting and concise language.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574179
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574179
KW  - Clarity
KW  - LaTeX
KW  - Research Methods
KW  - Submission Process
KW  - Writing
ER  - 

TY  - CONF
TI  - HCI Research in Sensitive Settings: Lessons Learned from Technology Design and Ethical Challenges in Dementia
AU  - Houben, Maarten
AU  - Lee, Minha
AU  - Foley, Sarah
AU  - Morrissey, Kellie
AU  - Brankaert, Rens
T3  - CHI EA '23
AB  - In this course, we will share concrete guidelines for HCI research in sensitive settings based on our research experience in dementia. We share how these lessons learned apply in sensitive settings regarding how designing for and with people with dementia has general implications for design and computing. First, we will provide real-world insights on designing technologies in sensitive settings by analyzing example cases from academia and industry. Next, we instruct designers and researchers in practical ethical conduct with stakeholders through hands-on exercises, such as facilitating informed consent and modifying common co-design activities for sensitive contexts.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574193
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574193
KW  - Course
KW  - Dementia
KW  - Design
KW  - Ethics
KW  - Sensitive Settings
ER  - 

TY  - CONF
TI  - HCI History and Today’s Opportunities – What We Anticipated, What We Did Not
AU  - Grudin, Jonathan
T3  - CHI EA '23
AB  - In a time of rapidly-changing global digital immersion, what can the past tell us? More than you might think. Not everything remains relevant, but technology still collides with unchanging human nature, challenges still arise in collaborating across disciplines, we still must integrate UX, Design, and AI. We should understand how unanticipated consequences emerged. We often see positive potential but not negative consequences. HCI draws on computer science, human factors, information systems, and information science. Design is integral. We interact with AI. You are on a trajectory into the future. I identify significant elements that you can consider and address.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574188
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574188
KW  - AI
KW  - Design
KW  - Future
KW  - HCI
KW  - History
KW  - Human Factors
KW  - Information Science
KW  - Information Systems
ER  - 

TY  - CONF
TI  - Going Beyond Usability and UX: Adding Dependability, Safety and Security to Interactive Systems and Interactive Technologies
AU  - Palanque, Philippe
T3  - CHI EA '23
AB  - This course takes both a practical and theoretical approach to introduce the principles, methods and tools for including “non-standards” properties inside interactive systems and interaction technologies. The course focusses on safety, dependability and security but encompasses additional contributing factors such as privacy, availability and trustworthiness and relate them to HCI-centric properties such as User Experience and Usability. The course will cover design, implementation and evaluation activities to assess these properties. A special attention will be made on how the properties are competing with one another in terms of knowledge of designers and resources required at development time. To paraphrase Susan Dray: “if it is not usable, it does not work” this course will argue that “if it does not work (i.e. it is not dependable) it is not usable” as well as “if it is not safe, it is not usable”. The concepts in this course will be supported by multiple concrete examples taken from industries including autonomous cars, aircraft cockpits, large command and control systems but also research labs prototypes targeting at deploying technologies in real-life settings.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574186
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574186
ER  - 

TY  - CONF
TI  - Experiential Educational Accessibility Modules
AU  - Moses, Heather
AU  - Thazin, Su Thit
AU  - Malachowsky, Samuel
AU  - Krutz, Daniel
T3  - CHI EA '23
AB  - Our Accessibility Learning Labs both inform participants about how to properly create accessible software, and also demonstrate the need to create accessible software. Five labs are currently available on the topics of: Colorblindness, Hearing, Blindness and Dexterity. Material is available on our website: https://all.rit.eduDue to their self-contained web-based nature and the inclusion of all instructional materials (e.g., &nbsp;slides, quizzes, etc.), the labs enable easy integration into a wide variety of curricula ranging from high schools (9-12) to graduate courses. This session will provide an overview of the labs, and usage instructions and information for adopters.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574180
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574180
KW  - Accessibility Education
KW  - Computing Accessibility
KW  - Computing Education
ER  - 

TY  - CONF
TI  - Experience Data-enabled Design!
AU  - Lovei, Peter
AU  - Noortman, Renee
AU  - Raviselvam, Sujithra
AU  - Funk, Mathias
T3  - CHI EA '23
AB  - During the Experience Data-enabled Design! (DED) course attendees will learn about designing for intelligent ecosystems while using data as a creative material. After a brief introduction of the method, and (industrial) cases the participants will collect their data from the context of the conference using personalized design probes. This course offers a careful balance between hands-on work and DED theory. The learning outcomes focus on topics of (physical) prototyping, (remote) data collection and analysis, using data as a creative material, and designing remote interventions.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574175
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574175
KW  - behavior
KW  - context
KW  - data design
KW  - experience
KW  - prototyping
KW  - situated explorations
ER  - 

TY  - CONF
TI  - Find your way in the UX process jungle: An introduction to UX process models and methods and a practical session on how to find a suitable process for your project
AU  - Niels, Adelka
AU  - Fortmann, Jutta
T3  - CHI EA '23
AB  - Many UX process models have emerged over time. Especially beginners, but also advanced users, often find it difficult to orient themselves and to choose a suitable process for a specific project. In the first part of this course, we will explain different UX process models, their similarities and differences, associated UX methods, and their application areas. In the second part, participants will divide into groups to work out a concrete case study, in which they will decide upon suitable processes and methods for a specific use case. The course is designed to inspire, deepen knowledge, and refine practical skills.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574163
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574163
ER  - 

TY  - CONF
TI  - Empirical Research Methods for Human-Computer Interaction
AU  - Mackenzie, Ian Scott
AU  - Read, Janet
AU  - Horton, Matthew
T3  - CHI EA '23
AB  - Most attendees at CHI conferences will agree that an experiment (user study) is the hallmark of good research in human-computer interaction. But what constitutes an experiment? And how does one go from an experiment to a CHI paper? This course will teach how to pose testable research questions, how to make and measure observations, and how to design and conduct an experiment. Specifically, attendees will participate in a real experiment to gain experience as both an investigator and as a participant. The second session covers the statistical tools typically used to analyze data. Most notably, attendees will learn how to organize experiment results and write a CHI paper.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574165
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574165
KW  - Empirical research
KW  - experiment design
KW  - quantitative methods
KW  - user study
KW  - writing a CHI paper.
ER  - 

TY  - CONF
TI  - Cognitive Modelling: From GOMS to Deep Reinforcement Learning
AU  - Jokinen, Jussi P. P.
AU  - Oulasvirta, Antti
AU  - Howes, Andrew
T3  - CHI EA '23
AB  - This course introduces computational cognitive modeling for researchers and practitioners in the field of HCI. Cognitive models use computer programs to model how users perceive, think, and act in human–computer interaction. They offer a powerful approach for understanding interactive tasks and improving user interfaces. This course starts with a review of classic architecture based models such as GOMS and ACT-R. It then rapidly progresses to introducing modern modelling approaches powered by machine learning methods, in particular deep learning, reinforcement learning (RL), and deep RL. The course is built around hands-on Python programming using notebooks.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574173
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574173
KW  - cognitive architectures
KW  - Cognitive modeling
KW  - computational rationality
KW  - cooperative intelligence
KW  - deep learning
KW  - reinforcement learning
KW  - user interface optimization
ER  - 

TY  - CONF
TI  - CHI2023 Course on How to Peer Review for CHI (and Beyond)
AU  - Wilson, Max L
T3  - CHI EA '23
AB  - A key challenge for people that are new to reviewing is pitching the review at the right level, and getting the tone and structure of a review right. This course aims to help participants understand a) the different expectations of different venues and submission types, b) the processes they use to make decisions, and c) good techniques for producing a review for these different circumstances. Combined with developing a good understanding of these different expectations, participants have a chance to critique anonymised but real reviews, and try to guess the venue they are written for and the recommendation they make.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574183
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574183
KW  - Peer Review
KW  - Reviewer
KW  - Reviewing
ER  - 

TY  - CONF
TI  - Ethical Experience Design for the Value of Privacy based on Psychological Needs
AU  - Hoth, Veronica
AU  - Krueger, Anne Elisabeth
AU  - Langner, Moritz
AU  - Brandenburg, Stefan
T3  - CHI EA '23
AB  - Ethical design can avoid collateral damage by anticipating or counteracting possible negative consequences of technology on society, users, environment, among others. In this course, we aim to provide knowledge about psychological needs and values and the ethical implications of experience-centered interaction design. Therefore, the course consists of three interactive sessions. Each session includes briefings on the scientific background and approach, followed by interactive exercises and discussions so that participants can directly apply and deepen their knowledge. The course concludes with a summary of the learnings and a discussion about the applied methods. The results will be documented and subsequently made available to the participants.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574166
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574166
KW  - course
KW  - ethics
KW  - experience design
KW  - fundamentals of HCI
KW  - psychological needs
KW  - values
ER  - 

TY  - CONF
TI  - DIY Ecological Momentary Assessment
AU  - Charitos, Sydney
AU  - Brigden, Amberly
AU  - Bird, Jon
T3  - CHI EA '23
AB  - Ecological Momentary Assessment (EMA) is an increasingly used methodology in HCI which captures an individual’s experiences, typically digitally. The benefits of EMA include: reducing recall bias with ‘in-the-moment’ measurement; improving ecological validity with ‘in-the-context’ measurement and enabling exploration of the dynamic interplay of variables from repeated measurement. This course will teach participants about EMA by providing hands-on practical skill development in how to use off-the-shelf software to develop their own EMA system. At the end of the course, participants will be able to rapidly prototype and run custom EMA studies securely and at scale without the usual associated costs.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574184
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574184
KW  - Ecological Momentary Assessment
KW  - Experience Sampling
KW  - Rapid Prototyping
ER  - 

TY  - CONF
TI  - Create Effective and Responsible AI User Experiences with The Human-AI Experience (HAX) Toolkit
AU  - Vorvoreanu, Mihaela
T3  - CHI EA '23
AB  - The HAX Toolkit (https://aka.ms/haxtoolkit) is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. The Toolkit is grounded in a set of Guidelines for Human-AI Interaction [1] that prescribe how AI systems should behave when interacting with people. Course attendees will explore the nuances of each guideline and learn how to use the AI patterns and examples in the HAX Design Library to apply the Guidelines. Course attendees will also learn how to guide cross-disciplinary teams in planning user-facing AI systems by using the HAX Workbook. For NLP systems, course attendees will learn to use the HAX Playbook [2] to anticipate and design for failures.The HAX Toolkit is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. Course attendees will learn the nuances of the Guidelines for Human-AI Interaction, how to lead cross-disciplinary teams in planning human-AI interaction using the HAX Workbook, and how to use the HAX Workbook to plan for failures of NLP systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574191
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574191
KW  - artificial intelligence
KW  - human-AI interaction
KW  - responsible AI
ER  - 

TY  - CONF
TI  - Bringing a Coaching Mindset to Supervision & Management: Achieving more by doing less
AU  - Fitzpatrick, Geraldine
T3  - CHI EA '23
AB  - Supervision and management is a key part of our work as academics yet we are rarely trained how to play these roles well. Responsibility can weigh heavily to give the right advice and have all the answers. But is this the best approach? This course will offer a set of practical conversational techniques that focus instead on the power of good listening and of asking good questions. Such a coaching mindset to supervision and management is a much more effective approach for helping people develop as independent resourceful academics/researchers. It also means doing less to achieve more.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574162
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574162
ER  - 

TY  - CONF
TI  - Re-articulating North-South Collaborations in HCI
AU  - Talhouk, Reem
AU  - Alabdulqader, Ebtisam
AU  - Kutay, Cat
AU  - Awori, Kagonya
AU  - Wong-Villacres, Marisol
AU  - Kumar, Neha
AU  - Zaman, Tariq
AU  - Wulf, Volker
AU  - Almeraj, Zainab
AU  - Lazem, Shaimaa
T3  - CHI EA '23
AB  - Research connecting the ‘Global South’ and ‘Global North’ is not new to HCI. However, over the last few years we have seen a prominent shift in the ways we understand, represent and engage in North-South collaborations. Central to these discussions is the need to re-frame the nature of collaboration between and across geographies in which power dynamics, coloniality and the handling of differences are at the fore. In this panel, we will discuss experiences of HCI collaboration across the ‘Global South’ and ‘Global North’. The panel will unpack the joys, fluidity and tensions within such collaborations from various geographical perspectives, in an effort to de-homogenize the Global South, and provide ways forward for an HCI flavored re-articulation of collaboration across geo-politically established and epistemic borders.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583752
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583752
KW  - Global Justice
KW  - International collaboration
KW  - Research collaboration
ER  - 

TY  - CONF
TI  - Mental Health and the Metaverse: Ample Opportunities or Alarming Threats for Mental Health in Immersive Worlds?
AU  - Meinlschmidt, Gunther
AU  - Herta, Stefanie
AU  - Germann, Stefan
AU  - Chee Pui Khei, Cliona
AU  - Klöss, Sebastian
AU  - Borrmann, Moritz
T3  - CHI EA '23
AB  - The proportion of the global burden of disease attributable to mental disorders has been continuously increasing since its first recording and is already at a critical level. While responses to the global mental health crisis are urgently required, implementation of countermeasures has so far been inadequate. Due to potential cost-effectiveness and scalability, technological solutions might play an important role in addressing current and projected mental health needs. The various proposed applications of the metaverse might provide unique opportunities in this regard, while also potentially creating additional mental health strain on individuals. In this panel, we will discuss the challenges and opportunities the metaverse might pose for the future of mental health, and the steps we can take now to harness the metaverse for positive change in global mental health – or prevent it from exacerbating already pressing concerns.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583750
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583750
ER  - 

TY  - CONF
TI  - Bridging Cultural Differences with Critical Design in a Globalized World
AU  - Sun, Huatong
T3  - CHI EA '23
AB  - Are simplicity and minimalism the universal standards for interaction design? How can we avoid stereotyping with personas in design practices? What AI algorithms and design mechanism made “digital blackface” phenomenon on social media so popular? This interactive course teaches participants to reconsider some commonly held design beliefs and routine design practices with a lens of cultural differences. Illustrated with design case studies, it introduces strategies and techniques to turn differences into design resources for inclusivity. Participants will learn essential critical design skills of creating engaging and empowering designs in a globalized world at a divisive time.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3574182
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3574182
KW  - bias
KW  - Critical design
KW  - cultural differences
KW  - discursive affordances
ER  - 

TY  - CONF
TI  - Third Wave or Winter? The Past and Future of Smell in HCI
AU  - Brooks, Jas
AU  - Lopes, Pedro
AU  - Obrist, Marianna
AU  - Amores Fernandez, Judith
AU  - Kaye, Jofish
T3  - CHI EA '23
AB  - Over the last hundred years, the integration of scent in technology could roughly be seen as having two public waves, analogous to virtual reality's three or four. These waves include the cinematic technologies of the 1960s and the rise of olfactory desktop peripherals and home fragrance technologies for the internet in the 1990s and early 2000s. In the last few decades, an impressive, multi-disciplinary effort in Human-Computer Interaction has been made to incorporate smell into interactive systems. This panel asks whether exciting recent developments in smell for Human-Computer Interaction mark the cusp of a third wave and whether the field is here to stay or should prepare for another winter.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583749
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583749
KW  - Multi-sensory stimulation
KW  - Olfactory interfaces
KW  - Smell
ER  - 

TY  - CONF
TI  - Making with Data (and Beyond)
AU  - Oehlberg, Lora
AU  - Willett, Wesley
AU  - Huron, Samuel
AU  - Nagel, Till
AU  - Thudt, Alice
AU  - Ijeoma, Ekene
AU  - Offenhuber, Dietmar
AU  - Hornecker, Eva
T3  - CHI EA '23
AB  - In this proposed panel, we will discuss the practice of Making with Data—the practice of creating physical artifacts that represent a dataset. This topic lies at the intersection of several CHI communities: data visualization, fabrication, and tangible interaction. Our goal is to discuss contemporary practices, but also to envision future ways that we might continue to make physical representations of data in the future, given emerging fabrication techniques, data representation practices, and desired interactions and experiences with data.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583748
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583748
KW  - data physicalization
KW  - data sculpture
KW  - design process
KW  - fabrication
KW  - physical data representation
ER  - 

TY  - CONF
TI  - Is it Art, is it HCI? Exploring Tensions Between Practice and Research
AU  - Lewis, Makayla
AU  - Sturdee, Miriam
AU  - Davis, Josh Urban
AU  - Gamboa, Mafalda
AU  - Alaoui, Sarah Fdili
AU  - Ohlenschlager, Claire Elisabeth
AU  - Gaver, William
AU  - Blevis, Eli
AU  - Loke, Lian
T3  - CHI EA '23
AB  - Art has the weight of our history as a people behind it, whilst in comparison, Human-Computer Interaction is relatively young. Artistic practice is a propeller of the innovations within HCI but works in this area often focus on the user study, the interaction, or the need for empirical evaluation. The plurality and tensions in art practice clash with this focus. Arts need not define the beholder as a ’user’, but the addition of interaction and technology challenges its purpose. Aesthetics in isolation is not seen as impactful output, but as we investigate ways to bring art and HCI together, should we not focus on process and influence? This panel brings together a diverse group of artists, designers, practitioners, makers, and researchers, focusing on the challenges and variety of approaches in this space. The aim is to build dialogue to encourage a plurality of practices and creative responses in HCI.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583744
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583744
KW  - Art
KW  - Comics
KW  - Craft
KW  - Dance
KW  - Drawing
KW  - Making
KW  - Painting
KW  - Photography
KW  - Sewing
KW  - Sketching
ER  - 

TY  - CONF
TI  - How can we can create an equitable CHI
AU  - Grady, Siobahn Day
AU  - Bauer, Christine
AU  - Wehbe, Rina
AU  - Spiel, Katta
AU  - Muller, Michael
AU  - Harrington, Christina
T3  - CHI EA '23
AB  - This panel aims to generate conversation toward creating a more equitable CHI. In recognizing our community’s hard work thus far, this panel seeks to engage panelists and participants with thought-provoking questions to garner and promote actionable items for the community. We intend to have an open dialogue on allyship, diversity, equity, and inclusion to achieve a CHI for all.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583746
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583746
KW  - allyship
KW  - diversity
KW  - equality
KW  - equity
KW  - inclusion
ER  - 

TY  - CONF
TI  - Hardware is Hard—is it Worth it?
AU  - Hodges, Steve
AU  - Kristensson, Per Ola
AU  - Hester, Josiah
AU  - Krüger, Antonio
AU  - Mankoff, Jennifer
AU  - Olivier, Patrick
AU  - Rogers, Yvonne
T3  - CHI EA '23
AB  - Within the field of technical human-computer interaction (HCI), there is a community of researchers who innovate in hardware: they build new device form factors, experiment with sensing, actuation and displays, and they deploy and study novel devices. Their work underpins many new and inclusive user experiences. A common perspective is that developing hardware is hard, especially in comparison to purely software-based activities. It typically involves a multitude of disciplines in addition to software, likely relies on third parties such as parts suppliers and manufacturing partners, has inherent delays that stifle agility, and it costs more. Is hardware really ‘harder’ though? And if it is, is innovation in hardware a worthwhile endeavor for the HCI community? This panel will discuss these topics with the aim of giving attendees a deeper understanding of the difficulties and benefits of hardware research in an HCI context.&nbsp;
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583751
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583751
KW  - device innovation
KW  - Hardware research
KW  - interactive devices
KW  - IoT
KW  - ubiquitous computing
ER  - 

TY  - CONF
TI  - Emerging Transdisciplinary Perspectives to Confront Dark Patterns
AU  - Gray, Colin M.
AU  - Chivukula, Shruthi Sai
AU  - Bongard-Blanchy, Kerstin
AU  - Mathur, Arunesh
AU  - Gunawan, Johanna T.
AU  - Schaffner, Brennan
T3  - CHI EA '23
AB  - Technology ethics is increasingly at the forefront of human-computer interaction scholarship, with increasing visibility not only to end users of technology, but also regulators, technology practitioners, and platforms. The notion of “dark patterns” has emerged as one common framing of technology manipulation, describing instances where psychological or perceptual tricks are used to decrease user agency and autonomy. In this panel, we have assembled a group of highly diverse early-career scholars that have built a transdisciplinary approach to scholarship on dark patterns, engaging with a range of socio-technical approaches and perspectives. Panelists will discuss their methodological approaches, key research questions to be considered in this emerging area of scholarship, and necessary connections between and among disciplinary perspectives to engage with the diverse constituencies that frame the creation, use, and impacts of dark patterns.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583745
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583745
KW  - dark patterns
KW  - ethics
KW  - privacy
KW  - transdisciplinarity
ER  - 

TY  - CONF
TI  - Accountability in Algorithmic Systems: From Principles to Practice
AU  - Wilkinson, Daricia
AU  - Crawford, Kate
AU  - Wallach, Hanna
AU  - Raji, Deborah
AU  - Rakova, Bogdana
AU  - Singh, Ranjit
AU  - Strohmayer, Angelika
AU  - Zuckerman, Ethan
T3  - CHI EA '23
AB  - Growing concerns over the societal implications of artificial intelligence has motivated an interdisciplinary push towards mechanisms and tools that hold algorithmic systems accountable. Although there have been considerable strides around defining what it means to hold AI systems accountable, operationalizing those principles have created a barrage of challenges. Researchers, practitioners, and regulators have all raised concerns about the completeness of accountability methods and observed spikes in anxiousness about the potential risk of these tools being manipulated as rubber stamps of approval while harms continue to slip through the cracks. This interactive panel gathers researchers and practitioners with expertise in HCI, Responsible AI, Machine Learning, and Public Policy to critically discuss issues regarding accountability in algorithmic systems to reflect on potential opportunities for re-imagining scalable directions for accountability within these systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583747
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583747
KW  - Accountability
KW  - algorithmic systems
KW  - artificial intelligence
KW  - policy
KW  - responsible AI
ER  - 

TY  - CONF
TI  - Special Interest Group on Creativity and Cultures in Computing
AU  - Kato, Jun
AU  - Frich, Jonas
AU  - Lu, Zhicong
AU  - Jacobs, Jennifer
AU  - Nakakoji, Kumiyo
AU  - Latulipe, Celine
T3  - CHI EA '23
AB  - Research on creativity support tools (CSTs) has a long history in Human-Computer Interaction (HCI); however, researchers often focus on developing novel CSTs and verifying them in a controlled lab setting, rather than on capturing the creative process in the wild. In reality, creative activity is exploratory, laborious, and involves multiple CSTs; which together form a creativity support environment or ecology. Creative activity is also social, cultural, and collaborative with people distributing, modifying, and reacting to the creations of others. This process can inspire subsequent iterations. To understand and support open-ended, culturally embedded, collaborative creativity, HCI researchers are seeking new methods to study the sociocultural aspects of creativity support. This Special Interest Group on Creativity and Cultures in Computing (SIGCCC) invites diverse researchers to provide a forum for CST discussions from a wide sociocultural lens. The participants will identify and discuss the state-of-the-art and conceptualize future directions for creativity support research.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583175
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583175
KW  - creativity support
KW  - interaction design
KW  - psychology
KW  - social science
ER  - 

TY  - CONF
TI  - SketCHI 5.0: Diversity & Accessibility at the core of Sketching in HCI
AU  - Lewis, Makayla
AU  - Sturdee, Miriam
AU  - Hoang, Thuong
AU  - Gamboa, Mafalda
AU  - Jain, Pranjal
T3  - CHI EA '23
AB  - Sketching is a universal tool, one that has been with us from the earliest days of humanity. This freehand technique is visible both in analog and computational form using ‘pencils’ and ‘pens’, although the creation of a sketch requires human consideration and action. It is the act of sketching that we will examine in the context of cross-cultural, diverse, and accessible sketching in HCI, where it is embodied in ideation, design spaces, storytelling, impact, and much more – a sketch can be a section of code, rapid prototyping, algorithmic recognition, digital representation and more. SketCHI 5.0 will bring CHI attendees from around the world together to discuss and co-create thoughts, resources, and exemplars around the topic of Diversity and Accessibility at the core of Sketching in HCI practice.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583182
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583182
KW  - Accessibility
KW  - Diversity
KW  - Drawing
KW  - Sketching
KW  - Visual Thinking
ER  - 

TY  - CONF
TI  - SIG on Data as Human-Centered Design Material
AU  - Gomez Ortega, Alejandra
AU  - Lovei, Peter
AU  - Noortman, Renee
AU  - Toebosch, Romain
AU  - Bowyer, Alex
AU  - Kurze, Albrecht
AU  - Funk, Mathias
AU  - Gould, Sandy J. J.
AU  - Huron, Samuel
AU  - Bourgeois, Jacky
T3  - CHI EA '23
AB  - Behavioral data is ubiquitous in products, services, and systems that people interact with. It is increasingly used by design and HCI researchers and practitioners throughout their human-centered and participatory design processes. The highly dynamic nature of behavioral data makes it deeply intertwined with people, their behavior, and their experiences. Thus, it presents unique opportunities and challenges. This Special Interest Group will provide a space to reflect and discuss effective and responsible ways to engage with behavioral data in human-centered design processes. We will explore questions about the types and scale of data used, the contexts in which data is embedded and applied, the methods we rely on, and the forms of engagement of the multiple stakeholders. In doing so, our goal is to collaboratively develop a research agenda, setting the scope for an annual, international symposium on Data-Centric Design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583180
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583180
KW  - Behavioral Data
KW  - Data-Centric Design
KW  - Human-Centered Design
KW  - Participatory Design
ER  - 

TY  - CONF
TI  - Reflecting on Hybrid Events: Learning from a Year of Hybrid Experiences
AU  - Ansah, Alberta A
AU  - Vivacqua, Adriana S
AU  - Zhong, Sailin
AU  - Boll, Susanne
AU  - Constantinides, Marios
AU  - Verma, Himanshu
AU  - El Ali, Abdallah
AU  - Lushnikova, Alina
AU  - Alavi, Hamed
AU  - Rintel, Sean
AU  - Kun, Andrew L
AU  - Shaer, Orit
AU  - Cox, Anna L
AU  - Gerling, Kathrin
AU  - Muller, Michael
AU  - Rusnak, Vit
AU  - Machado, Leticia Santos
AU  - Kosch, Thomas
AU  - Collective, Chiwork
AU  - Executive Committee, Sigchi
T3  - CHI EA '23
AB  - The COVID-19 pandemic led to a sudden shift to virtual work and events, with the last two years enabling an appropriated and rather simulated togetherness—the hybrid mode. As we return to in-person events, it is important to reflect on not only what we learned about technologies and social justice, but about the types of events we desire, and how to re-design them accordingly. This SIG aims to reflect on hybrid events and their execution: scaling them across sectors, communities, and industries; considering trade-offs when choosing technologies; studying best practices and defining measures of “success” for hybrid events; and finally, identifying and charting the wider social, ethical, and legal implications of hybrid formats. This SIG will consolidate these topics by inviting participants to collaboratively reflect on previous hybrid experiences and what can be learned from them.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583181
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583181
KW  - blended experiences
KW  - hybrid events
KW  - measurement
KW  - remote work
KW  - user experience
ER  - 

TY  - CONF
TI  - More-Than-Human Perspectives and Values in Human-Computer Interaction
AU  - Yoo, Daisy
AU  - Bekker, Tilde
AU  - Dalsgaard, Peter
AU  - Eriksson, Eva
AU  - Fougt, Simon Skov
AU  - Frauenberger, Christopher
AU  - Friedman, Batya
AU  - Giaccardi, Elisa
AU  - Hansen, Anne-Marie
AU  - Light, Ann
AU  - Nilsson, Elisabet M.
AU  - Wakkary, Ron
AU  - Wiberg, Mikael
T3  - CHI EA '23
AB  - In this special interest group (SIG) we invite researchers, practitioners, and educators to share their perspectives and experiences on the expansion of human-centred perspective to more-than-human design orientation in human-computer interaction (HCI). This design for and with more-than-human perspectives and values cover a range of fields and topics, and comes with unique design opportunities and challenges. In this SIG, we propose a forum for exchange of concrete experiences and a range of perspectives, and to facilitate reflective discussions and the identification of possible future paths.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583174
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583174
KW  - HCI
KW  - more-than-human
KW  - values
ER  - 

TY  - CONF
TI  - Human-Centered Responsible Artificial Intelligence: Current & Future Trends
AU  - Tahaei, Mohammad
AU  - Constantinides, Marios
AU  - Quercia, Daniele
AU  - Kennedy, Sean
AU  - Muller, Michael
AU  - Stumpf, Simone
AU  - Liao, Q. Vera
AU  - Baeza-Yates, Ricardo
AU  - Aroyo, Lora
AU  - Holbrook, Jess
AU  - Luger, Ewa
AU  - Madaio, Michael
AU  - Blumenfeld, Ilana Golbin
AU  - De-Arteaga, Maria
AU  - Vitak, Jessica
AU  - Olteanu, Alexandra
T3  - CHI EA '23
AB  - In recent years, the CHI community has seen significant growth in research on Human-Centered Responsible Artificial Intelligence. While different research communities may use different terminology to discuss similar topics, all of this work is ultimately aimed at developing AI that benefits humanity while being grounded in human rights and ethics, and reducing the potential harms of AI. In this special interest group, we aim to bring together researchers from academia and industry interested in these topics to map current and future research trends to advance this important area of research by fostering collaboration and sharing ideas.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583178
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583178
KW  - AI ethics
KW  - human-centered AI
KW  - responsible AI
ER  - 

TY  - CONF
TI  - Going Global: A SIG on the Challenges and Perspectives of Internationalization Within and Across the World of HCI
AU  - Executive Committee, SIGCHI
AU  - Vivacqua, Adriana S.
AU  - Sturm, Christian
AU  - Rivera-Loaiza, Cuauhtémoc
AU  - Gamage, Dilrukshi
AU  - Yafi, Eiad
AU  - Dray, Susan
T3  - CHI EA '23
AB  - As a premier international association for professionals, academics, and students who are interested in Human-Computer Interaction, SIGCHI has always been committed to diversity and inclusion. Over the years, SIGCHI Conferences have provided various venues to discuss matters that promote voices from diverse constituents. With this SIG, we would like to add to this effort, by bringing attention to barriers and opportunities for improvements in geographic inclusion at SIGCHI, and also highlighting efforts that were conducted before and might be adaptade to address ongoing challenges. We will assemble a geographically inclusive group of participants in a roundtable discussion to share their insights based on their lived experiences with geographic inclusion (at SIGCHI and elsewhere), and encourage the audience to engage in discourse with them.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583171
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583171
KW  - global
KW  - globalization
KW  - inclusion
KW  - internationalization
ER  - 

TY  - CONF
TI  - Foundation Models in Healthcare: Opportunities, Risks & Strategies Forward
AU  - Thieme, Anja
AU  - Nori, Aditya
AU  - Ghassemi, Marzyeh
AU  - Bommasani, Rishi
AU  - Andersen, Tariq Osman
AU  - Luger, Ewa
T3  - CHI EA '23
AB  - Foundation models (FMs) are a new paradigm in AI. First pretrained on broad data at immense scale and subsequently adapted to more specific tasks, they achieve high performances and unlock powerful new capabilities to be leveraged in many domains, including healthcare. This SIG will bring together researchers and practitioners within the CHI community interested in such emerging technology and healthcare. Drawing attention to the rapid evolution of these models and proposals for their wide-spread adoption, we aim to demonstrate their strengths whilst simultaneously highlighting deficiencies and limitations that give raise to ethical and societal concerns. In particular, we will invite the community to actively debate how the field of HCI – with its research frameworks and methods – can help address some of these existing challenges and mitigate risks to ensure the safe and ethical use of the end-product; a requirement to realize many of the ambitious visions for how these models can positively transform healthcare delivery. This conversation will benefit from a diversity of voices, critical perspectives, and open debate, which are necessary to bring about the right norms and best practices, and to identify a path forward in devising responsible approaches to future FM design and use in healthcare.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583177
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583177
KW  - ethics
KW  - Foundation models
KW  - healthcare
KW  - interaction design
KW  - responsible AI
KW  - socio-technical systems
ER  - 

TY  - CONF
TI  - Developing Participatory Methods to Consider the Ethics of Emerging Technologies for Children
AU  - Hourcade, Juan Pablo
AU  - Alper, Meryl
AU  - Antle, Alissa N.
AU  - Baykal, Gökçe Elif
AU  - Bonsignore, Elizabeth
AU  - Clegg, Tamara
AU  - Currin, Flannery Hope
AU  - Dindler, Christian
AU  - Eriksson, Eva
AU  - Fails, Jerry Alan
AU  - Garzotto, Franca
AU  - Giannakos, Michail
AU  - Gonzalez, Carina S.
AU  - Iversen, Ole Sejer
AU  - Landoni, Monica
AU  - Medina Medina, Nuria
AU  - Quintana, Chris
AU  - Read, Janet
AU  - Roussou, Maria
AU  - Rubegni, Elisa
AU  - Schmuecker, Summer
AU  - Shahid, Suleman
AU  - Sylla, Cristina Maria
AU  - Walsh, Greg
AU  - Yarosh, Svetlana
AU  - Yip, Jason
T3  - CHI EA '23
AB  - This SIG will provide child-computer interaction researchers and practitioners, as well as other interested CHI attendees, an opportunity to discuss topics related to developing participatory methods to consider the ethics of emerging technologies for children. While the community has extensively debated on ethical issues, we have not had ample discussion of methods to study the ethical implications of emerging technologies. Consequently, we have been largely reactive and have not made significant contributions to public discussions on these topics, leaving these largely to experts from other fields. Our community is well-placed to contribute unique perspectives by leveraging its expertise in participatory methods, combining expert views with those of stakeholders, including children.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583172
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583172
KW  - children
KW  - emerging technologies
KW  - ethics
KW  - extended reality
KW  - participatory methods
ER  - 

TY  - CONF
TI  - Games and Play SIG: Connecting Through Social and Playful Technologies
AU  - Robinson, Raquel B
AU  - Mirza-Babaei, Pejman
AU  - Alvarez, Alberto
AU  - Garreta Domingo, Muriel
AU  - Mandryk, Regan L
AU  - Isbister, Katherine
T3  - CHI EA '23
AB  - Games have always been popular for connecting people, from local single-player and couch co-op, to massively multiplayer online. Throughout the COVID-19 pandemic, remote games that involved and fostered social interactions and connections were a highlight among strategies for staying connected. For this year’s games and play SIG, we come together to discuss the relevant and timely topic of social and playful technologies, and how they can be designed to best foster meaningful social connections over a distance. We bring together attendees from not only the games community, but also those in the broader field of CHI focusing on social and playful technologies.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583176
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583176
KW  - games
KW  - HCI
KW  - play
KW  - playful interactions
KW  - social technology
ER  - 

TY  - CONF
TI  - Dark Patterns and the Emerging Threats of Deceptive Design Practices
AU  - Gray, Colin M.
AU  - Santos, Cristiana Teixeira
AU  - Tong, Nicole
AU  - Mildner, Thomas
AU  - Rossi, Arianna
AU  - Gunawan, Johanna T.
AU  - Sinders, Caroline
T3  - CHI EA '23
AB  - Growth hacking, particularly within the spectre of surveillance capitalism, has led to the widespread use of deceptive, manipulative, and coercive design techniques in the last decade. These challenges exist at the intersection of many different technology professions that are rapidly evolving and “shapeshifting” their design practices to confront emerging regulation. A wide range of scholars have increasingly addressed these challenges through the label “dark patterns,” describing the content of deceptive and coercive design practices, the ubiquity of these patterns in contemporary digital systems, and the impact of emerging regulatory and legislative action on the presence of dark patterns. Building on this convergent and trans-disciplinary research area, the aims of this SIG are to: 1) Provide an opportunity for researchers and practitioners to address methodologies for detecting, characterizing, and regulating dark patterns; 2) Identify opportunities for additional empirical work to characterize and demonstrate harms related to dark patterns; and 3) Aid in convergence among HCI, design, computational, regulatory, and legal perspectives on dark patterns. These goals will enable an internationally-diverse, engaged, and impactful research community to address the threats of dark patterns on digital systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583173
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583173
KW  - dark patterns
KW  - deceptive design
KW  - ethics
KW  - privacy
KW  - regulation
KW  - technology practice
ER  - 

TY  - CONF
TI  - Visualising Forest Sound: Justice-led Ecoacoustic Data Interaction
AU  - Longdon, Joycelyn
T3  - CHI EA '23
AB  - Recent advances in technology and reduction in hardware costs have made the collection of acoustic environmental recordings more accessible, thereby facilitating easier acquisition of biodiversity data for monitoring, research and conservation. Despite these advances, and the growing power of machine learning and automated techniques to process acoustic data, there exists a lack of tools to facilitate accessible visualisation and exploration of long-duration acoustic recordings collected in the field. Additionally, the exclusion of forest communities and traditional beliefs and practices in tropical forest conservation, originating from colonialism and continuing through neocolonial approaches, often results in tension between conservation practitioners, projects, and forest communities. While there has been a proliferation of citizen science projects, tools and applications arising from ecoacoustics research, there is a need to respond to calls, from other citizen science domains, for this work to engage with “citizens" outside the role of ‘data collector’, towards more co-creative citizen science. Through the lens of participatory design, my research attends to both issues by developing alternative methods of data visualisation that enable more accessible analysis and exploration of big ecoacoustics data, while attending to questions of conservation data justice and participation in forest fringe settings.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577039
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577039
KW  - Citizen Science
KW  - Conservation Data Justice
KW  - Ecoacoustics
KW  - t-SNE
ER  - 

TY  - CONF
TI  - A Special Interest Group on Developing Theories of Language Use in Interaction with Conversational User Interfaces
AU  - Peña, Paola Raquel
AU  - Doyle, Philip R
AU  - Ip, Emily Yj
AU  - Di Liberto, Giovanni
AU  - Higgins, Darragh
AU  - Mcdonnell, Rachel
AU  - Branigan, Holly
AU  - Gustafson, Joakim
AU  - Mcmillan, Donald
AU  - Moore, Robert J
AU  - Cowan, Benjamin R.
T3  - CHI EA '23
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3583179
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3583179
KW  - conversational user interfaces
KW  - human-machine dialogue
KW  - psycholinguistic models
KW  - speech agents
ER  - 

TY  - CONF
TI  - Wearable Biofeedback for Knee Joint Health: Improving Haptics for Precision Rehabilitation
AU  - Rokhmanova, Nataliya
T3  - CHI EA '23
AB  - The human body has the tremendous capacity to learn a new way of walking that can reduce the risk of musculoskeletal disease progression. Wearable haptic biofeedback has been used to teach this new gait to patients with knee osteoarthritis, enabling reductions in pain and improvement in function. However, this promising gait retraining therapy is not yet a part of standard clinical practice. Here, I propose a two-pronged approach to improving the design and implementation of biofeedback for gait retraining. The first section concerns prescription, aiming to provide clinicians with a model that predicts the mechanical outcome of gait retraining in order to best guide their treatment decisions. The second section concerns learning, seeking to understand how internal physiological state and external environmental factors influence the process of learning a therapeutic gait. This work aims to address the challenges keeping this intervention from being widely used to maintain pain-free mobility throughout the lifespan.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577063
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577063
KW  - biofeedback
KW  - biomechanics
KW  - knee osteoarthritis
KW  - precision health
ER  - 

TY  - CONF
TI  - Understanding Physical Breakdowns in Virtual Reality
AU  - Tseng, Wen-Jie
T3  - CHI EA '23
AB  - Virtual Reality (VR) moves away from well-controlled laboratory environments into public and personal spaces. As users are visually disconnected from the physical environment, interacting in an uncontrolled space frequently leads to collisions and raises safety concerns. In my thesis, I investigate this phenomenon which I define as the physical breakdown in VR. The goal is to understand the reasons for physical breakdowns, provide solutions, and explore future mechanisms that could perpetuate safety risks. First, I explored the reasons for physical breakdowns by investigating how people interact with the current VR safety mechanism (e.g., Oculus Guardian). Results show one reason for breaking out of the safety boundary is when interacting with large motions (e.g., swinging arms), the user does not have enough time to react although they see the safety boundary. I proposed a solution, FingerMapper, that maps small-scale finger motions onto virtual arms and hands to enable whole-body virtual arm motions in VR to avoid physical breakdowns. To demonstrate future safety risks, I explored the malicious use of perceptual manipulations (e.g., redirection techniques) in VR, which could deliberately create physical breakdowns without users noticing. Results indicate further open challenges about the cognitive process of how users comprehend their physical environment when they are blindfolded in VR.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577064
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577064
KW  - Break-Out
KW  - Physical Breakdown
KW  - Safety Boundary
KW  - Virtual-Physical Perceptual Manipulation
ER  - 

TY  - CONF
TI  - Toward Safer Social Media Platforms
AU  - Franco, Mirko
T3  - CHI EA '23
AB  - Social media and the spreading of mobile devices have provided people with access to unprecedented opportunities anywhere and anytime. Yet, this has raised new challenges for users’ privacy and safety, which become even more complex considering the different cultural values, norms and perceptiveness that people have regarding the correctness and safeness of online behaviours. In this context, this doctoral research project aims to investigate how social media platforms can empower their users, especially the vulnerable ones, and guarantee them a safer experience. In order to answer this question, I will exploit the interdisciplinary approach of the doctoral school and strong international connections, as well as the feedback I will collect from peers and experts by participating in conferences and in this Doctoral Consortium.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577059
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577059
KW  - messaging systems
KW  - online safety
KW  - social media
ER  - 

TY  - CONF
TI  - To Do or Not To Do? Managing Intentions with Technology
AU  - Scott, Ava Elizabeth
T3  - CHI EA '23
AB  - An overarching goal of human-computer interaction is to build technologies that empower users to do what they want to do i.e. to realise their intentions. To achieve high-level goals and values, people have to do certain things and not do other things. Written for the CHI 2023 Doctoral Consortium, this article briefly describes the initial results from two studies which explore how reminders can help people to exhibit and inhibit behaviours, respectively. The first study demonstrates that metacognitive reflection guides reminder setting for everyday intentions. The second study explores how reminders to reflect can empower individuals to use social media more intentionally. These findings are used to inform future directions for research and design.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577046
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577046
KW  - confidence
KW  - ecological methods
KW  - end-user programming
KW  - in-the-wild
KW  - metacognition
KW  - prospective memory
KW  - reflection
KW  - reminders
KW  - social media addiction
ER  - 

TY  - CONF
TI  - The Modern Informed Citizen: Understanding Trade-offs in Digital News Consumption
AU  - Aubin Le Quéré, Marianne
T3  - CHI EA '23
AB  - In local and global contexts, the link between individual news consumption and beneficial or harmful effects is debated. Some communication theories posit that individuals must stay up-to-date with news to make civic choices like voting, volunteering, and participating in community organizing. Nonetheless, there is increasing evidence that overuse or overreliance on news can have harmful effects on mental health and lead to news avoidance. In a contested and polarized news landscape, understanding how individuals can sustain productive, healthy engagement with civic information is vital. In my work, I draw on literature in the communication and journalism fields to understand the impact of shifting media ecosystems on individuals. My studies employ methods from computational social science and human-computer interaction to analyze news content and exposure in more nuanced ways than previously available. I outline my agenda to run experiments to identify risk-benefit trade-offs at the individual level for engaging with evolving technological news systems.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577051
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577051
KW  - communication
KW  - information ecosystems
KW  - journalism
KW  - local news
KW  - news
KW  - trace data
ER  - 

TY  - CONF
TI  - The Human Factors of AI-Empowered Knowledge Sharing
AU  - Kernan Freire, Samuel
T3  - CHI EA '23
AB  - Many industries are facing the challenge of how to capture workers’ knowledge such that it can be shared, in particular tacit knowledge. The operation of complex systems such as a manufacturing line is knowledge-intensive, especially if the operator must frequently reconfigure it for different products. Considering the breadth and dynamic nature of this knowledge, existing solutions for sharing knowledge (e.g., word-of-mouth, issue reports, document creation, and decision support systems) are inefficient and/or resource-intensive. Conversational user interfaces are an efficient way to convey information that mimics the way humans share knowledge; however, we know little about how to design them specifically for this purpose, especially regarding tacit knowledge. In this work, my main goal is to investigate how a cognitive assistant can be designed to facilitate (tacit) knowledge transfer between users of dynamic complex systems. I aim to achieve this by outlining the design requirements, challenges, and opportunities in factories; by collaboratively designing, implementing, and evaluating a cognitive assistant for sharing knowledge; studying the effects of design characteristics on aspects such as user experience; and finally, creating a set of design guidelines.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577044
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577044
KW  - chatbots
KW  - cognitive assistant
KW  - human-centred AI
KW  - industry 5.0
KW  - knowledge sharing
ER  - 

TY  - CONF
TI  - Mixed-Initiative Interaction with Computational Generative Systems
AU  - Lehmann, Florian
T3  - CHI EA '23
AB  - Machine learning models provide functions to transform and generate image and text data. This promises powerful applications but it remains unclear how users can interact with these models. With my research, I focus on designing, implementing, and evaluating functional prototypes for understanding human-AI interactions. Methodologically, I focus on web-based experiments with a mixed-methods approach. Furthermore, I use these prototypes and generative models as a material to understand fundamental concepts in human-AI interactions, such as initiative, intent, and control. In an already conducted study, for example, I showed that the levels of initiative and control afforded by the UI influence perceived authorship when writing text. For the future, I plan to carry out more studies on collaborative writing. With my dissertation, I contribute to how we will build human-AI interactions and how we will collaborate with computational generative systems in future.
C1  - New York, NY, USA
C3  - Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544549.3577061
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
UR  - https://doi.org/10.1145/3544549.3577061
KW  - control
KW  - functional prototypes
KW  - generative systems
KW  - human-ai interaction
KW  - initiative
KW  - intent
KW  - language model
KW  - mixed-initiative
KW  - text generation
KW  - typing
KW  - writing
ER  - 

TY  - CONF
TI  - Evaluating Quality of DIBR-synthesized Views based on Texture and Perceptual Hashing Similarity
AU  - Zheng, Dongsheng
AU  - Zhang, Huan
AU  - Cao, Jiangzhong
AU  - Zhang, Xu
AU  - Yao, Ximei
AU  - Ling, Wing Kuen
T3  - ACAI '22
AB  - Depth-Image-Based Rendering (DIBR) technology is widely used in 3D video systems to synthesize virtual views. However, the DIBR rendering process tends to introduce local and global distortions, especially local geometric distortion, that will severely affect the perception. In addition, traditional 2D quality metrics may fail to handle this issue since only global distortion is considered. Therefore, in order to evaluate the quality of virtual views more accurately, we propose a full reference DIBR-synthesized views quality assessment model that considers both local and global aspects. Local standard deviation texture images of the reference and distorted images are used to detect local distortions due to local distortions in the virtual view result in a large degree of variation in texture information. The intensity similarity and gradient similarity of the texture images are fused to obtain the final local distortion map. The perceptual hash similarity between the reference and the distorted image is used to quantify the global sharpness due to its powerful frequency domain analysis capability. Depending on the experimental results on the IRCCyN/IVC and IETR databases, the performance of our metric is competitive with the state-of-the-art methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579687
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579687
KW  - Full-reference
KW  - local distortion.
KW  - quality of experience (QoE)
ER  - 

TY  - CONF
TI  - A method for accelerating relations search over big data scenario
AU  - Liu, Lihua
AU  - Wang, Mao
AU  - Xiao, Kaiming
AU  - Chen, Haiwen
T3  - ACAI '22
AB  - We propose an acceleration method for relations search over big data scenario. The relations search is in essence an induced subgraph search of graph data model, which is to search all edges with all adjacent vertices falling into a given vertex set. For example, in the risk-control scenario for anti-fraud, for a swindling gang of highly similar fraud behaviors, figuring out all relations between these swindlers can be greatly beneficial to precisely attack all similar gangs. In-memory induced subgraph search requires lots of random accesses, while in big data scenario, relations data tend to be stored on disk when the memory is limited, and the corresponding random lookups over disk incorporate huge overhead. Also, even a singleton disk access could be costly since there are usually many properties data in a relation. Hence, existing methods would suffer considerable performance bottlenecks when applied over data on disk. We build graph over disk-based edge index, and propose multiple BFS (Bread First Search) level gaps based induces subgraph acceleration method, with efficient performance guarantee when the memory is limited. We avoid imbalance in performance for query evaluation with edge index based data organization, with which we further reduce redundant I/O accesses. We filter most invalid no-result edge queries based our BFS level gaps framework. We find that, for each BFS, we can confirm the no edge status between a pair of vertices if their BFS accessing level are of distance more than 1, which indicates the nonexistence of edge. Extensive experiments over real world graph datasets confirm the effectiveness of our method. We find that more than 97% invalid edge queries are filtered by our method, which greatly improve the system performance. Hence, our method with multiple BFS level gap encoding over vertices could greatly filter no-result edge queries and improve the relation search performance. Out method also reduce the redundant I/O access over disk with performance stability guarantee.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579686
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579686
KW  - Big Data
KW  - External-memory Algorithm
KW  - Graph Model
KW  - Induced Subgraph
KW  - Query Acceleration
ER  - 

TY  - CONF
TI  - Research on Ship target recognition based on attention mechanism
AU  - Dong, Tengjiao
T3  - ACAI '22
AB  - Abstract: Marine ship target recognition can effectively identify the categories of sailing ships and realize effective management of ships. It is strategically important for both civil and military domains, but it is highly demanding in terms of accuracy. In this paper, a novel neural network ByCTE(Bayesian Classification Transformer-Encoder) is proposed to realize ship target recognition by using track information. First, the raw data is preprocessed to make the processed data more favorable for model learning. Secondly, four BayesianLinear Encoder(BLE) modules are used to learn the complex relationship between different spatial positions of the sequence, so as to capture the long-term dependence relationship between the input sequences, and further extract the deep features of the sequence. Finally, complete the recognition by attention layer and softmax function. We select the best performing model in the training and use open dataset Automatic Identification System (AIS) data from Europe for training and validating the validity of the proposed model. ByCTE can achieve better accuracy by comparison with other methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579683
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579683
KW  - Feature extraction
KW  - Key words: Neural network
KW  - Ship target recognition
KW  - Track
ER  - 

TY  - CONF
TI  - Matching Long-form Document with Topic Extraction and Aggregation
AU  - Cai, Hua
AU  - Hu, Jingxi
AU  - Ma, Ren
AU  - Lu, Yixiao
AU  - Xu, Qing
T3  - ACAI '22
AB  - BERT-based models have been widely used for document matching, but they generally do not perform well on the matching of long-form documents, as the sequence length limitation could lead to loss of information in the document. Also, the increased noise of a long-form document would further complicate the capture of key matching signals. To tackle these existing problems, we propose a new long-form document matching model, named EA-BERT. In this model, a set of topics are first extracted from the pair of documents. For each topic, we gather related sentences from both documents to form a "bag of sentences", which is then encoded by BERT into a vector containing topic-level information. All topic vectors are then passed to a transformer encoder to aggregate topic-level information into a document-level matching result for the pair of documents. In this way, our approach overcomes the sequence length limitation of BERT-based models, filters out the increased noise of long-form documents, and integrates matching signals from multiple topics. Experiments show that the proposed method outperforms current long-form document matching models on both Chinese and English document-level datasets.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579685
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579685
KW  - datasets
KW  - gaze detection
KW  - neural networks
KW  - text tagging
ER  - 

TY  - CONF
TI  - A New Handwritten Essay Dataset for Automatic Essay Scoring with A New Benchmark
AU  - Hu, Shiyu
AU  - Yang, Qichuan
AU  - Yang, Yibing
T3  - ACAI '22
AB  - The study of algorithms for Automatic Essay Scoring (AES) currently is motivated by textual essay-scoring datasets constructed by anonymous teachers from schools. We propose VisEssay, the first essay-scoring dataset containing handwriting images. VisEssay consists of over 13,000 visual essays originating from 25+ professional in-service teachers whose personal scoring accuracy are recorded by his/her scoring history, together with crowdsourced OCR result per handwriting image. VisEssay differs from the many existing AES datasets because 1) handwriting images are captured from non-native speakers with complementary essay types for existing datasets, 2) teachers scoring these essays are with personal profiles and score accuracy, and 3) corresponding text is checked to keep the consistency. Evaluation of modern algorithms for AES and text classification reveals that the proposed VisEssay is a challenging dataset. In the cause of encouraging a larger community to develop more generalized educational algorithms, we introduce three novel AES systems together with VisEssay and analysis the result as a new benchmark.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579684
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579684
KW  - automatic essay scoring
KW  - image-text dataset
KW  - multi-modual
ER  - 

TY  - CONF
TI  - High-Quality-High-Quantity Semantic Distillation for Incremental Object Detection
AU  - Kang, Mengxue
AU  - Zhang, Jinpeng
AU  - Wang, Xiashuang
AU  - Huang, Xuhui
T3  - ACAI '22
AB  - Model is required to learn from dynamic data stream under incremental object detection task. However, traditional object detection model fails to deal with this scenario. Fine-tuning on new task suffers from a fast performance decay of early learned tasks, which is known as catastrophic forgetting. A promising way to alleviate catastrophic forgetting is knowledge distillation, which includes feature distillation and response distillation. Previous feature distillation methods have not discuss knowledge selection and knowledge transfer at the same time. In this paper, we propose high-level semantic feature distillation and task re-balancing strategy that consider both high-quality knowledge selection and high-quantity knowledge transfer simultaneously. Extensive experiments are conducted on MS COCO benchmarks. The performance of our method exceeds previous SOTA methods under all experimental scenarios. Remarkably, our method reduces the mAP gap toward full-training to 2.58, which is much better than that of the previous SOTA method with a gap of 3.30.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579682
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579682
KW  - catastrophic forgetting
KW  - feature distillation
KW  - Incremental object detection
ER  - 

TY  - CONF
TI  - High-performance ultrasonic beamforming algorithm based on deep learning
AU  - Zhang, Qiong
AU  - Kuang, Yonghai
AU  - Yin, Zhengnan
T3  - ACAI '22
AB  - In this paper, a new deep neural network (DNN) ultrasonic beamformer was proposed to suppress off-axis scattering and improve image quality. The simulated channel signals from cysts and single point targets were decomposed by wavelet, and then the original signals and the features extracted by wavelet transform were combined into the input of DNN. DNN divided the input data into on-axis signals and off-axis signals, and the off-axis signals were suppressed by the network. The performance of DNN beamformer with parallel input of semantic information and ultrasonic signals was analyzed. According to the experimental results, the proposed DNN beamformer can significantly improve the CNR and CR while maintaining the SNRs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579678
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579678
KW  - beamforming
KW  - neural network
KW  - off-axis scattering
KW  - parallel input
KW  - Wavelet decomposition
ER  - 

TY  - CONF
TI  - Electromagnetic Pattern Cluster in Latent Space in Near Filed Scanning of a Device
AU  - Huang, Quan
AU  - Wu, Yuxin
T3  - ACAI '22
AB  - Electromagnetic pattern is an image generated from near field electromagnetic field of a device such as microprogrammed control unit (MCU) when it is working. Many Electro-Magnetic Interference (EMI) sources can be located using the electromagnetic patterns. The cluster of electromagnetic patterns is helpful to distinguish the types of EMI, and problems caused by the same EMI are basicly addressed in the same way. Different frequencies in integrated circuite (IC) can have the same electromagnetic patterns, especially for those frequencies that are multiple integer of a small frequency called the basic frequency. The magnitude of electromagnetic pattern becomes weak when the the corresponding frequency gets higher, which makes the EMI source cluster inaccurate. To tackle this problem, we cluster the electromagnetic patterns in the latent space.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579679
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579679
KW  - cluster
KW  - electromagnetic pattern
KW  - emssion source
ER  - 

TY  - CONF
TI  - Lip Reading Bengali Words
AU  - Rahman, Md. Masudur
AU  - Tanjim, Md Rashad
AU  - Hasan, Saraf Sumaita
AU  - Shaiban, Sayeed Md.
AU  - Khan, Mohammad Ashrafuzzaman
T3  - ACAI '22
AB  - This work aims to lip-read Bengali words from talking faces without using audio. Lip reading for English words and sentences is well explored in literature. However, to our knowledge, we are the first to explore this for Bengali words, a language spoken by about 272 million people in south-east Asia [7]. We used a CNN to extract features from the video frames in sequence and provided the features to a bidirectional LSTM network followed by a classifier. We trained the entire network end-to-end. We investigated the effects of using different types of convolution operations during feature collection. We used convolution with filters of multiple scales in a single stage (Inception [24]), depthwise and pointwise convolution (MobileNet [25]), traditional CNN (VGG16 [26], ResNet [17], DenseNet [27], ResNeXt [28]), and a custom CNN. For Bengali word lip reading, MobileNet [25] (as CNN) followed by a bidirectional LSTM and classifier achieved the highest accuracy of 84.75%. Moreover, we found that longer words have better detection rates than shorter ones using any type of convolution.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579677
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579677
ER  - 

TY  - CONF
TI  - A deep learning based scene text detector combining two strategies
AU  - Jin, Ting
AU  - Zhang, Zhaogong
AU  - Zhang, Zhichao
T3  - ACAI '22
AB  - Detecting scene text has been a challenging task due to the complex geometric layouts of texts. We can broadly classify the state-of-the-art scene text detection methods into two categories. The first category is the top-down methods, which view text as a whole and locate text by regression learning on the points of text bounding boxes or by learning the geometric properties of text, but most algorithms have difficulty in separating neighboring text. The second category is the bottom-up methods, which treat the text as composed of simple local components and obtain text instances by post-processings, but most algorithms rely on accurate segmentation results. In this paper, we propose a method that combines these two types of ideas while avoiding their drawbacks. Specifically, we use a top-down strategy to obtain text contours, and then use a contour scoring module to score the text contours to obtain more accurate results. In addition, we use a bottom-up strategy to obtain kernels and similarity vectors. Subsequently, pixel aggregation is used to combine the results of the two parts to obtain a more flexible representation of the text instances. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579676
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579676
KW  - Clustering
KW  - Contour Regression
KW  - Text Detection
ER  - 

TY  - CONF
TI  - High-quality rainy image generation method for autonomous driving based on few-shot learning
AU  - Shao, Haiyan
AU  - Yang, Jihong
AU  - Chen, Guancheng
AU  - Xie, Yixiang
AU  - Qin, Huabiao
AU  - Huang, Linyi
T3  - ACAI '22
AB  - Rainy image generation aims to transfer images from standard domains such as daytime into rainy domains. Related researches can be divided into unsupervised methods and supervised methods according to use of semantic label constraints. The generalization ability of unsupervised methods is highly related to the domain gap between rain-free images and rain-effect images, which is difficult to keep the layout consistency due to the lack of semantic constraints on the paired data of the target domain. In supervised generative models, the scarcity of paired datasets has a serious impact on the performance of generative results. Moreover, most of the existing rainy paired datasets are synthesized by simply merging and the rain simulated by noise, which can be very different from the images shot in natural condition. So, in order to improve the realism of rainy image generation, we proposed a realistic paired rainy dataset (PRD) in autonomous driving scenes to explore the real rain representations and fusion mechanism with clear images. Besides, aiming at lack of paired samples in autonomous driving scenarios, we are committed to the study of the few-shot learning in generative models. An incremental hybrid training strategy is proposed to make full use of a few datasets. Through extensive experiments, we verify the effectiveness of our proposed method, which achieves more realistic results on limited labeled data. In the future, the dataset can be applied in many other tasks of autonomous driving.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579673
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579673
KW  - Few-shot learning
KW  - Incremental hybrid training strategy
KW  - Rainy image generation
ER  - 

TY  - CONF
TI  - Analyses of Software Data and Their Interpretations: A Framework of Information Granules
AU  - Bakare, Ayomide
AU  - Bugayenko, Yegor
AU  - Kruglov, Artem
AU  - Pedrycz, Witold
AU  - Succi, Giancarlo
T3  - ACAI '22
AB  - Data collected from software applications such as issue management systems or version control systems are abstract and require their thorough and comprehensive analysis. Automated issue generation is an understudied area in automated software development despite its effectiveness, safety, and satisfaction which increases developer productivity. Analysis of software data from automated issue generation provides information which could be used by relevant tools or monitored as any other feature in the development process. In this paper, we systematically apply a suite of methods, including clustering algorithms, cluster validity indexes, and information granularity, to generate explainable prototypes using software data from generated GitHub Issues. Among other approaches of data analytics, we employ the principle of justifiable granularity and a method of optimal information allocation. These methods are applied to two dimensional synthetic Gaussian data to illustrate the performance of the methods. The study provides the experimental results using the methods applied to real industrial data coming from the 0pdd software. The resultant groups provide some insights into structure for organising puzzles with similar characteristics.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579675
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579675
KW  - Cluster Validity
KW  - Clustering
KW  - Information Granules
KW  - Principle of Justifiable Granularity
KW  - Prototypes
KW  - Unsupervised Learning
ER  - 

TY  - CONF
TI  - A Tailored Physics-informed Neural Network Method for Solving Singularly Perturbed Differential Equations
AU  - Pang, Yiwen
AU  - Li, Ye
AU  - Huang, Sheng-Jun
T3  - ACAI '22
AB  - Physics-informed neural networks (PINNs) have recently been demonstrated to be effective for the numerical solution of differential equations, with the advantage of small real labelled data needed. However, the performance of PINN greatly depends on the differential equation. The solution of singularly perturbed differential equations (SPDEs) usually contains a boundary layer, which makes it difficult for PINN to approximate the solution of SPDEs. In this paper, we analyse the reasons for the failure of PINN in solving SPDE and provide a feasible solution by adding prior knowledge of the boundary layer to the neural network. The new method is called the tailored physics-informed neural network (TPINN) since the network is tailored to some particular properties of the problem. Numerical experiments show that our method can effectively improve both the training speed and accuracy of neural networks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579674
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579674
KW  - boundary layer
KW  - physics-informed neural network
KW  - prior knowledge
KW  - singularly perturbed differential equation
ER  - 

TY  - CONF
TI  - Cross-Individual Obstructive Obstructive Apnea Detection in Snoring Signals Using Hybrid Deep Neural Networks
AU  - Lin, Xu
AU  - Lu, Yun
AU  - Li, Heng
AU  - Qian, Yukun
AU  - Zhou, Lianyu
AU  - Wang, Mingjiang
T3  - ACAI '22
AB  - Sleep apnea syndrome (SAS) is a common sleep problem, among which obstructive sleep apnea (OSA) is the most common. It is estimated that 936 million adults aged 30-69 years suffer from mild to severe obstructive sleep apnea that can result in poor sleep quality and even endanger their lives. In our study, 2051 OSA snoring fragments and 2271 normal snoring fragments were collected, and then the two were classified by the hybrid neural network. The most important innovation of this paper is the cross-individual snoring classification, which is different from the previous work, making the model more generalized. The experimental dataset was from 24 patients, the snores of 20 patients were used for the training model, and the snores of 4 people were used for the test. Finally, the accuracy of classification on the test set was 73.75%, and a portable snore classification platform is realized by using an embedded platform and edge computing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579670
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579670
ER  - 

TY  - CONF
TI  - Hybrid Feature Measurement based on Linear and Nonlinear Nonnegative Matrix Factorization
AU  - Ye, Sicong
AU  - Zhao, Yang
AU  - Pei, Jihong
T3  - ACAI '22
AB  - The nonnegative matrix factorization algorithm is an effective data dimensionality reduction method. The principle is to convert the image into a nonnegative linear combination of low dimensional basis images. Nonnegative matrix factorization can be divided into linear algorithm and nonlinear algorithm. Because of different decomposition theory, linear NMF algorithms mainly extract first-order features of data, while nonlinear NMF algorithms mainly extract high-order features. Most of the current studies only focus on one of the models without combining the two together, which leads to the lack of data features. Therefore it is necessary to integrate the two types of algorithms for research. The paper proposes hybrid feature measurement based on linear and nonlinear nonnegative matrix factorization. The algorithm utilizes the idea of feature fusion. The basis image features of the two algorithms are mixed in the model. Finally a feature similarity measurement is obtained as the measure method. The proposed algorithm has good performance on the public datasets and effectively improves the recognition.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579672
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579672
KW  - Basis image
KW  - Hybrid feature measurement
KW  - Nonnegative matrix factorization
ER  - 

TY  - CONF
TI  - Life assessment method of electronic components based on reliability factor sharing model
AU  - Shi, Linlin
AU  - Yang, Peiliang
AU  - Zhou, Bin
AU  - Chen, Si
AU  - Zhou, Zhenwei
AU  - Hong, Danni
T3  - ACAI '22
AB  - An important problem to be solved in reliability simulation of electronic components is to build component-level reliability models based on device-level evaluation results. When the structure or device information and connection composition information of electronic components are obtained, the reliability index information of single point failure can be calculated by device/structure failure model and distribution model. In this paper, a reliability factor sharing model is proposed to evaluate the lifetime of electronic components. For the general case that the components or structures of electronic components are subject to different failure distributions, the non-elementary mapping relationship between device failure distribution and electronic component failure can be established. Furthermore, an efficient and low-complexity method for solving the reliability life of electronic components is constructed by using numerical techniques.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579669
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579669
KW  - electronic components
KW  - life assessment
KW  - reliability
KW  - sharing model
ER  - 

TY  - CONF
TI  - Self-attention mechanism-based SAR for YOLO-v3 maritime ships image target detection
AU  - Li, Xinyu
AU  - Wang, Zhongxun
AU  - Zhang, Mengyu
T3  - ACAI '22
AB  - In recent years, China's maritime construction has been gradually strengthened, and the security of our territorial waters has become a top priority. In this paper, we propose a self-attentive mechanism-based target detection model for YOLO-v3SAR images, and through experiments, we add a self-attentive mechanism before and after the feature fusion part for target detection, and compare the accuracy, we conclude that adding a self-attentive mechanism before each predicted feature layer can effectively improve the detection accuracy. After adding the self-attention mechanism, the detection accuracy of SSDD dataset increases by 10%, Increased from 84.7 to 94.3%, and that of Ship-dataset dataset increases by 9%, from 79% to 88%. The experiments prove that the improved algorithm model is adapted to SAR image target detection and reaches the advanced level, which provides a new idea for SAR image target detection of maritime ships.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579668
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579668
KW  - Deep learning
KW  - SAR images
KW  - Self-attention mechanism
KW  - Target detection
KW  - YOLO-v3
ER  - 

TY  - CONF
TI  - Three-stage Logical Table-to-Text Generation based on Type Control
AU  - Shi, Weiwei
AU  - Liu, Yubo
AU  - Wu, Jie
AU  - Liao, Jianming
T3  - ACAI '22
AB  - Table-to-Text generation is to express the information in the table in words. Considering the simplicity and logic of the statement, the task of logical Table-to-Text generation is derived. Logical Table-to-Text generation is to generate logically faithful and smooth text based on tables. However, there are few studies on this task at present, and the effect of related generative models is not ideal, which makes this task still very challenging. In this paper, we propose a three-stage generative model that conforms to the human thinking of generating logical texts. On the basis of generating surface fact texts from tables, coarse templates are generated first, and then logical texts are generated. At the same time, in order to enhance the rationality of generating texts of different logical types from the same table input, we propose to take the logical type of the reference text as a known premise and input it together with the table and table title to generate texts with higher similarity. Experiments on the LogicNLG dataset show that both ideas have their effectiveness, and the model outperforms the baseline model overall. Combining the two ideas for experiments, the overall effect of the model is better, especially in terms of text similarity.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579667
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579667
KW  - Logic generation
KW  - Logical type
KW  - NLG
KW  - Table-to-Text
KW  - Three-stage generation
ER  - 

TY  - CONF
TI  - Infrared detector fault classification and prediction technology based on sensitive parameter learning
AU  - Shi, Linlin
AU  - Yang, Peiliang
AU  - Yu, Pengfei
AU  - Lai, Canxiong
AU  - Zhou, Zhenwei
AU  - Hong, Danni
T3  - ACAI '22
AB  - Infrared detector is an important device with a wide range of applications. Based on the fault sensitive parameter data of infrared detectors, this paper studies the fault classification and fault prediction model of infrared detectors by using machine learning methods such as neural network BPNN and long and short term memory network LSTM. Through the establishment and verification analysis of the fault classification model, it provides a model reference and basis for the multi-type fault diagnosis of infrared detectors. Through the establishment and analysis of the fault prediction model, it provides a modeling method for the lifetime prediction of infrared detectors. The application of infrared detector fault classification and prediction technology can improve the reliability of infrared detector products.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579665
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579665
KW  - fault classification
KW  - life prediction
KW  - PHM
KW  - reliability technology
ER  - 

TY  - CONF
TI  - Customer Churn Combination Prediction Model Based on Convolutional Neural Network and Gradient Boosting Decision Tree
AU  - Li, Shiyang
AU  - Xia, Guoen
AU  - Zhang, Xianquan
T3  - ACAI '22
AB  - In order to improve the hit ratio of lost customers in telecom industry, a combination prediction model of customer churn based on one-dimensional convolutional neural network(1DCNN) and gradient boosting decision tree(GBDT) is proposed. Firstly, customer data is fed into 1DCNN model, which uses one-dimensional convolution to automatically extract customer features and then predicts customer churn through full connection layer. If the prediction result of 1DCNN model is churn, the result is directly output. If the prediction result is non-churn, the customer data will be re-introduced into GBDT model for second forecast, and the new prediction result will be output. Experiments on two publicly available telecom customer data set show that the proposed combined model significantly improves the recall rate and F1 score of customer churn prediction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579666
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579666
KW  - combination model
KW  - customer churn prediction
KW  - gradient boosting decision tree
KW  - one-dimensional convolutional neural network
ER  - 

TY  - CONF
TI  - Research on the medication regularity of traditional Chinese medicine for common chronic diseases based on association rules
AU  - Wang, Renmin
AU  - Li, Jie
AU  - Wang, Yuanyuan
T3  - ACAI '22
AB  - Chronic diseases are the kind of diseases that cause the most severe disease burden in China and have brought significant challenges to the health of our people. With the increase of its global prevalence, it has become a serious global public health problem. Association rules can be used to mine the high-frequency groups of traditional Chinese medicine treating common chronic diseases and the strong association between them and find valuable information hidden in medical data sets. This study uses the FP-growth algorithm to mine and analyzes the Chinese patent medicine prescriptions for five common chronic diseases. The primary purpose is to use association rule mining technology to mine the hidden patterns in traditional Chinese medicine prescriptions for treating chronic diseases and to provide chronic disease medical personnel and related researchers with the characteristics and laws of traditional Chinese medicine for treating chronic diseases, which has significant theoretical value for further understanding and innovating traditional Chinese medicine treatment methods for chronic diseases.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579664
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579664
KW  - Association rules
KW  - Chronic disease
KW  - FP-growth
KW  - Medication regularity
KW  - Traditional Chinese medicine
ER  - 

TY  - CONF
TI  - A transmission line fault identification method based on long short-term memory network and random matrix principle
AU  - Lin, Xu
AU  - Cai, Xinlei
AU  - Zhu, Jinzhou
AU  - Cui, Yanlin
AU  - Wang, Naixiao
T3  - ACAI '22
AB  - In the past decade, driven by the policy of maximizing the consumption of renewable energy, renewable energy is being integrated into the power grid in the form of centralized power generation or decentralized power generation. The volatility and randomness of renewable energy generation lead to great uncertainty in the power flow of transmission lines, which leads to the increasing diversity of the types and characteristics of transmission line faults. This paper presents an intelligent fault identification method for transmission lines based on long short-term memory network and stochastic matrix principle. Firstly, a method to determine the fault time of transmission lines in stochastic matrix theory is proposed. Secondly, on this basis, a learning and training method of large sample fault random matrix is given. Furthermore, the fault types of transmission lines are further identified based on long short-term memory network. Finally, an actual transmission line is taken as an example to demonstrate the effectiveness of the proposed method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579662
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579662
KW  - Fault
KW  - long short-term memory network
KW  - Random matrix
KW  - Transmission line
ER  - 

TY  - CONF
TI  - A Method for the Optimization of Active Power in AC/DC Hybrid System
AU  - Zhu, Jinzhou
AU  - Cai, Xinlei
AU  - Lin, Xu
AU  - Cui, Yanlin
T3  - ACAI '22
AB  - With the continuous expansion of the scale of wind power, it is necessary to adapt to the change of wind farm output to achieve the consumption of wind power, in order to reduce the total power loss of the entire alternating current (AC) and direct current (DC) system. In this paper, the AC/DC hybrid system with wind farm and flexible DC transmission is studied, and a method for the optimization of active power in AC / DC hybrid system is proposed. By establishing the corresponding active power optimization model of AC / DC hybrid system, the minimum total network loss of AC / DC system is taken as the objective function, and it is constrained to optimize the power transmission efficiency of AC / DC system with flexible DC transmission. Finally, an 18-node AC / DC hybrid system is taken as an example to verify the proposed optimization method. The results show that the proposed optimization method can not only achieve the consumption of wind power, but also improve the economy of AC / DC system operation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579663
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579663
KW  - AC/DC hybrid system
KW  - active power optimization
KW  - VSC-HVDC
KW  - wind farm
ER  - 

TY  - CONF
TI  - Regularization Strength Impact on Neural Network Ensembles
AU  - Njieutcheu Tassi, Cedrique Rovile
AU  - Börner, Anko
AU  - Triebel, Rudolph
T3  - ACAI '22
AB  - In the last decade, several approaches have been proposed for regularizing deeper and wider neural networks (NNs), which is of importance in areas like image classification. It is now common practice to incorporate several regularization approaches in the training procedure of NNs. However, the impact of regularization strength on the properties of an ensemble of NNs remains unclear. For this reason, the study empirically compared the impact of NNs built based on two different regularization strengths (weak regularization (WR) and strong regularization (SR)) on the properties of an ensemble, such as the magnitude of logits, classification accuracy, calibration error, and ability to separate true predictions (TPs) and false predictions (FPs). The comparison was based on results from different experiments conducted on three different models, datasets, and architectures. Experimental results show that the increase in regularization strength 1) reduces the magnitude of logits; 2) can increase or decrease the classification accuracy depending on the dataset and/or architecture; 3) increases the calibration error; and 4) can improve or harm the separability between TPs and FPs depending on the dataset, architecture, model type and/or FP type.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579661
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579661
KW  - Calibration error
KW  - Ensemble
KW  - Mixture of Monte Carlo Dropout (MMCD)
KW  - Monte Carlo Dropout (MCD)
KW  - Quality of uncertainty
KW  - Regularization strength
KW  - Separating true predictions (TPs) and false predictions (FPs)
ER  - 

TY  - CONF
TI  - Prediction of Protein-ATP Binding Sites Based on Word Vector Convolution Model
AU  - Song, Zerui
AU  - Song, Chuyi
AU  - Song, Jiazhi
AU  - Jiang, Jingqing
T3  - ACAI '22
AB  - Recent studies have shown that the interaction between protein and ATP is closely related to human diseases, and the ATP-binding sites in protein sequences have become the focus of drug design. In order to improve the prediction accuracy of Protein-ATP binding sites, in this paper, we propose a prediction method based on word vector convolution neural network. Firstly, we extract five types of features from protein sequences including the position specific scoring matrix, protein secondary structure, solvent accessible surface area, sequence characteristics and residue physicochemical property. Then, the RepeatedEditedNearestNeighbours method is used to clean the data, and the sample imbalance problem is solved by random under-sampling. The under-sampled data is encoded by word vectors. Finally, the improved deep convolution neural network model is trained and compared with the related prediction methods. The experimental results show that our proposed prediction method can predict the Protein-ATP binding sites more precisely.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579660
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579660
KW  - Deep convolutional neural network
KW  - Protein sequence features
KW  - Protein-ATP binding site
KW  - Word vector
ER  - 

TY  - CONF
TI  - A multi branch feature learning approach for fine-grained visual recognition
AU  - Hu, Xin
AU  - Wei, Bing
AU  - Hao, Kuangrong
AU  - Liu, Xiaoyan
AU  - Han, Tao
AU  - Wang, Hengqian
T3  - ACAI '22
AB  - Fine-grained visual classification (FGVC) has always been subjecting to large intra-class variances and fine inter-class variances. How to seek discriminative features as many as possible is key factor for FGVC. Traditional FGVC methods tended to adopt strongly supervised learning with part/bounding box annotations to locate objects region, which design is relatively complicated and training process is not end-to-end. Most existing weakly supervised approaches, based on attention mechanism, usually focus on the most salient feature so that overlook other potential distinguishing features and do not fully utilize multi dimensions information. In this paper, we introduce a three branches framework made up by global branch, which is responsible for extracting whole image's features, cropping branch that focuses on the object region and hidden branch aiming at hiding high response and mining potential distinct features for classification. In addition, we adopt a multi-branch feature learning strategy to reduce the intra-class loss caused by cross-entropy function and further improve the performance of the proposed network. Furthermore, our method only uses image level labels and can be trained in an end-to-end manner. Experiment results on three datasets show that our method can get competitive performance compared with some state-of-the-art methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579658
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579658
KW  - Attention mechanism
KW  - end-to-end
KW  - FGVC
KW  - Multi branch feature learning
ER  - 

TY  - CONF
TI  - An Improving List Scheduling Algorithm Based on Reinforcement Learning and Task Duplication
AU  - Wang, Zhi
AU  - Duan, Hancong
AU  - Cheng, Yamin
T3  - ACAI '22
AB  - Task scheduling plays an important role in query execution, which affects the response time and system throughput of queries. Current database systems use simple heuristic algorithms to determine the order of scheduled tasks and executor allocation. This makes it hard for the scheduler to make full use of the characteristics of the task graph and the state information of executors to optimize the scheduling process dynamically. Especially in heterogeneous environments, it is difficult for heuristic algorithms to generate a better sequence for task execution and balance loads of executors. To address these challenges, we design a DAG scheduler based on graph attention network and reinforcement learning to make scheduling decisions. At first, the scheduler extracts features of each node in the DAG through the graph attention network and utilizes an LSTM module to obtain the high-level representations. Then, the RL agent calculates the probabilities by these representations and selects the node with the maximum probability for each step. Finally, the parameters of the agent will be updated until all the nodes of a DAG have been scheduled. The experimental results based on random DAGs and TPC-H workload reveal that the proposed model can outperform the existing heuristic algorithms by 30% at most on average makespan, which also has significant improvements on TPC-H workload.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579657
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579657
ER  - 

TY  - CONF
TI  - Part-GCNet: Partitioning Graph Convolutional Network for Multi-Label Recognition
AU  - Zhang, Yuan
AU  - Han, Tao
AU  - Wei, Bing
AU  - Hao, Kuangrong
T3  - ACAI '22
AB  - During the rapid development of deep learning, the multi-label recognition task has achieved pretty performance. Recently, the emergence of graph convolution network (GCN) has further improved the accuracy of multi-label recognition. However, in the learning process, how to better represent the feature information of labels and innovatively design structures to obtain good recognition performance is still unclear. To solve these problems, we propose a partitioning graph convolutional network framework for multi-label recognition. First, we segregate the computational graph into multiple sub-graphs. Then, we perform batch normalization operation on each output layer, which can further improve the recognition performance of the network. Finally, extensive experiments are carried out on a multi-label PPT dataset, showing that our proposed solution can greatly improve the feature information utilization of labels and improve the recognition performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579659
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579659
KW  - graph convolutional network (GCN)
KW  - multi-label
KW  - partitioning learning
KW  - sub-graphs
ER  - 

TY  - CONF
TI  - Retrieval Augmented via Execution Guidance in Open-domain Table QA
AU  - Chen, Siqin
AU  - Liu, Yubo
AU  - Wu, Jie
AU  - Hou, Mengshu
T3  - ACAI '22
AB  - The goal of the open-domain table QA task is to answer a question based on retrieving and extracting information from a large corpus of structured tables. Currently, the accuracy of the most popular framework in open-domain QA: the two-stage retrieval, is limited by the table retriever. Inspired by the research on Text-to-SQL, this paper proposes to use execution guidance to enhance the effect of table retrieval. Our contributions are mainly threefold: 1. Proposed using execution-guided method to enhance table retrieval to fully leveraging schema information of tables. 2. Proposed the pure Text-to-SQL task for open domains. We design a two-stage Table QA framework based on semantic parsing to generate logical forms and answers simultaneously. 3. Proposed an open-domain Text-to-SQL dataset: Open-domain WikiSQL. We change the original WikiSQL to become suitable for the Open-domain setting, by removing the approximate tables, decontextualizing the questions, etc. We conducted experiments on the new dataset using BM25 and DPR as the retriever, and HydraNet as the generator of SQL. The results show that the execute-guided significantly improves the table retrieval by 19% (DPR in hit@1) and achieves good performance (accuracy of logical form and execution improves by 12.7% and 13.1%) on end-to-end open-domain Text-to-SQL tasks as well.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579656
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579656
KW  - Execution Guidance
KW  - Open-domain Table QA
KW  - Table Retrieval
KW  - Text-to-SQL
ER  - 

TY  - CONF
TI  - Crowd Counting Using Scale Enhanced Network with Dual Attention Booster
AU  - Zeng, Xin
AU  - Hu, Shizhe
AU  - Guo, Qiang
AU  - Wu, Yunpeng
AU  - Ye, Yangdong
T3  - ACAI '22
AB  - Crowd counting has been a fundamental yet challenging problem in pattern recognition. Most recent deep models for crowd counting rely on Convolutional Neural Networks (CNNs). Although CNN visual features comprise the spatial and channel features, existing deep models on crowd counting have limited descriptive ability as they only focus on the spatial or channel information. In this paper, we propose Scale Enhanced Network with Dual Attention Booster named as SEN-DAB, a novel method to jointly learn the representations of spatial and channel information for crowd counting. Moreover, to further leverage the multi-scale information, a pyramid residual scale enhanced block is presented to process the multi-scale features. As a result, the learned spatial, channel and multi-scale features can be robust to appearance changes of the crowd. Our model is tested on three benchmarks and the experimental results confirm that the promising performance of SEN-DAB when compared with various networks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579654.3579655
PB  - Association for Computing Machinery
SN  - 978-1-4503-9833-6
UR  - https://doi.org/10.1145/3579654.3579655
KW  - attention mechanism
KW  - crowd counting
KW  - density map estimation
KW  - multi-scale features
ER  - 

TY  - CONF
TI  - Point cloud registration method based on deep learning
AU  - Tang, Jialin
AU  - Ma, Chenhao
AU  - Lai, Yunting
AU  - Chen, Jiongjiang
AU  - Liang, Wanxin
AU  - Zhou, Zhuang
AU  - Wang, Tenghui
AU  - Lin, Shounan
T3  - EITCE '22
AB  - Many significant progresses have been made in the field of deep learning. This paper mainly discusses the 3D Match point cloud registration method based on deep learning and its improvement. The method introduced in this article is divided into four steps. The first is to obtain point cloud data. This step uses a bilateral filtering algorithm, which plays a good role in removing noise points from point clouds. The second step is to use 3d match to register key points. This step uses the truncated distance function (TDF) to perform preliminary processing on the point cloud data, and input the Siamese network matching with metric learning to learn the features of the point cloud. The third step eliminates the wrong point pair, this step uses the classic RANSAC algorithm. The fourth step is similarity measurement. The 3D Match network will output a set of 512-dimensional feature vectors, and the spatial dimension is relatively high. Therefore, a cosine similarity that is more suitable for multi-dimensional feature similarity measurement is used to replace the commonly used Euclidean distance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573714
SP  - 1969
EP  - 1972
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573714
ER  - 

TY  - CONF
TI  - Imbalanced Nodes Classification for Graph Neural Networks Based on Valuable Sample Mining
AU  - Liu, Min
AU  - Jin, Siwen
AU  - Jin, Luo
AU  - Wang, Shuohan
AU  - Fang, Yu
AU  - Shi, Yuliang
T3  - EITCE '22
AB  - Node classification is an important task in graph neural networks, but most existing studies assume that samples from different classes are balanced. However, the class imbalance problem is widespread and can seriously affect the model's performance. Reducing the adverse effects of imbalanced datasets on model training is crucial to improve the model's performance. Therefore, a new loss function FD-Loss is reconstructed based on the traditional algorithm-level approach to the imbalance problem. Firstly, we propose sample mismeasurement distance to filter edge-hard samples and simple samples based on the distribution. Then, the weight coefficients are defined based on the mismeasurement distance and used in the loss function weighting term, so that the loss function focuses only on valuable samples. Experiments on several benchmarks demonstrate that our loss function can effectively solve the sample node imbalance problem and improve the classification accuracy by 4% compared to existing methods in the node classification task.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573772
SP  - 1957
EP  - 1962
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573772
KW  - Graph Neural Network
KW  - Imbalanced dataset
KW  - Loss function
KW  - Node classification
ER  - 

TY  - CONF
TI  - Site selection of the rural tourism logistics network based on the evolution game under the heuristic algorithm
AU  - Zhou, Jiang
AU  - Feng, Lan
AU  - Bu, Zhiyong
T3  - EITCE '22
AB  - In order to actively respond to the spirit of the 20th National People's Congress of the Communist Party of China and revitalize rural development, China has set off a upsurge of rural tourism, which is conducive to alleviating the large difference between urban and rural development, and also plays a positive role in the development of traditional villages. However, rural logistics is closely related to rural tourism, which can not only improve the convenience of rural tourism, but also further promote the development of rural tourism. However, at present, the development of rural logistics under the background of rural tourism still has problems to be solved. Taking some traditional villages such as Yongxing County, Chenzhou City, Hunan Province as an example, the construction of its logistics service network is not perfect. Based on this paper according to the Chenzhou yongxing county, the location of the passenger population distribution, using unconstrained optimization, heuristic algorithm, established the mathematical model of logistics service network site selection, using Matlab software to solve the preliminary site conclusion, then use the evolution game to the conclusion, so as to achieve the purpose of more accurate. The significance of this paper is to choose the construction of appropriate tourism logistics outlets to promote the development of rural tourism and maximize the economic benefits, but also to let more tourists and villagers to get faster services.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573558
SP  - 1963
EP  - 1968
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573558
KW  - evolution game
KW  - heuristic algorithm
KW  - Matlab solution
KW  - unconstrained optimization
ER  - 

TY  - CONF
TI  - A Low Complexity Localization Method for Nested Arrays via DFT-MUSIC Algorithm
AU  - Chen, Luo
AU  - Qian, Yang
T3  - EITCE '22
AB  - A low complexity localization method for nested arrays via DFT-MUSIC algorithm is investigated in this study. The array aperture and degree of freedom are extended by using nested array, and the number of received signals is increased. DFT algorithm uses DFT to realize DOA initial estimation, and then carries out accurate DOA estimation. DFT algorithm can process more sources by using the complete degree of freedom of virtual array, and the performance of angle estimation is better than that of spatial smoothing algorithm. Based on the DFT algorithm, the DFT-MUSIC method transforms the global spectral peak search process into local search with the help of the DFT initial estimation process, which greatly reduces the computational complexity of the algorithm. The potential patterns in the data are found by clustering method, and the pseudo points are eliminated to find out the position estimation of the radiation source.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573771
SP  - 1951
EP  - 1956
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573771
KW  - Clustering method
KW  - DFT-MUSIC algorithm
KW  - Low complexity localization
KW  - Nested arrays
ER  - 

TY  - CONF
TI  - An Improved PMF-FFT Acquisition Algorithm Based on Trigonometric Polynomial Interpolation
AU  - Huang, Ran
AU  - Li, Cuiling
AU  - Zhang, Hongyan
AU  - Xie, Qingli
T3  - EITCE '22
AB  - Aiming at the problem of low accuracy of Doppler frequency offset estimation under the low SNR (Signal-to-Noise Ratio) condition of PMF-FFT acquisition algorithm, we propose an improved PMF-FFT acquisition algorithm based on trigonometric polynomial interpolation. Based on the PMF-FFT acquisition algorithm, the improved algorithm uses the differential coherent accumulation algorithm to process the PMF-FFT output results to improve the SNR of the signal, and uses the trigonometric polynomial interpolation algorithm to improve the Doppler frequency shift estimation accuracy. The simulation results show that the improved PMF-FFT acquisition algorithm effectively improve the SNR and accuracy of Doppler frequency offset estimation, without increasing the number of FFT (Fast Fourier Transform) operation points, and is more suitable for low SNR environments, ensuring the effective acquisition of the receiver loop in the low SNR environment, is of great significance to modern satellite communications.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573770
SP  - 1947
EP  - 1950
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573770
KW  - Differential coherent accumulation
KW  - Doppler frequency offset
KW  - Low SNR
KW  - PMF-FFT
KW  - Trigonometric polynomial interpolation
ER  - 

TY  - CONF
TI  - Research on Wine Classification Model Based on Machine Learning
AU  - Zhang, Ying
AU  - Liu, Yang
AU  - Si, Dantong
AU  - Li, Sizuo
AU  - Wang, Jiaqi
AU  - Wang, Yi
T3  - EITCE '22
AB  - Traditional wine quality identification technology, with the shortcomings of slow-processing, failing to scale up and highly specialized, is conducted mainly in manual, instrumental and chemical, so it is important to build a model for rapid wine quality identification. Machine learning, the core technology of artificial intelligence, is now used in various fields. The paper investigates the performance of the wine classification models constructed by each classification algorithm by applying machine learning algorithms to the wine quality identification. It also analyses the impact of dimensionality reduction methods with different features on model performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573769
SP  - 1940
EP  - 1946
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573769
KW  - Machine learning
KW  - Naive Bayes
KW  - Random Forest
KW  - Support vector machine
KW  - Wine quality identification
ER  - 

TY  - CONF
TI  - SA-CNN: Application to text categorization issues using simulated annealing-based convolutional neural network optimization
AU  - Guo, Zihao
AU  - Cao, Yueying
T3  - EITCE '22
AB  - Convolutional neural networks (CNNs) are a representative class of deep learning algorithms including convolutional computation that perform translation invariant classification of input data based on their hierarchical architecture. However, classical convolutional neural network learning methods use the steepest descent algorithm for training, and the learning performance is greatly influenced by the initial weight settings of the convolutional and fully connected layers, requiring re-tuning to achieve better performance under different model structures and data. Combining the strengths of the simulated annealing algorithm in global search, we propose applying it to the hyperparameter search process in order to increase the effectiveness of convolutional neural networks (CNNs). In this paper, we introduce SA-CNN neural networks for text classification tasks based on Text-CNN neural networks and implement the simulated annealing algorithm for hyperparameter search. Experiments demonstrate that we can achieve greater classification accuracy than earlier models with manual tuning, and the improvement in time and space for exploration relative to human tuning is substantial.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573788
SP  - 1932
EP  - 1939
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573788
KW  - Deep Learning
KW  - Self-optimization
KW  - Simulated Annealing Algorithm
KW  - Text Classification
ER  - 

TY  - CONF
TI  - Fast CU Partition Algorithm Based on CNN in Intra Prediction
AU  - Wang, Rong
AU  - Hu, Yan
T3  - EITCE '22
AB  - The latest video coding standard, Versatile Video Coding (VVC) also called H.266, adopts quadtree with nested multitype tree (QTMT) coding block structure and still uses recursive rate-distortion (RD) to find the best intraframe coding unit (CU) partition, which accounts for more than 97% of the coding time. To address this problem, in this paper, we propose a fast CNN-based intraframe CU partition algorithm. The proposed approach, containing the CNN model, is implemented on the VVC official software VTM 14.0. A CU size of 64 × 64 is the input of the CNN, and the common test condition (CTC) sequences are encoded using four QPs 22,27,32,37 in the All-Intra (AI) configuration to verify the proposed method. The results showed that the encoding time was reduced by 42.15% in AI mode at the cost of a 0.85% increase in Bjøntegaard delta bit rate (BD-BR) compared with the official VTM14.0.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573767
SP  - 1926
EP  - 1931
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573767
ER  - 

TY  - CONF
TI  - A Video Synopsis Algorithm Based on Target Detection for Ghosting Optimization: Synopsis Video for Pedestrian Surveillance Video Based on Deep Learning
AU  - Liu, Yue
AU  - Luo, Li
AU  - Hong, WeiBin
AU  - Xin, ZhaoLong
AU  - Chen, Yanwen
AU  - Yu, XiangYang
T3  - EITCE '22
AB  - In recent years, with the development of deep learning and computer vision, pedestrian surveillance video synopsis technology has also become the focus of research in the field of intelligent surveillance analysis. The video synopsis technology compresses the video content and strives to quickly extract the content of interest in the video. In the field of public safety, it has played an irreplaceable role in maintaining social order. Based on the exploration and analysis of existing video synopsis technology algorithms, this paper proposes a video synopsis method based on deep learning target detection to achieve ghosting optimization. The detection and tracking algorithm is used to extract the foreground moving targets in the video, and a background modeling algorithm is designed to establish the background. Considering that the moving speed of the target will cause the targets to chase each other, the target whose moving speed difference between the targets is within a certain threshold is placed in the same or similar time period of the video, it can minimize overlap of goals. Finally the target can be placed merge into the background image. Experiments result shows that this method can effectively condense surveillance video. Compared with the existing method, it has a better compression ratio. Meanwhile, it can completely extract the key information and effectively reduce the overlap between targets.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573765
SP  - 1913
EP  - 1919
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573765
KW  - Background Modeling
KW  - Ghosting Optimization
KW  - Target Detection
KW  - Trajectory Reconstruction
KW  - Video Synopsis
ER  - 

TY  - CONF
TI  - Research on Service Function Chain Deployment Algorithm Based on Proximal Policy Optimization
AU  - Sun, Peng
AU  - Lin, Hai
AU  - Yu, Huailong
AU  - Zhong, You
AU  - Wu, Xiaoping
AU  - Sun, Bing
T3  - EITCE '22
AB  - In the future, business scenarios will become diversified, but it is difficult for the existing network architecture to provide strong support for them. Network function virtualization (NFV) technology decouples network functions from dedicated hardware devices and provides customized services for users in the form of service function chain (SFC). At present, the deployment of SFC has been proved to be a NP-hard problem. Most of the solutions are integer linear programming algorithms, but the process of such algorithms is complex. When the network topology scale becomes larger, the calculation process is very time-consuming, and the results sometimes fall into local optimal solutions, which makes it difficult to achieve the desired effect. In this case, reinforcement learning (RL) algorithms show great advantages, learning strategies through interaction with the environment to maximize rewards or achieve specific goals. Therefore, this paper proposes a SFC deployment algorithm based on proximal policy optimization (PPO) reinforcement learning, which aims at maximizing access rate and minimizing resource consumption. The simulation results show that the proposed algorithm has good convergence and stability, which is more conducive to the actual deployment of the SFC.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573766
SP  - 1920
EP  - 1925
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573766
KW  - Deployment algorithm
KW  - Network function virtualization (NFV)
KW  - Proximal policy optimization (PPO)
KW  - reinforcement learning (RL)
KW  - Service function chain (SFC)
ER  - 

TY  - CONF
TI  - Improved Practical Byzantine Fault Tolerance Algorithm Based on Supply Chain
AU  - Xiao, Yuanyuan
AU  - Zhou, Chuangming
AU  - Yang, Zhou
T3  - EITCE '22
AB  - The combination of blockchain technology and supply chain meets the needs of effective management and transparency of supply chain information, and promotes the development of all walks of life. However, the Practical Byzantine Fault Tolerant algorithm (PBFT) is not suitable for large-scale supply chain due to its poor scalability, arbitrary selection of master nodes and simple grouping. To solve this problem, this paper proposes a Re-PBFT algorithm (Reputation-PBFT, Re-PBFT) based on reputation-value assessment group. Firstly, the reputation value of the node is evaluated according to the historical transaction record of the node. Secondly, the nodes are grouped according to their reputation value, and the nodes with high reputation value are selected as the master nodes to construct a double-layer PBFT algorithm to improve their efficiency in multi-node situation. Finally, the impeachment mechanism is established to optimize the nodes of the consensus group. Experimental results show that Re-PBFT algorithm has higher scalability and reliability than PBFT algorithm, and the efficiency of the algorithm is also improved.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573764
SP  - 1904
EP  - 1912
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573764
KW  - blockchain
KW  - impeachment mechanism
KW  - PBFT
KW  - reputation value
KW  - supply chain
ER  - 

TY  - CONF
TI  - Analysis of The Change of Softmax Value in The Training Process of Neural Network
AU  - Chen, Yuyang
T3  - EITCE '22
AB  - Classification is an essential field in deep learning. Generally, the category corresponding to the maximum value of softmax is mainly used as the prediction result and the softmax value as the prediction probability. However, whether softmax can indeed serve as a prediction probability needs further confirmation. This paper first focuses on the classification of paintings through Convolutional Neural Network. To deal with the imbalanced dataset problem, only those with more than 200 paintings are selected. Besides, class weight is also taken into consideration. Next, data augmentation is applied to enlarge the dataset and add more relevant data. For the modeling and training part, transfer learning is employed to avoid training from scratch on a new dataset and reduce the cost of later training. Techniques such as ‘EarlyStopping’ and ‘ReduceLROnPlateau’ are also used to avoid overfitting. The final prediction accuracy can achieve 99 percent on the training and 87 percent on the validation sets. Furthermore, the paper studies the change of softmax distribution during the training process and the relationship between the average maximum value of softmax and the classification performance of classes. The experiments show that the maximum value of softmax will gradually shift to the corresponding correct label during the training process. Still, there is no correlation between the classification performance and the average maximum value of softmax. Therefore, softmax cannot be used as a probability value for classification.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573763
SP  - 1899
EP  - 1903
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573763
KW  - Convolutional Neural Network
KW  - Image classification
KW  - Softmax
KW  - Transfer learning
ER  - 

TY  - CONF
TI  - Detection on chemical fiber silk detects by deep learning
AU  - Guo, Lei
AU  - Wang, Yang
AU  - Jin, Zhengxuan
AU  - Chen, Chaoxin
AU  - Chen, Jiangyi
AU  - Shen, Peng
T3  - EITCE '22
AB  - There are many surface defects which are difficult to detect manually in the process of chemical fiber silk production. In order to realize the intelligent detection on these defects and improve detection accuracy, an improved Faster RCNN algorithm was proposed. Firstly, the deformable convolution model was added to the backbone feature extraction network to improve the adaptability of the network to different defect features. Secondly, the Feature Pyramid Network was replaced by Recursive Feature Pyramid structure to extract features twice. Finally, the Loss function was improved, and RS Loss function was used to replace the original classification loss function to solve the problem caused by imbalanced sample categories. Experiment result shows that the mAP value calculated by the improved model is 84.7%, which is 4.3% higher than original Faster RCNN model. The improved model can meet the requirements of intelligent detection on chemical fiber silk defects in practical production and processing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573760
SP  - 1882
EP  - 1886
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573760
KW  - Chemical fiber silk
KW  - deformable convolution
KW  - detect detection
KW  - Faster RCNN
KW  - Feature Pyramid Network
KW  - Rank&
KW  - Sort Loss
ER  - 

TY  - CONF
TI  - Research on Range Profile Target Detection Algorithm of Stepped-Frequency Ground Penetrating Radar
AU  - Zhang, Xinxin
AU  - Zhang, Yanbo
AU  - Li, Xiangdong
AU  - Zhao, Xingwen
AU  - Yan, Guang
T3  - EITCE '22
AB  - Stepped-frequency ground penetrating radar (SFGPR) is a non-destructive detection method that transmits continuous waves to the target through the antenna and receives the echo through the antenna after reflection and refraction. After data processing, the position of the underground target and the distribution of the medium inside the target can be determined. Therefore, it is crucial to accurately determine the location of the target. In this paper, after smoothing, threshold setting and target wave peak judgment of the one-dimensional range profile of the SFGPR, a more accurate peak can be detected by using the weighted average method. The algorithm can not only make up for the shortcomings of strict waveform requirements in Gaussian fitting but also be simple to understand and more accurate in peak localization compared with Gaussian fitting peak search.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573759
SP  - 1878
EP  - 1881
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573759
KW  - Gaussian fitting
KW  - peak detection
KW  - range profile
KW  - SFGPR
KW  - weighted average
ER  - 

TY  - CONF
TI  - Application of hybrid particle swarm optimization and genetic algorithm and 5G network slicing technology in intelligent transportation
AU  - Wu, Xiaodie
AU  - Zhu, Na
AU  - Wang, Yukun
T3  - EITCE '22
AB  - In this paper, an scheduling optimization scheme based on particle swarm optimization and genetic hybrid algorithm is designed for the poor performance and low efficiency of the traditional bus scheduling algorithm with the analysis and research of the current technology of bus scheduling system, which has been applied to the intelligent bus system integrating GPS/GIS, sensor technology, wireless communication, computer network and other technologies. In the research of the core technologies of the scheme, the computational mechanism and the merit-seeking characteristics of particle swarm and genetic algorithms are analyzed in depth, the advantages of the two algorithms are complemented, and the computational flow and the optimal timing for the fusion of the hybrid algorithms when searching for the final solution are determined. Finally, a correlation analysis of the hybrid algorithm is conducted, and it is concluded that it is significantly better than the current scheduling scheme with a single algorithm in terms of operational performance and solution efficiency.Additionally, it has integrated the concept of 5G network slicing, where a single network and computing infrastructure is used to deploy customized service slices that meet specific needs, in order to meet the specific service needs of different application scenarios of intelligent transportation systems (ITS).
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573762
SP  - 1893
EP  - 1898
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573762
KW  - 5G network slicing
KW  - Genetic algorithm
KW  - Intelligent transportation Systems
KW  - Particle swarm optimization
ER  - 

TY  - CONF
TI  - Research on Reconstruction Algorithm of Blast Furnace Throat Temperature Field
AU  - Luo, Xiaoyu
AU  - Liu, Piliang
AU  - Cui, Guimei
AU  - Nan, Tongxin
T3  - EITCE '22
AB  - Aiming at the obvious limitations of the traditional blast furnace temperature measurement, such as slow response speed, easy damage, and inconvenient replacement, a non-contact ultrasonic measurement technology is proposed. The energy detector uses classical least squares to reconstruct the temperature field. Due to the problem of missing edge information, Kriging interpolation and radial basis interpolation are used to extrapolate and predict the edge temperature information. The basis interpolation method has a slight advantage. Looking at the number of installations, when 8 ultrasonic transducers are installed, the reconstruction accuracy is ideal, which proves the feasibility of the scheme.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573761
SP  - 1887
EP  - 1892
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573761
KW  - least square method
KW  - MATLAB
KW  - reconstruction of temperature field
KW  - ultrasonic temperature measurement
ER  - 

TY  - CONF
TI  - An End-to-End Visual Odometry System Based On Multi-Branch Convolutional Neural Network
AU  - Wei, Zhiwen
AU  - Wang, Liuhuo
AU  - Pan, Wei
AU  - Chen, Zhenliang
AU  - Li, Zhenqi
T3  - EITCE '22
AB  - Visual odometry (VO) is one of the essential techniques in mobile robots field. An accurate VO system is of great significance for mobile robot simultaneous localization and mapping (SLAM). In this paper, we propose an end-to-end multi-branch convolutional VO system for estimating the ego-motion of the monocular camera. A multi-branch structure of convolutional neural network (CNN) is designed to extract multi-scale and multi-frequency feature maps in image sequences, which is helpful for understanding the content of surroundings especially in a multi-object environment. Meanwhile, a novel adaptive activation function based on funnel ReLU is proposed to adaptively activate network neurons. Experiments on several public datasets demonstrate that the proposed framework provides competitive performance in ego-motion estimation compared with other classical and state-of-the-art learning-based methods in the accuracy and inference-time costs. And compared with purely CNN-based VO methods, the average translational error and rotational error of all the evaluation sequences in KITTI are reduced by 52.1% and 51.1% respectively without extra inference-time costs.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573756
SP  - 1862
EP  - 1866
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573756
ER  - 

TY  - CONF
TI  - Research on Double Threshold Reconstruction Algorithm Based on 1-Bit Compression Sensing
AU  - Yang, Chenlong
AU  - Chen, Lei
AU  - Han, Dongsheng
AU  - Guo, Zihao
T3  - EITCE '22
AB  - Binary Iterative Hard Threshold (BIHT) algorithm is improved by changing the sampling threshold of BIHT and introducing a dual threshold strategy because the threshold limits the reconstruction performance of the algorithm to a certain extent. A BIHT algorithm based on double threshold is proposed to reconstruct the shock wave signal. The 50 psi shock wave signal is used. First, the limit number is sparse, and the sparse signal is quantized by 1 bit using double threshold. The shock wave signal is reconstructed through the set double threshold. The results show that the reconstruction error of shock wave reconstruction signal is about 88.91%, 95.8% and 41.7% respectively compared with the commonly used reconstruction algorithm MSP, FPC and BIHT of 1Bit compressed sensing, which further proves the superiority of the double threshold BIHT algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573758
SP  - 1873
EP  - 1877
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573758
ER  - 

TY  - CONF
TI  - Design and Implementation of Neural Network Accelerated SOC Based on Small RISC-V Processor
AU  - Qin, Dexing
AU  - Bai, Xue
AU  - Wu, Yiliang
AU  - Hu, Yendo
T3  - EITCE '22
AB  - The convolutional neural network runs slowly on the mobile edge devices with limited hardware resources. Based on hummingbird E203 processor and Tiny-Yolo neural network, this paper designs a SOC chip for real-time accelerated recognition of common objects. A neural network acceleration system is constructed based on the Tiny-Yolo algorithm framework. The input and output of the Tiny-Yolo network, the data types of the network weights and the calculation results of the convolution layer and the pooling layer are optimized for the hardware implementation. Finally, the acceleration processing is performed in the form of a coprocessor. At the same time, the corresponding coprocessor instruction set architecture is developed to coordinate the processing tasks between the main processor and the coprocessor. The SOC system is implemented and tested on FPGA.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573757
SP  - 1867
EP  - 1872
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573757
KW  - Coprocessor
KW  - RISC-V
KW  - Tiny-Yolo algorithm
ER  - 

TY  - CONF
TI  - Analysis of Data Parallelism Methods with Deep Neural Network
AU  - Chen, Ming
T3  - EITCE '22
AB  - The deep neural network has significantly contributed to the detection, prediction, and classification aspects. Despite its emerging field, some flaws must be rectified to perform better. A problem with large datasets is that the model cannot be trained and tested rapidly, and the worst-case scenario is to have to wait hours for the result. Consequently, the paper evaluated the performance of two data parallelism methods and compared the situations of a diverse quantity of GPUs to decrease the model's testing time. Upon analyzing the consequences, it is evident that the communication overhead contributed to the low accuracy, even though it took less time to complete. An additional experiment involves increasing the number of times of testing to ensure accuracy and save time.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573755
SP  - 1857
EP  - 1861
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573755
KW  - data parallel
KW  - distributed data parallel
KW  - gradient descent
KW  - PyTorch
ER  - 

TY  - CONF
TI  - Research on Localization Algorithm of Bogie Based on Machine Vision
AU  - Liao, Bo
AU  - Dai, Jie
AU  - Zhang, Aofei
T3  - EITCE '22
AB  - To realize the precise automatic detection of the vehicle bogie by the robot, this paper proposes a method for 3D reconstruction of the local area of the bogie based on machine vision technology. A binocular camera is used to acquire images and reconstruct three-dimensional features; the reconstruction effect was significant and can meet the following shape feature extraction requirements. Finally, location recognition of vehicle bogie and positioning of robotic arm were achieved by 3D point cloud registration algorithm and hand-eye calibration technology, to realize the automatic detection of the framework. Experimental results indicate that the reconstruction resolution of this algorithm is approximately 0.5mm and the reconstruction error is less than 1.5mm. At the same time, the rotation error of the end of the industrial robot manipulator is ±0.25°, and the translation error is about 3mm, which meets the requirements of field applications.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573754
SP  - 1851
EP  - 1856
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573754
ER  - 

TY  - CONF
TI  - Research on the application of artificial intelligence algorithms in drought prediction
AU  - Liu, Mengxi
AU  - Zai, Guangjun
AU  - Wang, Guofu
AU  - Shi, Weiwei
AU  - Zhang, Guanqun
T3  - EITCE '22
AB  - With the aggravation of global warming, drought has caused more and more serious impact on society and national economy, so the accurate prediction of drought is also the most important thing to deal with the frequent drought problem. On the other hand, artificial intelligence technology has shown its advantages in various fields and has a broad application prospects, so it is gradually being used in drought prediction. In this paper, drought prediction algorithms in recent years are reviewed, and existing cases of drought prediction using different arithmetic models for different drought indices are studied. The advantages and disadvantages of different algorithms are compared, the challenges of drought prediction are summarized, and the future of drought prediction is prospected.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573753
SP  - 1845
EP  - 1850
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573753
KW  - Drought forecasting
KW  - Machine learning
KW  - Time series forecasting
ER  - 

TY  - CONF
TI  - Study on Students' emotional concentration in online classroom based on convolutional Neural Network
AU  - Jia, Baoxian
AU  - Cui, Yingying
T3  - EITCE '22
AB  - In view of the lack of supervision methods for students in online education, convolutional neural networks have unique advantages in face recognition. This paper establishes a machine learning sentiment analysis model support vector machine, a deep learning model convolutional neural network, long-term memory and long-term memory. network, bidirectional long-term and short-term memory network, and proposed a new BERT-C-BiLSTM model, using real data sets for model training, and comparing the five established models to verify that the accuracy of the new model has indeed improved. The learning concentration detection system of the online education platform designed based on this algorithm has been tested in simulated scenarios, which can effectively evaluate the students' classroom concentration according to the face detection results, and improve the classroom quality and students' learning effect.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573752
SP  - 1839
EP  - 1844
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573752
KW  - Bert. The image processing
KW  - convolutional neural network
KW  - Deep learning
KW  - Emotion analysis
ER  - 

TY  - CONF
TI  - Heterogeneous Graph Neural Network for Chinese Financial Event Extraction
AU  - Yao, Shunyu
AU  - Hu, Jie
AU  - Sun, Chuxiong
AU  - Gao, Zhiqiao
AU  - Liu, Ning
T3  - EITCE '22
AB  - Financial event extraction aims to detect events from financial announcements and extract corresponding event arguments. This task is challenging because financial announcements are often long text, the arguments of an event are always scattered among different sentences in the document, and multiple events can coexist in the same document. It requires a comprehensive understanding of the document and the ability to aggregate arguments across multiple sentences. Most existing sentence-level event extraction methods only extract event arguments within the sentence range. These methods are not very effective for this task, and it is difficult to handle a large number of financial announcements. To address these issues, we propose a novel heterogeneous graph-based model HGCFEE with six types of edges designed to capture the interactions between sentences and entities using heterogeneous graphs. In-depth experiments and comprehensive analysis demonstrate the superiority of HGCFEE over baseline methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573749
SP  - 1822
EP  - 1827
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573749
KW  - Artificial Intelligence
KW  - Event Extraction
KW  - Natural Language Processing
KW  - Neural Network
ER  - 

TY  - CONF
TI  - A low-complexity time delay estimation algorithm based on spectral factorization in OFDM system
AU  - Su, Jia
AU  - Li, Ming
AU  - Hou, Yanli
T3  - EITCE '22
AB  - When the Root-MUSIC algorithm (Root-Multiple Signal Classification) is used to estimate time delay in the Orthogonal Frequency Division Multiplexing (OFDM) system, there exists computational redundancy because of the required roots being conjugating symmetry. Aiming at this problem, a Root-MUSIC algorithm based on spectral factorization—SF-Root-MUSIC algorithm is proposed. Based on the structural characteristics of Laurent polynomials, the proposed algorithm uses spectral factorization to reduce the order for the root polynomial by half thus reducing the computational complexity. The simulation results show that the proposed algorithm has lower computational complexity while maintaining the same precision, and is more suitable for real-time computing.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573751
SP  - 1833
EP  - 1838
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573751
ER  - 

TY  - CONF
TI  - A Privacy Set Intersection Algorithm Based on Batch Blind Signatures on Lattice∗
AU  - Huang, Xiuju
AU  - Du, Yunfei
AU  - Li, Zichen
T3  - EITCE '22
AB  - As an essential branch of secure multi-party computation, privacy set intersection, which is widely used in federated learning, federated query, and other fields, plays a critical role in privacy computation. This paper proposes a privacy set intersection protocol based on the batch blind signature on lattices. It can directly perform a blind signature on a set to obtain the signatures of elements. In the interaction, one party is the signing party, signing its own private set in general and blindly signing the other party's data. Both parties get the signature of the signer and finally obtain the set intersection by signature verification. Privacy can be protected by the blind signature and hash function. The scheme is resistant to quantum attacks, and only two signatures are required.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573750
SP  - 1828
EP  - 1832
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573750
KW  - batch blind signatures
KW  - privacy set intersection
KW  - secure multi-party computation
ER  - 

TY  - CONF
TI  - Super-Resolution Reconstruction Algorithm Based on Improved Generative Adversarial Network
AU  - Deng, Xiangyu
AU  - Ma, Yao
AU  - Bian, Yangyang
T3  - EITCE '22
AB  - The current super-resolution algorithm for generative adversarial networks (SRGAN) has problems such as an unstable model training process and excessive smoothing of reconstructed images, which can affect the quality of generated images to a large extent. In this paper, based on SRGAN, all BN layers in the generative network are removed, and WGAN is used instead of JS scatter to optimize the discriminate network, This efficiently prevents the phenomenon of gradient disappearance and resolves the issue of unstable training of generative adversarial networks. The SA module is added to the vgg19 feature extraction network to obtain better feature information and improve the quality of the generated images. The experiments show that the proposed method has better stability in the training process compared with the traditional SRGAN on the DIV2K datasets, improvements are made to the reconstructed images' peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and visual effect performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573748
SP  - 1816
EP  - 1821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573748
KW  - BN
KW  - Image super-resolution
KW  - Shuffle Attention
KW  - SRGAN
KW  - WGAN
ER  - 

TY  - CONF
TI  - Credit Card Fraud Detection Based on Multiple Machine Learning Models
AU  - Chen, Muyuan
T3  - EITCE '22
AB  - Credit cards have long been one of the most popular methods of making payments. But this kind of payment still carry risks —— credit card fraud. Machine learning has played an essential role in detecting credit card fraud. This study uses machine learning methods to provide most accurate prediction of fraudulent transactions. These algorithms include Random Forest, Logistic Regression, SVM, and Extreme Gradient Boosting (XGBoost). Dataset used in this study is from Kaggle and is highly skewed. In order to find out if imbalanced dataset will affect predictions of models, three oversampling methods, Random oversampling, SMOTE, and ADASYN, are used to resample dataset for comparative analysis. From the analyzed results, oversampling methods tend to cause overfitting of models. XGBoost is the only technique that are not affected by oversampling methods. Since overfitting is a problem that should be avoided in classification problem, original data is selected for further evaluation of models. Performance of four algorithms are evaluated based on F-measure, Cohen's Kappa, AUC score, and accuracy. The results show that Random Forest and XGBoost outperform SVM and Logistic Regression. As a result, a fusion model is constructed based on these two classifiers. Log loss and brier score are used to further evaluate their predictions. The results show that Random Forest and XGBoost provide best predictions and close to each other. Fusion model has a little improvement compared to these two classifiers.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573745
SP  - 1801
EP  - 1805
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573745
KW  - Credit card fraud detection
KW  - Logistic Regression
KW  - Oversampling methods
KW  - XGBoost
ER  - 

TY  - CONF
TI  - Design of real-time transmission system combined with object detection algorithm
AU  - Li, Zhe
AU  - Yu, Zhicheng
AU  - Zhou, Mudan
T3  - EITCE '22
AB  - With the rapid development of robotics and artificial intelligence technology, robots are increasingly appearing in the rescue scene of natural disasters, terrorist activities and various types of unexpected accidents. If the rescue robot wants to complete the task quickly and accurately, the command personnel are crucial to the remote control of the robot. As the "eye" of the robot, image transmission technology is the key to realize the remote control of the robot. Image transmission is a technology that transmits the image from the robot's perspective to the operator in real time to assist the operator to achieve remote control. With the increasing complexity of the work involved in robots, the traditional real-time image transmission system is gradually difficult to meet the needs.In the traditional robot control system, there is a completely separate relationship between the acquisition of visual information and the control of motion, which leads to the inevitable hysteresis of motion control.In order to meet the new requirements of the robot image transmission system, this paper presents a design scheme of real-time image transmission system combined with object detection algorithm. The target coordinates identified by the algorithm are directly sent back to the motion control mechanism, and the visual information and motion control are directly connected to improve the overall response speed of the system. The specific implementation is to obtain the image data through ESP32, and then send it to the host through the network. The host realizes the target detection, and then sends the detection results back to ESP32 through the cloud server, and ESP32 transmits messages to the main control of the motion system.The design scheme has been tested in practice and has good recognition effect and stability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573747
SP  - 1811
EP  - 1815
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573747
KW  - ESP32
KW  - object detection
KW  - OpenCV
KW  - real-time image transmission
KW  - YOLOv5
ER  - 

TY  - CONF
TI  - Facial Features Extraction and Clustering with Machine Learning
AU  - Yang, Yunbo
T3  - EITCE '22
AB  - Computer vision is always one of the most popular topics in machine learning, and face recognition is one of the essential parts of computer vision studies. Today, most studies focused on locating and distinguishing faces. In contrast, this paper focuses more on interpreting components of faces or facial features. Instead of using intentional high variance images to train robust models that fit multiple real-world situations, the study uses standardized photos from Chicago Face Database (CFD). Images are preprocessed to fit the transfer learning model using a slightly adjusted version of The Visual Geometry Group, 16 layers version model (VGG 16) for features extraction. Then data is again processed using Principal Component Analysis (PCA) for computational efficiency and clustered using the K-means algorithm with k election based on common knowledge. The results for flat facial features such as eyes and mouths show an effective clustering. In contrast, confusing results exist in clustering features such as noses and face shapes, which may require higher dimensional data for satisfying clustering. The resulting dataset consists of the name of each face image and its facial features labels, which can be used for further study relationships between facial features and races and genders. It can also be used for face generation programs based on selected facial features.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573746
SP  - 1806
EP  - 1810
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573746
KW  - Face Generator
KW  - Facial features Extraction
KW  - K-means Clustering
ER  - 

TY  - CONF
TI  - Abnormal behavior detection method of highway vehicle based on BP neural network
AU  - Liu, Lulu
AU  - Hui, Zengqiang
T3  - EITCE '22
AB  - By studying the trajectory of vehicles on the highway, the analysis focuses on potentially dangerous traffic accidents such as retrograde, parking, U-turns (left and right turns), speeding and so on. The complex vehicle trajectory is summarized into six categories, namely: going straight, reversing, turning left, turning right, speeding, parking illegally. The features of the involved objects are extracted and the mathematical model is established according to the driving behavior of the vehicles. Using video based on traffic events to create the multi-weather, multi-scenario vehicle abnormal behavior detection dataset. And then the BP neural network is used, and the trajectory feature attributes are used as the input layer of the BP neural network algorithm, the trajectory similarity measurement valuesare the output layer. The hidden layer coefficients are adjusted to obtain the training model, so as to identify the abnormal behavior trajectory of the vehicle. The experimental results show that the diversified datasets improve the accuracy of vehicle detection, at the same time, the BP network structure is used to greatly improve the speed of detection. The method provides a reference for the detection of abnormal vehicle behavior in highway scenes.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573744
SP  - 1795
EP  - 1800
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573744
KW  - abnormal behavior detection
KW  - Back Propagationneural network
KW  - Highway vehicles
KW  - training model
KW  - trajectory attributes
KW  - Trajectory dataset
ER  - 

TY  - CONF
TI  - Neural Network Models Performance Analysis of Large-Scale Text Recognition∗
AU  - Zou, Yunchao
T3  - EITCE '22
AB  - The continuous development of computer technology leads to booming image data and throws a tricky question to scholars about how to process these data intelligently. Luckily, it is a dream come true to the recognition of images with the help of progressive deep-learning technology. Nowadays, image recognition based on neural networks is widely used, and recognizing a large scale of text information is one of the critical applications. Therefore, this paper will first review the development history of image recognition technology and introduce the concept of the convolutional neural network model. After that, it will analyze the performance of multiple algorithms in recognizing a large amount of text information based on Reginal Convolutional Neural Network, Spatial Pyramid Pooling, Fast Region Convolutional Neural Network, and Faster Convolutional Neural Network. Last but not least, it also points out the prospect of the future development direction of the current image processing technology and its defections. Analysis shows that the biggest drawback of deep learning technology is its dependence on training data. More specifically, when the training data is incomplete, it will be hard for the network model to maintain its recognition accuracy, especially in large-scale text recognition. To further improve the image recognition technology, we should put the effort into constructing a deep neural network model, optimize the training data, reduce the model training parameters, and improve the model accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573742
SP  - 1785
EP  - 1789
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573742
KW  - CNN
KW  - Deep learning
KW  - Neural network
KW  - Text recognition technology
ER  - 

TY  - CONF
TI  - Research on Prediction Model of Xiamen Air Quality Index Based on Machine Learning
AU  - Chen, Nan
AU  - Yang, Shuang
T3  - EITCE '22
AB  - Air quality is an environmental issue that everyone must take seriously. Establishing an Air Quality Index (AQI) prediction model, and predicting AQI timely can help ensure people's quality of life and maintain sustainable development of the society. Based on the hourly air quality data of Xiamen City from January 1, 2020 to December 31, 2021, this topic firstly uses grey relational analysis (GRA) to analyze the factors affecting air quality. Secondly, establish the Random Forest, XGBoost, RNN, and LSTM models to predict AQI, and ues the genetic algorithm to optimize the number of hidden layers, Dense layers and the number of neurons in the LSTM model to obtain the GA-LSTM model. The result shows that the GA-LSTM model has high prediction accuracy (MSE=13.048, RMSE=3.612, MAE=2.350, R2=0.915).
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573741
SP  - 1779
EP  - 1784
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573741
ER  - 

TY  - CONF
TI  - Industry Classification Algorithm Based on Improved BERT Model
AU  - Xu, Liangbin
AU  - Ji, Baiyang
T3  - EITCE '22
AB  - With the rapid development of the economy, many enterprises are derived, and different enterprises have different economic activities, and the description of economic activities is usually in the form of short texts. The latest National Standard of the People's Republic of China - Classification of National Economic Industries is divided into 1,381 categories according to categories, major categories, medium categories and minor categories, and industry classification often relies on human experience, which takes a long time and the work is more mechanical. This paper aims to reduce the time and labor costs consumed by traditional industry classification methods. This paper draws on short text classification algorithm, convolutional neural network algorithm, and considers the particularity of different industries. An industry classification algorithm based on the improved BERT model is proposed. Based on the BERT model, the algorithm combines the convolutional neural network and the three-channel model to analyze the main business description of the listed company from the three levels of words, words and concepts, so as to determine the industry attribution. Taking the main products of listed companies screened in Shanghai Stock Exchange and Oriental Fortune Net in the past three years as a data set, the experimental results show that this method is excellent for industry classification.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573743
SP  - 1790
EP  - 1794
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573743
KW  - BERT
KW  - convolutional neural network
KW  - Industry classification
KW  - short text classification
KW  - three-channel model
ER  - 

TY  - CONF
TI  - Fast Pedestrian Detection Algorithm Based on Improved YOLOv3
AU  - Li, Jiahao
AU  - Tian, Yin
AU  - Jiang, Yanxuan
AU  - Yang, Jie
AU  - Chen, Zhichao
AU  - Feng, Zhichen
T3  - EITCE '22
AB  - Aiming at the problems of fast-moving speed, easy occlusion, and complex background of pedestrians in traffic scenes, a fast pedestrian detection algorithm based on improved YOLOv3 is proposed. First, choose the efficient lightweight network ShuffleNetv2 to replace the original backbone network Darknet-53 to reduce the model complexity and improve the detection speed. Second, a reverse residual structure is introduced in the detection network layer to enhance the expressiveness of features. Third, a coordinate attention mechanism is introduced to suppress useless information and enhance the network's ability to focus on key features. Fourth, the spatial pyramid pooling structure is introduced to realize multi-scale feature fusion of the network and improve the detection accuracy of small objects. The experimental results show that compared with YOLOv3, the improved YOLOv3 proposed in this paper can improve the detection accuracy and detection speed by 0.7% and 53.8% respectively, which is more conducive to the rapid detection of pedestrians.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573740
SP  - 1771
EP  - 1778
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573740
KW  - Coordinate attention mechanism
KW  - Pedestrian detection
KW  - Reverse residual
KW  - ShuffleNetv2
KW  - Spatial pyramid pooling
ER  - 

TY  - CONF
TI  - Hybrid Genetic Algorithms for Large Scale Optimization Problem
AU  - Guo, Qingteng
AU  - Li, Qingshun
AU  - Dong, Xueshi
T3  - EITCE '22
AB  - In the fields, such as engineering system and multiple tasks cooperation, many real-world problems can be modeled by colored traveling salesmen problem (CTSP). Since CTSP has been proved belong to the NP-hard, the intelligent algorithms, such as genetic algorithm (GA), have been used for solving small or median scale cases where the number of cities is less than 1000. This paper uses three improved hybrid genetic algorithms, including GA with greedy algorithm (GAG), hill-climbing GA (HCGA), and simulated annealing GA (SAGA), to solve large scale CTSP, where three algorithms greedy algorithm, hill-climbing and simulated annealing are used to improve GA. The experiments show that hybrid genetic algorithms demonstrate an improvement over GA in term of solution quality.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573739
SP  - 1765
EP  - 1770
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573739
KW  - Colored traveling salesman problem
KW  - Hybrid genetic algorithms
KW  - Large scale optimization
KW  - Simulated annealing
ER  - 

TY  - CONF
TI  - Ensemble Learning for Diabetic Foot Ulcer Segmentation based on DFUC2022 Dataset
AU  - Xu, Pin
AU  - Wu, Xin
AU  - Li, Yanyi
AU  - Haq, Ejaz Ul
AU  - Yin, Jianping
AU  - Li, Kuan
T3  - EITCE '22
AB  - In order to increase the segmentation impact of the Diabetic Foot Ulcer Challenge 2022 dataset, we train a selection of popular deep learning segmentation algorithms and improve training methods, such as adding Dice term to loss function, employing transfer learning and poly learning rate update strategy, etc., in this paper. Experiments show that our method is effective, we get a Dice score of 0.7045, which is better than the official baseline result of 0.6277. Moreover, we integrate the above segmentation models using four ensemble methods to evaluate segmentation performance, such as Averaging, Weighting, Voting, and Stacking. We observed that our proposed one-layer CNN stacking network exhibits superior segmentation performance (Dice score: 0.7142) compared to single CNN model and other three ensemble methods. Our performance surpasses the baseline result, placing us in the top 10 in the Diabetic Foot Ulcer Challenge 2022.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573737
SP  - 1750
EP  - 1754
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573737
KW  - Deep learning
KW  - DFUC2022
KW  - Diabetic foot ulcer
KW  - Ensemble learning
KW  - Image segmentation
ER  - 

TY  - CONF
TI  - Chinese News Headline Classification Model Based on ERNIE and Deep Learning Algorithm
AU  - Sui, Deyi
AU  - Qi, Yunsong
T3  - EITCE '22
AB  - Although the Word2Vec model can solve the problem of sparse features and high dimensionality in text representation, it cannot handle the problem of multiple meaning words in Chinese vocabulary. Therefore, this paper proposes a text classification model (EBGM) based on a combination of ERNIE, bidirectional gated recurrent unit (BiGRU) and maximum pool processing. First, more contextual semantic representation of Chinese text is performed by ERNIE pre-training model; then, to enhance the relevance of contextual semantics, contextual semantic information is extracted by BiGRU; finally, maximum pooling is performed to obtain important information of the text. The final results on the experimental dataset show that the model has good performance in the Chinese news headline classification task, which proves the feasibility of the model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573736
SP  - 1746
EP  - 1749
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573736
KW  - BiGRU
KW  - ERNIE
KW  - Max-pooling
KW  - semantic representation
KW  - text classification
ER  - 

TY  - CONF
TI  - Detection of Marine Chemical Pollution Based on Image Processing and Machine Learning
AU  - Chen, Lingyun
AU  - Gao, Mingjie
AU  - Wang, Langyu
AU  - Xue, Chuhan
T3  - EITCE '22
AB  - The problem of oil spills is lethal to the ocean ecosystem. To solve the problem, one of the most important key steps is to detect the ocean surface and judge whether there are or not oil spills. Remote sensing provides the advantage of controlling and observing events remotely, and it can cover the areas that people cannot access, so we use it to build a database. Next, we choose to use Matlab for the pre-image processing and then use the neural network by Python to realize and there are five pre-processing methods: expanding the dynamic histogram range in the ‘Y’ channel (method 1), expanding the dynamic histogram range in three channels (method 2), contrast enhancement (method 3), expanding the dynamic histogram range and then contrast enhancement (method 4), and contrast enhancement, and then expanding the dynamic histogram range (method 5). Finally, we use a neural network to test accuracy, in comparison, method 1 is the best and we improve the accuracy from 72% to 82%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573785
SP  - 1755
EP  - 1764
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573785
KW  - Contrast
KW  - Histogram
KW  - Image processing
KW  - Neural network
ER  - 

TY  - CONF
TI  - Simultaneous Feature Selection and SVM Parameter By Using Artificial Bee Colony Algorithm
AU  - Zhang, Xiaomin
AU  - Liu, Chuan
AU  - Xue, Lian
AU  - Zeng, Heqiong
T3  - EITCE '22
AB  - Support vector machine (SVM) is one of the most successful classifiers in data mining. The performance of SVM is mainly affected by the parameters and features used. Some approaches have been put forward to ensure the best performance of SVM, which usually utilized evolutionary computation algorithms or swarm intelligence algorithm to learn the optimal parameters or select the best subset for SVM. However, these procedures are conducted separately, which made it difficult to obtain the global optimal SVM classifier as features and parameters are interacted each other. In this paper, it proposes to simultaneously determine the parameters and accomplish feature selection for SVM by using Artificial Bee Colony Algorithm, which might acquire the overall optimal SVM classifier to the largest extent. The proposed method has been run on some UCI data set, as well, particle swarm optimization algorithm (PSO) and genetic algorithm (GA) are utilized to optimize SVM in the same way. Experimental results show that the proposed method has good adaptability and the classification accuracy, it can simultaneously obtain the optimal SVM classifier, which is better than PSO and GA in the term of optimization ability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573735
SP  - 1737
EP  - 1745
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573735
KW  - Artificial bee colony algorithm
KW  - Feature selection
KW  - Parameter optimization
KW  - Support vector machine
ER  - 

TY  - CONF
TI  - A Deep Learning-based Recognition Model for Chinese Book Subject Words
AU  - Lin, Li
AU  - Guo, Xiaoxi
T3  - EITCE '22
AB  - In order to effectively identify subject words in Chinese books and documents, this paper proposes an automatic recognition model for subject words based on deep learning. The model first builds word vectors with the word to vector (Word2vec) model to obtain the feature information at the semantic granularity level of the vocabulary, and then uses the deep neural network (DNN) model to train the feature weights of the vocabulary to predict the probability that the keywords belong to the subject words to achieve binary classification. Finally, experimental results on a library bibliographic data set show that the TopicDNN model has a prediction accuracy of 85.32%, which has better performance for subject words recognition than traditional machine learning methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573734
SP  - 1731
EP  - 1736
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573734
ER  - 

TY  - CONF
TI  - Cooperative jamming resource allocation model based on the improved firefly algorithm
AU  - Yao, Zekun
AU  - Liu, Tianhao
AU  - Wang, Chao
T3  - EITCE '22
AB  - In this paper, the jamming resource allocation technology of netted radar is studied. A complete jamming resource allocation model including jamming beam, jamming power and other influencing factors is established. Then the objective function of radar detection probability is constructed, and the improved firefly algorithm is used to optimize the jamming resource allocation model and random keys are used in this paper to improve the coding mode of firefly algorithm. At the end of the paper, results show that in the condition of limited jamming resources, the model and algorithm in this paper can achieve a better effectiveness of resource allocation and provide a new idea for future research.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573732
SP  - 1719
EP  - 1724
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573732
KW  - Cooperative jamming
KW  - Improved firefly algorithm
KW  - Jamming resource allocation
KW  - Netted radar
ER  - 

TY  - CONF
TI  - An Improved Dense Crowd Detection Algorithm Based on YOLOv5
AU  - Li, Yu
AU  - Li, Tiejun
AU  - Huang, Huixiang
T3  - EITCE '22
AB  - Due to the particularity with a large number of labels in dense crowd dataset, the dense crowd detection difficulty is mainly reflected in the missed detection and false detection of small objects. In order to better detect small objects, this paper proposes a more efficient feature fusion network based on YOLOv5. The experiment uses the crowd human public dataset, which improves the average accuracy of detection while ensuring the inference speed. Experimental results show that mAP@0.5 of the improved YOLOv5 network reaches 92.07%, which is 6.21% higher than the original YOLOv5s. The detection frame rate is 49FPS, which has good real-time detection ability. Therefore, the improved algorithm proposed in this work can be a better alternative in dense crowd detection task.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573731
SP  - 1713
EP  - 1718
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573731
ER  - 

TY  - CONF
TI  - Personalized recommendation algorithm of books based on the diffusion of reader's interest
AU  - Min, Lei
T3  - EITCE '22
AB  - The ever-growing books help readers acquire knowledge faster than ever before. But the huge scale of these resources also easily makes people fall into the dilemma of "Information-Explosion", which prevents the reader from easily locating the books that are really suitable for them. To alleviate this dilemma, we analyzes the principle of the "Networks-Based-Inference" algorithm (NBI), which is a classical heuristic algorithm for recommendation. We also proposes an improved algorithm—NBI algorithm using Interest Diffusion (NBI-ID), that derives from this classical algorithm. This improved algorithm inherits the advantages of NBI method in simplicity and effectiveness, and optimizes the allocation of initial information in the process of information diffusion with an interest related indicator. Thus increasing the efficiency of the recommendation results. Experiments on the GoodBooks dataset show that the proposed algorithm improves in accuracy, recall and diversity compared to the classic NBI, CF (Collaborative Filtering) and GRM (Global Ranking Method) algorithms.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573733
SP  - 1725
EP  - 1730
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573733
KW  - Bipartite networks
KW  - Book resources
KW  - Interest diffusion
KW  - Personalized recommendation
KW  - Reader's interest
ER  - 

TY  - CONF
TI  - Canny Edge Detection Algorithm Based on Sparse Representation Denoising
AU  - Wei, Dongwei
AU  - Ling, Yongfa
AU  - Zhang, Wenjie
T3  - EITCE '22
AB  - Since the traditional Canny edge detection algorithm has the problem of being susceptible to noise interference, which makes the algorithm unable to accurately extract the edge information of an image in a noisy environment, in order to solve this problem, this paper proposes a Canny edge detection algorithm based on sparse representation denoising. In this paper, the sparse representation denoising method based on K-SVD replaces the Gaussian filtering in the traditional Canny operator, which can ensure that the edge information of the image is well preserved while removing the noise ; the gradient templates of horizontal, vertical, 45°and 135°directions in Sobel operator are used to calculate the image gradient value, which not only reduces the missed detection rate of edges, but also improves the anti-jamming performance of the algorithm; Otsu is used to overcome the issue of artificially set double thresholds and improve the adaptiveness and accuracy of edge detection of traditional algorithms. From the experimental results, it is found that the proposed algorithm can extract edge information from images with Gaussian noise more accurately and adaptively, which has obvious advantages compared with the traditional Canny algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573730
SP  - 1707
EP  - 1712
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573730
KW  - Canny operator
KW  - Edge detection
KW  - K-SVD
KW  - Otsu
KW  - Sparse representation denoising
ER  - 

TY  - CONF
TI  - Deep reinforcement learning and imitation learning based on VizDoom
AU  - Xu, Yingyu
T3  - EITCE '22
AB  - Reinforcement learning is a field of machine learning that focuses on intelligent agents, primarily the concept of what actions an intelligent agent takes in the environment to maximize cumulative reward. In environments where rewards are scarce, a manual approach is necessary. However, manually designing the reward function to meet the desired behavior can be very complicated. A very useful solution is Imitation Learning (IL). This paper proposes two reinforcement learning algorithms for the basic scene of the VizDoom video game, and uses IL to improve the performance of one of the models.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573729
SP  - 1700
EP  - 1706
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573729
KW  - Imitation learning
KW  - Reinforcement learning
ER  - 

TY  - CONF
TI  - Image Classification Method Based on Neural Network Feature Extraction
AU  - Zhang, Hanwen
T3  - EITCE '22
AB  - Image classification relies on supervised learning, which employs deep neural networks and conventional machine learning techniques to continually learn the characteristics that correlate to tags and accomplish classification. In this situation, the quantity of the dataset, the quality of the labels, and the selection of an appropriate approach frequently significantly impact how robust the model is. In this study, classification predictions on the CIFAR-10 dataset are made using the traditional machine learning algorithm Support Vector Machine (SVM) and the neural network models LeNet5 and VGG16. At the same time, the features learned by the neural network are used for migration and combined with the SVM. The SVM is used as a fully connected layer for prediction. The experimental results show that switching from the SVM to a neural network can significantly refine the classification accuracy of the dataset CIFAR-10. Still, feature transfer is not helpful for optimization. The prediction accuracy of the two neural network models is quite different, indicating that the order and number of layers in the neural network design perform differently for other datasets and tasks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573728
SP  - 1696
EP  - 1699
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573728
ER  - 

TY  - CONF
TI  - A safety helmets and overalls detection algorithm based on improved Yolov5
AU  - He, Xu
AU  - Lan, Zhangli
AU  - Peng, Changyong
AU  - Gou, Yuting
T3  - EITCE '22
AB  - Workers in the factory need to wear safety helmets and overalls according to regulations. In order to detect whether someone violates the rules during working hours in real time, a deep learning detection algorithm based on yolov5 is proposed. The images are collected by the camera in the factory, and two different types of datasets are constructed. The experimental comparison shows that the detection accuracy and recall rate of the datasets have improved after adding additional categories. After optimizing the datasets, this paper adds coordinate attention mechanism to the backbone of yolov5 network. The results show that the improved algorithm has at least 1% improvement in recall and accuracy, and can effectively and timely detect illegal wear in complex operation scenarios.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573727
SP  - 1692
EP  - 1695
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573727
KW  - coordinate attention
KW  - detection
KW  - factory
KW  - overalls
KW  - safety helmets
KW  - yolov5
ER  - 

TY  - CONF
TI  - Developing an algorithm for Sprouted Potato Recognition Based On Mobilenet-Yolov4
AU  - Liang, Jianfeng
AU  - Thelma D, Palaoag
AU  - Liang, Jiahai
T3  - EITCE '22
AB  - Aiming at the problems of poor environmental anti-interference, poor mobility of equipment, slow detection rate, false detection and missed detection in the traditional image recognition method of sprouted potato, this paper proposes a sprouted potato based on a lightweight image deep learning model (MobileNet-YOLOv4). The identification method can improve the accuracy and speed of sprouting potato identification, and at the same time improve the mobility of identification equipment. First, the collected sprouting potato picture sample data is enhanced by CutMix and Mosaic data to improve the generalization of the sample data, and the LabelImg tool is used for image labeling and data set production, and then based on the YOLOv4 model, use the more lightweight MobileNeV3 network structure replaces the main network structure (Backbone) in the original YOLOv4 model, thereby reducing the overall parameter amount of the model, improving the detection speed and the generalization of the model used in the device. Second, optimize the regression box loss function of the model, using the EIoU loss function with higher positioning accuracy is used to improve the accuracy of sprouting potato identification. Finally, the experimental results show that the improved EIoU+MobileNetv3-YOLOv4 model reduces the number of parameters by about 78% compared to the original YOLOv4 model, and the detection speed is improved 28%, the identification speed of sprouted potatoes is faster, the false detection and missed detection rate is lower, and the identification accuracy rate reaches 97.18%, thus providing better technical support for potato automation, high quality and rapid storage.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573726
SP  - 1687
EP  - 1691
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573726
KW  - EIoU
KW  - Image Recognition
KW  - MobileNetV3
KW  - Sprouted Potatoes
KW  - YOLOv4
ER  - 

TY  - CONF
TI  - Improved YOLOv5 lightweight grassland smoke detection algorithm
AU  - Su, Jiaxin
AU  - Liu, Zhiqiang
AU  - Zhang, Xu
AU  - Li, Wenjing
AU  - Zhu, Mixue
T3  - EITCE '22
AB  - To address the problems of low detection performance and large memory consumption of traditional smoke and fire detection methods in complex scenes such as grasslands. Based on the YOLOv5 model, a YOLOv5-GDE optimization model is proposed. The C3 module in YOLOv5 is replaced by GhostC3 with a smaller number of parameters, and some standard convolution blocks are replaced by depth-separable convolutions to make the model more lightweight. Finally, to solve the problem of unstable target regression frame, the EIoU loss function is introduced, which effectively improves the convergence speed and detection accuracy of the model. Experimental results on the homemade grassland smoke dataset show that the optimized model reduces the number of parameters and computational effort by 65.4% and 65.8%, respectively, compared with the original model, and the model size is only 36.8% of the original model, which is more suitable for smoke target detection in grassland scenes and more suitable for deployment in embedded devices with limited computational power, under the premise of ensuring detection accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573724
SP  - 1675
EP  - 1681
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573724
KW  - depthwise separable convolution
KW  - GhostC3
KW  - smoke detection
KW  - YOLOv5
ER  - 

TY  - CONF
TI  - Machine learning performance comparison of CSI 300 stock price movement prediction after disclosure of corporate annual reports of year 2020
AU  - Han, Fengyu
AU  - Wang, Yue
T3  - EITCE '22
AB  - In the current stock market, machine learning based investment robots are widely applied to predict stock price movement. This work studies predicting the stock price movement on the next day just after the release of the annual reports of enterprises, which is different from the scenarios of related work. We use five kinds of machine learning methods, including neural network, decision tree, random forest, logistic regression, prototypical network (a few-shot learning method). Different financial indicators (core and extended) are used in the experiments of this work. We obtain these financial data from the EastMoney website, and we get the results indicating that the machine learning models we use do not behave well to predict companies' price trend. Besides, we also filtrate those stocks which have ROE above 0.15 and net profit cash ratio above 0.9 in hope of improving prediction under this good financial criterion. We conclude that the stock price tendency's predictability on the next day just after the release is weak, and we get the highest accuracy about only 59.6% and the highest precision about only 56% using the random forest classifier which is the best, but the corresponding recall is low (only 13%), and the filtering does not help to enhance the performance very much. Among the models we use, random forest is the best classifier and prototypical network performs better than MLP.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573725
SP  - 1682
EP  - 1686
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573725
KW  - decision tree
KW  - few-shot learning
KW  - logistic regression
KW  - machine learning
KW  - neural network
KW  - prototypical networks
KW  - random forest
KW  - stock price prediction
ER  - 

TY  - CONF
TI  - Study of a two-level variable model optimization algorithm based on differential privacy
AU  - Wang, Pengfei
AU  - Wang, Xun
T3  - EITCE '22
AB  - Traditional ADMM methods suffer from slow convergence and low recognition when faced with group-structured data. This paper therefore uses the parallel alternating directional multiplier method (PADMM) algorithm based on a two-layer penalty variable model with cross-features to solve the model, and uses an optimisation algorithm with normalised weight decay Nadam to improve the convergence speed of the model. Considering the risk of privacy leakage when the data is iterated, a moderate amount of noise is added to the model solving process by perturbing the output of the algorithm to achieve privacy protection of the data. Experiments show that for the same privacy budget, the DP-Nadam with weight attenuation is more accurate than the DP-Nadam in terms of model accuracy as the number of training rounds increases, and the loss is also less than that of the traditional DP-Nadam.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573784
SP  - 1670
EP  - 1674
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573784
KW  - Nadam
KW  - Privacy protection
KW  - Weight Decay
ER  - 

TY  - CONF
TI  - Byzantine Fault Tolerant Consensus Algorithm Based on Credit Model and Verifiable Random Function
AU  - Yu, Xiaofan
AU  - Zhong, Yanru
AU  - Zhang, Zhaoyi
T3  - EITCE '22
AB  - Blockchain technology has the advantages of decentralization, data tampering and data transparency, so that the application field of this technology continues to expand. However, the current consensus algorithm applied in blockchain system has some problems, such as arbitrary selection of master nodes, high communication complexity and low consensus efficiency. An enhanced consensus algorithm (BV-PBFT) is suggested in this study. The consensus protocol is simplified, the communication complexity of the algorithm is reduced, and the effectiveness of consensus is improved. First, the credit value of nodes is calculated by the credit model, and according to the credit value of nodes, the nodes in the network are divided into three types of nodes with different responsibilities. Secondly, the random and verifiable characteristics of verifiable random function (VRF) are used to construct an anonymous master selection algorithm to improve the selection of master nodes. According to experimental findings, the suggested consensus algorithm, when compared to the PBFT method, minimizes the time complexity from to , significantly lowers communication overhead and consensus delay in the network, and increases consensus efficiency and throughput.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573721
SP  - 1659
EP  - 1664
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573721
KW  - blockchain
KW  - consensus algorithm
KW  - credit model
KW  - Practical Byzantine Fault Tolerance (PBFT)
KW  - Verifiable Random Function (VRF)
ER  - 

TY  - CONF
TI  - An Analysis of The Small Sample Datasets Based on Machine Learning
AU  - Zhou, Shaoxuan
T3  - EITCE '22
AB  - In machine learning, building the optimal model for small sample data has become a widespread issue in the data science community. Some methods have been proven to achieve high accuracy in training small sample datasets. However, the solution to more extreme minor sample problems still lacks further exploration. Therefore, this paper will explore the prediction accuracy of machine learning methods for small sample datasets. Collecting the forest fire dataset and pulsar dataset from Kaggle as examples, the prediction of various machine learning models (SVM, random forest, neural networks, regression) was carried out, respectively. It was found that the machine learning model failed to achieve high prediction accuracy in the imbalanced samples represented by the forest fire dataset. Because of the small number and the imbalanced distribution, the model cannot obtain an apparent discrimination degree for each feature.To summarize, the prediction of small sample datasets needs to adopt better methods in model building and obtain more cases in data collection. Otherwise, machine learning cannot provide much help to the actual situation.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573720
SP  - 1654
EP  - 1658
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573720
KW  - class imbalance
KW  - machine learning
KW  - Small sample datasets
ER  - 

TY  - CONF
TI  - Stock Price Prediction Based on LSTM Neural Network: Take Dongfeng Motor's Stock Price as an Example
AU  - Li, Baofeng
AU  - Feng, Yichan
T3  - EITCE '22
AB  - In recent years, stocks have gradually entered our field of vision. Due to the unstable fluctuation of stocks, there are often large fluctuations due to national and social policies, which also makes it difficult for investors to achieve investment profits in the stock market. With the rapid rise of artificial intelligence, computers have also become flexible in dealing with some mathematical problems, so try to bring stocks to computers, and use the extraordinary computing power of computers to analyze and predict the trend of the stock market. This paper mainly studies the prediction of stock price changes by LSTM neural network model. Therefore, this paper selects the stock historical data of Dongfeng Motor from July 1, 2021 to July 29, 2022, a total of 6000 items for research. First, after standardizing the data and dividing the training set and test set, the multi-feature LSTM neural network prediction is carried out, the parameters of the model are adjusted and optimized, and all 5 indicators are included in the model for prediction. The MSE of the prediction result is 0.0078, and the test set MSE is 0.645, the two are relatively close. From the results of the model, it can be concluded that the fitting effect of the multi-feature model is better, and a more accurate stock price data trend can be obtained.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573722
SP  - 1665
EP  - 1669
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573722
KW  - LSTM neural network models
KW  - price prediction
KW  - stock
ER  - 

TY  - CONF
TI  - Learnable-graph convolutional neural network for point cloud analysis
AU  - Xu, Guoquan
AU  - Cao, Hezhi
AU  - Zhang, Yifan
AU  - Wan, Jianwei
AU  - Xu, Ke
T3  - EITCE '22
AB  - The tasks of point cloud analysis are very challenging. Designing efficient convolution operation is the key to accomplish these tasks. In order to capture the structure information, neighborhood usually needs to be considered when designing convolution. At present, most of the works adopt K-Nearest Neighbor or ball query to construct neighborhood. However, these two methods only focus on the spatial distance relationship and ignore the long-distance dependence between points. In this paper, Learnable-Graph Convolutional Neural Network (LG-CNN) is proposed, which can adaptively search the backbone graph of objects. The key of LG-CNN is to design a learning-based neighborhood search method, which adaptively searches the overall backbone information of the object for each central point. Compared with updating the central point through local information aggregation, the effect of using backbone information to update the central point is better. Moreover, a graph convolution is designed to adaptively obtain the unique relationship between points and capture the diversified links between different neighbors. The challenging benchmark experiments of three tasks verify LG-CNN achieves competitive results.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573719
SP  - 1648
EP  - 1653
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573719
KW  - Backbone information
KW  - Construct neighborhood
KW  - Graph convolution
KW  - Point Cloud
ER  - 

TY  - CONF
TI  - Analysis of K-means Algorithm and Its Application in Short and Medium Term Trading Behavior
AU  - Wang, Fengke
AU  - Fei, Miaomiao
T3  - EITCE '22
AB  - With the development of Internet technology, users leave more and more behavior information on the Internet. It is of great significance for business decision-making and theoretical research to find the inherent laws between behaviors and reveal their potential value information by using data mining technology. In the field of Internet finance, investors' trading behavior also contains a lot of information. In order to explore the characteristics of stock investors' trading behavior, this paper takes stock investors' trading behavior as the research object to study the law between their trading behavior and stock returns. Taking the short and medium-term trading records as the research object, this paper divides them into four categories by K-means clustering algorithm, analyzes the behavior characteristics of each category, and finds that the short and medium-term profitability is greatly affected by the trading style of the whole transaction, while the operation frequency has little influence.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573717
SP  - 1636
EP  - 1641
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573717
KW  - Data mining
KW  - K-means algorithm
KW  - Trading behavior of investors
ER  - 

TY  - CONF
TI  - Improved Algorithm for YOLOX-S Object Detection Based on Diverse Branch Block (DBB)
AU  - Zhang, Li
AU  - Zou, Fengshan
AU  - Wang, Xiaofeng
AU  - Wei, Zizhong
AU  - Li, Yang
T3  - EITCE '22
AB  - The YOLO series of algorithms are commonly used in the field of object detection, and YOLOX, as one of them, is an improvement on YOLOv5, which improves the detection accuracy but decreases the inference speed. In order to further improve the detection accuracy of YOLOX and solve the problem of slow inference speed, the YOLOX-DBB algorithm is proposed on the basis of YOLOX-S with reference to the idea of structural re-parameterization. Experimental results on the VOC dataset showed that YOLOX-DBB achieved 62.88% mAP0.5:0.95, a 3.47% improvement over YOLOX-S; meanwhile, YOLOX-DBB achieved 82.46% mAP0.5, an improvement of 1.02%. In inference speed, YOLOX-DBB takes only 10.36(ms) to infer a picture, while YOLOX-S takes 12.55(ms) in the same environment. Therefore, the new network has improved detection accuracy, and the inference speed is also faster than the original network. Finally, YOLOX-DBB was applied to the art craft surface defect detection task, and the results showed that it still had better indicators than YOLOX-S.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573715
SP  - 1624
EP  - 1630
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573715
KW  - DBB
KW  - defect detection
KW  - SPPF
KW  - structural re-parameterization
KW  - VOC dataset
KW  - YOLOX
ER  - 

TY  - CONF
TI  - Global Optimization Based on Hybrid Adaptive Differential Evolution Algorithm and Sooty Tern Optimization Algorithm
AU  - Yang, Hui
AU  - Jin, Luo
AU  - Yang, Mingyue
AU  - Jin, Li
AU  - Jian, Jiabo
T3  - EITCE '22
AB  - This paper proposes a hybrid algorithm combining STOA and DE, called STOA-ADE, for optimization problems. In STOA-ADE. Firstly, a mechanism of selecting mutation operators according to the diversity of the population is proposed to produce higher quality solutions. Further, based on the fitness value and diversity of the population, STOA is applied to the excellent individuals to improve the quality of the solution. The algorithm is tested on cec2015 benchmark function problems. The experiment proves that the strategy mechanism and algorithm proposed in this paper are effective and competitive.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573789
SP  - 1619
EP  - 1623
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573789
KW  - adaptive parameter control
KW  - differential evolution
KW  - global optimization
KW  - hybridization
ER  - 

TY  - CONF
TI  - Point-based Attention Convolutional Neural Networks for Point Clouds Semantic Segmentation
AU  - Li, Ying
AU  - Li, Qing
T3  - EITCE '22
AB  - Convolutional neural network (CNNs) have achieved success in processing data with regular grid structures, demonstrating the great potential of applying CNN to point cloud data. However, the disorder and irregularity of 3D point cloud data hinder this progress. To address this issue, we propose a point-based attention convolutional neural network, which consists of a dynamic attention convolution module (DAC) and a point-based feature relation matrix aggregation module (PRA). DAC is used to extract features. At each layer of the network, DAC recomputes the dynamic update graph and assigns attention weights to each edge across the feature space of different points, and finally updates the features by the weighted sum of adjacent points. PRA utilizes the raw and aggregated features of points to generate a global relation matrix, which can adjust the aggregated features for biases from DAC, while obtaining long-range contextual information. Our network structure consists of an encoder and a decoder, and in order to enhance the results of multi-scale feature fusion, we optimize the feature fusion process after upsampling to form a more detailed end-to-end trainable network. Through segmentation and classification experiments on challenging 3D point cloud benchmarks, we demonstrate that our algorithm can meet or outperform the performance of existing state-of-the-art methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573718
SP  - 1642
EP  - 1647
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573718
KW  - 3D point cloud
KW  - Deep learning
KW  - Point attention network
KW  - Semantic segmentation
ER  - 

TY  - CONF
TI  - Machine learning-based study of eye features under the emotion of anger
AU  - Huang, Zhuoluo
AU  - Li, Yafang
T3  - EITCE '22
AB  - Based on the theory of "the liver is open to the eyes", this study uses a machine learning approach to explore methods and models that can be applied to the identification of eye features for angry emotions, in the hope of providing some ideas for objective identification of angry emotions. We used the angry emotion faces in the China Affective Picture System (CAPS) as the research object. Using multiple feature point inspection, we use openface software to obtain the 3D coordinate point coordinate information of the eye features of the angry emotion images. The aggregated data were then statistically analyzed using matlab software to calculate the eye feature values to be used, and then continued to process them using the classifier function to build a face eye feature point model based on Support Vector Machine (SVM), Linear Discriminant Analysis(LDA), K-Neares Neighbor, Ensemble Subspace Discriminant (ESD), Decision Tree(DT) and other classifiers, and the model was comprehensively evaluated in terms of accuracy, area under the ROC curve and other evaluation metrics. For the results of the measured classification tests, the correct rate obtained by DT classification reached 83.1%, KNN reached 84.7%, ESD reached 88.1%, SVM reached 84.7% correct rate and LDA reached 88.1%. The effect of the eye feature description parameters on the classification effect of anger emotion was verified through experiments, and the best performance of ESD and LDA classification was achieved. Based on the above results we can draw the following conclusions. "The eye is the heart's ambassador", and the classifier constructed based on the eye diagnosis information can play the role of classification, which has certain scientific value and can provide objective diagnostic guidance for clinically relevant psychosomatic problems.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573716
SP  - 1631
EP  - 1635
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573716
KW  - Anger emotions
KW  - Eye features
KW  - Image processing
KW  - Machine learning
ER  - 

TY  - CONF
TI  - Sales Demand Forecast based on Recurrent Neural Network∗
AU  - Zhu, Zhaomin
AU  - Lu, Lin
AU  - Wu, Ning
T3  - EITCE '22
AB  - In this paper, we compare the performance of RNN, LSTM and GRU, which are the most popular cyclic neural networks, in predicting the total sales of products in each store next month. A dropout layer is added to the model to reduce over-fitting. The results show that the root mean square errors between the predicted value and the actual value for all the three models are less than 0.47, while the value of GRU model is 0.39, which has the best performance. At the same time, LSTM and GRU prove that they are more robust to the gradient disappearance and gradient explosion problems of RNN. Compared with LSTM, RNN and GRU still have some over fitting problems.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573712
SP  - 1614
EP  - 1618
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573712
KW  - GRU
KW  - LSTM
KW  - Recurrent Neural Network
KW  - RNN
ER  - 

TY  - CONF
TI  - Long Text Semantic Span Extraction Algorithm for Medical Electronic Medical Record
AU  - Chen, Xueliang
AU  - Liu, Tianming
AU  - Tang, Gongzheng
AU  - Liu, Yujiang
T3  - EITCE '22
AB  - Named entity recognition (NER) is one of the hotspots in the field of Natural Language Processing (NLP). NER, as one of the most important sub tasks in the field of information extraction, aims to find some key phrases in massive texts, such as names of people, places, diseases and drugs. At present, researchers have proposed some models that are easy to implement and have good effects. However, because entity span usually contains little semantics and is not easy to understand, and in the medical field, there are high requirements for the semantics of the extracted span, so the semantic span extraction task appears. Semantic span may be a word or phrase, or it may be composed of one or more sentences. Due to the limitation of coding length, the extraction of semantic span from long text is subject to many restrictions. Because of the particularity of this task, so far, there is little research on the direction of semantic span extraction. We tried a variety of models on our medical electronic medical record dataset. The experimental results show that the proposed model is simple and effective for extracting semantic span from long text.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573711
SP  - 1609
EP  - 1613
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573711
ER  - 

TY  - CONF
TI  - High-density Image Object Counting Network Based on Spatial Context and Channel Attention: Take crowds and vehicles in a statistically dense scene as an example
AU  - Wang, Yu
AU  - Liu, Mingsheng
AU  - Yi, Hu
AU  - Xie, Yunchi
AU  - Tan, Zhengyu
AU  - Ji, Cunyu
T3  - EITCE '22
AB  - Accurate object counting is a challenging task in image analysis, low-density image object counting can usually be achieved by object detection algorithms, and high-density object counting still has limited counting accuracy. We propose a high-density image object counting network based on spatial context and channel attention, abbreviated as HIOC-Net, which divides low-level features into multiple blocks of different scales through a spatial context-aware module to extract rich contextual features, and then uses the channel attention-aware module to process the interdependence of feature information in the channel dimension, so that the model can focus on useful features, suppressing the irrelevant background. This paper conducts extensive experiments on large-scale crowd and vehicle counting datasets, including ShanghaiTech, UCF_CC_50, WorldExpo'10, TRANCOS, and HBR_YD datasets. The results show that our method not only surpasses many state-of-the-art methods in counting accuracy but also achieves competitive localization accuracy, resulting in high-quality object density maps.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573708
SP  - 1592
EP  - 1596
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573708
ER  - 

TY  - CONF
TI  - Research on Recognition Method of Floating Objects on Water Surface Based on improved ResNet
AU  - Guo, Haonan
AU  - Ma, Yangyi
AU  - Hua, Lei
AU  - Wan, Dingsheng
T3  - EITCE '22
AB  - With the continuous population growth and rapid economic development, problems such as scarcity and pollution of freshwater resources are increasingly emerging. Floating objects on the water surface are one of the causes of water pollution, so the research on the identification algorithm of floating objects is of great significance. To further improve the accuracy of the identification of floating objects on the water surface, this paper proposes a DS-ResNet model based on the improved ResNet. Compared to previous work, DS-ResNet employs several innovations to improve training and testing speed while also increasing recognition accuracy. We established an actual data sample set in the field of rivers and lakes, and a modified ResNet model was constructed by Tensorflow for training. The experimental results show that the training cycle time of DS-ResNet is reduced by about 7% compared with the traditional ResNet, and the recognition accuracy of common targets reaches 98%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573710
SP  - 1603
EP  - 1608
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573710
ER  - 

TY  - CONF
TI  - Blind source separation of electromagnetic signals based on one-dimensional U-Net
AU  - Chen, Yang
AU  - Liu, Jinming
AU  - Mao, Jian
T3  - EITCE '22
AB  - Digital electronic equipment emits electromagnetic signals under working conditions, resulting in information leakage and a serious threat to information security. To explore the extent of leakage of important information, blind source separation techniques are used to separate and detect mixed electromagnetic radiation signals. Deep learning techniques provide a feasible option for blind source separation detection of electromagnetic signals in noisy environments. In this paper, we use a one-dimensional u-net to blindly separate the electromagnetic signals leaked by the LCD display. Experiments show that the one-dimensional U-Net with five layers of ELU activation function has the best performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573709
SP  - 1597
EP  - 1602
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573709
KW  - Blind source separation
KW  - Convolutional neural network
KW  - Deep learning
KW  - Single-channel signal separation
ER  - 

TY  - CONF
TI  - Direct Position Determination using Distributed Unfold Coprime Arrays with Unknown Mutual Coupling: based on Reduced-Dimension Search
AU  - Li, Baobao
AU  - Zhang, Xiaofei
AU  - Li, Jianfeng
AU  - Cao, Jinke
T3  - EITCE '22
AB  - The direct position determination (DPD) approach has higher localization accuracy and better robustness than the classical two-step approach when localizing multiple sources with distributed antenna arrays. This paper focuses on the DPD algorithm using multiple Unfolded Coprime Arrays (UCAs) with unknown mutual coupling. To reduce the adverse effects of the mutual coupling, we first expand the unfolded coprime arrays into the DPD scenario. Subsequently, we introduce the HD-DPD-Capon algorithm, which fuses all inverse covariance matrices of distributed arrays, simultaneously searching for multiple unknown mutual coupling coefficients and source positions. Finally, in advance of the reduced-dimension search, we propose the RMCD-ICF algorithm, which only needs to search the two-dimension position, to reduce the high computational complexity of the HD-DPD-Capon algorithm caused by the high-dimensional search. Simulation results verify the superiority of the proposed algorithm on computation complexity and localization accuracy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573706
SP  - 1581
EP  - 1586
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573706
ER  - 

TY  - CONF
TI  - Pedestrian Abnormal U-turn Behavior Recognition Model Based on Baidu AI
AU  - Zhu, Wenjie
AU  - Zhao, Rongyong
AU  - Dong, Chengxiao
AU  - Zhang, Hao
AU  - Li, Cuiling
AU  - Ma, Yunlong
AU  - Jia, Ping
T3  - EITCE '22
AB  - With the economic development and social progress, in order to meet people's increasing travel or entertainment needs, there are more and more crowd gathering places, such as traffic stations, venues, shopping malls and stadiums. Crowd gathering places contain many cross channels, where the anisotropy of crowd behavior is obvious, which is an important part of crowd safety monitoring. In this paper, the abnormal behavior model of the crowd in the intersection of public places is established, the abnormal U-turn behavior of pedestrians in this scene is analyzed, and the human centroid model is proposed by calling the relevant Baidu AI human key point recognition module interface. Pedestrian U-turn behavior in video is recognized by continuous frame images, and a pedestrian U-turn behavior recognition model based on Baidu AI is constructed. This study can provide targeted protection for high-risk areas in large crowd gathering places, and inform security personnel in time after identifying the abnormal behavior of pedestrians, which is helpful for man-machine cooperation to ensure the safety of pedestrians and reduce the accident rate.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573707
SP  - 1587
EP  - 1591
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573707
KW  - Abnormal U-turn Behavior
KW  - Behavior Recognition
KW  - Cross Passage
KW  - Human Key Point Recognition
ER  - 

TY  - CONF
TI  - Human Action Recognition Based on Graph Convolution Spatio-temporal Fusion Attention Mechanism
AU  - Jiao, Xuming
AU  - Qi, Yunsong
T3  - EITCE '22
AB  - Human skeleton maps are concise and robust, and the recent advances in human action recognition, driven by graph convolutional networks (GCNs), are huge. At present, most human action recognition based on graph convolutional network, such as spatiotemporal graph convolutional network (ST-GCN), extracts the spatial features of skeleton points and the temporal features of consecutive frames. Inspired by this, considering the continuity of human actions during motion, the information of each action is related to the information of the previous time point, and a spatio-temporal fusion attention graph convolutional network is proposed for human action recognition. Spatially, the feature difference between the skeleton points of the previous and previous frames is used to generate an attention mask, and the spatial features of each frame are extracted in the temporal domain to generate an attention tensor. Compared with other methods such as ST-GCN, the comparative experiments designed to evaluate and test the model with CS and CV data sets on the data set NTU-RGBD verify the accuracy and effectiveness of the network model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573705
SP  - 1575
EP  - 1580
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573705
KW  - Action recognition
KW  - attention mask
KW  - graph convolution
KW  - Human Skeleton Diagram
ER  - 

TY  - CONF
TI  - A Human Eye-based Text Color Scheme Generation Method for Image Synthesis
AU  - Wang, Shaowei
AU  - Luo, Xiangyu
AU  - Huang, Guanjie
T3  - EITCE '22
AB  - Synthetic data used for scene text detection and recognition tasks have proven effective. However, there are still two problems: (1) The limitation and confusion of the existed color pairs learning from the real dataset; (2) The restriction of the text position which can only have the same color depth. In this paper, we design a novel method to generate color schemes, which is consistent with the characteristics of the human eyes to observe things. The advantages of our method are as follows: (1) It overcomes the problem of color confusion between the text and background caused by dirty data; (2) The generated texts are allowed to appear in most locations of any image, even across depths; (3) The speed of generating images is fast, nearly one image generated per three milliseconds; (4) It exceeds the state-of-the-art methods on several public datasets.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573704
SP  - 1569
EP  - 1574
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573704
ER  - 

TY  - CONF
TI  - A Construction for the Decomposition of Hypergraphs
AU  - Yan, Jie
AU  - Wang, Chengmin
AU  - Lv, Shan
T3  - EITCE '22
AB  - The decomposition problems of hypergraph have many practical applications, including network communication, information exchange and other fields. It is well known that the complete k-uniform hypergraph on n vertices can be partitioned into disjoint perfect matchings. The solution given by Baranayai is by using a network flow algorithm. This solution is not explicit and its not linear in the number of hyperedges. It is still desirable for applications to have a direct construction of the disjoint matching and if possible with a linear time algorithm in the number of hyperedges in the hypergraph. Such an efficient construction is known for and . In this paper we present an efficient doubling construction for and .
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573703
SP  - 1564
EP  - 1568
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573703
KW  - Decomposition
KW  - Doubling construction
KW  - Hypergraph
KW  - Parallel class
KW  - Partition
ER  - 

TY  - CONF
TI  - Research on Dehazing of Cable Tunnel Image Based on Dark Channel Prior
AU  - Li, Qian
AU  - Chen, Yuechao
AU  - Feng, Junguo
AU  - Zhang, Jun
AU  - Sun, Xiaoyun
AU  - Cao, Yuchao
T3  - EITCE '22
AB  - The cable tunnel is an architectural structure to protect the cable. The building is located underground, and the cable is not visible to the naked eye on the ground like overhead lines. In order to protect and maintain the cable, there is a cable monitoring system. Among them, the most important thing for the monitoring system is to capture the images in the cable tunnel, and the generation of fog in the tunnel is unfavorable for the monitoring images. So there is a dehazing method. The traditional dehazing method is roughly divided into a dehazing method based on a physical model and a non-physical model. This paper studies the dehazing of the cable tunnel image based on the dark channel prior algorithm of the physical model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573702
SP  - 1559
EP  - 1563
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573702
KW  - Cable tunnel
KW  - Dark channel prior
KW  - Defogging
KW  - Physical model
ER  - 

TY  - CONF
TI  - Data-missing k-means based on intra-cluster and inter-cluster distances
AU  - Qiu, Jiaji
AU  - Xu, Huiying
AU  - Zhu, Xinzhong
T3  - EITCE '22
AB  - This paper proposes a method that reduces the intra-cluster distance and increases the inter-cluster distance in the k-means problem with missing data. Filling in missing data, calculating intra-cluster distances between clusters, and clustering problems are integrated into one function, and solved through loop iterations. Finally, the method is applied to 4 UCI datasets, and the results show that the method has good effect.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573701
SP  - 1554
EP  - 1558
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573701
KW  - clustering
KW  - incomplete data
KW  - k-means
ER  - 

TY  - CONF
TI  - Self-attention Pyramidal Convolutional Network for Weakly-supervised Video Anomaly Detection
AU  - Liu, Tianhao
AU  - Cai, Yiheng
AU  - Jun, Panjian
T3  - EITCE '22
AB  - Video anomaly detection refers to detecting and recognising abnormal performance in videos that deviate from normal behaviour. The anomaly detection performance in weakly supervised video anomaly detection degrades due to the lack of attention to temporal information in the video features extracted by the pre-trained network. To address this problem, we propose a weakly supervised video anomaly detection method based on a self-attention pyramidal convolutional network (SAP-net), which includes a redesigned multi-scale module with a self-attention mechanism. Experimental results show the SAP-net outperforms the state-of-the-art method in the UCF-Crime dataset.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573698
SP  - 1538
EP  - 1541
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573698
ER  - 

TY  - CONF
TI  - Image Restoration Using Multi-Stage Progressive Encoder-Decoder Network With Attention and Transfer Learning (MSP-ATL)
AU  - Wei, Bingcai
AU  - Wang, Di
AU  - Wang, Zhuang
AU  - Zhang, Liye
AU  - Liu, Cong
T3  - EITCE '22
AB  - Convolutional neural network (CNN) is widely used in the field of image restoration, however, most existing CNN based image restoration methods only focus on a part of image restoration without considering the relationship between image deblurring, image de-raining and image denoising. In addition, training a neural network model for different image restoration tasks requires a large amount of training data, plenty of hardware overheads and a great deal of time. In order to reduce resource consumption and improve the generality of the model, this paper proposes an image restoration algorithm using multistage progressive encoder-decoder network with attention and transfer learning (MSP-ATL). First of all, we design a multi-stage progressive encoder-decoder network with attention mechanisms, which does not require down-sampling or fragmentation of the input, and can retain the overall information of the image. Secondly, following the idea of coarse-to-fine which is widely used in the field of image restoration, we propose a multistage progressive loss function to recover images from coarse to fine by cooperating with the multi-stage network structure. Finally, using transfer learning, the obtained deblurring model can be transferred to image de-raining and image denoising tasks with less training data and simple training process. Extensive experimental results on commonly used datasets demonstrate the efficiency and effectiveness of the proposed method.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573695
SP  - 1517
EP  - 1525
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573695
KW  - Image Deblurring
KW  - Image Restoration
KW  - Loss Function
KW  - Multi-Stage Neural Network
KW  - Transfer Learning
ER  - 

TY  - CONF
TI  - Improved wavelet threshold function for reducing pipeline leakage signal noise
AU  - Sun, Xue
AU  - Zhao, Hongliang
AU  - Hou, Changzhe
T3  - EITCE '22
AB  - When the wavelet is used to denoise the signal of water pipe leakage, the effective components of the signal will be lost and the reconstruction will be distorted. These problems affect whether the pipeline can be successfully detected and whether the source of the leak can be accurately found. Aiming at the problem of how to improve the efficiency of noise filtering, a wavelet threshold function is put forward, which can enhance the denoising result through parameter adjustment. In order to make the experimental effect more obvious, we try to make improvements in two aspects: the reasonable selection of the threshold and the problem of decomposing the signal in several layers. Next, the result of the improved method was confirmed using the metered leakage signal. Experimental results show that noise is controlled and effective characteristics of signals are preserved, which lays a basis of the following diagnosis and location of pipe leakage.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573700
SP  - 1548
EP  - 1553
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573700
KW  - Adaptive threshold
KW  - Denoise
KW  - Modified wavelet threshold function
KW  - Positioning analysis
ER  - 

TY  - CONF
TI  - Low-Rank Tensor Completion with Total-Variation-Regularized Transformed Tensor Schatten-p Norm for Video Inpainting
AU  - Liu, Jiahui
AU  - Tian, Jialue
T3  - EITCE '22
AB  - Due to the existence of missing entries in real-world tensor data, low-rank tensor completion (LRTC) problem has received increasing attention. In this paper, we propose a new transformed tensor Schatten- norm to replace the rank norm and develop a transformed multi-tensor-Schatten- norm surrogate theorem to convert the non-convex transformed tensor Schatten- norm with 0&lt;&lt;1 into the sum of multiple convex functions. However, tensor completion constrained by low-rank prior alone cannot protect local smoothness along the spatial and tubal dimensions. To address this drawback, we combine anisotropic total variation (TV) regularization with non-convex transformed tensor Schatten- norm with 0&lt;&lt;1 for LRTC. The combination of global low-rank prior and local TV prior is beneficial to improving the final completion effect. Our experimental results on grey-scale video inpainting demonstrate that our proposed method outperforms other existing state-of-the-art methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573699
SP  - 1542
EP  - 1547
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573699
KW  - anisotropic TV regularization
KW  - convex optimization
KW  - low-rank tensor completion
KW  - transformed tensor Schatten- norm
ER  - 

TY  - CONF
TI  - Detection of railway signal light based on improved YOLOR
AU  - Ma, Lei
AU  - Zhang, Jie
T3  - EITCE '22
AB  - Transportation is not only an importantly strategic hub of a country, but also an indispensable part of social life. With the development of science and technology, smart transportation has gradually been changed from a concept only to a reality. In consequence, automatic driving technology has become a hot research topic that attracts a number of attentions. Autonomous driving covers fully automated driving and assisted driving. And automatic driving technology based on deep learning is becoming more maturing and advanced. One of the necessary conditions for the development of automatic driving is to recognize traffic signals firstly. And the application of automatic driving technology in highway traffic has begun to show great achievements. However, research in the railway field is still relatively weak, and railway transportation plays a pivotal role in both national strategy and people's livelihood. Based on this gap and need, this paper proposes a lightweight to improve YOLOR object detection algorithm for railway traffic signal recognition method. The method uses YOLOv4-tiny as the baseline model, selectively adds implicit knowledge used by YOLOR, and improves the loss function to enhance the model's ability to prevent overfitting and solve long tail problem adaptively. In addition, the number and size of anchor frames in the self-made data set are optimized. Compared with the same lightweight YOLOv4-tiny model, AP has increased by 2.44, and the model file size only occupies 31.4M.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573697
SP  - 1533
EP  - 1537
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573697
ER  - 

TY  - CONF
TI  - Research on EEG signals of autistic children based on SSVEP-BCI
AU  - Gao, Qing
AU  - Wu, Xiaopei
AU  - Gao, Xiangping
AU  - Zhang, Chao
AU  - Wei, Meijing
T3  - EITCE '22
AB  - There are many children with autism in today's society who have social interaction difficulties and language impairments. To further understand the neural basis of autism, in this paper, we investigate the similarities and differences of EEG characteristics between children with autism spectrum disorder (ASD) and typically developing (TD) children on a brain-computer interface system based on steady-state visual evoked potentials (SSVEP-BCI). We acquired the SSVEP signals elicited at different frequencies (8-11Hz) in 9 channels from three children with ASD and two TD children. For SSVEP signals analysis, we extracted the power spectral density (PSD), the canonical correlation coefficient (CCA), and the extended canonical correlation coefficient (eCCA). To further analyzed the difference between signals of children, we calculated the SSVEP recognition rates in different channels using the one-dimensional convolutional neural networks (CNN). The experiment result shows that children with ASD responded more significantly to SSVEP stimulation than children with TD, and most strongly at the Oz channel.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573696
SP  - 1526
EP  - 1532
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573696
KW  - autism spectrum disorder
KW  - convolutional neural network
KW  - extended typical correlation analysis
KW  - Power Spectrum Density
KW  - SSVEP-BCI
ER  - 

TY  - CONF
TI  - Ground-based SAR image coupling suppression technology
AU  - Shi, Qing
AU  - Wang, Yanping
AU  - Lin, Yun
AU  - Shen, Wenjie
AU  - Li, Yang
AU  - Tian, Ziwei
T3  - EITCE '22
AB  - When Ground Synthetic Aperture Radar (GBSAR) encounters an enclosed space scene, the transmitted signal will be subject to a certain amount of multipath interference. At the same time, the transmitted signal and multipath interference will be coupled to the radar receiver and affect the imaging. Therefore, this paper proposes to use RPCA algorithm to decompose the scene into low rank sparse parts, and adjust the threshold to separate better coupling and echo. Finally, the experimental results demonstrate the effectiveness of RPCA coupling suppression.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573694
SP  - 1511
EP  - 1516
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573694
KW  - Coupling suppression
KW  - PCA
KW  - RPCA
ER  - 

TY  - CONF
TI  - Research on Noise Processing Methods of Speech Recognition in Noisy Environment
AU  - Zhao, Zebin
AU  - Yang, Nan
AU  - Yang, Shulin
T3  - EITCE '22
AB  - Speech noise reduction technology helps automatic speech recognition technology become an important tool to meet excellent human-computer interaction. According to the location of noise processing modules, it can be classified into two modes: signal-side noise reduction and model-side noise reduction. According to the methods used in speech noise reduction, it can be divided into digital signal noise reduction methods and model noise reduction methods. At present, speech noise reduction technology is in the detail development stage of striving for perfection. By introducing the current research status of speech noise reduction technology in academic circles and classifying signal noise reduction methods and model noise reduction methods, the improvement and innovation of these methods are summarized, and the advantages and disadvantages and applicable scenarios of the mainstream speech recognition noise reduction methods are objectively compared. The development and shortcomings of automatic speech recognition technology in the field of noise reduction are expounded, and the predicting the key direction of more optimized development of noise reduction methods can be used as reference for further research on automatic speech recognition noise reduction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573693
SP  - 1504
EP  - 1510
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573693
KW  - automatic speech recognition
KW  - deep learning
KW  - noise reduction of speech
KW  - signal processing
KW  - speech enhancement
ER  - 

TY  - CONF
TI  - Single Image Defogging Method Based on optimized Double Dark Channel with Gaussian Weighting
AU  - Zhang, Saisai
AU  - Tian, Yimin
AU  - Shen, Liwen
AU  - Wang, Hai
AU  - Du, Yunfei
AU  - Chen, Hongmei
T3  - EITCE '22
AB  - In this paper, we propose a single image defogging methods based on an optimized double dark channel with Gaussian weighting to address the problems of artefacts and residual fog at depth-of-field abrupt changes in the defogged images obtained by the traditional dark channel a priori algorithm. The two dark channels are first obtained using super pixel block filtering and median square filtering for each layer, the two filtered dark channels are then combined at the pixel level and enhanced by constructing a Gaussian weighting function, and then the transmittance is optimized using a guided filtering method. The fog map is then converted to HSV color space and the white areas containing the sky etc. are extracted, the probability function was introduced to take the average of the brightness components of the first 10% of the pixel points in the white area as the atmospheric light estimate. Finally, the contrast stretching method was used to improve the image brightness. The experimental results show that the proposed algorithm can better preserve the details of the image and remove the residual fog at the depth-of-field abrupt changes, and improve the artifacts with good visual effects.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573690
SP  - 1489
EP  - 1493
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573690
KW  - dark channel a priori
KW  - Gaussian weighting
KW  - guided filtering
KW  - image defogging
ER  - 

TY  - CONF
TI  - A fisheye distortion correction method based on deep learning
AU  - Han, Dongsheng
AU  - Chen, Lei
AU  - Guo, Zihao
AU  - Yang, Chenlong
T3  - EITCE '22
AB  - As machine vision involves many fields such as photogrammetry, national defense and military, and security surveillance, fisheye cameras have also been widely used as an ultra-wide-angle lens. Different from ordinary cameras, fisheye cameras can obtain a wider viewing angle, but their imaging laws will produce nonlinear distortion, which needs to be corrected to achieve better visual effects. In this paper, a fisheye distortion correction method based on deep learning is proposed. According to the parameter division model, the distortion dataset is synthesized, the neural network is constructed, and the parameter model is trained. Finally, the fisheye image is corrected by extracting the distortion features and estimating the distortion parameters. Image enhancement. This method overcomes the limitation of traditional correction methods that rely heavily on imaging model or camera calibration, benefits from the learning features of neural networks, and has better universality; The results show that this method has better performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573692
SP  - 1499
EP  - 1503
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573692
KW  - deep learning
KW  - distortion correction
KW  - Fisheye camera
KW  - neural network
ER  - 

TY  - CONF
TI  - Deep Learning Approaches for Image Classification
AU  - Yu, Yanzheng
T3  - EITCE '22
AB  - Deep learning models can achieve a higher accuracy result compared with traditional machine learning algorithm. It is widely useful in different areas, especially in images classification area. In recent years, because of the improvement of hardware and the discovery of new deep learning network structures, the accuracy and reliability of deep learning model used in image classification have been greatly improved. However, in the field of images classification with deep learning technology, the reviews of the recent researches are lack. This paper will make a review about the recent researches of images classification based on deep learning. It includes the latest studies to improve the performance about deep learning. Additionally, the potential problems and challenges on deep learning technology and the possible future improvement and research direction are analyzed and discussed in the review.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573691
SP  - 1494
EP  - 1498
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573691
KW  - Convolution neural network
KW  - Deep learning
KW  - Image classification
ER  - 

TY  - CONF
TI  - Research and implementation of a trend prediction model based on trend similarity for the changing trends of fashion elements in clothing
AU  - Zhu, Ming
AU  - Zhan, Shunguang
T3  - EITCE '22
AB  - Trend forecasting of clothing fashion elements is an important guide for product development and sales of garment companies. Existing work can only capture simple changing trend laws and patterns of mutual influence between trends but cannot give effective and practical guidance on the trend changes of clothing fashion elements. This paper uses user information to group rich fashion elements in a more accurate and meaningful way to predict the trend of future trends in fashion elements. By comparing the similarity between the recent trend changes and the historical trend information, we continuously evaluate the next change trend information from the similar historical trend information, learn the laws and patterns of clothing fashion element change trends and predict the future trend change direction. Our experiments show that the model proposed in this paper can effectively capture the changing laws of clothing fashion elements and the patterns that affect each other to predict the changing trends. Compared with the baseline method, the model has the best performance in MAE and MAPE indicators.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573685
SP  - 1460
EP  - 1466
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573685
ER  - 

TY  - CONF
TI  - Research on Image Enhancement of Rural Orchard Security Monitoring under Low Illumination
AU  - Zhou, Zili
AU  - Gu, Shenming
T3  - EITCE '22
AB  - It is great significance to improve the quality of the monitoring image for the low illumination situation and to improve the security of the rural orchard. In this paper, an improved block homomorphic filtering algorithm is proposed to improve the quality of video surveillance image due to low illuminance in real environment. On the basis of image block adaptation and according to different illumination conditions, the filtering effect is improved by adding and adjusting the weight factor of the transfer function, and the blocking edge effect is alleviated by smoothing filtering. In order to solve the problem of low saturation of low illumination image, the image saturation is adjusted hierarchically and the saturation lower than the threshold value is nonlinear pulled up, so as to restore the color saturation of the image as much as possible. The experimental results show that the PSNR, SSIM and IE are improved by 6%, 21% and 4% respectively. Ultimately, it can improve effectively the image quality of orchard video monitoring under low illumination.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573689
SP  - 1484
EP  - 1488
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573689
KW  - Improved block homomorphic filtering
KW  - Low illumination
KW  - Monitoring image
KW  - Rural orchard
KW  - Saturation stratification adjustment
ER  - 

TY  - CONF
TI  - Beampattern Synthesis for Dynamic Metasurface Antenna via Alternating Direction Multiplier Method
AU  - Wang, Jing
AU  - Ran, Longyao
T3  - EITCE '22
AB  - Dynamic metasurface antenna (DMA) is a new type of analog array structure, which can effectively reduce the power, hardware cost and complexity. It is therefore a promising technology of antenna array in low-cost and low-power communications and radar applications. For effective work in communications or radar transmitter, this paper focuses on synthesizing a desired beampattern using DMA, where the essence is to solve the DMA weight optimization problem with the nonconvex constraints. Based on alternating optimization, the weight optimization is first decomposed into two sub-problems. By introducing an auxiliary variable, the decoupling between the objective and the constraints is achieved. Then an alternating direction multiplier method-based algorithm is designed to find the DMA weights. Numerical results show that DMA has better beampattern synthesis performance than traditional phased arrays in several typical scenarios.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573688
SP  - 1479
EP  - 1483
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573688
KW  - alternating direction multiplier method
KW  - beampattern matching
KW  - Beampattern synthesis
KW  - dynamic metasurface antenna
KW  - nonlinear optimization
ER  - 

TY  - CONF
TI  - 3D object detection based on the fusion of projected point cloud and image features
AU  - Ma, Jianhong
AU  - Wang, Xiyao
AU  - Duan, Hao
AU  - Wang, Ruijuan
T3  - EITCE '22
AB  - The complementary advantages of point cloud and image can provide more accurate 3D and semantic information to the model. Aiming at the problems that most existing methods adopt a single fusion strategy and thus fail to achieve deep fusion of image and point cloud features, this paper studies and analyzes the existing fusion strategy of image and point cloud data, and proposes a model based on the fusion of projected point cloud and image features. The model utilizes a projection fusion and feature fusion strategy, introduces a wide threshold processing in the projection module, meanwhile applies the fusion of point clouds and image features after projection cropping, finally integrates both features in depth by adding a weight fusion layer in the feature fusion stage. Extensive experiments on the public KITTI dataset demonstrate that mAP of the proposed method is improved by 3.34% in the average values of easy difficulty compared with similar models, indicating that the algorithm is more effective in 3D object detection with point cloud and image fusion.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573687
SP  - 1473
EP  - 1478
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573687
KW  - 3D object detection
KW  - Multimodal fusion
KW  - Point cloud
ER  - 

TY  - CONF
TI  - 3D reconstruction based on monocular image sequences
AU  - Dai, Shuo
AU  - Nai, Changxin
AU  - Wang, Peiyun
T3  - EITCE '22
AB  - Aiming at the complex operation of active 3D reconstruction technology, which is easily affected by external environment and equipment, this paper adopts a series of monocular image sequences taken by cell phone cameras from different angles to realize 3D scene reconstruction. Firstly, Structure-From-Motion (SFM) algorithm is used for sparse point cloud reconstruction, and the similarities and differences between incremental and global SFM algorithms for sparse reconstruction are compared; secondly, Multi-View-Stereo (MVS) is used for dense point cloud reconstruction, and finally, the surface and texture information of the object is recovered. The surface and texture information of the objects are recovered to achieve the reconstruction of 3D scenes. The experimental results show that the method can achieve better 3D reconstruction of monocular image sequences.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573686
SP  - 1467
EP  - 1472
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573686
KW  - monocular reconstruction
KW  - MVS
KW  - SFM
KW  - three-dimensional reconstruction
ER  - 

TY  - CONF
TI  - Speech Emotion Recognition Based on Multi-feature Fusion and DCNN
AU  - Ma, Yifei
AU  - Guo, Juan
AU  - Fang, Lianbiao
T3  - EITCE '22
AB  - In order to get more effective information and improve the recognition accuracy, this paper proposes a speech emotion recognition model based on multi-feature fusion and deep convolutional neural network. First, the speech emotion data is preprocessed to obtain the two-dimensional three-channel fusion feature parameters, which are used as the input layer of the AlexNet DCNN model. Second, the model is improved. Batch normalization is added after each convolutional layer, and use genetic algorithm and simulated annealing algorithm to optimize the model. Final, we use SoftMax classifier to classify emotion. In this paper, the cross-validation method is used to evaluate the model, and it is verified on the EMO-DB and IEMOCAP datasets. The experimental results verify that the method is superior to the existing speech emotion recognition technology.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573684
SP  - 1454
EP  - 1459
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573684
KW  - Deep convolutional neural network
KW  - Genetic and simulated annealing algorithm (GSA)
KW  - Multi-feature fusion
KW  - Speech emotion recognition
ER  - 

TY  - CONF
TI  - Improved Inception Network for wild mammal Behavior Recognition
AU  - Deng, Shichao
AU  - Tang, Guizhong
AU  - Mei, Lei
T3  - EITCE '22
AB  - The wildlife resources are significantly important parts of the ecosystem, and protecting wildlife resources is vital to the environment on which people live. Therefore, the behavior analysis of wild animals has become an important initiative to protect wild animals. This paper proposes a convolutional neural network architecture based on spatial-temporal information for action recognition of wild mammal. Since pixel-based object segmentation methods cannot eliminate the influence of background, we use the contour-based method Deep Snake to detect the animal contours in images as spatial features. The skeleton-based animal action recognition model is used to extract the joint coordinates during consecutive frames, then the fluctuate of the joint coordinates is used to distinguish the diversity of different behaviors of wild mammal in temporal space, which helps to characterize the difference of joint point movement speed of different behaviors. In addition, we also compute leg joint angle for distinguishing the behaviors running and standing. Finally, the temporal features and spatial features are fused into the convolutional neural network for action recognition of wild mammal. The experiments analyze the effect of the joint point angle, contour features, joint coordinates as well as their fusion features for wild mammal behavior recognition. It is concluded that the fusion features of coordinate fluctuate of joint points during consecutive frames, contour features and knee joint angle can significantly improve the accuracy of wild mammal action recognition. The model can effectively recognize four representational behaviors of animals: running, sitting, walking, and standing. The average accuracy of the proposed scheme for recognizing behavior of wild mammal achieve 95.5%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573683
SP  - 1448
EP  - 1453
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573683
KW  - action recognition
KW  - Improved Inception Network
KW  - spatial-temporal information
KW  - wild mammal
ER  - 

TY  - CONF
TI  - A rotary intelligent garbage sorting box integrating detection, identification and compression and its method
AU  - Wang, Hongxia
AU  - Wang, Wentao
AU  - You, Lingchen
AU  - Tan, Zichen
AU  - Che, Tongtong
AU  - Wang, Fei
AU  - Huang, Zhuang
AU  - Liu, Yantong
T3  - EITCE '22
AB  - Various intelligent trash cans on market at present have many drawbacks. They are complex, expensive, and have only a few functions. A new type of intelligent garbage classification box is designed, which contains four garbage classification buckets. It has the ability to automatically open or close the trash can when users pass by through infrared sensor, classify the garbage into four categories using Raspberry PI, rotate the platform on which the garbage classification buckets are based to put the garbage in place. In addition, the capacity of the garbage sorting bucket is also monitored by ultrasonic ranging sensors. When the bucket is almost full, the garbage can will compress the garbage below or set off an alarm to warn users. The intelligent garbage sorting box is of much use and possesses a high degree of automation, meeting the needs of the majority of home users. So it has a good market application prospect.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573682
SP  - 1440
EP  - 1447
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573682
KW  - Automatic control
KW  - Garbage classification
KW  - Image recognition
KW  - Intelligent garbage sorting box
ER  - 

TY  - CONF
TI  - Laplacian Pyramid Network for Transferring Picture into Van Gogh's Style
AU  - Cheng, Youpeng
T3  - EITCE '22
AB  - Artistic style transfer has become a heated field for machine learning research, where many methods exist to solve the problem. However, transferring a picture into another style is still a complicated image processing task. Each method has its advantages and disadvantages. Laplacian Pyramid Network (Lapstyle), is a novel feed-forward method that could provide artistic style transfer with high efficiency. In this paper, several of Van Gogh's paintings and various pictures are set as style images and content images, including portraits, scenery, and so on, to look at their performance in different situations. The result is that Lapstyle performs well when the style image is a distant view with simple color. At the same time, the stylized picture is awful when the style image is a portrait. Even though the style is paintings of the same artist, the performance varies significantly. In conclusion, the style image for Lapstyle is paintings with simple colors and few details, and portraits are unsuitable.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573681
SP  - 1434
EP  - 1439
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573681
KW  - Computer Vision
KW  - Lapstyle
KW  - Machine Learning
KW  - Style transfer
KW  - Van Gogh
ER  - 

TY  - CONF
TI  - Deep Neural Network Based on Convolution Factor Decomposition for Wireless Signal Modulation Recognition
AU  - Zhou, Xiaoyu
AU  - Fan, Hua
AU  - Zheng, Yi
AU  - Jiang, Mengxi
AU  - Yang, Guangsong
AU  - Ye, Qiubo
T3  - EITCE '22
AB  - In recent years, deep neural network (DNN) technology is widely used in the radio signal modulation recognition task to achieve a high recognition accuracy. However, the performance of DNN depends on a large number of training samples to solve a large number of neural network model parameters. Thus, sufficient training data are required and solving DNN parameters is time-consuming. To alleviate these issues, we propose to use a special module - the Inception module combined with CNN to build a novel neural network for radio signal modulation recognition. In our approach, using the idea of convolution factorization (a key idea in the Inception module), we broaden the network to ensure the model learning ability while reducing the model parameters. Moreover, we use the data enhancement strategy to increase the number of training samples to improve recognition performance. The experiment results show the effectiveness of our approach.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573680
SP  - 1428
EP  - 1433
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573680
KW  - Dataset enhancement
KW  - Deep neural network
KW  - Inception
KW  - Radio signal modulation recognition
ER  - 

TY  - CONF
TI  - New IT Service Tracks Study based on Product Trends and Typical Forecast Model Analysis
AU  - Wei, Muhua
AU  - Zhao, Xuyu
AU  - Zhang, Zheng
AU  - Zhang, Wei
AU  - Pan, Hongyun
T3  - EITCE '22
AB  - New industries and technologies continue to emerge as a result of the digital economy's explosive growth, by creating new markets and tracks for economic advancement. A practical issue worth doing research for business is how to select and acquire better advantages in the new tracks. In this paper, we analyze the product development trends, use multiple regression analysis and Vector Auto-Regression (VAR) model to study the key factors affecting the development of potential tracks, and carry out empirical analysis on the identified development tracks to make a prediction on the track development and help relevant enterprises to choose new tracks and layout in advance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573679
SP  - 1420
EP  - 1427
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573679
ER  - 

TY  - CONF
TI  - EEG emotion recognition based on WPD-1DCNN-LSTM
AU  - Zhang, Jiayang
AU  - Guo, Bin
AU  - Cui, Zhanying
T3  - EITCE '22
AB  - As an important task in the advanced stage of artificial intelligence, the study of emotional EEG has received more and more attention in recent years. In order to improve the accuracy and reliability of EEG emotion recognition and prevent extracting a large number of redundant features with little relevance, this paper proposes a WPD-1DCNN-LSTM EEG emotion recognition algorithm, which first extracts EEG rhythm power and alignment entropy features from EEG signals reconstructed using wavelet packet decomposition (WPD), and then constructs a 1DCNN-LSTM network in the DEAP dataset from the validity -Emotional regions were classified into four categories at the arousal level: anxious and irritable emotion, depressed and sad emotion, pleasant and relaxed emotion, and excited and agitated emotion. The experimental results showed that the method achieved 98.6% classification accuracy on the DEAP dataset, which verified the feasibility and effectiveness of the method proposed in the paper.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573677
SP  - 1406
EP  - 1411
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573677
KW  - DEAP
KW  - EEG signal
KW  - Emotion recognition
KW  - WPD-1DCNN-LSTM
ER  - 

TY  - CONF
TI  - COVID-19 Diagnostic Classification from Chest X-Ray Scan Images Based on Random Forest and DenseNet
AU  - Wong, Hin Kit Eric
AU  - Yang, Shun
T3  - EITCE '22
AB  - The outbreak of the coronavirus disease 2019 (i.e. COVID-19) pandemic has made an extremely serious impact on the world, and the false positive rate of X-ray images in the diagnosis of COVID-19 is a challenge for the management of the pandemic. To better assist doctors in the rapid detection of patients with COVID-19 patients, 9, 208 chest X-Ray images in 4 types of pneumonia patients, including ’COVID-19’, ’Normal’, ’Viral-caused Pneumonia’ and ’Bacterial-caused Pneumonia’ are implemented to build the models via DenseNet and Random Forest to classify whether a patient has signs of infection. The accuracy of the Densenet and Random Forest models is 82.03% and 88% separately according to the experimental results. Based on it, a conclusion can be summarized that when the sample size is very small, random forest is a better model than the DenseNet (i.e. Convolution Neural Network Model), which demonstrates the potential of traditional machine learning methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573676
SP  - 1401
EP  - 1405
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573676
KW  - Chest X-ray
KW  - COVID-19
KW  - DenseNet
KW  - Pneumonia
KW  - Random Forest
ER  - 

TY  - CONF
TI  - Shadow Generation for Composite Image with Multi-level Feature Fusion
AU  - Liu, Tianyanshi
AU  - Li, Yuhang
AU  - Ding, Youdong
T3  - EITCE '22
AB  - Shadow generation for composite image aims to generate shadows for the foreground with reference to the background information, reducing the floating feeling of the foreground due to the lack of shadows caused by simple overlays. The existing two-stage methods are not effective in generating shadows for composite images with complex foregrounds. First, in the Shadow Mask Prediction stage, foreground information and background lighting information are not fully extracted, resulting in inaccurate prediction range and shape of foreground shadows. Second, in the Shadow Filling Stage, the amount of shadow parameter information will decrease as the residual network level deepens, and the shadow parameter prediction is inaccurate, which greatly affects the foreground shadow filling effect. Therefore, we add a multi-scale feature enhancement module to obtain a wider range of feature information and improve the mask prediction accuracy. Meanwhile, we propose a multi-level feature fusion module to reduce the loss of information in the process of shadow parameter prediction by multiplexing features at different levels. Our experiments on the public dataset DESOBA show that the method generates shadow regions with more accurate range and shape.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573675
SP  - 1396
EP  - 1400
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573675
KW  - Composite image
KW  - Multi-level feature fusion
KW  - Multi-scale
KW  - Shadow generation
ER  - 

TY  - CONF
TI  - MAFF: Multi-scale and self-adaptive attention feature fusion network for pancreatic lesion detection in PET / CT images
AU  - Wang, Heng
AU  - Wu, Zhongyi
AU  - Wang, Fei
AU  - Wei, Wenting
AU  - Wei, Kezhen
AU  - Liu, Zhaobang
T3  - EITCE '22
AB  - Accurate, automated medical image detection is critical in clinical diagnosis and analysis. Since the pancreatic lesions in CT images are similar to the surrounding tissues, they are difficult to be detected. The lesions in PET images have the disadvantage of blurred edges that the precise localization is slightly insufficient. PET/CT integrates functional and anatomical imaging, combining the advantages of the high contrast of PET images and the high spatial resolution of CT images to assist doctors in detecting lesions. Therefore, it is significant for us to study the object detection of lesions based on PET/CT. At the same time, the context information extraction ability of the basic framework Faster R-CNN is insufficient. Therefore, we propose a multi-scale adaptive attention feature fusion network (MAFF) based on PET/CT to realize the automatic detection of pancreatic lesions. First, we fuse multi-scale features through a feature pyramid module to obtain richer contextual information and add an attention module to achieve preliminary screening of input features. Second, we design an adaptive attention feature fusion network to make feature semantic information selection more focused by recalibrating multimodal feature maps. Finally, we adopt a pooling module, which not only solves the problem of different sizes of region proposals but also avoids the localization error caused by quantization. Experimental results show that our proposed multimodal algorithm outperforms other algorithms on two challenging tasks, pancreatic cancer lesion detection, and head and neck cancer lesion detection.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573678
SP  - 1412
EP  - 1419
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573678
ER  - 

TY  - CONF
TI  - Chinese medical named entity recognition based on ensemble column-wise convolution
AU  - Ou, Ruxuan
AU  - Qiu, Yiming
AU  - Liu, Mei
AU  - Liang, Anhui
AU  - Wang, Everett Xiao
T3  - EITCE '22
AB  - For the named entity recongnition task, with an uneven distribution of entities, the model usually fails to correctly identify minor entities because of the influence of other major entities Therefore, a name entity recognition model based on ensemble column-wise convolution is proposed. Column-wise convolution performs the corresponding convolution operation on each dimension of the word embedding separately, and then concatenates the results into a final feature. Combined with the integrated network architecture, it enables access to richer semantic information to further enhance the generalisation of the model. Experiments were conducted on CMeEE datasets and the model reached 69.47% levels in F1-score, confirming that they were both better than the other comparison models., and there is a significant improvement in the accuracy of recognition of minor entities.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573674
SP  - 1389
EP  - 1395
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573674
KW  - column-wise convolution
KW  - integrated network architecture
KW  - medical field
KW  - named entity recognition
KW  - pre-training model
ER  - 

TY  - CONF
TI  - Research on Data Augmentation Strategy Methods for Image Caption
AU  - Lin, Nan
AU  - Li, Shuang
AU  - Han, Ying
AU  - Liu, Mengdi
T3  - EITCE '22
AB  - Data augmentation can effectively expand the number of samples in a dataset and increase the diversity of samples. Image caption refers to the generation of a description statement corresponding to an image, and its accuracy directly affects the accuracy of the description statement. In this paper, we study and analyze data augmentation and VizWiz dataset, then we find that data augmentation can effectively simulate the image quality problems existing in VizWiz dataset. In order to improve the accuracy of the image caption model on the VizWiz dataset, this paper presents a method based on a data augmentation strategy, which mainly uses four data augmentation operators to simulate camera shake, out-of-focus, flash and low light conditions. The strategy space also contains basic translate, shear and contrast operations for the image. The method achieves a score: BLEU_1 of 62.5, BLEU_4 of 23.1, ROUGE_L of 46.6 and CIDEr of 49.6 on the VizWiz dataset.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573673
SP  - 1383
EP  - 1388
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573673
KW  - Computer vision
KW  - Data augmentation
KW  - Image caption
ER  - 

TY  - CONF
TI  - Multi-scale Information Aggregation Network for Spine MRI Image Segmentation∗
AU  - Cheng, Mengdan
AU  - Qin, Juan
AU  - Lv, Lianrong
AU  - Wang, Biao
AU  - Li, Lei
AU  - Xia, Dan
AU  - Wang, Shike
T3  - EITCE '22
AB  - Intervertebral disc herniation, spinal stenosis, and degenerative disc are spinal diseases with a high incidence. Accurate segmentation of spinal images is crucial for the diagnosis and treatment of related diseases. This paper proposes a multi-scale information aggregation U-shaped network (MIAU-Net) for spinal magnetic resonance images. MIAU-Net is a novel semantic segmentation model which improved on the U-Net. This model gets better segmentation performance by redesigning the encoder-decoder and the skip connection module. Specifically, the proposed multi-scale information aggregation module is used to capture features of different scales through different receptive fields. While the redesigned skip connection module can speed up the training process and alleviate the problem of gradient disappearance. The model is evaluated using the publicly available SpineSagT2Wdataset3 spine image dataset. Evaluation metrics include the Dice similarity coefficient (DSC), intersection over union, true positive rate, positive predictive value, and F1 score. The DSC score can reach 90.41%. Comparing with other state-of-the-art networks can verify that this method realizes more accurate semantic segmentation of the spine.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573672
SP  - 1377
EP  - 1382
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573672
KW  - Computer vision
KW  - Convolutional neural network
KW  - Deep learning
KW  - Magnetic resonance imaging
KW  - Multi-scale information aggregation module
KW  - Semantic segmentation
KW  - Spine image
ER  - 

TY  - CONF
TI  - Monocular Camera Video Based Reconstruction of 3D human model
AU  - Xie, Daoshun
AU  - Wang, Zongyue
AU  - Cai, Guorong
AU  - Xia, Qiming
AU  - Chen, Yidong
AU  - Yang, Shengming
T3  - EITCE '22
AB  - This paper addresses a method to obtain an accurate 3D human body model and a photorealistic free-view image of an arbitrary person from a monocular camera video. Recent works has shown that it is possible to reconstruct a human model at a level of detail from a single image. However, inferring a complete 3D human model from a network model will be ill-posed if rely on a single photograph of a person. In order to reasonably infer the 3D human model, we propose method based on implicit field representation to integrate the information of video frames by a set of structured latent code. The core of our method is to construct the implicit field by relatively sparse structured latent code. Meanwhile, align the vertices of the parametric human model and structured latent code to the same coordinate system. Extensive experimental results on monocular datasets demonstrate the effectiveness of our approach in generating accurate 3D human models. Our method utilizes a monocular camera to obtain a 3D model which enables consumers create their personality digital model.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573670
SP  - 1365
EP  - 1371
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573670
ER  - 

TY  - CONF
TI  - Three-Dimensional Spatial Location Method Using Intraoperative X-ray Image for Distal Holes of Intramedullary Nails
AU  - Wang, Fei
AU  - Jiang, Junfeng
AU  - Chen, Liang
AU  - Deng, Ziyue
AU  - Tang, Cheng
AU  - Huang, Rui
T3  - EITCE '22
AB  - In the repair of human long bone fracture, the intramedullary nail needs to be inserted into the medullary cavity in order to fix the fracture area. Afterwards, the screw needs to be placed into the distal hole to fix the intramedullary nail. The difficulty is that the distal hole posture will change with the shape of medullary cavity. Therefore, it is difficult to target the distal hole with the matching aiming instrument. At present, the success rate of this operation is only 30%, and the error needs to be controlled within 2mm. Based on two intraoperative X-ray images at different angles, a method to accurately locate the distal hole is proposed through deep feature extraction and deep regression of the hole axis. Firstly, the nail's contour is extracted by the object detection algorithm, and the deep neural network is used to predict the projection of the hole's axis in the imaging plane. Then, the 3D axis posture of the distal hole is preliminarily determined according to the dual-plane intersection. Finally, using the contour information of the nail, the CMA-ES (Covariance Matrix Adaptation Evolutionary Strategies) algorithm is used for pose iterative correction. The experiments are carried out in the simulated and clinical environments, and the distal hole's axis calculated by this method is compared with the real hole's axis. In the simulated environment, the average distance error is 0.34 mm, and the average angle error is 0.35°. Furthermore, the clinical experimental results show that the average distance error is 0.68 mm, and the average angle error is 0.72°. The method can meet the actual surgical needs of distal hole location; and improves the efficiency of location and planning in the distal locking nail surgery.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573671
SP  - 1372
EP  - 1376
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573671
KW  - computer-aided surgical navigation
KW  - deep regression
KW  - distal hole location
KW  - image guidance
ER  - 

TY  - CONF
TI  - Simulation of basic digital signal processing operations
AU  - Shen, Liwen
AU  - Tian, Yimin
AU  - Wang, Hai
AU  - Zhang, Saisai
AU  - Du, Yunfei
AU  - Chen, Hongmei
T3  - EITCE '22
AB  - With the continuous development of information technology, digital signal processing is also getting more and more attention. Meanwhile, MATLAB, as an excellent and efficient scientific computing application software for science and engineering, has been widely used in many fields. In this paper, we design and develop a digital signal processing simulation platform for visualizing the basic operations of digital signal processing with the help of MATLAB GUI and demonstrate the course contents in an interactive real-time dynamic manner. The system implements simple operations and provides corresponding display functions. The simulation platform is simple to operate, intuitive to display, comprehensive in function, with good interactivity and strong intuitive, can make abstract and difficult to understand algorithms become visualized, students will be able to learn the course content more intuitive and comprehensive, easy to understand and master, improve the quality of student learning while enriching the teacher's teaching tools.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573669
SP  - 1359
EP  - 1364
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573669
KW  - Basic Operations
KW  - Digital Signal Processing
KW  - MATLAB GUI
KW  - Simulation Platform
ER  - 

TY  - CONF
TI  - Joint extraction method of entity relationship in Chinese Medicine based on Data Augmentation and Deep Learning
AU  - Luo, Jigen
AU  - Yuan, Yang
AU  - Du, Jianqiang
AU  - Shi, Qiang
AU  - Xiong, Wangping
AU  - Zheng, Qiming
T3  - EITCE '22
AB  - TCM texts are rich in evidence-based information, and a crucial step in knowledge mining is using high-tech tools to organize and store TCM texts in a systematic manner. Knowledge graphs are better suited to organizing and preserving the knowledge of TCM texts with complex relationships than typical databases are. Building high-quality knowledge maps requires accurate and efficient entity relationship extraction, and completely automated entity relationship extraction necessitates the creation of a sizable amount of high-quality corpus data, which increases expenses and lowers productivity. Because the same entity can generate many relations in the joint extraction of TCM entity relations and there are insufficient corpus data, these issues must be addressed. The joint extraction model of TCM entity interactions proposed in this paper is based on deep learning and data augmentation. Using a multi-head selective bidirectional long and short-term memory network (multi-head-BILSTM), the relationship overlap problem is first solved, and the data is then enhanced using five mechanisms: entity replacement, random addition, random deletion, random replacement, and integrated enhancement. We quantitatively assess the benefits and drawbacks of several relationship extraction algorithms as well as the performance improvements of TCM entity relationship joint extraction brought about by five alternative data augmentation mechanisms. In conclusion, our research has the potential to significantly enhance the efficiency of joint TCM entity relationship extraction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573668
SP  - 1349
EP  - 1358
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573668
KW  - Data Augmentation
KW  - Deep Learning
KW  - Joint extraction method of entity relationship
ER  - 

TY  - CONF
TI  - Target temperature region detection of converter thermal infrared image based on improved YOLOv5s
AU  - Tong, Yu
AU  - Li, Ailian
T3  - EITCE '22
AB  - Aiming at the difficulty of real-time temperature detection in the converter smelting process, most of the production sites use sub-guns for only end point detection, In this paper, the YOLOv5s-XCB detection algorithm is used to automatically extract the target temperature area of the converter thermal infrared image. It lays the foundation for the next step to realize automatic temperature measurement combined with the temperature matrix of this area. Based on the YOLOv5s algorithm, the research adds a small target detection layer and a CBAM attention mechanism to solve the problem that small targets and weak target temperature regions are difficult to detect. The BiFPN structure is used in the Neck layer to fuse the original feature information extracted by the backbone network to enhance the detection accuracy. The results show that the average mean precision (mAP) of the improved algorithm is 95.8%, the FPS is 69.5, and the confidence of the detection frame is significantly improved, which solves the problem that the original YOLOv5s algorithm is difficult to detect small target temperature areas and weak target temperature areas.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573667
SP  - 1343
EP  - 1348
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573667
ER  - 

TY  - CONF
TI  - Deep Learning-based Optimization of HDFS for Massive Geographic Image Storage
AU  - Li, Shuainan
AU  - Liu, Ke
AU  - Wan, Honglin
T3  - EITCE '22
AB  - In today's era, a large number of geographical images cannot be stored properly due to their small memory and large number of characteristics. As HDFS has its limitations in storing small files, and in order to cope with the storage and reading needs of a large number of geographical images, a method is proposed to classify small files by means of a deep learning classifier, merge the classified images to establish an index, upload the metadata generated by the merger to a Redis cache database, upload the merged files to HDFS, and at the same time subsequently implement the reading of the files through the index file The merged files are then uploaded to HDFS, and the files are subsequently read from the index file.The experimental results show that the architecture proposed in this paper has high efficiency in geographic image storage, improves the efficiency of storing and accessing massive small images, and has good results.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573666
SP  - 1338
EP  - 1342
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573666
ER  - 

TY  - CONF
TI  - Deep Learning for Fake News Detection: Theories and Models
AU  - Huang, Lu
T3  - EITCE '22
AB  - With the rapid growth of networking platforms, fake news has experienced a wide spread on social media during the past few years, which is a critical threat to public safety. There are a series of potential detrimental societal impacts along with fake news, such as weakening the public trust in journalists and governments. Therefore, detecting fake news has gained interests from researchers in different industries. As deep learning improves in recent years, some researchers begin to apply deep neural networks to the task of misinformation detection. Despite the effectiveness of current deep-learning-based disinformation detection algorithms, there is a lack of a systematic comprehensive framework of recent-year developments in detecting fake news. Therefore, this paper reviews and compare different research on fake news detection and presents their strategies adopted and performances achieved. In addition, this paper analyses the potentials and limitations involved in automated fake news tasks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573663
SP  - 1322
EP  - 1326
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573663
KW  - deep learning
KW  - fake news
KW  - fake news detection
KW  - recurrent neural network
ER  - 

TY  - CONF
TI  - Robust UWB Localization for Indoor Pedestrian Tracking Using EKF and Adaptive Power-Driven Parallel IMM
AU  - Chi, Wenzhao
AU  - Cai, Guofa
AU  - Xu, Zhiping
AU  - Song, Yang
T3  - EITCE '22
AB  - Indoor pedestrian localization accuracy is unsatisfactory and unreliable in a complex environment where some non-line-of-sight (NLOS) channels may persist for a long term while some other line-of-sight (LOS) channels may exist for a short period. In this paper, we propose an adaptive power-driven parallel interacting multiple model (APIMM) algorithm, which is applied into an extended Kalman filter (EKF) based ultra-wideband (UWB) localization system for indoor pedestrian tracking. We refer to this localization system as APIMM-UWB-EKF system. In the proposed APIMM-UWB-EKF system, two parallel IMMs execute simultaneously and are connected by power-driven mechanism. For each IMM, both KF-based LOS and NLOS ranging models are constructed, the observation values of which is obtained by using UWB ranging data. Furthermore, the APIMM algorithm can adaptively adjust the Markov state transition probability matrix according to the received power. Finally, an EKF is utilized to estimate the position information based on the predicated location from the ranges processed by APIMM algorithm. The experiments demonstrate that the proposed system is more accurate and robust in complex NLOS indoor environments compared with the existing schemes.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573782
SP  - 1332
EP  - 1337
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573782
KW  - adaptive power-driven parallel IMM
KW  - NLOS mitigation
KW  - pedestrian localization
KW  - UWB localization
ER  - 

TY  - CONF
TI  - Analysis of Tourist Destination Image Perception Based on Web Data Mining Technology: – Take Wuzhen Scenic Area in Zhejiang Province as an Example
AU  - Liu, Yi
T3  - EITCE '22
AB  - With the rapid development and spread of the Internet, social media has become the main platform for contemporary tourists to obtain information and communicate destination image. The image of a tourism destination constructed by online reviews plays an important role in the travel decisions of potential tourists. Data mining techniques are an important tool in destination image analysis. Taking Wuzhen scenic area in Zhejiang Province as a case study, ROST Content Mining software was used to explore the tourism destination image of Wuzhen scenic area in terms of tourists' cognition and emotion through online reviews. It was found that tourists' image perception of Wuzhen west fence scenic area was divided into four dimensions: tourism landscape, tourism experience and atmosphere, tourism government information and tourism facilities, and tourists' emotional perception was mainly positive, and suggestions were provided for the marketing and promotion of Wuzhen scenic area.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573664
SP  - 1327
EP  - 1331
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573664
KW  - Computer technology
KW  - Online tourism platform
KW  - Semantic network analysis
KW  - Sentiment analysis
KW  - Web data mining
ER  - 

TY  - CONF
TI  - Misleading Image Classification with Multi-shearing and Random Padding
AU  - Li, Chenwei
AU  - Li, Zheming
AU  - Yang, Bo
AU  - Zhang, Hengwei
T3  - EITCE '22
AB  - Neural networks are vulnerable when input data is applied with human-imperceptible perturbations, which is called adversarial examples. When used in image classification models, adversarial examples mislead neural netwoks to classify images with wrong labels, posing great threat to network security. White-box attack has achieved considerable success rate, for the model structure is already known. But black-box attack remains to be improved, so as to the transferability. We refer to the model augmentation method in network training process, and apply to generating adversarial examples to reduce overfitting. Consulting fundamental methods in adversarial examples, we propose a multi-cropping transformation method to alleviate overfitting and enhance transferability. Firstly, referring to data augmentation, we multi-crop original images in every iteration with random possibilities in adversarial exaples generating process. Secondly, the gradient of model loss function is calculated, and the perturbations are added to original images. Finally, we generate adversarial examples with iterative perturbations. The validation of our method is verified on single models and ensemble models, and the transferability is improved, compared to other fundamental methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573661
SP  - 1312
EP  - 1316
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573661
KW  - Adversarial examples
KW  - Image padding
KW  - Image shearing
KW  - Neural networks
KW  - Transferability
ER  - 

TY  - CONF
TI  - A Method of Mask-Wearing Detection Based on Improved YOLOv4
AU  - Liu, Xuanyu
AU  - Yu, Changgeng
AU  - Yang, Dewang
T3  - EITCE '22
AB  - In this paper, a lightweight network based on improved YOLOv4 is proposed to solve the problems of complex model structure and unsatisfactory performance of detection speed in fast-moving situations. Firstly, the inverted residual blocks (IRB) based on Mobilenetv2 are adopted into the backbone feature extraction network to reduce the complexity of the model structure. Then, the feature fusion network based on the depth-wise separable convolution is applied to minimize model calculations and parameters. Experimental results show that the proposed model has the advantages of high accuracy, fast detection speed, and lightweight, which has satisfied the requirements of real-time detection of mask-wearing in fast-moving situations.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573662
SP  - 1317
EP  - 1321
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573662
KW  - Deep learning
KW  - Lightweight
KW  - Mask-wearing detection
KW  - YOLOv4
ER  - 

TY  - CONF
TI  - Handwritten number recognition system based on Image processing
AU  - Zong, Shilong
T3  - EITCE '22
AB  - Numbers recognition requires a person to present a handwritten number, which can be recognized from the designed system. This paper demonstrates the handwritten number recognition system through the image preprocessing algorithms and image binarization method in detail. Also, this paper introduces the meaning and generalization of the handwritten number recognition system. The results from the analysis show that the proposed image processing method for handwritten number recognition is effective.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573660
SP  - 1306
EP  - 1311
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573660
KW  - Algorithms
KW  - Handwritten number recognition system
KW  - Image binarization
KW  - Image preprocessing
ER  - 

TY  - CONF
TI  - Analyzing speaker information in self-supervised models to improve unsupervised speech recognition
AU  - Li, Sirui
AU  - Zhang, Qinya
AU  - Li, Yunpeng
AU  - Li, Guanyu
AU  - Li, Senyan
AU  - Wang, Shaoxuan
T3  - EITCE '22
AB  - The quality of speech representation is the key to the success of unsupervised speech recognition. Self-supervised models contain a variety of audio information, and non-speech content information is not beneficial or even harmful to speech recognition, so removing speaker information can greatly improve the accuracy of unsupervised speech recognition. To effectively remove speaker information, this paper first analyzes the audio features extracted by wav2vec 2.0 and HuBERT self-supervised model qualitatively and quantitatively, and derives the mean value of each sentence as a representation of speaker information. The extracted speech representations are then speaker normalized to obtain valid features to be fed into the unsupervised speech recognition model for training. Experimental results on the TIMIT dataset show that the speaker normalization method can significantly reduce the error rate of unsupervised speech recognition.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573659
SP  - 1300
EP  - 1305
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573659
KW  - speech recognition
KW  - speech representation learning
KW  - unsupervised learning
ER  - 

TY  - CONF
TI  - Diversity Processing of HFM Signals
AU  - Du, Qingxuan
AU  - Ling, Xiao
AU  - Jing, Tiantian
AU  - Peng, Yuankun
T3  - EITCE '22
AB  - Sonar plays an important role in ocean exploration. As the background noise of underwater targets gets lower and lower, Passive detection is more and more difficult, and active detection has gradually become a new development trend. HFM is widely used because of its invariant characteristics. In order to overcome the frequency-selective fading of the target echo caused by the widening of the distance and the time-selective fading of the target echo caused by the channel fluctuation; the diversity processing of a single signal is adopted. When the noise ratio is high, the diversity signal can obtain more echoes of different frequency bands than the ideal HFM processing, which can better observe the echo information characteristics of the target in different frequency bands, and provide the signal identification. more support. In this paper, the Doppler delay caused by HFM is deduced, and the subsequent signal processing and simulation of the diversity signal are carried out.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573658
SP  - 1295
EP  - 1299
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573658
KW  - delay
KW  - frequency diversity
KW  - hyperbolic FM signal
KW  - time diversity
ER  - 

TY  - CONF
TI  - Concrete Inspection Signal Pre-processing Method Based On TFM Imaging
AU  - Ge, Lulu
AU  - Huang, Lixia
AU  - Wang, Zhigang
AU  - Wang, Haitao
AU  - Dong, Dexiu
AU  - Li, Qiufeng
T3  - EITCE '22
AB  - The concrete structure contains a large amount of gravel, aggregate and steel bars, which form a variety of acoustic interfaces. The signal components in the concrete structure are complex, and the ultrasonic energy is easily attenuated. Ultrasonic testing for concrete structure has always been a research hotspot. In order to improve the concrete detection resolution and signal-to-noise ratio, a concrete ultrasonic array detection method based on the total focusing method is proposed. At first, the concrete ultrasonic array simulation study is carried out through the establishment of a concrete finite element model, and the array probes are stimulated sequentially by simulating a excitation and multi-receiving method, and the detection signal is obtained; Then full matrix capture is obtained after convoluted filtering, waveform envelope analysis and signal sharpening processing which would avoid errors caused by noise and phase; Finally, the full matrix capture is processed and imaged according to the total focusing method to display the model detection results. The simulation experiment results show that the proposed imaging algorithm can achieve higher resolution and signal-to-noise ratio compared with the synthetic aperture focusing algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573656
SP  - 1282
EP  - 1288
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573656
KW  - Concrete Structure
KW  - Signal-to-noise Ratio
KW  - Synthetic Aperture
KW  - Total Focusing Method
KW  - Ultrasonic Array
ER  - 

TY  - CONF
TI  - Ultrasonic Array F-SAFT Imaging Method With PSM
AU  - Yu, Xiwen
AU  - Huang, Hua
AU  - Wang, Zhigang
AU  - Wang, Haitao
AU  - Dong, Dexiu
AU  - Li, Qiufeng
T3  - EITCE '22
AB  - With the development of industrial manufacturing level, the requirements for industrial nondestructive testing are becoming higher and higher. In order to achieve faster and more accurate detection, an ultrasonic imaging algorithm method of frequency domain synthetic aperture focusing technique (F-SAFT) based on phase shift migration (PSM) is proposed here. Firstly, the acquired time-domain array signals are processed with two-dimensional Fourier transform. Then the sound field is reconstructed with PSM. Finally, the two-dimensional inverse Fourier transform is used to image the detection area layer by layer. The experimental results show that the resolution and signal-to-noise ratio (SNR) of the imaging results are greatly improved after processing by the proposed method. Compared with the processing results of the time domain synthetic aperture algorithm, the SNR is increased by 23.37dB and the calculation time is saved by 69.43% under the same experimental conditions.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573657
SP  - 1289
EP  - 1294
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573657
KW  - F-SAFT
KW  - PSM
KW  - SNR
KW  - Two-dimensional Fourier Transform
KW  - Ultrasonic Array
ER  - 

TY  - CONF
TI  - X-Ray Image Compression Using Variational Auto-encoder
AU  - Guo, Zihao
AU  - Zhao, Shuang
AU  - Han, Dongsheng
AU  - Yang, Chenlong
T3  - EITCE '22
AB  - With the rapid development of medical industry, medical imaging related equipment is becoming more and more advanced, image data are becoming larger and larger, and it is more and more common for medical images to be stored and viewed in the cloud. Therefore, effective image compression of medical images plays a vital role in today's medical information system. In this paper, a variational self-encoder based on deep learning is proposed to compress medical images. We have carried out image compression experiments on CHESTX-Ray8 data set of the National Institute of Health (NIH), and compared the performance with another deep learning compression method and the compression method without deep learning. Experimental results show that this algorithm outperforms other methods in Peak Signal-to-Noise Ratio (PSNR).
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573655
SP  - 1277
EP  - 1281
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573655
KW  - deep learning
KW  - image compression
KW  - medical images
ER  - 

TY  - CONF
TI  - Research on Image Perception of Red Tourism Scenic Spot based on computer text Data – A Case study of Jiaxing Nanhu Scenic Spot
AU  - Dong, Zheng
T3  - EITCE '22
AB  - In an increasingly developed under the background of the Internet technology and intelligent terminal, information, production speed and quantity of computer text data for tourism research provides a rich variety of data sources, and tourists in computer network and emotional expression and greatly affected the travel decisions and marketing, tourism under the background of the big data research arises at the historic moment. Taking Jiaxing Nanhu Scenic Spot, a famous red tourist destination in Zhejiang Province, as an example, this paper studies tourists' perception characteristics of Jiaxing Nanhu Scenic Spot based on computer text data. Using ROSTCM6.0 (Rost Content Mining) text Content Mining system software, including word frequency analysis, social network and semantic network analysis, lexical sentiment analysis, the comprehensive formation of the Jiaxing South Lake scenic spot tourists perception image analysis results. The majority of tourists perceive positive and neutral emotions, while there are negative emotions. The negative perception is the main direction of future operation and management improvement of South Lake Scenic spot. Finally, the results of big data analysis are integrated to put forward corresponding suggestions for Jiaxing Nanhu Scenic Area. This study is expected to provide a new data-based analysis perspective for tourist attractions in the era of Internet big data.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573654
SP  - 1272
EP  - 1276
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573654
KW  - Computer big data
KW  - Network text analysis
KW  - Scenic spot image
KW  - tourist perception
ER  - 

TY  - CONF
TI  - Face recognition based on deep feature mapping to kernel space
AU  - Wang, Meng
AU  - Liu, Qingqing
AU  - Cheng, Xiaotong
T3  - EITCE '22
AB  - Deep face recognition has attracted more and more researchers' attention due to its layer-by-layer feature learning. However, the classical sparse representation methods have strong classification ability. Considing above two advantages of deep learning and sparse representation, this paper proposed a face recognition algorithm based on deep local dictionary (DLD) feature optimization combining weighted and joint kernel collaborative representation (WJKCR) classification. The main contribution of this paper as follows: (1) the normal probability density function is used to extract local blocks from multi-angle face images. (2) Deep CNN and transfer learning theory were used to extract features from image blocks, and the feature set was selected as the optimal local feature dictionary. (3) Use the weighted and joint kernel collaborative representation for face classification to verify the effectiveness of our algorithm.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573653
SP  - 1267
EP  - 1271
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573653
ER  - 

TY  - CONF
TI  - Research on the application of voice interaction technology based on WebRTC in the Smart Water Supply System
AU  - Wang, Baoren
AU  - Guan, Shengfu
AU  - Wang, Nan
T3  - EITCE '22
AB  - In order to achieve voice operation of the Smart Water Supply System, the voice signal noise reduction algorithm in industrial environment is studied and simulated. The simulation results show that the algorithm can effectively improve the signal-to-noise ratio. Using WebRTC voice processing technology as the front-end tool, the experiment of integrating voice processing module into the Smart Water Supply System is carried out. The results show that the speech recognition system can achieve 98% recognition accuracy in real operation environment, and the response time of the device is not more than 1500ms, which can meet the requirements of the voice operation of the Smart Water Supply System.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573652
SP  - 1262
EP  - 1266
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573652
KW  - Signal-to-noise ratio
KW  - Smart Water Supply System
KW  - Speech recognition
KW  - WebRTC
ER  - 

TY  - CONF
TI  - Auditory and Haptic Interaction Design of Accessible Digital Museum Based on the Blind Information Processing Theory
AU  - Luo, Yalan
AU  - Dong, Yuchen
AU  - Nie, Xiaomei
AU  - Qian, Xiang
AU  - Zhou, Junchi
AU  - Wu, Dingjun
AU  - Jiang, Zihan
AU  - Chen, Xi
T3  - EITCE '22
AB  - Visual centralization is the main feature of the traditional museum, which causes great difficulties for the blind to visit. To solve the problem, this article proposes an accessible digital museum based on the blind information processing theory. It is an interactive platform based on auditory and haptic interaction design, which aims to help the blind convert visual information into auditory and haptic information. We cooperated with Nanshan Museum and Shenzhen Accessible Environment Association to carry out experiments. A total of 13 blind people participated in the experiment, 7 of them participated in the pre-experiment and 6 participated in the formal experiment. Results show that the accessible digital museum based on the blind information processing theory has a positive effect on the information perception, museum experience and self-efficacy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573651
SP  - 1256
EP  - 1261
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573651
ER  - 

TY  - CONF
TI  - Credit Card Fraud Detection Based on Combination of Sparse Autoencoder and Support Vector Machine
AU  - Li, Honlam
T3  - EITCE '22
AB  - Credit card fraud has become a serious issue for banks and businesses as more and more transactions take place online. A number of machine learning methods have been developed to learn patterns in credit card frauds. These methods usually depend on sophisticated feature engineering because gaining representative features can improve their performances. However, manual feature engineering is impossible due to the ever-increasing amount of data and complicated relationships between transactions. In this work, a Sparse Autoencoder-Support Vector Machine (SAE-SVM) model is proposed to solve the issue of feature engineering. The SAE is an unsupervised machine learning method that learns representative features from the raw data. The SVM model later uses these features to predict whether the transaction is fraudulent. This SAE-SVM method achieves 0.80 F2 score on the Credit Card Fraud Detection dataset on Kaggle, compared to only 0.71 F2 score by the SVM method alone. In addition, the SAE-SVM model outperforms other autoencoder-based models regarding the F2 value. It is shown that the SAE can extract useful and low-dimensional features without much loss of information. The deployment of the SAE may relax supervised machine learning from complicated feature engineering. Furthermore, the SAE model is robust toward the concept drift issue, making it preferable over manual feature engineering.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573650
SP  - 1252
EP  - 1255
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573650
KW  - Autoencoder
KW  - Credit card fraud detection
KW  - Support vector machine
ER  - 

TY  - CONF
TI  - Data augmentation for speaker verification
AU  - Yang, Shiqing
AU  - Liu, Min
T3  - EITCE '22
AB  - Data augmentation is a hot issue in neural network training. In this paper, we investigate data augmentation for speaker recognition, and we propose two data augmentation methods to enhance the performance of neural network system. One of which is spectral augmentation. Spectral augmentation is a newly proposed data augmentation method which applied to speech recognition and got state-of-the-art performance, by masking blocks of frequency channels(F-mask), and/or by masking blocks of time steps(T-mask). We also investigate the method of speed perturbation, which adjusts the time-scale of a given audio signal without altering its pitch content. Experimental results show that both two methods can boost the performance. By combining TF-mask with speed perturbation, we can obtain more than 5.2% and 8.7% relative improvements over the baseline systems in the Vox-H and WX tasks.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573649
SP  - 1247
EP  - 1251
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573649
ER  - 

TY  - CONF
TI  - Implementation and Debugging Method of a High-end Controller Chip Safety Debugging System
AU  - Zhang, Yanxin
AU  - He, Longlong
AU  - Ning, Zhenhai
AU  - Li, Jinwang
AU  - Tan, Lang
AU  - Yang, Lixin
T3  - EITCE '22
AB  - Focusing on the requirements of chip localization in the relay-protection equipment of State Grid, our company has developed a high-end controller chip. To improve security of the chip, we implement a special debug system in it. This paper introduces the way of the use of common debugging tools in the process of debugging and application development based on the high-end controller chip to provide extensive support to customers.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573648
SP  - 1241
EP  - 1246
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573648
ER  - 

TY  - CONF
TI  - Platform of Formal Modeling and Analysis for Airborne Software Requirements
AU  - Lyu, Jiarun
AU  - Hu, Jun
AU  - Wang, Lisong
T3  - EITCE '22
AB  - Airborne software systems play very important roles in modern civil aircraft systems, and there are several safety standards, including DO-178B/C, etc., that are compulsory to be satisfied before airborne software can be certificated by the authority of government. According to the DO-178B/C, the consistency and integrity of airborne software requirements must be analyzed and verified in the early stage of software development. In this paper, we introduce a formal modeling and analysis tool platform (ART: Avionics Requirement Tools) for airborne software natural language requirements, and a case study of the requirements of the software subsystem of the Indication-Recording System (IRS) is provided. Firstly, we give the semantics of a formal Variable Relationship Model (VRM), the platform architecture, and toolchain of ART. Then a methodology of formal analysis of requirement consistency and integrity based on a multi-paradigm is given. After that, some details of the case study of IRS are shown including: how to make a preproccessing of original requirements and the automatic analysis process of the requirement model, such as the preprocessing and standardization of original requirement items, automatic generation of VRM models and multi-paradigm based formal analysis, etc. Lastly, some experiences of this case study are shown.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573646
SP  - 1221
EP  - 1234
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573646
KW  - Formal methods
KW  - Formal modeling for airborne software
KW  - Natural language requirement modeling
KW  - Variable relation model
ER  - 

TY  - CONF
TI  - Construction of financial big data framework based on management accounting
AU  - Tian, Zhujin
T3  - EITCE '22
AB  - The rapid progress of big data technology makes many traditional enterprises have the idea of reforming financial management, which leads to the traditional financial accounting must master the information-based financial management mode [1]. The transformation from financial accounting to management accounting has made great changes in the way of data analysis. With the help of big data technology, this change has evolved into a financial big data framework. This paper explains the theoretical framework of financial data and the establishment process of each subsystem from the perspective of management accounting, and highlights the importance of big data algorithm. The final research results show that the construction effect of financial data framework is significant.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573647
SP  - 1235
EP  - 1240
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573647
KW  - Accounting
KW  - big data
KW  - Finance
KW  - frame
KW  - Management
ER  - 

TY  - CONF
TI  - Research on the Construction of Accounting Big Data Analysis Platform Based on Cloud Computing
AU  - Xiao, Jiahao
T3  - EITCE '22
AB  - The traditional accounting model has obvious disadvantages: high cost, low efficiency, tedious work, and there is a large development space in the existing accounting system. This paper introduces the development process of cloud computing, and expounds the shortcomings of the existing accounting information system, and leads to the construction of accounting big data analysis platform based on cloud computing. The feasibility, construction principles, function construction, system architecture and other aspects of the platform construction are analyzed in depth, and the basic outline of the platform is presented to the readers, which provides some reference for the follow-up scholars ' research.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573645
SP  - 1214
EP  - 1220
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573645
KW  - Data mining
KW  - Data storage
KW  - Feasibility analysis
KW  - System construction
ER  - 

TY  - CONF
TI  - Research on Information Security of Enterprise Group Financial Sharing in Cloud Computing Environment
AU  - Liu, Tian
T3  - EITCE '22
AB  - With the continuous development of the economy and technology in the information age, a series of problems such as high financial cost, low efficiency of financial management and structural redundancy appear in large enterprise groups with large business scale and numerous subordinate groups. In this context, more and more enterprises have begun to provide services through financial sharing to solve internal problems. [1] At the same time, cloud computing promotes the construction of a highly process-oriented financial sharing operation system, and greatly improves the data storage capacity and computational analysis ability of the system. It can improve the quality of accounting information and provide technical support for the financial sharing service center of enterprise groups to better perform financial functions, enhance decision support and strategic impetus. However, with the increasing scale of financial sharing services of enterprise groups, the urgent problem to be solved is how to ensure the financial sharing services provided by enterprises in the cloud computing environment. This paper will take the AHP-fuzzy comprehensive evaluation method as the core, on the basis of a concise scientific principle, dynamic principle, objectivity principle and comprehensive principle, combined with index classification method, expert guidance method, questionnaire survey method and literature research method to complete the construction of financial sharing information security evaluation system, which will play a certain reference role in the information security research of financial sharing of enterprise groups.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573642
SP  - 1201
EP  - 1207
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573642
KW  - AHP
KW  - Cloud Computing
KW  - Financial Sharing
KW  - Information Safety
KW  - System Construction
ER  - 

TY  - CONF
TI  - An encrypted traffic classification model based on the raw traffic and spatiotemporal characteristics
AU  - Zhao, Guanglong
AU  - Wang, Zhen
AU  - Yang, Ziheng
T3  - EITCE '22
AB  - Deep learning techniques are frequently utilized and produce effective results in the classification of encrypted traffic. In the current encryption traffic classification process, the network traffic characteristics are not sufficiently extracted, which is a concern. An encrypted traffic classification model based on raw network traffic and its spatiotemporal characteristics is proposed in this paper. The raw network traffic is divided into sessions, and the packets inside each session are then split into 784-byte slices, and the traffic is then described using the slice data. The time feature vector and the spatial feature vector are then created by combining ResNet and GRU models to generate features from raw network data in parallel. The traffic is then classified using the combined features. According to experimental findings, the proposed model's recognition accuracy on the ISCX-NonVPN-VPN2016 dataset reached 99.36%, which is an improvement over other approaches currently in use.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573644
SP  - 1208
EP  - 1213
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573644
KW  - Deep learning
KW  - Encrypted traffic classification
KW  - GRU
KW  - ResNet
ER  - 

TY  - CONF
TI  - A Transformation Framework From SysML to AltaRica Models for System Safety Analysis
AU  - Dong, Yanhong
AU  - Hu, Jun
AU  - Wang, Lisong
AU  - Huang, Ximeng
T3  - EITCE '22
AB  - As concerns about system safety have grown in recent years, it has become a research emphasis to convert architectural system models into system safety analysis models. Therefore, the paper proposes the rule and algorithm of SysML to AltaRica 3.0 conversion that can effectively bridge the gap between design and safety analysis models. Firstly, the paper presents a modeling and safety analysis tool to improve system safety. Then, the paper designs the transformation rule and proves the correctness. Secondly, the transformation algorithm S2A is proposed and completes the model conversion function of this tool. Finally, the landing gear system is given as an example to evaluate the accuracy of S2A and the tool's efficacy.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573641
SP  - 1190
EP  - 1200
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573641
ER  - 

TY  - CONF
TI  - Research on A Convenient Home Care System for Gravida Based on Sensing Data Analysis
AU  - Qin, Jilin
T3  - EITCE '22
AB  - With the development of the times, more and more urban women are getting married late because of their emphasis on study and work. The proportion of older pregnant women is rising rapidly. The birth risks such as premature birth, abortion, gestational diabetes and hypertension are greatly increased, which brings new challenges to the quality of birth and the health of pregnant women. In particular, the incidence of premature infants increased year by year. Premature infants not only have a low survival rate, but also are likely to have intellectual problems. It is urgent to pay attention to the care of pregnant women and improve the birth quality of babies. This paper studies and designs a home convenient pregnant women care system based on sensor data analysis which involved Arduino board, relevant sensors and the software system. The system has the advantages of convenient use, multi-function, low cost and customizable. It can detect the ambient temperature and humidity, user's heart rhythm, harmful gas leakage, blood oxygen saturation, etc. The system also has some additional functions, such as first-aid skills for pregnant women, psychological counseling for pregnant women, fetal education music, and recipes for pregnant women, which are designed to reduce the burden and worry of pregnant women.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573640
SP  - 1185
EP  - 1189
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573640
KW  - Gravida
KW  - MAX30102
KW  - MQ-2
KW  - Sensing Data
KW  - Uno R3
ER  - 

TY  - CONF
TI  - Research on the Application of Digital Education Resource Data Security Sharing Based on Blockchain and Access Control
AU  - Peng, Jiao
AU  - Yang, Shulin
AU  - Li, Xiang
AU  - Zhou, Meiqi
AU  - Huang, Yongliang
T3  - EITCE '22
AB  - With the rapid development of online education, the security sharing of digital education resources has become a hot topic. Blockchain technology is difficult to be tampered with, decentralized and other characteristics, suitable for protecting the copyright of digital education resources, but the on-chain data is transparent and open, there are hidden dangers of on-chain data security. Secondly, blockchain has limited storage capacity and is not suitable for storing a large number of digital educational resources. The education resource access control model proposed in this paper combines distributed file system with blockchain, which stores the summary information of education resource data. Based on the one-to-many sharing scenario of digital education resources, Ciphertext-Policy Attribute Based Encryption is adopted to implements fine-grained access control. Based on the storage demand of massive education data, IPFS is used to distribute all kinds of digital education resource files to share the storage pressure of blockchain.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573639
SP  - 1179
EP  - 1184
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573639
KW  - ABE
KW  - Block Chain
KW  - Educational Resources
KW  - Hyperledger Fabric
ER  - 

TY  - CONF
TI  - Construction of network security domain knowledge graph for network attack detection
AU  - Chen, Yu
AU  - Liu, Jian
AU  - Xian, Ming
AU  - Wang, Huimei
AU  - Zhang, Yuxiang
AU  - Han, Jiujiang
AU  - Zhang, Renfei
AU  - Zhang, Lei
T3  - EITCE '22
AB  - The introduction of knowledge graph technology in the field of network security can enable network security personnel to better grasp the network security situation, detect network attacks, analyze and determine the network attack chain, and then take targeted preventive measures to continuously improve the security of network space. This paper proposes a method of constructing knowledge graph based on network security domain ontology. Aiming at the multi-source heterogeneous network security data, extracting the association relation and designing the network security domain ontology model. Through knowledge extraction of massive structured, semi-structured and unstructured data, the network security domain knowledge graph is constructed according to the top-down construction method, and the knowledge is stored, displayed and queried through the Neo4j graph database. The constructed domain knowledge graph implements association analysis of multi-source heterogeneous data from six dimensions of network security-related, including asset dimension, attack dimension, vulnerability dimension, weakness dimension and alarm dimension, laying a foundation for network attack analysis and detection.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573638
SP  - 1171
EP  - 1178
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573638
KW  - Attack predict
KW  - Complex attack
KW  - Knowledge graph
KW  - Network security
KW  - Ontology construction
ER  - 

TY  - CONF
TI  - Design of Bare Metal Network Architecture Based on Smart NIC
AU  - Liu, Chuanhui
AU  - Wang, Peihui
AU  - Zhang, Yuan
AU  - Zhang, Zhaozeng
T3  - EITCE '22
AB  - Currently, traditional virtualized servers in the cloud computing space suffer from excessive network stack overhead and insufficient CPU resources available for virtual machines. The article proposes a bare metal network architecture design based on smart NICs, by which carrying traffic loads and implements virtual NIC transmissions through Virtio technology to provide a data communication path from bare metal servers to smart NICs. Furthermore, OVS and DPDK technologies are used inside the smart NIC to offload the control forwarding process of network messages, which makes the smart NIC handle traffic data directly and greatly shorten the forwarding path of messages. Through experimental verification, this bare-metal network architecture can significantly reduce the utilization of network services on the server CPU and provide resiliency for the bare-metal server, further enhancing the overall performance of the system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573635
SP  - 1153
EP  - 1158
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573635
KW  - architecture design
KW  - bare metal
KW  - hardware offload
KW  - Smart NIC
ER  - 

TY  - CONF
TI  - Design of Lightweight Human Resource Management System Based on Scrum
AU  - Yu, Jiujiu
AU  - Zhang, Jishan
AU  - Yu, Yanxing
AU  - Wu, Ning
AU  - Sun, Wenling
AU  - Mei, Yingying
AU  - Zhu, Canglu
T3  - EITCE '22
AB  - The research is based on Scrum of agile development, and taking a human resource management system of ABC Company as an example. This study is devoted to the rapid development of this system with the lightweight design framework of Spring Boot, a feasible development process of the first Sprint for Scrum is described and the feedback on application is positively. Finally, further work is put forward in the future. Firstly, an integrated platform for common interface should be developed to connect with other related sub-systems for ABC Company. Secondly, artificial intelligence algorithms are required to be embedded in the system to achieve the function of intelligent push of talent information.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573637
SP  - 1166
EP  - 1170
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573637
ER  - 

TY  - CONF
TI  - Time Interest Network for Click-Through Rate Prediction
AU  - Miao, Hui
AU  - Zhou, Qinglei
AU  - Song, Huawei
AU  - Wan, Fangjie
T3  - EITCE '22
AB  - In the era of the information explosion, it is very important to accurately predict the user's next behavior (such as browsing, collecting and commenting) through the user's characteristics. As a key research issue in the traffic distribution process of the Internet industry, CTR is of great significance to content recommendation and online advertising. However, most existing research ignores the intrinsic structure of user behavior traits: User behavior changes over time, leading to changes in user interest characteristics. Toward that, this paper proposes a new CTR model called click-through rate prediction (TIN) based on the network of temporal interest. The model first maps large-scale sparse input features into low-dimensional embedding vectors, the characteristics of the user's interest in each time window are then extracted by the multi-head self-attention mechanism, Bi-LSTM is then utilized to capture changes of interest between various time periods, and then, it is beneficial for the residual network to achieve gradient multiplication and backpropagation process, effectively avoiding the problem of gradient disappearance, and finally connecting to the multilayer perceptron (MLP) to learn the nonlinear relationship between features. Extensive experiments have conducted on the advertising dataset and the results have demonstrated that the proposed model is competitive with superior CTR estimation ability.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573636
SP  - 1159
EP  - 1165
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573636
KW  - Attention mechanisms
KW  - Deep learning
KW  - Time window
KW  - User Preferences
ER  - 

TY  - CONF
TI  - Super-resolution adversarial generative fish classification based on Swin-Transformer
AU  - Gong, Yaohan
AU  - Gu, Shenming
AU  - Guan, Linting
T3  - EITCE '22
AB  - The development of fish detection and identification technology is crucial in fishery production. Due to the large intra-class difference and high inter-class similarity, fish classification tasks are considered to be fine-grained. In addition, the acquisition of fish images is often affected by lumps, angles, complex backgrounds, weather, and other factors, which makes the classification task difficult. We present a fish classification method that combines super-resolution reconstruction, multi-scale feature information, and self-attention to improve image quality and classification. Through super-resolution reconstruction and data augmentation, image quality can be improved. A feature extraction network based on Swin-Transformer is used to extract the image's multi-scale feature information and self-attention. The method was evaluated using the Nature Conservancy's publicly available fisheries monitoring dataset. The results of the experiments reveal that the approach may significantly increase image quality while completing the fish classification. At the same time, we compared our results to those of other approaches.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573634
SP  - 1146
EP  - 1152
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573634
ER  - 

TY  - CONF
TI  - Multi-Feature Convergence Network for Acoustic Scene Classification
AU  - Wu, Menglong
AU  - Dong, Hongxia
AU  - Cai, Xichang
AU  - Qiao, Ziling
AU  - Qin, Cuizhu
AU  - Zhang, Lin
T3  - EITCE '22
AB  - This paper investigates a multi-feature convergence network for acoustic scene classification (ASC). A series of neural network models designed with features of the Log Mel spectrogram, Deltas, and Delta-Deltas superimposed on the channel have achieved good classification results. However, the low-frequency part of the speech spectrogram feature extracted from the audio signal has a mosaic shape due to its low resolution, which leads to the loss of information in the low-frequency part of the Log Mel-Deltas-DeltaDeltas feature and reduces the classification accuracy. To solve this problem, the constant Q-transform (CQT) spectrogram is introduced and this feature is superimposed on the channel with the log Mel-Deltas-DeltaDeltas feature to form a 4-channel feature spectrum as the input to the network model. Moreover, the proposed network model is deepened by increasing the 8 residual blocks from the baseline system to 10 residual blocks and a snapshot integration operation is performed on the various models saved during the training process due to the complementary information. And then, a 3-classifier is added based on the ASC's primarily categorized scenes' 10-classifier and chooses the final scene classification by combining the 3–10 two-stage classification scores. The classification accuracy of our proposed network reached 77.4%, which is 5.1% higher than the baseline system set in this paper and 26% higher than the baseline on the official website of DCASE 2020.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573633
SP  - 1142
EP  - 1145
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573633
ER  - 

TY  - CONF
TI  - Design and Implementation of Intelligent Parking System for Housing Compounds Based on WeChat Mini Program
AU  - Zhang, Wenjie
AU  - Ling, Yongfa
AU  - Wei, Dongwei
T3  - EITCE '22
AB  - A visual intelligent parking system for the housing compounds is designed aiming at the problem that the owner drove out of the housing compounds when they found that there were no internal parking spaces due to the unknown occupancy of them. First of all, the ultrasonic whose velocity is corrected is used to detect the parking space and the data of each detected node is transmitted to the coordinator through the Zigbee network, and then the coordinator uploads the data to the MQTT server through WIFI. Finally, the mini program fetches the data from the cloud and displays the visual interface. The results show that the average error of ranging is only 0.85% after the velocity of ultrasonic is corrected, which can meet the precision requirements of parking space judgement. And the interface of the mini program can display the states of all parking spaces accurately, which can greatly facilitate owners to grasp the real-time occupancy of internal parking spaces and optimize owners’ parking experience.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573632
SP  - 1136
EP  - 1141
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573632
KW  - MQTT protocol
KW  - Ultrasonic ranging
KW  - WeChat Mini Program
KW  - Zigbee protocol
ER  - 

TY  - CONF
TI  - New Cryptocurrencies Framework: Artificial Intelligence and Proof of Work
AU  - Zhang, Zhenrui
T3  - EITCE '22
AB  - People are getting familiar with cryptocurrencies because of the rapid development of cryptography, and bitcoin, a traditional decentralized digital currency, becomes famous. Thus, it is necessary to establish a digital currency allocation framework. Two existing methods both share the same goal of reaching blockchain consensus; however, the processes are different: The proof of Work system is completely related to tasks, but the Proof of Stake system is related to tokens. Hence, service providers are more than glad to apply the Proof of Work theory after distinguishing the difference between these two systems; this system which does not have high limitations is more fair and balanced. To enhance the traditional Proof of Work system, Artificial Intelligence can properly help and make the new framework works more efficiently. AI model can pre-assign a trustworthy score via the IP address, and then it can take the responsibility to generate the puzzle for the qualification. After the model verifies the output, the trustworthy score can increase or decrease based on the performance. Finally, it can establish a loop from the trustworthy score to puzzle difficulty, and then back to the trustworthy score. Therefore, an AI assistant can accurately monitor the entire transaction process and ensure validation to be environmentally friendly.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573631
SP  - 1131
EP  - 1135
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573631
KW  - Artificial Intelligence
KW  - Cryptocurrencies
KW  - Information Technology
KW  - Proof of stake
KW  - Proof of Work
ER  - 

TY  - CONF
TI  - Study on the amplitude distribution of W-band tree clutter based on measured data∗
AU  - Liu, Tianhao
AU  - Tang, Chuanbin
AU  - Yuan, Naichang
T3  - EITCE '22
AB  - This paper investigates the amplitude statistical characteristics of the measured tree clutter data of the W-band HH-polarized vehicle-mounted radar system, estimates the parameters of five amplitude statistical models including the K-distribution using the method of moments and the maximum likelihood estimation method, obtains the clutter amplitude fitting curves of various theoretical distributions.Then, the root mean square error of the fitted data and the Chi-Squared test value are obtained from the measured tree clutter data of the W-band radar, and the fitting effect of various statistical models is evaluated.The lognormal and K-distributions were concluded to be good fits for the amplitude distributions of the tree clutter data in the two cases measured in this paper, respectively, and the effects of experimental conditions such as W-band tree clutter signal-to-noise ratio and thermal noise on the K-distribution model parameters were further analyzed. This paper provides some reference for W-band tree clutter amplitude modeling.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573630
SP  - 1124
EP  - 1130
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573630
KW  - Amplitude statistical model
KW  - K-distribution
KW  - Tree clutter
KW  - W-band
ER  - 

TY  - CONF
TI  - Application Analysis of Web data Mining technology in Tourism Operation – A Case study of Chunan Qiandao Lake Scenic Area
AU  - Zang, Feifei
T3  - EITCE '22
AB  - With the continuous development of computer technology, online booking of tourism products has become a major mode of tourism consumption, which helps people eliminate information barriers and improve the efficiency of tourism. Web data mining technology is a very important application technology in tourism research. Through the travel notes and comments published by tourists, the group characteristics and travel preferences of tourists can be deeply explored and analyzed, which can provide a certain direction for the marketing of tourist destinations. This paper takes Chunan Qiandao Lake Scenic Area as an example. Based on the characteristics of communication, real-time and richness of Ctrip database, it uses computer Web data mining technology to collect the data published by tourists from January 2021 to June 2022, and analyzes the cognitive emotion of tourists through emotion analysis and content analysis.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573629
SP  - 1119
EP  - 1123
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573629
KW  - Computer technology
KW  - Online tourism platform
KW  - Web data mining
ER  - 

TY  - CONF
TI  - Research on An Encryption Method Combining RSA and Hill Cipher
AU  - Zhang, Zhiyuan
T3  - EITCE '22
AB  - As an important algorithm in cryptography, RSA (generated by Rivest, Shamir and Adelman) cipher system bases on Integer Factor Problem and has outstanding performance and security. Hence, it is widely used in data transportation, network communication and plenty of fields+. over roughly 40 years. On the other hand, based on knowledge of linear algebra, Hill Cipher is a type of classical and efficient encryption system firstly generated by Lester S. Hill in 1929. However, in practical applications, RSA has high computational complexity to encrypt data and spent a lot of time and computing resources, hence RSA is suitable to encrypt a small amount of messages. Because of the essence of Hill Cipher is linear transformation, the processes of encryption and decryption is simple and quick for modern electronic equipment. However, the system of Hill Cipher is apt to be broken for modern equipment as well. Now, there is a method called RSA-Signature-Hill, combing two algorithms and designing a safe encrypting scheme with high running speed. The algorithm combines the advantages of RSA and Hill Cipher and it is a typical scheme of improving efficiency of the entire encrypting system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573628
SP  - 1113
EP  - 1118
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573628
KW  - Cryptography
KW  - Digital signature
KW  - Hill Cipher
KW  - RSA
ER  - 

TY  - CONF
TI  - Analysis and diagnosis system for various industrial network protocols
AU  - Wang, Jian
AU  - Jin, Ni
T3  - EITCE '22
AB  - For a comprehensive and systematic analysis of the communication quality in the industrial field, it is important for manufacturing enterprises to study effective diagnosis and evaluation methods and develop software tool to meet the actual needs of industrial communication networks for high quality, rapid diagnosis and positioning of anomalies. By analyzing the characteristics of various industrial network protocols, this paper studies the measurement methods of the key indicators of the real-time performance of industrial communication networks and the methods of communication anomaly diagnosis, and on this basis, designs and implements the analysis and diagnosis system for various industrial network protocols.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573626
SP  - 1101
EP  - 1106
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573626
KW  - Abnormal diagnosis
KW  - Industrial network protocols
KW  - Protocols analysis
ER  - 

TY  - CONF
TI  - Research on Real-time Log Data Processing And Monitoring Scheme of Printing Equipment Based on Flink Framework
AU  - Li, Xiang
AU  - Yang, Shulin
AU  - Huang, Yongliang
AU  - Peng, Jiao
AU  - Zhou, Meiqi
T3  - EITCE '22
AB  - With the arrival of the era of big data, machinery, information sensors and other equipment in the printing industry generate large-scale equipment log data through the running time. Mining and analyzing the real-time log data of these equipment can extract the potential value for detecting, warning, optimizing machinery and equipment and improving the efficiency of enterprises. However, these massive data have the characteristics of large-scale data, complex and changeable types and strong real-time, which are difficult to collect, detect and use effectively. In view of the above problems, this paper uses the distributed computing framework Flink, takes the real-time data of information sensors as the premise, combines Kafka message queue for real-time data caching, and uses the distributed open-source monitoring system ZABBIX and visualization tool Grafana for monitoring and early warning, effectively solving the real-time processing and analysis of equipment data.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573625
SP  - 1096
EP  - 1100
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573625
KW  - Big Data
KW  - Data Processing
KW  - Flink
KW  - Kafka
ER  - 

TY  - CONF
TI  - Virtual Network Function Resource Requirements Prediction Model Based on CNN-GRU
AU  - Mao, Chunqiao
AU  - Yi, Peng
AU  - Li, Dan
AU  - Shen, Juan
T3  - EITCE '22
AB  - The rise of network function virtualization (NFV) technology makes the realization of network function change from hardware middleware to virtual network function (VNF). The existing methods allocate fixed resources to each VNF instance, but this resource allocation method will cause resource waste, which will affect the quality of service. The resource requirements prediction model solves the resource allocation problem by predicting the change of resource requirements. In this paper, deep learning is used to solve the regression prediction problem, and a VNF resource requirements prediction model based on convolutional neural network (CNN) and gated recurrent unit (GRU) is proposed. Compared with other single model and combined model, the experimental results show that the prediction error rate of the proposed model is reduced by 23.3%.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573627
SP  - 1107
EP  - 1112
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573627
KW  - Convolutional neural network
KW  - Gated circulation unit
KW  - Resource requirements prediction
KW  - Virtual network function
ER  - 

TY  - CONF
TI  - Data-Driven Online Academic Forecasting Development: – Current Hot Topics Analysis and Future Research Trends
AU  - Li, Yan
AU  - Liu, Lingyan
T3  - EITCE '22
AB  - Massive amounts of data have emerged in the age of intelligence, facilitating the mining of learners' performance in the classroom, and determining the occurrence of course success in combination with learner behavior data. The keyword co-occurrence, time zone and emergent graphs are plotted by Citespace to explore the research hotspots in the field of academic prediction, and it is found that the machine learning method for academic prediction is still the prevalent prediction method nowadays. The future development of academic prediction is promising in terms of data selection towards multimodality, deep mining towards multi-algorithm integration, integration of academic prediction into implicit data, and construction of hybrid course prediction models.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573623
SP  - 1089
EP  - 1095
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573623
KW  - Academic prediction
KW  - data-driven
KW  - interventions
KW  - learning behavior data
KW  - visual analytics
ER  - 

TY  - CONF
TI  - Simplifying Access Policy Descriptions with Level Relationships between Attributes
AU  - Ding, Xiangwu
AU  - Wang, Wangsheng
AU  - Feng, Jiale
T3  - EITCE '22
AB  - Blockchain combined with distributed file system for storing data usually encounters the challenges of sensitive data protection and secure access control, and ABE can achieve access control to confidential data. However, an excessive number of attributes in an access policy can lead to a very complex access policy description. To solve the problem of complex access policy descriptions, this paper proposes an access control scheme that utilizes the level relationship between attributes to simplify the access policy descriptions and combines blockchain to protect the security of encrypted data. This scheme encrypts data through CP-ABE. When formulating the access policy, the level relationship between the attributes involved in the access policy is analyzed and the attribute level structure is constructed to simplify the access policy descriptions. A smart contract is constructed to store the data hash and attribute ciphertext in the blockchain to avoid malicious tampering of data. Build a cross-regional first-time ID card claiming consortium blockchain through FISCO BCOS and build IPFS cluster. Through experiments, the feasibility and effectiveness of the scheme are verified.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573622
SP  - 1083
EP  - 1088
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573622
ER  - 

TY  - CONF
TI  - A Small Sticker is Enough: Spoofing Face Recognition Systems via Small Stickers
AU  - Yang, Jiahui
AU  - Cheng, Yushi
AU  - Ji, Xiaoyu
AU  - Xu, Wenyuan
T3  - EITCE '22
AB  - Face recognition systems are widely used in various security-crucial applications such as financial payments, device unlocking, and personnel access. With the rapid development of deep learning, face recognition systems nowadays are usually based on deep neural networks (DNNs). However, recent studies have shown that DNN-based face recognition algorithms are vulnerable to adversarial example attacks and thus may suffer from real-world threats. In this paper, we propose Adv-Sticker, a physical adversarial attack against face recognition systems leveraging a small printed sticker. By optimizing both the attack region and the adversarial sticker, we manage to reduce the size of the sticker to 3*3 cm and make it robust across various environmental conditions. Evaluation on four commonly-used face recognition algorithms (Facenet, Mobile-Facenet, Ir152, and Irse50) shows that Adv-Sticker can physically spoof face recognition systems with an overall attack success rate of 96.9% for the dodging attack, and 70.1% for the impersonation attack.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573621
SP  - 1075
EP  - 1082
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573621
KW  - Adversarial attacks
KW  - face recognition system
KW  - physical world attack
ER  - 

TY  - CONF
TI  - A generation method of dual adversarial camouflage
AU  - Wang, Yekui
AU  - Cao, Tieyong
AU  - Zheng, Yunfei
AU  - Wang, Yang
AU  - Chen, Lei
AU  - Fu, Bingyang
AU  - Han, Tong
T3  - EITCE '22
AB  - The object detection model based on DNNs can efficiently detect camouflaged objects that are difficult to find by human eyes, which puts forward new requirements for camouflaged performance. Researchers attack the object detection model by generating the adversarial camouflage, but the appearance of existing adversarial camouflage is abrupt and easily observed by human eyes. This paper proposes a dual adversarial camouflage generation method. The generation process is divided into two stages: in the first stage, seven kinds of corresponding camouflage textures are generated according to the scene features; In the second stage, the camouflage generated in the first stage is used as input to generate adversarial examples through GAN training. In the generation process, the texture difference between the adversarial examples and the input is constrained by perceptual loss. The attack performance and subjective and objective experiments verify that the dual adversarial camouflage can effectively attack both the object detection model and the human visual system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573620
SP  - 1069
EP  - 1074
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573620
KW  - Adversarial
KW  - Camouflage
KW  - GAN
KW  - Object Detection
ER  - 

TY  - CONF
TI  - Design and implementation of AIoT-based non-contact interaction system
AU  - Chen, Xuanchong
AU  - Chen, Shubin
AU  - Pan, Zhihong
AU  - Wang, Mengbo
T3  - EITCE '22
AB  - The non-contact interaction proposed in this paper is a new interaction method based on artificial intelligence Internet of Things (AIoT), which can effectively reduce the risk of epidemic transmission and reduce the number of trips back and forth during work in factory production lines, thus improving production efficiency. This paper presents a contactless interaction system based on computer vision and Internet of Things technology, with a visual programming platform and a front-end display platform for WeChat applets, effectively reducing the user's threshold. The system transmits the images acquired by ESP32-CAM to the cloud server, which extracts the gesture features of the images and identifies the corresponding gestures, then returns the commands corresponding to the gestures to ESP32, responsible for the master control. The ESP32 master accesses the database to obtain the corresponding actions according to the acquired commands and then executes the actions to realize a round of interaction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573619
SP  - 1063
EP  - 1068
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573619
KW  - Computer Vision
KW  - Internet of Things
KW  - Non-contact interaction
KW  - Wechat Mini Program
ER  - 

TY  - CONF
TI  - MLRaft: Improvement of Raft Based on Multi-log Synchronization Model
AU  - Zhang, Menghao
AU  - Xu, Lizhen
T3  - EITCE '22
AB  - Raft is currently the most popular distributed consensus protocol. Due to the single leader mechanism of Raft, the performance of the distributed system is degraded to that of a single-machine system. Aiming at this shortcoming, this paper proposes a MLRaft protocol based on the multi-log synchronization model. MLRaft divides a single log file in Raft into n log files. For each log file, a leader can be elected to maintain the consistency of the log file. Multiple leaders jointly undertake the requests of the distributed system, which improves the performance of the distributed system and makes the entire cluster more balanced. At the same time, this paper also proposes the priority election method and the dynamic transfer mechanism of leader to ensure the uniform distribution of multiple leaders in distributed nodes. Finally, this paper built a 3-node KV storage system, and tested three aspects of throughput, latency, and load balance. The experimental results show that MLRaft has better performance than Raft.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573617
SP  - 1050
EP  - 1055
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573617
KW  - consensus protocol
KW  - distributed system
KW  - multi leader
KW  - Raft
ER  - 

TY  - CONF
TI  - Survey on Security and Privacy in 5G V2X
AU  - Qian, Jianxin
AU  - Wang, Weilu
AU  - Yang, Xueming
AU  - Xu, Huibin
T3  - EITCE '22
AB  - 5G vehicle-to-everything (V2X) improves road safety and reduces communication delays between vehicles. However, due to ubiquitous network connectivity, it also presents serious trust, security and privacy issues toward vehicles, which may impede the performance of 5G V2X. Therefore, a comprehensive survey on security and privacy of 5G V2X communication is analyzed in this paper. Specifically, Firstly, the key issues and research status of 5G V2X security and privacy protection are discussed, and then the challenges in trust, security and privacy protection are expounded. Finally, the future research direction is discussed.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573618
SP  - 1056
EP  - 1062
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573618
ER  - 

TY  - CONF
TI  - Fruit and vegetable disease identification based on updating the activation function for the ConvNeXt model
AU  - Zhang, Yumin
AU  - Zhang, Yiru
AU  - Zhang, Yiheng
T3  - EITCE '22
AB  - Early identification of lesion types is important for fruit and vegetable treatment. Currently, fruit and vegetable disease classification is designed based on convolutional neural networks, and traditional convolutional neural networks perform poorly in fine-grained inter-class similarity tasks. In this paper, the ConvNeXt model, which has performed well in recent years, is chosen as the backbone network. The model is trained in its entirety with binary classification pre-learning followed by multi-classification recognition. The GELU activation function in ConvNeXt may suffer from neuron "necrosis", and the efficient activation function ERelu, which is more suitable for small inter-class variation, is chosen to replace it. The model was validated to be effective in the multi-classification task of fruit and vegetable diseases, and the overall accuracy of the model reached 89.20%, an improvement of 0.61% over the original model. In addition, the trained model is built on the service platform of WeChat applets in this paper to facilitate practical applications.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573616
SP  - 1045
EP  - 1049
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573616
KW  - Adam optimizer
KW  - ConvNeXt model
KW  - ERelu function
KW  - Fruit and vegetable disease identification
KW  - Multiple classification
ER  - 

TY  - CONF
TI  - Study on the Development Status and Prospect of Blockchain Technology in the Energy Field
AU  - Zhang, Xuesen
AU  - Guo, Qinglei
AU  - Pan, Xiukui
AU  - Bai, Desheng
AU  - Pan, Xiaoting
AU  - Lv, Jiayu
T3  - EITCE '22
AB  - The initial exploration of the application of blockchain technology in the energy field has yielded many results. In the context of energy interconnection, information exchange, data sharing and China's "2030 carbon peak, 2060 carbon neutral" strategy, blockchain technology will play a greater role in the energy field, and the consensus mechanism is the energy block The key technology that the chain urgently needs to break through. First, this paper analyzes the opportunities and challenges faced by energy development, discusses the value and technical support of blockchain technology in the energy field, summarizes the current application status, and then proposes an on-chip consensus algorithm based on VRF, each shard can be processed in parallel On-chip transactions, run the consensus mechanism to verify and package these transactions, improve transaction execution efficiency, and verify the effectiveness and speed of the consensus mechanism proposed in this paper through example simulations. Finally, the application goals and several policy recommendations of energy blockchain are put forward, in order to provide reference for future energy planning.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573612
SP  - 1021
EP  - 1027
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573612
ER  - 

TY  - CONF
TI  - Tourism intelligent recommendation system based on big data mining
AU  - Wan, Yuhang
T3  - EITCE '22
AB  - In today's information explosion, the types and quantity of tourism resources show a diversified trend. Therefore, tourism data continues to soar, and people are trapped in a situation of information overload. How to make intelligent recommendation of users' personalized travel needs has become a necessary research direction. In view of this situation, this paper continues the analytical data mining technology to study the scenic spot recommendation algorithm based on the association rules and collaborative filtering transactions. According to the complexity and particularity of the application of the tourism recommendation system, a tourism recommendation system framework and page layout are proposed, and the collaborative filtering algorithm is optimized to design a very distinctive intelligent recommendation system for the tourism industry.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573615
SP  - 1040
EP  - 1044
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573615
KW  - Data mining
KW  - Personalized requirements
KW  - Recommendation algorithm
KW  - Travel recommend-ation system
ER  - 

TY  - CONF
TI  - Traffic Prediction Based on Dynamic Temporal Graph Convolutional Networks
AU  - Wang, Tianyu
AU  - Li, Shaomei
AU  - Ji, Lixin
AU  - Zhang, Desheng
T3  - EITCE '22
AB  - Traffic prediction is an important component of intelligent transportation system. Since traffic data is typical spatiotemporal data with spatial attributes and temporal attributes, how to integrate the information of temporal and spatial dimension to model traffic data and make effective prediction is an important way to improve the prediction effect. In terms of temporal modeling, most of the existing research uses RNN-based methods, which cannot effectively capture long-term sequence features. In terms of spatial modeling, the GCN model is used to model the static spatial structure, which cannot accurately reflect the dynamic relationship between the nodes in the graph structure, and in the multi-layer structure, the prediction error of each layer is easy to spread through the gradient to generate error accumulation. In view of the above deficiencies, we propose a traffic prediction model based on dynamic temporal graph convolutional networks. For temporal attribute modeling, dilated causal convolution is used to construct temporal relationships, and the influence of global temporal features on the extraction of temporal relationships is considered. For modeling the spatial relationship, a dynamic adjacency matrix is obtained by learning the relationship between the nodes in the graph through the attention mechanism, so that the model can capture the dynamic relationship between the nodes. At the same time, a Translate module is added between each spatiotemporal layer to reduce the propagation of prediction errors between spatiotemporal modules of each layer. The experimental results show that on the METR-LA dataset and the XIAN-TAXI dataset, compared with other mainstream traffic prediction methods, Our model achieves better prediction performance.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573614
SP  - 1033
EP  - 1039
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573614
KW  - error propagation
KW  - graph convolutional networks
KW  - intelligent transportation
KW  - spatiotemporal data
KW  - traffic prediction
ER  - 

TY  - CONF
TI  - Research on YOLOV5 Electric Workers Wear Detection Model Based on Channel Pruning and Attention Fusion
AU  - Zhu, Chengcheng
AU  - Gong, Miao
AU  - Luo, Wang
AU  - Chen, Xinsheng
AU  - Zhou, Xiaofa
AU  - Shao, Yuying
AU  - Sun, Boyang
AU  - Hao, Xiaolong
T3  - EITCE '22
AB  - At present, target detection based on deep learning has become a trend. The large model in target detection has high detection accuracy, but with the huge network depth and width, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, Firstly, we build a feature extraction network based on yolov5, and the CBAM (Convolutional Block Attention Module) attention structure are used to improve the detection accuracy. Finally, we force iterative channel-level pruning to the detection network to guide model Sparse training of BatchNormalization (BN) layers. The results show that the proposed method can improve the accuracy of target detection, While keeping a high average detection accuracy, the calculation amount of the YOLOv5m model is reduced by 39%, the inference speed on GPU 40% increase, which meets the requirements of real-time detection.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573613
SP  - 1028
EP  - 1032
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573613
KW  - Attention mechanism
KW  - Channel pruning
KW  - Feature pyramid
KW  - Object detection
ER  - 

TY  - CONF
TI  - Preparation and Simulation of Quantum States of Matrices
AU  - Liu, Zhengyu
AU  - Liu, Xiaonan
AU  - Xie, Haoshan
AU  - Zhao, Chenyan
T3  - EITCE '22
AB  - A basic problem of quantum computing is how to effectively express classical data in quantum systems. This problem is called state preparation problem, and the process of preparing quantum states is called coding. In this paper, the classical data of matrix is transformed into quantum states in the form of amplitude coding and simulated. This paper first introduces the detailed process of matrix transformation into the linear combination of quantum ground state, then designs a quantum circuit model to realize amplitude coding according to the idea of binary tree model and quantum random walk algorithm, and finally simulates the three matrices on IBM quantum cloud platform, and analyzes and introduces many situations. The experimental results verify the feasibility of converting the matrix into quantum states by amplitude coding, analyze the causes of errors in the experimental process, and put forward the corresponding solutions. This paper introduces in detail the whole process of matrix conversion to quantum states and the construction of quantum circuits for simulation. Compared with the existing experiments, the quantum circuits constructed in this paper are shorter in length, less in number of quantum gates, and more versatile.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573611
SP  - 1013
EP  - 1020
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573611
ER  - 

TY  - CONF
TI  - Robust Fuzzy Between-cluster Separation Clustering Based on Shrunk Patterns
AU  - Gao, Yunlong
AU  - Li, Huidui
AU  - Cao, Chao
T3  - EITCE '22
AB  - The partition-based fuzzy c-means clustering (FCM) is widely used in machine learning and pattern recognition. FCM uses membership degrees to describe the fuzzy logic between samples and clusters. FCM obeys the prior model assumption of identical distribution and the distribution structure of the data affects the clustering results. However, noise and outliers will destroy the data structure and lead to poor clustering results. Aiming at these problems, a fuzzy between-cluster separation clustering algorithm based on shrunk patterns is proposed in this paper. Initially, the flexible manifold of original data is recovered using pattern shrinking. Compared with the original data space, the flexible manifold provides better denoising performance. Then fuzzy clustering is performed on the shrunk patterns. But the shrinking process overemphasizes the cohesion within clusters and tends to lose the information between clusters. Considering the between-cluster information, a fuzzy between-cluster measure is introduced to keep the separation of clusters in clustering the shrunk patterns, and two adaptive update rules are proposed to determine the parameters. Extensive experiments are carried out on several benchmark data sets. Experimental results show that the proposed algorithm is more robust and effective than FCM and its variants.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573608
SP  - 996
EP  - 1001
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573608
KW  - Flexible manifold
KW  - Fuzzy between-cluster separation
KW  - Fuzzy c-means clustering
KW  - Shrunk patterns
ER  - 

TY  - CONF
TI  - Research and design of machine room management system based on digital twin
AU  - Su, Zeyin
T3  - EITCE '22
AB  - Machine room management and operation work involves a number of contents. In order to maintain the normal operation of the machine room, the machine room administrator needs to patrol the machine room equipment frequently, this will lead to low work efficiency. And the quality of the administrator 's work is difficult to guarantee, Sometimes unable to find and solve problems in time. Based on the digital twin technology, this paper studies and designs the solution of the intelligent management system of the machine room. The system provides remote visualization and intelligent management. The machine room administrator remotely view the real-time situation of each equipment and see detailed historical operation data of each equipment through the machine room management website or the equipment model based on digital twin. The system can timely alarm for equipment failure and troubleshoot the equipment by analysis of historical data. The experiment shows that this system solution can improve the operation and maintenance quality and the work efficiency of the machine room administrator.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573610
SP  - 1007
EP  - 1012
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573610
KW  - Digital twin
KW  - Digital twin model
KW  - Intelligent management system
KW  - Machine room management
KW  - Visualization
ER  - 

TY  - CONF
TI  - Construction and Application of Oral and Maxillofacial Surgery Teaching Platform Based on Virtual Reality
AU  - Fan, Lina
AU  - Zhou, Xiaofen
AU  - Wang, Haoyu
AU  - Lin, Xuejin
AU  - Jiang, Xing
AU  - Xiao, Yang
T3  - EITCE '22
AB  - The traditional teaching method of oral and maxillofacial surgery is relatively simple, and the effect is not good in teaching practice. Based on virtual reality technology, this study constructs a virtual reality teaching platform for oral and maxillofacial surgery. It realizes 360° full-scene surgery video observation teaching, at the same time set up a virtual simulation environment for surgical operation exercises, multi-stage evaluation and analysis of learning results, enhance students' interest in learning, improve learning efficiency, play a positive and effective role in the improvement of their theoretical level, practical operation and thinking ability. This platform can meet the teaching needs of oral and maxillofacial surgery. It has a broad application prospect.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573609
SP  - 1002
EP  - 1006
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573609
KW  - Appraisal and evaluation
KW  - Oral and maxillofacial surgery
KW  - virtual reality
ER  - 

TY  - CONF
TI  - Performance of interleaved CA-Polar concatenated codes in VLC System
AU  - Liu, Wenkai
AU  - Chen, Wenhan
AU  - Wu, Menglong
T3  - EITCE '22
AB  - The emerging visible light communication (VLC) technology, which has the advantages of high communication speed, security, and indoor lighting, has become a research hot point of indoor wireless communication technology. As the only forward error correction (FEC) coding technology theoretically proven to achieve Shannon's capabilities, Polar codes are adopted to improve communication performance in VLC systems. This paper proposes concatenated CRC-aided polar codes (CA-Polar codes) schemes with interleaving techniques for VLC systems. The results show that it can effectively correct errors in VLC systems. Compared to the polar codes, the CA-Polar codes are more suitable as the inner code of the concatenated polar codes. The experimental results demonstrate that the RS-CA-Polar scheme has a more significant descent slope. Under BER (10-6), it requires 1.3dB less signal-to-noise ratio than BCH-CA-polar scheme.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573607
SP  - 991
EP  - 995
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573607
KW  - Concatenated polar code
KW  - CRC aided polar codes (CA-Polar codes)
KW  - Interleaved concatenation
KW  - VLC system
ER  - 

TY  - CONF
TI  - Design and Implementation of Content Management System Based on Cloud Service and Cloud Storage
AU  - Xue, Xianwei
AU  - Peng, Xiangyan
T3  - EITCE '22
AB  - With the increasing demand for information technology, CMS system has become an important application field since 2000. CMS system can bring value to enterprises. Through the management of enterprise information, it can improve the image of enterprises and the competitiveness of the same industry. A large number of excellent CMS systems at home and abroad have emerged in the past 20 years. In 2011, the National Institute of Standards and Technology of the United States put forward the concept of cloud computing, and then the vigorous development of cloud computing technology created new opportunities for enterprises and people interested in computer science. Cloud technology enables enterprises to be flexible and efficient, and can meet new and growing demands. The traditional single CMS system can no longer meet the needs of enterprises, and the combination with cloud computing technology is the new vitality. This paper proposes a dynamic expansion of cloud storage mode and a content management system to provide cloud services, which injects new vitality into the development of CMS system.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573606
SP  - 986
EP  - 990
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573606
KW  - cloud service
KW  - cloud storage
KW  - CMS
KW  - front and rear end separation
ER  - 

TY  - CONF
TI  - Human-eye-based display color consistency studies
AU  - Li, Zixuan
T3  - EITCE '22
AB  - Aiming at the problem that the display effect obtained by the same picture is displayed in different displays, this paper proposes to use the luminance halftone pattern matching program to carry out research, through the stimulation of different halftone modes by the human eye, affect the accuracy of gamma and visually estimate the colors of different halftone modes based on human eye vision, and provide color characteristics for practical applications in the LCD field. Experimental results show that the chromatic aberration does not exceed 6, and the visual parameters of the halftone pattern of the liquid crystal display can be better estimated.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573604
SP  - 973
EP  - 978
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573604
KW  - color space conversion
KW  - Displays
KW  - GOG model
ER  - 

TY  - CONF
TI  - Intrusion detection method based on constrained Boltzmann machine and delayed decision
AU  - Hong, Liang
AU  - Han, Bin
T3  - EITCE '22
AB  - In the face of massive dimensional and nonlinear data, traditional intrusion detection algorithms suffer from inadequate feature extraction and inaccurate classification models. To this end, an intrusion detection method based on restricted Boltzmann machine (RBM) and delayed decision is proposed. The RBM is selected to perform feature extraction on the dataset, delayed decision is performed in the classification decision stage for behaviors that cannot be immediately classified and grouped into the boundary domain, and the feature extraction process is further repeated for behaviors in this domain and different granularity feature spaces are constructed, and finally the classification results are output. The experimental results show that the accuracy of this method on the NSL-KDD dataset is 96.1%, which is 2.5 percentage points higher than the hierarchical intrusion detection system based on spatio-temporal features, which has the highest accuracy among the compared methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573605
SP  - 979
EP  - 985
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573605
ER  - 

TY  - CONF
TI  - Research on Multi-level Classification Models for Imbalanced Network Intrusion Dataset
AU  - Li, Xiaofeng
AU  - Li, Luqun
T3  - EITCE '22
AB  - This paper explores the use of machine learning related methods to solve intrusion detection and bandwidth prediction for computer networks. It put forward multi-level classification models which cleverly solved the problem of categories of samples imbalanced dataset classification, and proposed a LSTM model for network intrusions bandwidth consumption prediction. The related research work has provided a reference for further network intrusion detection and bandwidth prediction.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573603
SP  - 967
EP  - 972
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573603
KW  - Classification
KW  - Intrusion detection
KW  - LSTM
KW  - Machine Learning
KW  - Network
ER  - 

TY  - CONF
TI  - An Innovative Approach To Software Modularization Based On The Artificial Fish Swarm Algorithm
AU  - Pan, Jianqiang
AU  - Zhang, Cheng
AU  - Jia, Huihui
T3  - EITCE '22
AB  - It gets more and more expensive to maintain the complete software system as time goes on since the software architecture grows more complicated and the software code is more difficult to understand. This issue may be solved by taking the essential parts out of the source code and organizing them into the appropriate subsystems. Hierarchy-based partitioning is more complex and less successful in solving issues with huge software modules. In order to do this, this work suggests an innovative artificial fish swarm method as a meta-heuristic to solve the software module clustering problems (SMCPs) and presents a mutation operator and a local search strategy to handle the premature situation. The performance of the suggested method is assessed on a range of real-world software systems by comparison to the most recent meta-heuristic methods. The outcomes of the experiments demonstrate that the suggested methodology works better than those of other methods.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573428.3573602
SP  - 961
EP  - 966
PB  - Association for Computing Machinery
SN  - 978-1-4503-9714-8
UR  - https://doi.org/10.1145/3573428.3573602
KW  - Artificial fish swarm algorithm
KW  - Software module clustering
KW  - Software refactoring
ER  - 

TY  - JOUR
TI  - Efficient combination graph model based on conditional random field for online multi-object tracking
AU  - Zhang, Junwen
AU  - Zhang, Xiaolong
AU  - Zhu, Ziqi
AU  - Deng, Chunhua
T2  - Complex & Intelligent Systems
AB  - The joint detection and re-identification (re-ID) strategy shares network features of detection and re-ID, sacrifices the complex probability graph model pairing strategy, and consolidates a two-stage video tracking process into a one-stage, making the multi-object tracking process simple, fast, and accurate. In dense scenes, identified transfer is a major challenge for joint detection and re-ID. To this end, a probability graph model suitable for joint detection and re-ID is presented. The proposed model abandons the idea of matching candidate detections with historical detections in a classical probability graph, uses a scheme to calculate the degree of matching between candidate detections and historical trajectories, and transforms task of ID matching in re-ID process into an energy minimization problem of a conditional random field (CRF). However, the solution space of general CRF is complex and requires an iterative search. To achieve efficient online tracking, the original CRF problem is approximately transformed into a combination of multiple CRF problems with closed-form solutions. Moreover, the proposed algorithm has been applied in practical applications using an edge-cloud model that maintains the balance between performance and efficiency. Extensive experiments on the well-known MOTchallenge benchmark demonstrate the superior performance of the proposed algorithm.
DA  - 2023/06/01/
PY  - 2023
DO  - 10.1007/s40747-022-00922-3
DP  - Springer Link
VL  - 9
IS  - 3
SP  - 3261
EP  - 3276
J2  - Complex Intell. Syst.
LA  - en
SN  - 2198-6053
UR  - https://doi.org/10.1007/s40747-022-00922-3
Y2  - 2024/02/02/07:02:04
L4  - https://link.springer.com/content/pdf/10.1007%2Fs40747-022-00922-3.pdf
KW  - Conditional random field
KW  - Edge-cloud model
KW  - Identify transfer
KW  - MOTchallenge
KW  - The joint detection and re-ID
ER  - 

TY  - JOUR
TI  - Dense Crowds Detection and Surveillance with Drones using Density Maps
AU  - Javier Gonzalez-Trejo
AU  - Diego Alberto Mercado-Ravell
T2  - arXiv: Computer Vision and Pattern Recognition
AB  - Detecting and Counting people in a human crowd from a moving drone present challenging problems that arisefrom the constant changing in the image perspective andcamera angle. In this paper, we test two different state-of-the-art approaches, density map generation with VGG19 trainedwith the Bayes loss function and detect-then-count with FasterRCNN with ResNet50-FPN as backbone, in order to comparetheir precision for counting and detecting people in differentreal scenarios taken from a drone flight. We show empiricallythat both proposed methodologies perform especially well fordetecting and counting people in sparse crowds when thedrone is near the ground. Nevertheless, VGG19 provides betterprecision on both tasks while also being lighter than FasterRCNN. Furthermore, VGG19 outperforms Faster RCNN whendealing with dense crowds, proving to be more robust toscale variations and strong occlusions, being more suitable forsurveillance applications using drones
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICUAS48674.2020.9213886
J2  - arXiv: Computer Vision and Pattern Recognition
UR  - https://arxiv.org/pdf/2003.08766.pdf
ER  - 

TY  - JOUR
TI  - Tracking Pedestrian Heads in Dense Crowd
AU  - Ramana Sundararaman
AU  - Cedric De Almeida Braga
AU  - Eric Marchand
AU  - Julien Pettré
AB  - Tracking humans in crowded video sequences is an important constituent of visual scene understanding. Increasing crowd density challenges visibility of humans, limiting the scalability of existing pedestrian trackers to higher crowd densities. For that reason, we propose to revitalize head tracking with Crowd of Heads Dataset (CroHD), consisting of 9 sequences of 11,463 frames with over 2,276,838 heads and 5,230 tracks annotated in diverse scenes. For evaluation, we proposed a new metric, IDEucl, to measure an algorithm’s efficacy in preserving a unique identity for the longest stretch in image coordinate space, thus building a correspondence between pedestrian crowd motion and the performance of a tracking algorithm. Moreover, we also propose a new head detector, HeadHunter, which is designed for small head detection in crowded scenes. We extend HeadHunter with a Particle Filter and a color histogram based re-identification module for head tracking. To establish this as a strong baseline, we compare our tracker with existing state-of-the-art pedestrian trackers on CroHD and demonstrate superiority, especially in identity preserving tracking metrics. With a light-weight head detector and a tracker which is efficient at identity preservation, we believe our contributions will serve useful in advancement of pedestrian tracking in dense crowds. We make our dataset, code and models publicly available at https://project.inria.fr/crowdscience/project/dense-crowd-head-tracking/.
DA  - 2021///
PY  - 2021
DO  - 10.1109/CVPR46437.2021.00386
SP  - 3865
EP  - 3875
UR  - https://openaccess.thecvf.com/content/CVPR2021/papers/Sundararaman_Tracking_Pedestrian_Heads_in_Dense_Crowd_CVPR_2021_paper.pdf
ER  - 

TY  - JOUR
TI  - Dense Crowds Detection and Surveillance with Drones using Density Maps
AU  - Javier Gonzalez-Trejo
AU  - Diego Alberto Mercado-Ravell
AB  - Detecting and Counting people in a human crowd from a moving drone present challenging problems that arise from the constant changing in the image perspective and camera angle. In this paper, we test two different state-of-the-art approaches, density map generation with VGG19 trained with the Bayes loss function and detect-then-count with Faster R-CNN with ResNet50-FPN as backbone, in order to compare their accuracy at counting and detecting people in different scenarios taken from a drone in flight. We show empirically that both proposed methodologies perform well for detecting and counting people in sparse crowds when the drone is near the ground. Nevertheless, Bayes Loss provides better accuracy on both tasks while also being lighter than Faster R-CNN. Furthermore, Bayes Loss outperforms Faster R-CNN when dealing with dense crowds, proving to be more robust to scale variations and strong occlusions, hence being more suitable for surveillance applications using drones.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICUAS48674.2020.9213886
UR  - https://arxiv.org/pdf/2003.08766
ER  - 

TY  - JOUR
TI  - Locate, Size, and Count: Accurately Resolving People in Dense Crowds via Detection
AU  - Deepak Babu Sam
AU  - Skand Vishwanath Peri
AU  - Mukuntha Narayanan Sundararaman
AU  - Amogh Kamath
AU  - R. Venkatesh Babu
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - We introduce a detection framework for dense crowd counting and eliminate the need for the prevalent density regression paradigm. Typical counting models predict crowd density for an image as opposed to detecting every person. These regression methods, in general, fail to localize persons accurate enough for most applications other than counting. Hence, we adopt an architecture that locate s every person in the crowd, size s the spotted heads with bounding box and then count s them. Compared to normal object or face detectors, there exist certain unique challenges in designing such a detection system. Some of them are direct consequences of the huge diversity in dense crowds along with the need to predict boxes contiguously. We solve these issues and develop our LSC-CNN model, which can reliably detect heads of people across sparse to dense crowds. LSC-CNN employs a multi-column architecture with top-down feature modulation to better resolve persons and produce refined predictions at multiple resolutions. Interestingly, the proposed training regime requires only point head annotation, but can estimate approximate size information of heads. We show that LSC-CNN not only has superior localization than existing density regressors, but outperforms in counting as well. The code for our approach is available at https://github.com/val-iisc/lsc-cnn .
DA  - 2021///
PY  - 2021
DO  - 10.1109/TPAMI.2020.2974830
VL  - 43
IS  - 8
SP  - 2739
EP  - 2751
J2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
UR  - https://arxiv.org/pdf/1906.07538.pdf
ER  - 

TY  - JOUR
TI  - A Multi-scale Fusion Method for Dense Crowd Counting
AU  - Liwen Shen
AU  - Zhao Qiu
AU  - Ping Huang
AU  - Yu Jin
AU  - Chao Li
AU  - Jinye Cai
AB  - We propose a dense crowd detection network, called MSFNet, which can deal with highly dense crowd scenes, make accurate counting estimation and generate high-quality density maps by deep learning. The network is mainly composed of two main parts: the front-end network uses VGG-16 as the 2D feature extraction module, and the back-end network uses convolution networks with different sizes of convolution kernels instead of linking operations. The network is composed of convolution layers, which is an easy training model. We verify our network on two representative data sets (ShanghaiTech Data Set, UCF CC 50 Data Set), and the performance has been improved.In the first data set of ShanghaiTech, the root mean square error (MSE) decreased by 10%, and the mean absolute error (MAE) and root mean square error (MSE) of the second data set both decreased by about 6%.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-78615-1_27
SP  - 305
EP  - 314
ER  - 

TY  - JOUR
TI  - Tracking Pedestrian Heads in Dense Crowd
AU  - Ramana Sundararaman
AU  - Cedric De Almeida Braga
AU  - Eric Marchand
AU  - Julien Pettré
T2  - arXiv: Computer Vision and Pattern Recognition
AB  - Tracking humans in crowded video sequences is an important constituent of visual scene understanding. Increasing crowd density challenges visibility of humans, limiting the scalability of existing pedestrian trackers to higher crowd densities. For that reason, we propose to revitalize head tracking with Crowd of Heads Dataset (CroHD), consisting of 9 sequences of 11,463 frames with over 2,276,838 heads and 5,230 tracks annotated in diverse scenes. For evaluation, we proposed a new metric, IDEucl, to measure an algorithm's efficacy in preserving a unique identity for the longest stretch in image coordinate space, thus building a correspondence between pedestrian crowd motion and the performance of a tracking algorithm. Moreover, we also propose a new head detector, HeadHunter, which is designed for small head detection in crowded scenes. We extend HeadHunter with a Particle Filter and a color histogram based re-identification module for head tracking. To establish this as a strong baseline, we compare our tracker with existing state-of-the-art pedestrian trackers on CroHD and demonstrate superiority, especially in identity preserving tracking metrics. With a light-weight head detector and a tracker which is efficient at identity preservation, we believe our contributions will serve useful in advancement of pedestrian tracking in dense crowds.
DA  - 2021///
PY  - 2021
J2  - arXiv: Computer Vision and Pattern Recognition
UR  - http://arxiv.org/pdf/2103.13516.pdf
ER  - 

TY  - JOUR
TI  - On Formal Models of Interactions Between Detectors and Trackers in Crowd Analysis Tasks
AU  - Andrzej Sluzek
AU  - M. Sami Zitouni
AB  - In crowd analysis tasks (crowds of humans, cattle, birds, drones, etc.) the low-level vision tools are usually the same, i.e. detection and tracking of either individuals or groups. The required results, however, are more complicated (e.g. patterns of group splitting/merging, changes in group sizes and membership, group formation and disappearance, etc.). To complete such tasks, raw results of detection/tracking are converted into data associations representing crowd structure/evolution. Normally, those associations are deterministic and based on target labeling. However, performances of detectors/trackers are non-perfect, i.e. their outcomes are effectively non-deterministic. We discuss matrix-based mathematical models of interactions between detectors and trackers to represent such data associations non-deterministically. In particular, a methodology for reconstructing weak or missing associations by alternative sequences of matrix operations is proposed. This can provide more reliable label correspondences between selected moments/points of monitored scenes. Apart from mathematical details, the paper presents examples illustrating feasibility of the proposed approach.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-22025-8_2
SP  - 17
EP  - 29
ER  - 

TY  - JOUR
TI  - An Experimental Study for Tracking Crowd in Smart Cities
AU  - Kai Li
AU  - Chau Yuen
AU  - Salil S. Kanhere
AU  - Kun Hu
AU  - Wei Zhang
AU  - Fan Jiang
AU  - Xiang Liu
T2  - IEEE Systems Journal
AB  - Knowledge about people density and mobility patterns is the key element toward efficient urban development in smart cities. The main challenges in large-scale people tracking are the recognition of people density in a specific area and tracking the people flow path. To address these challenges, we present SenseFlow , a lightweight people tracking system for smart cities. SenseFlow utilizes off-the-shelf sensors that sniff probe requests periodically polled by user's smartphones in a passive manner. We demonstrate the feasibility of SenseFlow by building a proof-of-concept prototype and undertaking extensive evaluations in real-world settings. We deploy the system in one laboratory to study office hours of researchers, a crowded public area in a city to evaluate the scalability and performance “in the wild,” and four classrooms in the university to monitor the number of students. We also evaluate SenseFlow with varying walking speeds and different models of smartphones to investigate the people flow tracking performance.
DA  - 2019///
PY  - 2019
DO  - 10.1109/JSYST.2018.2880028
VL  - 13
IS  - 3
SP  - 2966
EP  - 2977
J2  - IEEE Systems Journal
UR  - https://www.cister.isep.ipp.pt/docs/an_experimental_study_for_tracking_crowd_in_smart_cities/1471/view.pdf
ER  - 

TY  - JOUR
TI  - Robust Identification of Dense or Sparse Crowd Based on Classifier Fusion
AU  - Saikat Dutta
AU  - Soumya Kanti Naskar
AU  - Sanjoy Kumar Saha
AU  - Bhabatosh Chanda
AB  - For a video surveillance system, crowd behavior analysis and crowd managing are important tasks. Along with the event in which crowd participates, its volume and density are also important in managing the crowd. Hence, characterizing the crowd as dense or sparse is an essential component of a crowd handling system. In this context, most of the existing methods try to estimate the headcount. Unlike those, the proposed method exploits the domain-knowledge based low-level features to classify the crowd image as dense or sparse. We present three simple systems working with three different feature sets. These are all free from the burden of background estimation. Experiments are carried on a dataset formed by taking the images from UCF-CC50 and SanghaiTech. Performance of all three feature sets are satisfactory, and Corner-Point based methodology provides the best result.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-030-34869-4_15
SP  - 131
EP  - 139
ER  - 

TY  - JOUR
TI  - CrowdTracing: Overcrowding Clustering and Detection System for Social Distancing
AU  - Eiman Kanjo
AU  - Dario Ortega Anderez
AU  - Amna Anwar
AU  - Ahmad Al Shami
AU  - James Williams
AB  - Maintaining social distancing in public spaces plays a pivotal role in decreasing COVID-19 contagion and viral spread. COVID-19 has required many countries around the world to close work places, schools and public spaces. This has prompted policy makers, venue managers and local authorities to investigate practical mitigation strategies using technology to exit the lockdown safely and enable the reopening of cities and public spaces. This paper introduces CrowdTracing, a dynamic overcrowding detection system that encourages social-distancing and triggers an alert to venue, city council or facility managers in a dynamic and privacy-preserving manner. CrowdTracing utilises ubiquitous WiFi probing and density-based clustering techniques which can be performed in real-time to identify commonly crowded areas and assist in the estimation of excess gatherings. The proposed system can also be used to enable discovery of where social distancing rules are not being followed, enabling a rapid response, controlling or slowing down the spread of the virus. A classification recall of 0.85 on an experiment with 1000 simulated scenarios were achieved. This indicates the CrowdTracing system proposed was able to identify 85 out 100 scenarios in which social distancing rules were not being followed.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ISC253183.2021.9562914
SP  - 1
EP  - 7
ER  - 

